\section{Hardware} 

\subsection{GPU} 

  Look at this article\footnote{\href{https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/}{https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/}} for a thorough high-level explanation of how GPUs work. Here are some notes I took for things to consider when buying or using a GPU, in order of importance. 
  \begin{enumerate}
    \item \textit{Memory}. Also known as the VRAM, or ``global memory.'' If you can't fit your model in your GPU, then forget about training it or doing inference. So this should be the first thing to consider. Plus, higher memory allows you to increase your batch size. 

    \item \textit{Memory Bandwidth}. This is the internal bandwidth from the GPU memory (VRAM) to the actual cores/registers. According to the article, this is pretty much the single biggest bottleneck for GPU speed. For diagnosis, if there is high memory access (wandb: time spent accessing memory) and low GPU utilization (wandb: GPU Utilization), then, there is a memory bottleneck, and you need higher throughput. 

    \item \textit{Tensor Cores}. The tensor cores is what gives Nvidia their edge over AMD. I've also done a quick test and epoch time is roughly linearly proportional to cuda/tensor cores, for smaller batch sizes. These allow you to do matrix multiplication fast in just 1 cycle. 
  \end{enumerate} 

  The next few are things that I might think are important. 
  \begin{enumerate}
    \item \textit{PCIe Bandwidth}. This is the bandwidth between the GPU and the CPU. This should be important (?) but is stated not to be in the article. More benchmarking will need to be done. 

    \item \textit{Cuda Cores}. This seems to also have strong correlation with performance and is the first metric that most users look at. 

    \item \textit{FLOPs}. FP32 performance is prob most important. This seems to be more of a ``summary statistic.''
  \end{enumerate}

  The next ones are properties that are not as important for me. 

  \begin{enumerate}
    \item \textit{NVLink. } Basically the speed between GPUs for multi GPU. 

    \item \textit{Architecture}. If you are looking at the basic stat of the GPU, then the architecture may be irrelevant, minus a few technical upgrades for nuanced situations. 

    \item \textit{Ray Tracing (RT) Cores}. These are only relevant for graphics rendering. Not relevant for training unless you're working with models that do graphics. 

    \item \textit{Power Consumption}. Usually these aren't on your machine, so doens't matter how much power you're using on the cluster. 

  \end{enumerate}

  I should prob do studies on this. Ideally, make a script that generates a report on this for every new machine. 

\subsection{Nvidia Architectures} 

  




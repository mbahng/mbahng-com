\section{Vector Spaces}

  \begin{definition}[Vector Space]
     A \textbf{vector space over a field $F$} consists of an abelian group $(V, +)$ and an operation called \textbf{scalar multiplication} 
     \begin{equation}
       \cdot: F \times V \rightarrow V
     \end{equation}
    such that for all $x, y\in V$ and $\lambda, \mu \in F$, we have 
    \begin{enumerate}
      \item $\lambda \cdot (x + y) = \lambda \cdot x + \lambda \cdot y$
      \item $(\lambda + \mu) \cdot x = \lambda \cdot x + \mu \cdot x$ 
      \item $(\lambda \mu) \cdot x = \lambda \cdot (\mu \cdot x )$, which equals $(\mu \lambda) \cdot x = \mu \cdot (\lambda \cdot x)$ since $F$ is commutative 
      \item $1 \cdot x = x$ , where $1$ is the unity of $F$
    \end{enumerate}
  \end{definition}

  \begin{definition}
    A \textbf{left R-module} $M$ consists of an abelian group $(M, +)$ and an operation called \textbf{scalar multiplication}
    \begin{equation}
      \cdot: R \times M \longrightarrow M
    \end{equation}
    such that for all $\lambda, \mu \in R$ and $x, y \in M$, we have 
    \begin{enumerate}
      \item $\lambda \cdot (x + y) = \lambda \cdot x + \lambda \cdot y$
      \item $(\lambda + \mu) \cdot x = \lambda \cdot x + \mu \cdot x$ 
      \item $(\lambda \mu) \cdot x = \lambda \cdot (\mu \cdot x )$, not necessarily equaling $(\mu \lambda) \cdot x = \mu \cdot (\lambda \cdot x)$
      \item $1 \cdot x = x$ , where $1$ is the unity of $R$
    \end{enumerate}
    Note that a left $R$-module is a vector space if and only if $R$ is a field.
  \end{definition}

  \begin{definition}
    A \textbf{right $R$-module} $M$ is defined analogously to a left $R$-module, except that the scalar multiplication operation is defined
    \begin{equation}
      \cdot: M \times R \longrightarrow M
    \end{equation}
  \end{definition}

  \begin{definition}
    Let $A$ be a vector space over a field $F$ equipped with an additional binary operation 
    \begin{equation}
      \times: A \times A \longrightarrow A
    \end{equation}
    $A$ is an \textbf{algebra over $F$} if the following identities hold for all $x, y, z \in A$ and all $\lambda, \mu \in F$. 
    \begin{enumerate}
      \item Right distributivity. $(x + y) \times z = x \times z + y \times z$ 
      \item Left distributivity. $z \times (x + y) = z \times x + z \times y$
      \item Compatibility with scalars. $(\lambda \cdot x ) \times (\mu \cdot y) = (\lambda \mu) \cdot (x \times y)$ 
    \end{enumerate}
  \end{definition}

  Note that vector multiplication of an algebra does not need to be commutative. 

  \begin{example}
    The set of all $n \times n$ matrices with matrix multiplication is a noncommutative, associative algebra. Similarly, the set of all linear endomorphisms of a vector space $V$ with composition is a noncommutative, associative algebra. 
  \end{example}

  \begin{example}
    $\mathbb{R}^3$ equipped with the cross product is an algebra, where the cross product is \textbf{anticommutative}, that is $x \times y = - y \times x$. $\times$ is also nonassociative, but rather satisfies an alternative identity called the \textbf{Jacobi Identity}. 
  \end{example}

  \begin{example}
    The set of all polynomials defined on an interval $[a,b]$ is an infinite-dimensional subalgebra of the set of all functions $f: \mathbb{R} \longrightarrow \mathbb{R}$ defined on $[a,b]$.
  \end{example}

  \begin{definition}
    Similar to division rings, a \textbf{division algebra} is an algebra where the operation of "division" defined as such: Given any $a \in A$, nonzero $b \in A$, there exists solutions to the equation
    \begin{equation}
      A = bx
    \end{equation}
    that are unique. If we wish, we can distinguish left and right division to be the solutions of $A = b x$ and $A = x b$. 
  \end{definition}

  \begin{definition}
    Here are examples of division algebras.
    \begin{enumerate}
      \item $\mathbb{R}$ is a $1$-dimensional algebra over itself. 
      \item $\mathbb{C}$ is a $2$-dimensional algebra over $\mathbb{R}$. 
      \item There exists no $3$-dimensional algebra. 
      \item Quaternions forms a $4$-dimensional algebra over $\mathbb{R}$. 
    \end{enumerate}
  \end{definition}

  \begin{theorem}[Eigenvector Conditions for Algebraic Closedness]
    A field $F$ is algebraically closed if and only if for each natural number $n$, every endomorphism of $F^n$ (that is, ever linear map from $F^n$ to itself) has at least one eigenvector. 
  \end{theorem}
  \begin{proof}
    An endomorphism of $F^n$ has an eigenvector if and only if its characteristic polynomial has some root. $(\rightarrow)$ So, when $F$ is algebraically closed, every characteristic polynomial, which is an element of $F[x]$, must have a root. $(\leftarrow)$ Assume that every characteristic polynomial has some root, and let $p \in F[x]$. Dividing the polynomial by a scalar doesn't change its roots, so we can assume $p$ to have leading coefficient $1$. If $p(x) = a_0 + a_1 x + ... + x^n$, then we can identify matrix 
    \begin{equation}
      A = \begin{pmatrix}
      0 & 0 & ... & 0 & -a_0 \\
      1 & 0 & ... & 0 & -a_1 \\
      0 & 1 & ... & 0 & -a_2 \\
      ... & ... & ... & ... & ... \\
      0 & 0 & ... & 1 & -a_{n-1}
      \end{pmatrix}
    \end{equation}
    such that the characteristic polynomial of $A$ is $p$. 
  \end{proof}


\subsection{Modules}

  Vector space but over a ring. 

\subsection{Algebras}

  Vector space with bilinear product.  

\subsection{The Algebra of Quaternions}

  \begin{definition}
    The \textbf{quaternions} form an algebra of $4$-dimensional vectors over $\mathbb{R}$, with elements of the form
    \begin{equation}
      (a, b, c, d) \equiv a + bi + cj + dk
    \end{equation}
    where $a$ is called the \textbf{scalar portion} and $bi + cj + dk$ is called the \textbf{vector/imaginary portion}. The algebra of quaternions is denoted $\mathbb{H}$, which stands for "Hamilton." $\mathbb{H}$ is a $4$-dimensional associative normed division algebra over $\mathbb{R}$. 
  \end{definition}

  From looking at the multiplication table, we can see that multiplication in $\mathbb{H}$ is not commutative. 
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    i & i & -1 & k & -j \\ 
    \hline
    j & j & -k & -1 & i \\ 
    \hline
    k & k & j & -i & -1 \\ 
    \hline
    \end{tabular}
  \end{center}
  Note the identity 
  \begin{equation}
    i^2 = j^2 = k^2 = -1
  \end{equation}
  The algebra of quaternions are in fact the first noncommutative algebra to be discovered! 

  \begin{theorem}
    $\mathbb{H}$ and $\mathbb{C}$ are the only finite-dimensional divisions rings containing $\mathbb{R}$ as a proper subring. 
  \end{theorem}

  \begin{definition}
    The \textbf{quaternion group}, denoted $Q_8$ is a nonabelian group of order $8$, isomorphic to a certain $8$-element subset in $\mathbb{H}$ under multiplication. It's group presentation is 
    \begin{equation}
      Q_8 = \big\langle \bar{e}, i, j, k \;|\; \bar{e}^2 = e, i^2 = j^2 = k^2 = ijk = \bar{e} \big\rangle
    \end{equation}
  \end{definition}

  Going back to the algebra, we can set $\{1, i, j, k\}$ as a basis and define addition and scalar multiplication component-wise, and multiplication (called the \textbf{Hamilton product}) with properties
  \begin{enumerate}
    \item The real quaternion $1$ is the identity element. 
    \item All real quaternions commute with quaternions: $a q = q a$ for all $a \in \mathbb{R}, q \in \mathbb{H}$. 
    \item Every quaternion has an inverse with respect to the Hamilton product. 
      \begin{equation}
        (a + bi + cj + dk)^{-1} = \frac{1}{a^2 + b^2 + c^2 + d^2} \big( a - bi - cj - dk\big)
      \end{equation}
  \end{enumerate}
  Note that property 3 allows $\mathbb{H}$ to be a division algebra. 

  \begin{theorem}[Scalar and Vector Components]
    Let the quaternion be divided up into a scalar and vector part with the bjective mapping $a + bi + cj + dk \mapsto \big(a, (b, c, d)\big)$. 
    \begin{equation}
      q = (r, v), r \in \mathbb{R}, v \in \mathbb{R}^3
    \end{equation}
    Then, the formulas for addition and multiplication are
    \begin{align*}
      q_1 + q_2 & = (r_1, v_1) + (r_2, v_2) = (r_1 + r_2, v_1 + v_2) \\
      q_1 \cdot q_2 & = (r_1, v_1) \cdot (r_2, v_2) = (r_1 r_2 - v_1 \cdot v_2, r_1 v_2 + r_2 v_1 + v_1 \times v_2)
    \end{align*}
    where the $\cdot$ and $\times$ on the right hand side represnts the dot product and cross product, respectively. 
  \end{theorem}

  \begin{definition}
    The conjugate of a quaternion $q = a + bi + cj + dk$ is defined 
    \begin{equation}
      \bar{q}, q^* \equiv a - bi - cj - dk
    \end{equation}
    It has properties
    \begin{enumerate}
      \item $q^{**} = q$
      \item $(q p)^* = p^* q^*$
    \end{enumerate}
    $q^*$ can also be expressed in terms of addition and multiplication. 
    \begin{equation}
      q^* = -\frac{1}{2} \big( q + iqi + jqj + kqk \big)
    \end{equation}
  \end{definition}

  \begin{definition}
    The \textbf{norm} of $q$ is defined
    \begin{equation}
      ||q|| \equiv \sqrt{q^* q} = \sqrt{q q^*} = \sqrt{a^2 + b^2 + c^2 + d^2}
    \end{equation}
    with properties
    \begin{enumerate}
      \item Scaling factor. $||\alpha q|| = |\alpha| ||q||$
      \item Multiplicative. $||p q|| = ||p|| ||q||$
    \end{enumerate}
  \end{definition}

  The norm allows us to define a metric 
  \begin{equation}
    d(p, q) \equiv ||p - q||
  \end{equation}
  This makes $\mathbb{H}$ a metric space, with addition and multiplication continuous on the metric topology. 

  \begin{definition}
    The \textbf{unit quaternion} is defined to be
    \begin{equation}
      U_q = \frac{q}{||q||}
    \end{equation}
  \end{definition}

  \begin{corollary}
    Every quaternion has a polar decomposition
    \begin{equation}
      q = U_q \cdot ||q||
    \end{equation}
    With this, we can redefine the inverse as
    \begin{equation}
      q^{-1} = \frac{q^*}{||q||^2}
    \end{equation}
  \end{corollary}

\subsubsection{Matrix Representations of Quaternions}

  We can represent $q$ with $2 \times 2$ matrices over $\mathbb{C}$ or $4\times 4 $ matrices over $\mathbb{R}$. 

  \begin{theorem}
    The following representation is an injective homomorphism $\rho: \mathbb{H} \longrightarrow \GL(2, \mathbb{C})$. 
    \begin{equation}
      \rho: a + bi + cj + dk \mapsto \begin{pmatrix}
      a+bi & c+ di \\ -c + di & a - bi
      \end{pmatrix}
    \end{equation}
    It has properties
    \begin{enumerate}
      \item Constraining any two of $b, c, d$ to $0$ produces a representation of the complex numbers. When $c = d = 0$, this is called the \textbf{diagonal representation}. 
      \begin{align*}
        \begin{pmatrix}
        a+bi & 0 \\ 0 & a-bi
        \end{pmatrix},  \begin{pmatrix}
        a & c \\ -c & a
        \end{pmatrix},  \begin{pmatrix}
        a & di \\ di & a
        \end{pmatrix}
      \end{align*}
      \item The norm of a quaternion is the square root of the determinant of its corresponding matrix representation. 
        \begin{equation}
          ||q|| = \sqrt{\det \begin{pmatrix}
          a+bi & c+di \\ -c+di & a-bi
          \end{pmatrix}} = \sqrt{(a^2 + b^2) + (c^2 + d^2)}
        \end{equation}
      \item The conjugate of a quaternion corresponds to the conjugate (Hermitian) transpose of its matrix representation. 
        \begin{equation}
          \rho(q^*) = \rho(q)^H \iff a-bi-cj-dk \mapsto \begin{pmatrix}
          a-bi & -c-di \\ c-di & a+bi
          \end{pmatrix}
        \end{equation}
      \item The restriction of this representation to only unit quaternions leads to an isomorphism between the subgroup of unit quaternions and their corresponding image in SU$(2)$. Topologically, the unit quaternions is the $3$-sphere, so the underlying space SU$(2)$ is also a $3$-sphere. More specifically, 
        \begin{equation}
          \frac{\text{SU}(2)}{2} \simeq \text{SO}(3)
        \end{equation}
    \end{enumerate}
  \end{theorem}

  \begin{theorem}
  The following representation of $\mathbb{H}$ is an injective homomorphism $\rho: \mathbb{H} \longrightarrow \GL(4, \mathbb{R})$. 
  \begin{equation}
    \rho: a+bi+cj+dk \mapsto \begin{pmatrix}
    a&-b&-c&-d \\
    b&a&-d&c\\
    c&d&a&-b\\
    d&-c&b&a
    \end{pmatrix}
  \end{equation}
  or also as
  \begin{equation}
    a \begin{pmatrix}
    1 &0 &0 &0 \\
    0& 1&0&0\\
    0&0&1&0\\
    0&0&0&1
    \end{pmatrix} + b \begin{pmatrix}
    0&-1&0&0\\1&0&0&0\\0&0&0&-1\\0&0&1&0
    \end{pmatrix} + c\begin{pmatrix}
    0&0&-1&0\\0&0&0&1\\1&0&0&0\\0&-1&0&0
    \end{pmatrix} + d \begin{pmatrix}
    0&0&0&-1\\0&0&-1&0\\0&1&0&0\\1&0&0&0
    \end{pmatrix}
  \end{equation}
  It has properties
  \begin{enumerate}
    \item $\rho(q^*) = \rho(q)^T$
    \item The fourth power of the norm is the determinant of the matrix 
      \begin{equation}
        ||q||^4 = \det\big( \rho (q)\big)
      \end{equation}
    \item Similarly, with the $2\times 2$ representation, complex number representations can be produced by restricting $2$ of $b, c, d$ to $0$. 
  \end{enumerate}
  \end{theorem}

  Note that this representation in $\GL(4, \mathbb{R})$ is not unique. There are in fact 48 distinct representation of this form where one of the component matrices represents the scalar part and the other 3 are skew symmetric. 

\subsubsection{Square Roots of -1}

  In $\mathbb{C}$, there are two numbers, $i$ and $-i$, whose square is $-1$. However, in $\mathbb{H}$, infinitely many square roots of $-1$ exist, forming the unit sphere in $\mathbb{R}^3$. To see this, let $q = a+bi+cj+dk$ be a quaternion, and assume that its square is $-1$. Then this implies that
  \begin{equation}
    a^2 - b^2 -c^2 -d^2 = -1, 2ab = 2ac = 2ad = 0
  \end{equation}
  To satisfy the second equation, either $a=0$ or $b=c=d=0$. The latter is impossible since then $q$ would be real. Therefore, 
  \begin{equation}
    b^2 + c^2 + d^2 = 1
  \end{equation}
  which forms the unit sphere in $\mathbb{R}^3$. 

\subsection{Tensor Algebras}

  Remember that an algebra is (loosely) a vector space $V$ with a multiplication operation
  \begin{equation}
    \times: V \times V \longrightarrow V
  \end{equation}

  \begin{definition}
    The \textbf{tensor algebra} of vector space $V$ over field $\mathbb{F}$ is 
    \begin{align*}
      T(V) \equiv \bigoplus_{n = 0}^{\infty} V^{\otimes n} & = V^{\otimes 0} \oplus V^{\otimes 1} \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus ... \\
      & = \mathbb{F} \oplus V \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus V^{\otimes 4} \oplus ...
    \end{align*}
    with elements being infinite-tuples
    \begin{equation}
      (a, B^\mu, C^{\nu \gamma}, D^{\alpha \beta \epsilon}, ...)
    \end{equation}
    The addition operation is defined component-wise, and the multiplication operation is the tensor product 
    \begin{equation}
      \otimes: T(V) \times T(V) \longrightarrow T(V)
    \end{equation}
    and the identity element is
    \begin{equation}
      I = (1, 0, 0, ...)
    \end{equation}
    Linearity can be easily shown. 
  \end{definition}

  The tensor algebra is often used to "add" differently ranked tensors together. But in order to do this rigorously, we must define the canonical injections
  \begin{equation}
    i_j: V^{\otimes j} \longrightarrow T(V), \; i_j (T^{\kappa_1, ..., \kappa j}) = (0, ...,0, T^{\kappa_1, ..., \kappa j}, 0, ..., 0) 
  \end{equation}
  shown in the diagram
  \[\begin{tikzcd}
      & & T(V) & & \\
      \mathbb{F} \arrow{urr}{i_0} & V \arrow{ur}{i_1} & V^{\otimes 2} \arrow{u}{i_2} & V^{\otimes 3} \arrow{ul}{i_3} & ... \arrow{ull}
  \end{tikzcd}\]
  Therefore, with these $i_j$'s, we can implicitly define the addition of arbitrary tensors $A \in V^{\otimes n}$ and $B \in V^{\otimes m}$ as 
  \begin{equation}
    A + B \equiv i_n (A) + i_m (B) \in T(V)
  \end{equation}
  along with multiplication of tensors as
  \begin{equation}
    A \otimes B \equiv i_n(A) \otimes i_m(B) \equiv i_{n+m} (A \otimes B)
  \end{equation}
  We can also redefine the tensor product operation between two spaces to be an operation within $T(V)$ itself. 
  \begin{equation}
    i_i(V^{\otimes i}) \otimes i_j( V^{\otimes j}) = i_{i+j} (V^{\otimes (i+j)})
  \end{equation}
  We can now proceed to define Exterior and Symmetric algebras as quotient algebras. 

  \begin{definition}
    The \textbf{exterior algebra} $\Lambda(V)$ of a vector space $V$ over field $\mathbb{F}$ is the quotient algebra of the tensor algebra $T(V)$
    \begin{equation}
      \Lambda(V) \equiv \frac{T(V)}{I}
    \end{equation}
    where $I$ is the two-sided ideal generated by all elements of the form $x \otimes x$ for $x \in V$ (i.e. all tensors that can be expressed as the tensor product of a vector in V by itself). 

    The \textbf{exterior product} $\wedge$ of two elements of $\Lambda(V)$ is the product induced by the tensor product $\otimes$ of $T(V)$. That is, if 
    \begin{equation}
      \pi: T(V) \longrightarrow \Lambda(V)
    \end{equation}
    is the canonical projection/surjection and $a, b \in \Lambda(V)$ ,then there are $\alpha, \beta \in T(V)$ such that $a = \pi(\alpha), b = \pi(\beta)$, and 
    \begin{equation}
      a \wedge b = \pi(\alpha \otimes \beta)
    \end{equation}
    We can define this quotient space with the equivalence class
    \begin{equation}
      x \otimes y = - y \otimes x \pmod{I}
    \end{equation}
  \end{definition}

  \begin{definition}
    The \textbf{symmetric algebra} Sym$(V)$ of a vector space $V$ over a field $\mathbb{F}$ is the quotient algebra of the tensor algebra $T(V)$ 
    \begin{equation}
      \Lambda(V) \equiv \frac{T(V)}{J}
    \end{equation}
    where $J$ is the two-sided ideal generated by all elements in the form 
    \begin{equation}
      v \otimes w - w \otimes v
    \end{equation}
    (i.e. commutators of all possible pairs of vectors). 
  \end{definition}

\subsection{Exercises}

\section{Convergence} 

  \begin{definition}[Convergence in Measure]
    \textbf{$f_n \to f$ in measure} if for every $\eta > 0$, 
    \begin{equation}
      \lim_{n \to \infty} m \big( \{x \mid |f_n (x) - f(x)|  > \eta \}\big) = 0
    \end{equation}
  \end{definition}

  So we have 3 types of convergence: uniform convergence, a.e. convergence, and now convergence in measure. Now we want to relate this convergence to the ones we already have. 

  \begin{theorem}
    Suppose $E$ is measurable, $m(E) < +\infty$, and $f_n \to f$ a.e. in $E$ (assume $f_n$ all measurable). Then , $f_n \to f$ in measure. 
  \end{theorem}
  \begin{proof}
    Observe that if $f_n \to f$ uniformly, then it converges in measure, because given some $\eta > 0$, $\exists N$ s.t. 
    \begin{equation}
      \{ x \mid |f_n (x) - f(x) | > \eta \} = \emptyset
    \end{equation}
    by definition. It doesn't go to $0$; it is $0$. You can guess why we started with this, because now we can directly use Egorov's theorem. Fix any $\epsilon > 0$. Find $E_0 \subset E$ s.t. $m (E \setminus E_0) < \epsilon$, and $f_n \to f$ uniformly on $E_0$. It follows that for all $\eta > 0$, 
    \begin{equation}
      m(\{x \mid |f_n (x) - f(x)| > \eta\}) \leq \epsilon 
    \end{equation}
    for all $n \geq N(\eta)$. Since this is true for every $\epsilon > 0$, so this implies
    \begin{equation}
      \lim_{n \to \infty} m(\{ x \mid |f_n (x) - f(x)| > \eta\}) = 0
    \end{equation} 
    for every $\eta > 0$. 
  \end{proof}

  A few remarks. First, if the measure of $E$ is infinite, this need not be true. Consider $f_n (x) = \chi_{[n, n+1]} (x)$. Then, this converges to $0$ pointwise, but it does not converge to $0$ in measure. There is always a measure $1$ set where $f$ is $1$. Where the proof breaks down is in Egorov's theorem, since it does not work when $m(E) = +\infty$. 

  The second remark is that the converse is not true. Consider $[0, 1]$ and the sequence of functions 
  \begin{equation}
    \chi_{[0, 1/2]}, \chi_{[1/2, 1]}, \chi_{[0, 1/4]}, \chi_{[1/4, 1/2]}, \chi_{[1/2, 3/4]}, \ldots 
  \end{equation}
  Then $f_n \to 0$ in measure since the size shrinks at the rate of $2^{-n}$. However, it doesn't converge a.e. since for any point $x \in [0, 1]$, the function will be $1$ eventually as we hit the subinterval containing $x$, like ``waves.'' So $f_n(x)$ diverges for all $x \in [0, 1]$. So indeed, convergence in measure is the weakest type of convergence. 

  Here is a sort-of converse. 

  \begin{theorem}[Riesz]
    Suppose $f_n \to f$ in measure. Then, there exists a subsequence $f_{n_k} \to f$ a.e. 
  \end{theorem}
  \begin{proof}
    For every $k$, find $n_k$ s.t. for all $n \geq n_k$,
    \begin{equation}
      m(\underbrace{\{x \mid |f_n(x) - f(x)| > 1/k\}}_{E_k}) < 2^{-k}
    \end{equation}
    Then, 
    \begin{equation}
      \sum_{k=1}^\infty m(E_k) < +\infty
    \end{equation}
    By Borel-Cantelli, the set of all $x$'s that are in infinitely many $E_k$ have measure $0$. So, almost everywhere, $x$ is only in a finite number of $E_k$. So for a.e., $x$, there exists $N(x)$ s.t. $x \not\in E_k$ for all $k \geq N(x)$. This means 
    \begin{equation}
      | f_{n_k} (x) - f(x)| < 1/k 
    \end{equation}
    for all $k \geq N(x)$. Therefore, $f_{n_k} (x) \to f(x)$ for a.e. $x$. 
  \end{proof}

  In the example above, we can just skip the functions that evaluate $x$ to $1$.  

  Practically, proving convergence in measure is still pretty good since we can pass in a subsequence that converges a.e. Here is a corollary. 

  \begin{corollary}
    Let $f_n \geq 0$, integrable on $E$. Then, 
    \begin{equation}
      \lim_{n \to +\infty} \int_E f_n \,dx = 0  \iff f_n \to 0 \text{ in measure}
    \end{equation}
    $f_n$ are tight and uniformly integrable. 
  \end{corollary}
  \begin{proof}
    We prove bidirectionally. 
    \begin{enumerate}
      \item $(\rightarrow)$. Tight, uniformly integrable is true be definition. Also, $f_n \to 0$ in measure by Chebyshev. 
        \begin{equation}
          m(\{x \mid f_n (x) > \eta\}) \leq \frac{1}{\eta} \int_E f_n \,dx 
        \end{equation}
      \item $(\leftarrow)$ For the opposite, we use the previous theorem. Find $f_{n_k}$ s.t. that it converges to $0$ a.e., and then use Vitali's convergence theorem. 
    \end{enumerate}
  \end{proof}

  In general, if $f_n \to 0$ in measure, it doesn't mean that the integral will go to $0$ since you can take larger and larger bumps. So we need extra assumptions. 

  \begin{lemma} 
    Suppose $f$ is bounded, and there exists measurable sequences of functions $\phi_n, \psi_n$ s.t. 
    \begin{equation}
      \psi_n (x) \leq f(x) \leq \psi_n(x) \quad \forall x \in E
    \end{equation}
    and 
    \begin{equation}
      \lim_{n \to +\infty} \int_E (\psi_n - \phi_n) = 0
    \end{equation}
    Then, there exists $\Tilde{phi}_n \to f$ and $\Tilde{psi}_n \to f$ a.e. 
  \end{lemma}
  \begin{proof}
    Define 
    \begin{equation}
      \Tilde{\phi}_n (x) = \max\{\phi_1 (x) , \ldots, \phi_n (x) \}, \quad \Tilde{\psi}_n (x) = \min\{\psi_1 (x) , \ldots, \psi_n (x) \}
    \end{equation}
    We still have $\Tilde{\phi}_n (x) \leq f(x) \leq \Tilde{\phi}_n (x)$ for all $n$ and for all $x$. Also, $\Tilde{\phi}_n (x)$ is increasing, $\Tilde{\psi}_n (x)$ is decreasing. Now define 
    \begin{equation}
      \phi^\ast (x) \coloneqq \lim_{n \to \infty} \Tilde{\phi}_n (x), \qquad \psi^\ast (x) \coloneqq \lim_{n \to \infty} \Tilde{\psi}_n (x)
    \end{equation}
    Observe that 
    \begin{equation}
      \int (\Tilde{\psi}_n - \Tilde{\phi}_n) \leq \int (\psi_n - \phi_n) \implies \int (\Tilde{\psi}_n - \Tilde{\phi}_n) \to 0 \text{ as } n \to \infty 
    \end{equation}
    Also, 
    \begin{equation}
      \int (\underbrace{\psi^\ast (x) - \phi^\ast(x)}_{\geq 0}) \,dx \leq \int (\Tilde{\psi}^\ast - \Tilde{\phi}^\ast) 
    \end{equation}
    for all $n$. Therefore, 
    \begin{equation}
      \int (\psi^\ast (x) - \phi^\ast (x)) = 0 \implies \psi^\ast (x) = \phi^\ast (x) \text{ a.e.}
    \end{equation}
    And so $f(x)$, which is sandwiched between $\psi^\ast$ and $\phi^\ast$, must be equal a.e. We didn't assume that $f$ was measurable, but these $\psi_n, \phi_n$ is measurable by assumption. 
  \end{proof}

  Now, we can prove this master theorem. 

  \begin{theorem}[Characterization of Lebesgue Integrability]
    Let $f$ be bounded on measurable set $E$ of finite measure. Then $f$ is Lebesgue integrable iff $f$ is measurable. 
  \end{theorem}
  \begin{proof}
    The backward implication is true in general. We want to show that $f$ is measurable. Recall that for bounded functions, we defined Lebesgue integrals with $\underline{L}f$ and $\overline{L}f$. Therefore, we can find simple $\phi_n, \psi_n$ s.t. $\phi_n \leq f \leq \psi_n$, and $\int \psi_n - \int \phi_n \leq 1/n$. Now we are exactly in the setting of the lemma, and so by the lemma, we can find measurable $\Tilde{\psi}_n (x) \to f$ a.e. (in fact, $\Tilde{\psi}$ will be simple). Since the limit of measurable functions is measurable, $f$ is measurable.
  \end{proof}

  This is a very reasonable criterion, and you can't really hope for more then Lebesgue measurability. This following theorem on Riemmann integrability is much more restrictive, while for above, measurable functions can be very wild. 

  \begin{theorem}[Characterization of Riemann Integrability]
    $f$ is Riemann integrable on $[a, b]$ if the set of its discontinuities has measure $0$. 
  \end{theorem}
  \begin{proof}
    Not stated. In book. 
  \end{proof}


  Oct 8. Now we will build the theory of differentiation on monotone functions. 

  \begin{definition}[]
    Given a set $E$, a collection $\mathcal{F}$ \textbf{covers $E$ in Vitali sense} if $\forall x \in E, \forall \epsilon > 0$, there exists $I \in \mathcal{F}$ s.t. $x \in I$, $\ell(I) < \epsilon$. 
  \end{definition}

  Note that we don't assume that $E$ is measurable. It is easy to see that a Vitali set can be uncountable (all subintervals of $[0, 1]$) and even countable (all subintervals with rational endpoints). Nevertheless, we can still select a finite set of intervals that almost covers $E$. 

  \begin{lemma}[Vitali Covering Lemma]
    Suppose $m^\ast (E) < +\infty$ and $\mathcal{F}$ covers $E$ in Vitali sense. Then, $\forall \epsilon > 0$, $\exists$ a disjoint finite collection $I_1, I_2, \ldots, I_n$ of intervals from $\mathcal{F}$ s.t. 
    \begin{equation}
      m^\ast \bigg( E \setminus \bigcup_{k=1}^n I_k \bigg) < \epsilon
    \end{equation}
  \end{lemma}
  \begin{proof}
    Since $m^\ast (E) < +\infty$, by definition $\exists$ open $O$ s.t. $E \subset O$, $m(O) < +\infty$. WLOG we can assume that all intervals in $\mathcal{F}$ lie in $O$.\footnote{We can just discard any interval that it not Vitali in $O$ and keep only those intervals in $O$ such that it would still be in a Vitali cover. Indeed, we can discard all $I \subset \mathcal{F}$ s.t. $I \not\subset O$. Given $x \in E, x \in O$, so $d(x, O^c) > 0$ for all $\epsilon > 0$, $\exists I \in F$ s.t. $\ell(I) < \epsilon$, $x \in I, I \subset O$ (just take $\ell(I), < \min(\epsilon, d(x, O^c))$). So even remaining intervals cover $E$ in Vitali sense. }

    Note two things. 
    \begin{enumerate}
      \item If $I_1, I_2, \ldots, I_n$ are disjoint and belong to $O$, then $\sum_{k=1}^n \ell(I_k) < +\infty$ since it is less than the measure of $O$ which is finite. 

      \item Second, if we have finite collection $\{I_k\}_{k=1}^n \in \mathcal{F}$ , define 
      \begin{equation}
        \mathcal{F}_n \coloneqq \{I \in \mathcal{F} \mid I \cap \bigcup_{k=1}^n I_k = \emptyset \}
      \end{equation}
      Then every $x \in E \setminus \bigcup_{k=1}^n I_k$ lies in some $I \in \mathcal{F}_n$. 
    \end{enumerate}

    The ideal is to define $I_1, \ldots, I_n \in \mathcal{F}$ s.t. they are disjiont and 
    \begin{equation}
      E \setminus \bigcup_{k=1}^n I_k \subset \bigcup_{k=n+1}^\infty 5 I_k \quad \forall n \label{inclusion}
    \end{equation}
    where $5I$ means that we keep the center of the interval fixed and scale it up by 5 times. If we do that, then $\forall \epsilon > 0$, find $n$ s.t. $\sum_{k=n+1}^\infty \ell(I_k) < \epsilon / 5$. Take $I_1, \ldots, I_n$ as our intervals 
    \begin{equation}
      m^\ast \bigg( E \setminus \bigcup_{k=1}^n I_k \bigg) \leq \sum_{k=n+1}^\infty \ell(5 I_k) < \epsilon
    \end{equation}
    So it remains to select these intervals $I_1, \ldots, I_n$. We will do this inductively. 
    \begin{enumerate}
      \item $I_1$ be any interval in $\mathcal{F}$ s.t. 
      \begin{equation}
        \ell(I_1) \geq \frac{1}{2} \sup_{I \in \mathcal{F}} \ell(I) 
      \end{equation}

      \item Once $I_1, \ldots, I_n$ have been selected, we select $I_{n+1}$ from $\mathcal{F}_n$ s.t. 
      \begin{equation}
        \ell(I_{n+1}) \geq \frac{1}{2} \sup_{I \in \mathcal{F}_n} \ell(I)
      \end{equation}
      So these intervals are clearly disjoint from the ones that we have selected earlier. So it remains to show \ref{inclusion}. Suppose $x \in E \setminus \cup_{k=1}^n I_k$. Then, $\exists I \in \mathcal{F}_n$ s.t. $x \in I$. 
    \end{enumerate}
    Suppose $I \in \mathcal{F}_m$ for all $m \geq n$. This is impossible since by construction, $\ell(I_m) \geq \frac{1}{2} \ell(I)$. This contradicts $\sum \ell(I_m)$ is finite. Therefore, $\exists m$ s.t. $I \in \mathcal{F}_{m-1}$ but $I \not\in \mathcal{F}_m$. This implies that $I \cap I_m \neq \empty$ (while the intersection with the previous ones were empty). But then, $I \subset 5 I_m$, since $\ell(I_m) \geq \frac{1}{2} \ell(I)$.\footnote{The $5$ is needed since we have $1/2$. So we are taking the midpoint $3/4$ of the interval $[1/2, 1] \subset [0, 1]$, which should be blown up by $5$. } 
  \end{proof}

  This may be a heavy proof, but this lemma seems to be very convenient. 

  \begin{definition}[Derivative]
    Given any $f$ and $x$ in the interior of its domain, we can define the \textbf{upper and lower derivative} as
    \begin{equation}
      \overline{D} f(x) \coloneqq \lim_{h \to 0} \sup_{0 < |t| < h} \frac{f(x + t) - f(x)}{t}, \qquad \underline{D} f(x) \coloneqq \lim_{h \to 0} \inf_{0 < |t| < h} \frac{f(x + t) - f(x)}{t} 
    \end{equation}
    If they are equal, then we can define the \textbf{derivative} as either one, and we say $f$ is \textbf{differentiable} at $x$. 
  \end{definition}

  Note that as $h$ goes to $0$, the first is nondecreasing and the second is nonincreasing, and clearly 
  \begin{equation}
    \underline{D} f(x) \leq \overline{D} f(x)
  \end{equation}

  \begin{lemma} 
    Suppose $f$ is increasing on $[a, b]$. Then $\forall \alpha > 0$, then, 
    \begin{equation}
      m^\ast \{ x \mid \overline{D} f(x) \geq \alpha \} \leq \frac{1}{\alpha} \big( f(b) - f(a) \big)
    \end{equation}
    and 
    \begin{equation}
      m^\ast \{ x \mid \overline{D} f(x) = \infty\} = 0
    \end{equation}
  \end{lemma}
  \begin{proof}
    Fix $\alpha > 0$, define $E_\alpha = \{ x \mid \overline{D} f(x) \geq \alpha\}$. Take any $\alpha^\prime < \alpha$, any $\epsilon > 0$. Consider all intervals $[c, d] \subset [a, b]$ s.t. $f(d) - f(c) > \alpha^\prime (d - c)$. This collection covers $E_\alpha$ in Vitali sense. Since no matter how small $h$ is, we can find $t$ so that this ratio term is bigger than $\alpha^\prime$. 

    Now, we can use the covering lemma to find a finite disjoint collection $\{[c_k, d_k]\}_{k=1}^n$ s.t. $m^\ast ( E \setminus \cup_{k=1}^n [c_k, d_k]) < \epsilon$. Then, 
    \begin{equation}
      m^\ast (E) \leq \sum_{k=1}^n (d_k - c_k) + \epsilon 
    \end{equation}
    by subadditivity of outer measure. Using the inequality, 
    \begin{equation}
      \leq \frac{1}{\alpha^\prime} \sum_{k=1}^n \big( f(d_k) - f(c_k) \big) + \epsilon
    \end{equation}
    But $f$ is monotone, so 
    \begin{equation}
      \leq \frac{1}{\alpha^\prime} \big( f(b) - f(a) \big) + \epsilon
    \end{equation}
    This is true for all $\alpha^\prime < \alpha$ for all $\epsilon > 0$, proving the first claim. The second part follows since it is an intersection of all sets for $\alpha = n$ for all $n \in \mathbb{N}$, which go to $0$. 
  \end{proof}

  Since we are using outer measure, we don't have to worry nor rely on about measurability. Also, there can be uncountable set at which $f$ is infinite, but it just guarantees outer measure $0$.  
  
  \begin{theorem}[Lebesgue]
    Suppose $f$ is increasing on $(a, b)$. Then, it is differentiable a.e. on $(a, b)$. 
  \end{theorem}
  \begin{proof}
    WLOG, $(a, b)$ is bounded.\footnote{Otherwise, we can always split it into a countable union of bounded intervals. } Consider the countable family of sets 
    \begin{equation}
      E_{\alpha, \beta} = \{x \mid \overline{D} f (x) > \alpha > \beta > \underline{D}f(x), \alpha, \beta \in \mathbb{Q} \}
    \end{equation}
    Note that if the derivatives aren't equal, we can always squeeze 2 rationals in, so 
    \begin{equation}
      \{x \mid \overline{D} f(x) > \underline{D} f(x) \} \subset \bigcup_{\alpha, \beta \in \mathbb{Q}} E_{\alpha, \beta}
    \end{equation}
    We want to prove that $m^\ast (E_{\alpha, \beta}) = 0 \quad \forall \alpha, \beta$. Let's find $O$ open s.t. $E_{\alpha, \beta} \subset O$ and $m(O) < m^\ast (E) + \epsilon$, where we will denote $E = E_{\alpha, \beta}$. 

    Consider all intervals $[c, d] \subset O$ s.t. $f(d) - f(c) < \beta (d - c)$. Since we know $\underline{D} f(x) < \beta$, these intervals cover $E$ in Vitali sense. So you find a disjoint subcollections $[c_k, d_k]$ for $k = 1, \ldots, n$ s.t. 
    \begin{equation}
      m^\ast \bigg( E \setminus \bigcup_{k=1}^n [c_k, d_k] \bigg) < \epsilon 
    \end{equation}
    Observe that 
    \begin{align}
      \sum_{k=1}^n \big( f(d_k) - f(c_k) \big) & < \beta \sum_{k=1}^n (d_k - c_k) \\ 
                                               & \leq \beta \big( m^\ast (E) + \epsilon \big)
    \end{align}
    On the other hand, we can apply the previous lemma to $E \cap [c_k, d_k]$ to get 
    \begin{equation}
      m^\ast (E \cap [c_k, d_k]) \leq \frac{1}{\alpha} \big( f(d_k) - f(c_k) \big) 
    \end{equation}
    and so 
    \begin{align}
      m^\ast (E) & \leq \frac{1}{\alpha} \sum_{k=1}^n \big( f(d_k) - f(c_k) \big) + \epsilon \\ 
                 & \leq \frac{\beta}{\alpha} \big( m^\ast(E) + \epsilon) + \epsilon, \quad \forall \epsilon > 0 
    \end{align}
    So, $m^\ast(E) \leq \frac{\beta}{\alpha} m^\ast (E)$, where $\frac{\beta}{\alpha} < 1$. Therefore $m^\ast (E) = 0$. 
  \end{proof}

  But being differentiable doesn't imply that fundamental theorem of calculus holds. So integrating the derivative won't get you back these functions (think of step functions). So we will have to specify a class of functions such that this holds. 

  \begin{corollary}
    Suppose $f$ is increasing on $[a, b]$. Then $f^\prime$ is integrable, and 
    \begin{equation}
      \int_a^b f^\prime \leq f(b) - f(a)
    \end{equation}
  \end{corollary}
  \begin{proof}
    Define 
    \begin{equation}
      D_n f(x) = \frac{f(x + 1/n) - f(x)}{1/n}
    \end{equation}
    by Lebesgue theorem, $D_n f \to f^\prime$ a.e. By Fatau, 
    \begin{equation}
      \int_a^b \leq \liminf \int_a^b D_n f = 
    \end{equation}
    where 
    \begin{align}
      \int_a^b D_n f & = n \int_{a + 1/n}^{b + 1/n} f(x) - n \int_a^b f(x) \\
                     & = n \bigg( \int_b^{b + 1/n} f(b) - \int_a^{a + 1/n} f(x) \bigg) \\ 
                     & \leq f(b) - f(a)
    \end{align}
    Here we extended $f(x)$ by $f(b)$ for $x \in [b, b + \frac{1}{n}]$. 
  \end{proof}

  \begin{example}
    If $f$ is not monotone but continuous, $f^\prime$ doesn't have to be integrable. Consider 
    \begin{equation}
      f(x) = x^2 \sin \Big( \frac{1}{x^2} \Big)
    \end{equation}
    on $[0, 1]$. Then 
    \begin{equation}
      f^\prime (x) 2 x \sin \Big( \frac{1}{x^2} \Big) - \frac{2}{x} \cos \Big( \frac{1}{x^2} \Big)
    \end{equation}
  \end{example}

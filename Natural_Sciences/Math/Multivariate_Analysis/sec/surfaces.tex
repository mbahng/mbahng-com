\section{Surfaces}

  We can represent a $K$-dimensional subset $S \subset \mathbb{R}^N$ in multiple ways, where $K < N$. There are three conventional ways to do this. 
  \begin{enumerate}
      \item We can parameterize it with a function $f: D \subset \mathbb{R}^k \longrightarrow \mathbb{R}^n$ to create a \textbf{parameterized set} defined as the image of an \textit{injective} $f$ under $D$. Letting $\mathbf{x} \in \mathbb{R}^n$ and $\mathbf{u} \in \mathbb{R}^k$, the parameterization is defined 
      \[\mathbf{u} \mapsto f(\mathbf{u}) = \big( f_1 (\mathbf{u}), f_2 (\mathbf{u}), \ldots, f_n (\mathbf{u}) \big) \]
      
      \item A function $\mathbf{f}: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ of the form $\mathbf{y} = \mathbf{f}(\mathbf{x})$ creates an \textbf{explicit representation} by defining all $(\mathbf{x}, \mathbf{y}) \in \mathbb{R}^{n+m}$ satisfying 
      \[\mathbf{y} = \mathbf{f}(\mathbf{x})\]
      
      \item A \textbf{level set} of the form $\mathbf{F}(\mathbf{x}) = \mathbf{0}$ creates an \textbf{implicit representation} by defining all $\mathbf{x} \in \mathbb{R}^n$ satisfying 
      \[\mathbf{F}(\mathbf{x}) = \mathbf{0}\]
      Now if $\mathbf{F}$ was scalar valued, then the equation $F(\mathbf{x}) = 0$ defines a hypersurface in $\mathbb{R}^n$ with codimension 1. If $\mathbf{F}$ is a $k$-vector valued function, then the implicit surface generally has codimension $k$, since we can interpret $\mathbf{F}(\mathbf{x}) = \mathbf{0}$ as a system of $k$ constraint equations. 
  \end{enumerate}
  Generally, the change of representations is simple only when the explicit representation $\mathbf{y} = \mathbf{f}(\mathbf{x})$ is given. The implicit form is $\mathbf{F}(\mathbf{x}, \mathbf{y}) = \mathbf{y} - \mathbf{f}(\mathbf{x}) = \mathbf{0}$, and the parameterized form is the map $\mathbf{x} \mapsto (\mathbf{x}, \mathbf{f}(\mathbf{x}))$. However, the explicit representation is very limited in usefulness, because it can only describe sets that are graphs of functions that pass the vertical line test. The implicit function theorem, stated later, states conditions under which an equation $\mathbf{F}(\mathbf{x}) = 0$ can be solved explicitly for any of the $x_i$'s. The other two representations are much more versatile, with the implicit representation being slightly more general, but the parametric form being more useful, since we can directly compute points on the $S$. Some examples are: 
  \begin{enumerate}
      \item a 1-dimensional path/curve in $\mathbb{R}^n$ 
      \item a 2-dimensional surface in $\mathbb{R}^3$ 
      \item a $k$-dimensional set in $\mathbb{R}^n$ 
  \end{enumerate}

  If these surfaces are smooth enough, then there must exist geometric tangent vectors, geometric tangent planes, and geometric orthogonal vectors on them. We say "geometric" to distinguish them from the vectors in the tangent space $T_{\mathbf{x}_0} \mathbb{R}^n$. It is important to know how to derive them. 

  \begin{theorem}[Explicit Representation]
  Let us have the surface $S \subset \mathbb{R}^{n+1}$ defined by $y = f(\mathbf{x})$ and a point on the surface $(\mathbf{x}_0, f(\mathbf{x}_0))$. 
  \begin{enumerate}
      \item To get the equation of the set of affine points forming the geometric tangent plane, we look at all points $(\mathbf{x}, y)$ satisfying 
      \[y = f(\mathbf{x}_0) + D f_{\mathbf{x}_0} (\mathbf{x} - \mathbf{x}_0)\]
      and to get an arbitrary tangent vector protruding from $\mathbf{x}_0$, we look at all vectors $(\mathbf{v}, w)$ of form 
      \[w = D f_{\mathbf{x}_0} \mathbf{v}\]
      i.e. all vectors of form $(\mathbf{v}, D f_{\mathbf{x}_0} \mathbf{v})$. 
      \item To get the equation of the orthogonal vector, convert this to the implicit representation $g(\mathbf{x}, y) = y - f(\mathbf{x}) = 0$, and see that the gradient is orthogonal to the tangent plane. So, the orthogonal vector at $\mathbf{x}_0$ is 
      \[\nabla g (\mathbf{x}_0, f(\mathbf{x}_0)) = \begin{pmatrix} - \nabla f(\mathbf{x}_0) \\ 1 \end{pmatrix}\]
      Note that indeed, dotting this with an arbitrary tangent vector of the form above gives 
      \[\begin{pmatrix} -\nabla f(\mathbf{x}_0) \\ 1 \end{pmatrix} \cdot \begin{pmatrix} \mathbf{v} \\ D f_{\mathbf{x}_0} \mathbf{v} \end{pmatrix} = - \nabla f(\mathbf{x}_0) \cdot \mathbf{v} + D f_{\mathbf{x}_0} \mathbf{v} = 0\]
  \end{enumerate}
  \end{theorem}

  Given a level set $S = \{ \mathbf{x} \in \mathbb{R}^n \mid f(\mathbf{x}) = c\}$, a vector $\mathbf{v}$ is a \textbf{tangent vector} of $S$ at $\mathbf{a}$ if the directional derivative (if it exists) satisfies
  \[\nabla_\mathbf{v} f (\mathbf{a}) = 0\]
  If $f$ is differentiable at $\mathbf{a}$, then this condition is equivalent to 
  \[D f_\mathbf{a} \mathbf{v} = 0\]
  Intuitively, $D f_\mathbf{a} \mathbf{v}$ answers the question: "If I move infinitesimally in the direction $\mathbf{v}$, what happens to $f$?" We would want this direction to preserve the value of $f = c$, and so the derivative should be $0$. Therefore, we look for the vectors $\mathbf{v}$ satisfying $D f_\mathbf{a} \mathbf{v} = 0$, i.e. the annihilator $(D f_\mathbf{a})^0 \subset \mathbb{R}^n$. This result is precisely the well-known theorem that states that "gradients are orthogonal to level sets." It is intuitive to claim that if we have some sort of directional vector $\mathbf{v}$, then this $\mathbf{v}$ must be "tangent" if the directional derivative towards $\mathbf{v}$ must be $0$, essentially staying within the level set of value $c$. 

  \begin{theorem}[Implicit Representation]
  Let us have the surface $S \subset \mathbb{R}^n$ defined by $F(\mathbf{x}) = 0$ and a point $\mathbf{a} \in S$. 
  \begin{enumerate}
      \item The gradient $\nabla F(\mathbf{x}_0)$ is simply the orthogonal vector at $\mathbf{x}_0$. 
      \item The set of all directional tangent vectors protruding from $\mathbf{x}_0$ is defined by the set of directional vectors $\mathbf{v}$ satisfying 
      \[\nabla F(\mathbf{x}_0) \cdot \mathbf{v} = 0\]
      and the set of all affine points forming the geometric tangent plane are all $\mathbf{x} \in \mathbb{R}^n$ satisfying 
      \[\nabla F(\mathbf{x}_0) \cdot (\mathbf{x} - \mathbf{x}_0) = 0\]
  \end{enumerate}
  \end{theorem}
  \begin{proof}
  This is trivial since we can invoke Reisz representation theorem and see that 
  \[D f_\mathbf{a} \mathbf{v} = 0 \implies \nabla_\mathbf{a} f \cdot \mathbf{v} = 0\]
  \end{proof}

  This theorem now simplifies our derivation of tangent planes of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$. To find the equation of a tangent plane of $y = f(\mathbf{x})$ at $\mathbf{x} = \mathbf{a}$, we can simply write the one-line equation as 
  \[y = f(\mathbf{a}) + D f_{\mathbf{a}} (\mathbf{x} - \mathbf{x}_0)\]
  However, if we had an implicit function of the form $g(\mathbf{x}, y) = c$, then separating this into an explicit function of $y$ is hard. Therefore, we can simply treat $g$ itself as a function of the $n+1$ variables $(\mathbf{x}, y)$, and treat $g(\mathbf{x}, y) = c$ as a level set. 

  \begin{theorem}[Parametric Representation]
  Let us have $f: D \subset \mathbb{R}^k \longrightarrow \mathbb{R}^n$, with injective $f$ defining a surface $f(D) \subset \mathbb{R}^n$. Let us have $\mathbf{u}_0 \in D$ with $f(\mathbf{u}_0) = \mathbf{x}_0 \in f(D)$. Our idea is this: we compute $k$ directional derivatives of $f$ in $k$ linearly independent direction vectors at $\mathbf{u}_0$, which will give us $k$ (linearly independent, due to injectiveness of $f$, but not necessarily orthogonal) geometric tangent vectors protruding from $\mathbf{x}_0$ that span the tangent space $T_{\mathbf{x}_0}$. If $k = n-1$, then the orthogonal vector is uniquely defined to be the vector spanning $T_{\mathbf{x}_0}^\perp$, and is $k < n-1$, there is no unique orthogonal vector defined. 
  \begin{enumerate}
      \item The set of all directional tangent vectors $\mathbf{v}$ protruding from $\mathbf{x}_0$ is represented by the set of all linear combinations of the partials, aka the image of the Jacobian of $f$
      \[\{c_1 \partial_{u_1} f (\mathbf{u}_0) + \ldots + c_k \partial_{u_k} f (\mathbf{u}_0) \mid \mathbf{c} \in \mathbb{R}^n\} = \mathrm{Im} \begin{pmatrix} \vert & \ldots & \vert \\ \partial_{u_1} f (\mathbf{u}_0) & \ldots & \partial_{k} f (\mathbf{u}_0) \\ \vert & \ldots & \vert \end{pmatrix} = \mathrm{Im} D f_{\mathbf{u}_0}\]
      The tangent space is the space of all $\mathbf{x} \in \mathbb{R}^n$ of the form 
      \[f(\mathbf{x}_0) + D f_{\mathbf{x}_0} \mathbf{u} \text{ for all } \mathbf{u} \in \mathbb{R}^k\]
      \item If $k=n-1$, the orthogonal vector is the unique vector that is orthogonal to all $\partial_{u_i} f(\mathbf{u}_0)$, which can be computed using linear algebra techniques (e.g. kernel of $D f_{\mathbf{x}_0}$). If $n=3, k=2$, then this can simply be computed using the cross product. 
  \end{enumerate}
  \end{theorem}


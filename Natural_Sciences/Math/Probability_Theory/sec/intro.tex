An overview of probability using measures. We will denote probability measures defined over $\sigma$-algebras with $\mathbb{P}$ and probability functions defined over some sample space $\Omega$ or $\mathbb{R}$ with $P$ or $p$. When we say countable, we mean finite or countably infinite. I have used resources from: 
\begin{enumerate}
  \item Rick Durret's \textit{Elementary Probability} and \textit{Probability} textbooks. 
  \item Dr. Krishna's \textit{Probability Foundation for Electrical Engineers} lectures at IIT. 
  \item Various quant interview books and websites for examples. 
\end{enumerate}


\section{Jan 12}  

  \begin{example}[Branching Processes]
    Let $Z_n$ be the number of people in the $n$th generation, and $X_i^{(n+1)}$ be the number of offspring the $i$th person in the $n$th generation has. Assume $X_i^{(n+1)}$ is iid with distribution $X$. Then, we have 
    \begin{equation}
      Z_{n+1} = X_1^{(n+1)} + X_2^{(n+1)} + \ldots + X_{Z_n}^{(n + 1)}, \quad Z_1 = 1
    \end{equation}
    What is the extinction probability $\pi$ for given $X$? 
    \begin{equation}
      \pi = \mathbb{P}(\exists n \text{ s.t. } Z_n = 0)
    \end{equation}
    Some ideas is that we can try to compute $\mathbb{E}[X]$, use a Markov chain. We can also use a generating function, which is defined 
    \begin{equation}
      f(\theta) = \mathbb{E} [\theta^X] = \sum_{k=0}^\infty \theta^k \mathbb{P}(X = k)
    \end{equation}
    Then, we can define $f_n (\theta) = \mathbb{E}[\theta^{Z_n}]$. Let $\pi_n = \mathbb{P}(Z_n = 0)$. By the dominated convergence theorem, 
    \begin{equation}
      \pi = \lim_{n \to \infty} \pi_n
    \end{equation} 
    We claim that $f_n (\theta) = f_{n-1} (f(\theta))$, which can be proven by the Tower property:
    \begin{align}
      f_n (\theta) & = \mathbb{E}[ \mathbb{E}[\theta^{Z_n} \mid Z_{n-1}]] \\ 
                   & = \mathbb{E}[ \mathbb{E}[\theta^{X_1^{(n)}} + \ldots + X_{Z_n - 1}^{(n)} \mid Z_{n-1}] ] \\ 
                   & = \mathbb{E}[f(\theta)^{Z_{n-1}}] \\ 
                   & = f_{n-1} (f(\theta))
    \end{align}
    where the final line is true since $f_{n-1} (\alpha) = \mathbb{E}[\alpha^{Z_{n-1}}]$. This gives us a nice recursive formula, which implies that 
    \begin{align}
      \pi_n = f_n (0) & = f_{n-1} (f (0))  \\
                      & = \underbrace{(f \circ \ldots \circ f)}_{n \text{ times}} (0) \\ 
                      & = f(f_{n-1} (0)) \\ 
                      & = f(\pi_{n-1}) 
    \end{align}
    So $\pi$ satisfies $\pi = f(\pi)$ as long as $f$ is continuous. 

    So let's actually do some computation. 
    \begin{enumerate}
      \item Assume $X \sim \mathrm{Geom}(p)$ i.e. $\mathbb{P}(X = k) = (1 - p)^k p$ for $0 < p < 1$. Then, 
        \begin{equation}
          f(\theta) = \frac{p}{1 - (1 - p)\theta} 
        \end{equation}
        Since $\theta = f (\theta)$, o we can solve 
        \begin{equation}
          \theta = \frac{p}{1 - (1 - p) \theta} \implies \theta = 1 \text{ or } \theta = \frac{p}{1 - p}
        \end{equation}
        So how do we know which solution is $p$? If $p \geq 1/2$, then $\pi = 1$, but if $\frac{p}{p - 1} < 1$, then we can derive further 
        \begin{equation}
          f_n (0) = \frac{p \big(\frac{1 - p}{p} \big) - p}{(1 - p) \big( \frac{1 - p}{p} \big)^n - p} \to \frac{p}{1 - p}
        \end{equation}
        as $n \to \infty$, so $\pi = \frac{p}{1 - p}$ is the correct extinction probability. 
    \end{enumerate}
    It turns out that according to some deeper theorem, if $\mathbb{E}[X] > 1$, then $\pi$ is the unique solution to $x = f(x)$ on $(0, 1)$, and if $\mathbb{E}[X] \leq 1$, then $\pi = 1$. 
  \end{example}

  \begin{example}
    We can describe $Z_n$ more precisely as $n \to \infty$ using a Markov chain, which can be stated in the equivalent ways. 
    \begin{enumerate}
      \item 
        \begin{equation}
          \mathbb{P}(Z_{n+1} = j \mid Z_0 = i_0, \ldots, Z_n = i_n) = \mathbb{P}(Z_{n+1} = j \mid Z_n = i_n)
        \end{equation} 

      \item 
        \begin{equation}
          \mathbb{E}[Z_{n+1} \mid Z_0, \ldots, Z_n] = \mathbb{E}[Z_{n+1} \mid Z_n] 
        \end{equation}
    \end{enumerate}

    Observe that $M_n = Z_n / \mu^n$ is a martingale, with $\mu = \mathbb{E}[X]$, i.e. $\mathbb{E}[M_n \mid M_{n-1}] = M_{n-1}$. So, 
    \begin{equation}
      \mathbb{E}[M_n \mid M_{n-1}] = \mathbb{E}[Z_n \mid Z_{n-1}] = \mu \frac{Z_{n-1}}{\mu_n} = \frac{Z_{n-1}}{\mu^{n-1}} = M_{n-1}
    \end{equation}
    By a Martingale convergence theorem, setting $M_\infty (\omega) = \lim_{n \to \infty} M_n (\omega)$, we have $M_n \to M_\infty$ a.s. 
  \end{example}

  Next time, we'll review conditional expectation, then martingales, then markov chains, then ergodic theory (building on convergence results), and finally with Brownian motion.


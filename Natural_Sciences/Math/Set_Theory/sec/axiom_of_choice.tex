\section{Axiom of Choice}

  The axioms up to this point are pretty much undisputed and completes ZF set theory. Now that we've defined a function, let's quickly extend \hyperref[def:cart-prod]{our previous definition of a Cartesian product} into an arbitrary union of sets. 

  \begin{definition}[Choice Function]
    Given a set $X$ of sets, a \textbf{choice function} of $X$ is a function $f: X \to \cup X$, that assigns each $S \in X$ to one of its elements $f(S) \in S$. 
  \end{definition}

  \begin{example}
    Given $X = \{\{1, 4, 7\}, \{9\}, \{2, 7\}\}$, one possible choice function is 
    \begin{align}
      f(\{1, 4, 7\}) & = 4 \\ 
      f(\{9\}) & = 9 \\ 
      f(\{2, 7\}) & = 2
    \end{align}
  \end{example}

 
  \begin{definition}[Cartesian Product][def:cart-prod-2]
    If $\{X_\alpha\}_{\alpha \in A}$ is an indexed family of sets, then their \textbf{Cartesian product} is defined as the set of choice functions of $\{X_\alpha\}_{\alpha \in A}$. 
    \begin{equation}
      \prod_{\alpha \in A} X_\alpha \coloneqq \bigg\{ f: A \rightarrow \bigcup_{\alpha \in A} X_\alpha \;\Big|\; \forall \alpha \in A, f(\alpha) \in X_\alpha \bigg\} 
    \end{equation}
  \end{definition} 

  Therefore, we have used the power set axiom to define a finite Cartesian product, to then define a function, to then define a general Cartesian product. But this detail is irrelevant later on. Note also that this definition of Cartesian product is not the same as that of the previous definition. The binary Cartesian product is defined as $(a, b) = \{\{a\}, \{a, b\}\}$ while this defines as a function $f: \{1, 2\} \rightarrow A, B$. But once we have overwritten the old definition (which is still necessary!) we can just forget about it and use this new definition of Cartesian product since there is a canonical bijection between them. It is a lot less annoying to think of ordered tuples as just tuples rather than as sets of sets. 

  However, in our definition, we just call this a ``set of functions'' and have never proved that it actually contains anything. But we can see obviously that if this Cartesian product is nonempty then there exists a choice function, and if there exists a choice function then the Cartesian product is nonempty. It would be ideal if we can prove one of the two conditions, but it turns out we can't, and therefore we introduce the final axiom, called the \textit{axiom of choice}. Though controversial, it is required in the proofs of some notable theorems. If we include this axiom of choice, then we have ZFC set theory. The axiom of choice has many equivalent definitions. 

  Colloquially, the axiom of choice says that a Cartesian product of a collection\footnote{Note that this does not have to be finite} of non-empty sets is non-empty. That is, it is possible to construct a new set by choosing one element from each set, even if the collection is infinite. 

  \begin{axiom}[Axiom of Choice] 
    Let $X$ be any set of nonempty sets. Then, AC states the equivalent things: 
    \begin{enumerate}
      \item There exists a choice function on $X$. 
      \item The cartesian product $\prod X$ is nonempty. 
      \item There exists a set containing exactly one element from each set in the collection. 
    \end{enumerate}
  \end{axiom} 

  The controversy around AC is that is is nonconstructive by nature, and one cannot write down a specific formula or rule to define such a choice function. This is in contrast to---say, the axiom of infinity, since you can construct such a set inductively. For example, take a look at a choice function for the set of all subsets of the reals, which is considered as an ``unruly'' set. 

  \begin{example}[Choice Function on Power Set of Reals]
    Let $I$ be the set of all nonempty subsets of $\mathbb{R}$, and $X_i = i \in I$. Then an element $f$ in $\prod_{i \in I} X_i$ is a function which picks an element $f(T) \in T$ for every nonempty $T \subset \mathbb{R}$. How do you \textit{define} such an $f$? 
    \begin{enumerate}
      \item We might say, \textit{pick the minimum element}, but subsets like $(0, 1)$ does not have a minimum. 
      \item We could write a rule that says \textit{pick 1 if it is in the set, otherwise 2, otherwise 3, and so on}, but the choice function would not be defined for subsets that don't contain any natural number, such as $\{\pi, 2 \pi, e\}$. 
    \end{enumerate}
  \end{example}

  Therefore, there is no canonical choice of an element in a nonempty set of real numbers. But AC tells us that we don't have to worry about this. It gives us such a function, even if we cannot ``write it down'' (which means, construct it from the other ZF axioms).  However, there are still sets which this is possible. 

  \begin{example}[Choice Function on Power Set of Naturals]
    Let $I$ be the set of all nonempty subsets of $\mathbb{N}$. Then, we can define a choice function $f(T) = \min(T)$, which is always defined due to the well-ordering principle. 
  \end{example}

  \begin{example}[Choice Function on Open Sets of Reals]
    If we let $I$ be the set of all nonempty \textit{open} subsets of $\mathbb{R}$, then there is a choice function. Choose any bijection $\tau: \mathbb{N} \rightarrow \mathbb{Q}$, and then assign to each nonempty open subset $U \subset \mathbb{R}$ the element $\tau (\min\{n \in \mathbb{N} \mid \tau(n) \in U\})$. This works since $U \cap \mathbb{Q} \neq \emptyset$, and by the well ordering principle, we are guaranteed a minimum element. 
  \end{example} 

\subsection{Well-Ordering and Zorn's Lemma}

  The examples indicate that we must try to find some representative element of every subset of a set. This motivates the definition, followed by two additional axioms that turn out to be equivalent to AC. 

  \begin{definition}[Well-Ordered]
    A set $X$ is \textbf{well-ordered} by a strict total order $\leq$ if every nonempty subset of $X$ has a least element under $\leq$. 
  \end{definition}

  Therefore, if the well-ordering theorem holds, then we can see that every subset of the reals has such a least element, and therefore we can construct a choice function, which supports AC. It turns out that the converse is true as well. If AC is true, we can see generally that we would like to use a choice function to select a representative element of each set in $X$. Then we can use these to construct an order. 

  \begin{axiom}[Well-Ordering Theorem]
    Every set can be well-ordered. 
  \end{axiom}

  Despite the seeming equivalence between AC and the well-ordering theorem, the this result seems to be the most counterintuitive, since it claims the existence of such a total order on $\mathbb{R}$ such that \textit{every} nonempty subset of $\mathbb{R}$ has a minimum! Nobody has been able to explicitly construct such an ordering for the reals, and at first glance, perhaps one may try to \textit{prove} that such a well-ordering cannot exist. Let's move onto the second axiom. 

  \begin{axiom}[Zorn's Lemma]
    Let $X$ be a partially ordered set that satisfies the two properties. 
    \begin{enumerate}
      \item $P$ is nonempty. 
      \item Every \textbf{chain} (a subset $A \subset P$ where $A$ is totally ordered) has an upper bound in $P$. 
    \end{enumerate}
    Then $P$ has at least one maximal element. 
  \end{axiom} 

  The validity of Zorn's lemma is a bit ambiguous, which motivates the following quote from Jerry Bona: \textit{The axiom of choice is obviously true, the well-ordering principle obviously false, and who can tell about Zorn's lemma?} Ironically, all three results turn out to be equivalent. 

  \begin{theorem}[Equivalence]
    The following are equivalent. 
    \begin{enumerate}
      \item Axiom of Choice. 
      \item Well-Ordering Theorem. 
      \item Zorn's Lemma. 
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    
  \end{proof}
 
\subsection{Banach-Tarski Paradox}

  Most of my notes on this paradox is from Wahlberg's set of notes.\footnote{\href{https://arxiv.org/pdf/2206.13512}{https://arxiv.org/pdf/2206.13512}.} It helped me to not worry as much about the axiom of choice, as well as worry more about the axiom of infinity. Let $G_3$ be the group of all 3-dimensional rigid transformations $x \mapsto Ax + b$, where $x \in \mathbb{R}^3, A \in \mathrm{SO}(3), b \in \mathbb{R}^3$. 

  \begin{definition}[Equidecomposability]
    Let $G$ be a group acting on set $X$. We say that $A, B \subset X$ are \textbf{$G$-equidecomposable}, written $A \sim_G B$, if both sets have a decomposition 
    \begin{equation}
      A = A_1 \cup \ldots \cup A_n, \quad B = B_1 \cup \ldots \cup B_n
    \end{equation} 
    and $A_i = g_i B_i$ for some $g_i \in G$. We claim that $\sim_G$ is an equivalence relation on $2^X$. 
  \end{definition}
  \begin{proof}
    Listed. 
    \begin{enumerate}
      \item \textit{Reflexive}. Clearly, $A = e A$ where $e \in G$ is the identity transformation. 
      \item \textit{Symmetric}. If $A \sim_G B$, then we see that $A_i = g_i B_i$, but this means that $B_i = g_i^{-1} A_i$ for $g_i^{-1} \in G$, so $B \sim_G A$. 
      \item \textit{Transitive}. If $A \sim B$, $B \sim C$, then from $A \sim B$, we have 
        \begin{equation}
          A = A_1 \cup \ldots \cup A_n, \quad B = B_1 \cup \ldots \cup B_n, \qquad A_i = f_i B_i \text{ for } f_i \in G
        \end{equation}
        From $B \sim C$, we have 
        \begin{equation}
          B = B_1^\prime \cup \ldots \cup B_m^\prime, \quad C = C_1 \cup \ldots \cup C_m, \qquad B_j^\prime = g_j C_j \text{ for } g_j \in G
        \end{equation}

        Now we can take the common partition, which can have at most $n \cdot m$ partitions. 
        \begin{equation}
          A = \bigcup_{i, j} \big( A_i \cap f_i B_j^\prime \big), \quad C = \bigcup_{i, j} \big( g_j^{-1} B_i \cap C_j \big) 
        \end{equation}
        and see that 
        \begin{align}
          C & \mapsto \bigcup_j g_j \bigg( \bigcup_i \big( g_j^{-1} B_i \cap C_j \big) \bigg) = \bigcup_j \bigcup_i \big( B_i \cap g_j C_j \big) = \bigcup_j \bigcup_i \big( B_i \cap B^\prime_j \big) \\ 
            & \mapsto \bigcup_i f_i \bigg( \bigcup_j \big( B_i \cap B^\prime_j \big) \bigg) = \bigcup_i \bigcup_j \big( f_i B_i \cap f_i B_j^\prime \big) = \bigcup_{ij} \big( A_i \cap f_i B^\prime_j \big) = A
        \end{align}
    \end{enumerate}
  \end{proof}

  So equidecomposablity is stronger than a bijection, but not as strong as an isometry. It's in between, like a piecewise rigid transformation. 

  \begin{definition}[Paradoxical Sets]
    Let $G$ be a group acting on set $X$, and let $E \subset X$ be nonempty. Then, $E$ is \textbf{$G$-paradoxical} if 
    \begin{equation}
      E = A \sqcup B, \qquad E \sim_G A, \quad E \sim_G B
    \end{equation}
  \end{definition}

  Note that this essentially means that $E$ can be duplicated since 
  \begin{equation}
    E \sim A \cup B \sim g_1 A \cup g_2 B \sim g_1 E \cup g_2 E
  \end{equation}

  \begin{lemma}[Equidecomposable Sets Share Paradoxicality][thm:equi-paradox]
    Let $A \sim_G B$. Then, $A$ is $G$-paradoxical iff $B$ is $G$-paradoxical. 
  \end{lemma}
  \begin{proof}
    
  \end{proof}

  \begin{theorem}[The Banach-Schr√∂der-Bernstein Theorem]
    Let $G$ be a group acting on set $X$ and $A, B \subset X$. If $A$ is $G$-equidecomposable with a subset of $B$ and $B$ is $G$-equidecomposable with a subset of $A$, then $A \sim_G B$. 
  \end{theorem}

  \begin{corollary}[Conditions for Paradoxical][thm:disjoint-subset-paradoxical]
    Let $G$ be a group acting on set $X$. Then, $A \subset X$ is $G$-paradoxical if it contains disjoint subsets $A_1, A_2 \subset A$ both equidecomposable with $A$. 
  \end{corollary}

  \begin{example}[Vitali Paradox]
    Let $\mathrm{SO}(2)$ be the group of rotations in $\mathbb{R}^2$ and $S^1$ be the unit circle. For $p_1, p_2 \in S^1$, let $p_1 \sim p_2$ if the angle of rotation between them is a rational multiple of $2\pi$, which is an equivalence relation. Let us invoke the axiom of choice to define the choice set $C$ where each element contains a representative element of each equivalence class. Then, each point in $S^1$ can be expressed as an element of $C$, rotated by some rational $q \in [0, 1)$. By enumerating the rationals in the unit interval $(q_n)$, we get 
    \begin{equation}
      S^1 = q_1 C \sqcup q_2 C \sqcup q_3 C \sqcup \ldots = C_1 \sqcup C_2 \sqcup C_3 \sqcup \ldots
    \end{equation} 
    We can end up recreating $S^1$ be using only the sets of even or odd indices by applying a suitable rotation to them. 
    \begin{align}
      S^1 & = C_1 \sqcup \underbrace{C_3 + (q_2 - q_3)}_{C_2} \sqcup \underbrace{C_5 + (q_3 - q_5)}_{C_3} \sqcup \ldots \\ 
      S^1 & = \underbrace{C_2 + (q_1 - q_2)}_{C_1} \sqcup \underbrace{C_3 + (q_2 - q_3)}_{C_2} \sqcup \underbrace{C_5 + (q_3 - q_5)}_{C_3} \sqcup \ldots
    \end{align}
    Therefore, $S^1$ has a decomposition into two subsets such that each of them is ``\textit{countably} $\mathrm{SO}(2)$-equidecomposable'' with $S^1$, indicating that $S^1$ is ``countably $\mathrm{SO}(2)$-paradoxical.''
  \end{example}

  We say that a set $S$ can generate a group $G$. 

  \begin{definition}[Free Group]
    Let $G$ be the group generated by $S$. Then, $G$ is \textbf{free} if it satisfies the following equivalent definitions. 
    \begin{enumerate}
      \item No nonempty reduced word in $S$ represents the identity element in $G$. 
      \item Every element in $G$ can be represented by exactly one reduced word of $S$. 
    \end{enumerate}
    The number of elements of $S$---called the generators---is the \textbf{rank} of the free group. 
  \end{definition}

  \begin{example}[Free Group of Rank 1]
    Let $S = \{1\}$. Then, it generates the group $(\mathbb{Z}, +)$. Similarly, we can think of an irrational rotation in $S^1$, which will also give us a free generator. 
  \end{example}

  Let's extend this by one more dimension. 

  \begin{lemma}[Rank 2 Free Group is Paradoxical][thm:rank2-paradox]
    If a free group $G$ is of rank $2$, then it is $G$-paradoxical, where we view $G$ as acting on itself. 
  \end{lemma}
  \begin{proof}
    Let $G$ be freely generated by $S = \{\rho, \tau\}$, and for each $g \in \{\rho, \tau, \rho^{-1}, \tau^{-1}\}$, define $G_g$ as the set of all elements from $G$ represented by reduced words in $S$ having the leftmost letter as $g$. Since $G$ is a free group, we can partition $G$ as 
    \begin{equation}
      G = \{e\} \sqcup G_\rho \sqcup G_\tau \sqcup G_{\rho^{-1}} \sqcup G_{\tau^{-1}}
    \end{equation}
    Note that by separating out the first letter, we can decompose $G_\rho = \{\rho\} \sqcup \rho G_{\rho} \sqcup \rho G_\tau \sqcup \rho G_{\tau^{-1}}$. By transforming all elements by $\rho^{-1}$, we can ``remove'' the element as $\rho^{-1} G_{\rho} = \{e\} \sqcup G_\rho \sqcup G_\tau \sqcup G_{\tau^{-1}}$. Therefore, $G = \rho^{-1} G_\rho \sqcup G_{\rho^{-1}}$, and so 
    \begin{equation}
      G \sim_G G_\rho \sqcup G_{\rho^{-1}} 
    \end{equation}
    Similarly, we have $G \sim_G G_\tau \sqcup G_{\tau^{-1}}$. Since $G$ is $G$-equidecomposable with its two disjoint subsets $G_{\rho} \sqcup G_{\rho^{-1}}$ and $G_{\tau} \sqcup G_{\tau^{-1}}$, \hyperref[thm:disjoint-subset-paradoxical]{it follows that} $G$ is $G$-paradoxical. 
  \end{proof}

  \begin{theorem}[Free Subgroup in SO(3)][thm:free-subgroup]
    $\mathrm{SO}(3)$ has a subgroup that is free on two generators. 
  \end{theorem}
  \begin{proof}
    The general idea is to take motivation from the irrational angles as free generators. We pick the following rotations around the x and y axes as our free generators. For convenience, we also list their inverses. 
    \begin{equation}
      \sigma = \frac{1}{5} \begin{bmatrix} 5 & 0 & 0 \\ 0 & 4 & -3 \\ 0 & 3 & 4 \end{bmatrix}, \quad 
      \tau = \frac{1}{5} \begin{bmatrix} 4 & 0 & 3 \\ 0 & 5 & 0 \\ -3 & 0 & 4 \end{bmatrix}, \quad 
      \sigma^{-1} = \frac{1}{5} \begin{bmatrix} 5 & 0 & 0 \\ 0 & 4 & 3 \\ 0 & -3 & 4 \end{bmatrix}, \quad 
      \tau^{-1} = \frac{1}{5} \begin{bmatrix} 4 & 0 & -3 \\ 0 & 5 & 0 \\ 3 & 0 & 4 \end{bmatrix}
    \end{equation} 
    We claim that the subgroup $G = \langle \sigma, \tau \rangle$ is free. Since all 4 matrices can be treated as $\mathbb{Q}$-linear maps, we define the integer matrices $A_+ = 5\sigma$ and $B_+ = 5\tau$, along with their corresponding matrices for the inverses $A_{-} = 5\sigma^{-1}$ and $B_{-} = 5\tau^{-1}$:
    \begin{equation}
      A_{+} = \begin{bmatrix} 5 & 0 & 0 \\ 0 & 4 & -3 \\ 0 & 3 & 4 \end{bmatrix}, A_{-} = \begin{bmatrix} 5 & 0 & 0 \\ 0 & 4 & 3 \\ 0 & -3 & 4 \end{bmatrix}, \quad B_{+} = \begin{bmatrix} 4 & 0 & 3 \\ 0 & 5 & 0 \\ -3 & 0 & 4 \end{bmatrix}, B_{-} = \begin{bmatrix} 4 & 0 & -3 \\ 0 & 5 & 0 \\ 3 & 0 & 4 \end{bmatrix}
    \end{equation}
    Let $\rho = s_k \cdots s_1$ be any non-trivial reduced word of length $k \geq 1$, and we wish to show that $\rho$ cannot be the identity map. Let $M_i = 5s_i$ be the integer matrix corresponding to each generator. If $\rho = I$, then the product $M = M_k \cdots M_1$ must equal $5^k I$. We now consider the images of these matrices under the ring homomorphism $\pi: \mathbb{Z} \to \mathbb{Z}_5$. We define $\bar{A}_{+}, \bar{A}_{-}, \bar{B}_{+}, \bar{B}_{-} \in M_3(\mathbb{Z}_5)$ as:
    \begin{equation}
      \bar{A}_{+} = \begin{bmatrix} 0 & 0 & 0 \\ 0 & 4 & 2 \\ 0 & 3 & 4 \end{bmatrix}, \bar{A}_{-} = \begin{bmatrix} 0 & 0 & 0 \\ 0 & 4 & 3 \\ 0 & 2 & 4 \end{bmatrix}, \quad \bar{B}_{+} = \begin{bmatrix} 4 & 0 & 3 \\ 0 & 0 & 0 \\ 2 & 0 & 4 \end{bmatrix}, \bar{B}_{-} = \begin{bmatrix} 4 & 0 & 2 \\ 0 & 0 & 0 \\ 3 & 0 & 4 \end{bmatrix}
    \end{equation}
    If $\rho = I$, then $\pi(M) = \pi(M_k) \cdots \pi(M_1) \equiv \mathbf{0} \pmod 5$. To show this is impossible, we will investigate the range and kernel of each map. With some calculations\footnote{For example, $\bar{A}_{+}$ maps $(a, b, c)$ to $(0, 4b + 2c, 3b + 4c)$. But in $\mathbb{Z}_5$, we have that $4b + 2c = 3 (3b + 4c)$.}, we find that 
    \begin{align}
      \mathrm{range}(\bar{A}_{+}) &= \{ (0, 3m, m) \in \mathbb{Z}_5^3 \}, \quad \mathrm{ker}(\bar{A}_{+}) = \{ (m, n, 3n) \in \mathbb{Z}_5^3 \}, \\
      \mathrm{range}(\bar{A}_{-}) &= \{ (0, m, 3m) \in \mathbb{Z}_5^3 \}, \quad \mathrm{ker}(\bar{A}_{-}) = \{ (m, 3n, n) \in \mathbb{Z}_5^3 \}, \\
      \mathrm{range}(\bar{B}_{+}) &= \{ (m, 0, 3m) \in \mathbb{Z}_5^3 \}, \quad \mathrm{ker}(\bar{B}_{+}) = \{ (3m, n, m) \in \mathbb{Z}_5^3 \}, \\
      \mathrm{range}(\bar{B}_{-}) &= \{ (3m, 0, m) \in \mathbb{Z}_5^3 \}, \quad \mathrm{ker}(\bar{B}_{-}) = \{ (m, n, 3m) \in \mathbb{Z}_5^3 \}.
    \end{align}
    Note that $\mathrm{ker}(\bar{A}_{\pm}) \cap \mathrm{range}(\bar{B}_{\pm}) = \{0\}$ and $\mathrm{ker}(\bar{B}_{\pm}) \cap \mathrm{range}(\bar{A}_{\pm}) = \{0\}$. Therefore, there are no overlappings of kernels and ranges for pairs of mappings that are not inverses of each other. Since $M$ is given by a composition of mappings where none of $\bar{A}_{+} \bar{A}_{-}$, $\bar{A}_{-} \bar{A}_{+}$, $\bar{B}_{+} \bar{B}_{-}$, or $\bar{B}_{-} \bar{B}_{+}$ can occur, the only common element between the kernel and range of each mapping in the composition is the zero vector. Therefore, if a vector is not in the kernel of the first mapping, it gets mapped to a vector that is not in the kernel of the next, and continuing for all mappings gives a nonzero vector. One such vector is $(0, 0, 1)$, which can be verified. 
  \end{proof}

  \begin{theorem}[Lift of Paradoxical Decomposition of Group Action to Set][thm:lift]
    Let $G$ be a $G$-paradoxical group acting on set $X$. If only the identity in $G$ has any fixed points\footnote{An element $g \in G$ has a fixed in $X$ if there exists some $x \in X$ s.t. $gx = x$.} in $X$, then $X$ is also $G$-paradoxical. 
  \end{theorem}
  \begin{proof}
    Consider the orbits (with each orbit being a set $\{gx \in X \mid g \in G\}$) of the elements in $X$. By invoking the axiom of choice, we obtain a set $C$, containing one element from each unique orbit. Therefore, by construction applying all group actions to all elements of $C$ results in the whole set. 
    \begin{equation}
      GC \coloneqq \{ gc \mid g \in G, c \in C \} = \{Gc \mid c \in C\} = X
    \end{equation}
    Since $G$ is $G$-paradoxical, there exists a paradoxical decomposition $G = A \cup B$ with $G \sim_G A$, $G \sim_G B$. Just as $X = GC$, we can apply the group actions of $A$ and $B$ on $C$ to obtain a partition of $X$ by $Y \coloneqq AC$ and $Z \coloneqq BC$. We claim that $Y$ and $Z$ are disjoint. Assume that there is a common element, i.e. there exists $a \in A, b \in B$, and $c_1, c_2 \in C$ such that $ac_1 = b c_2$. But then, $c_1 = a^{-1} b c_2$, so both $c_1, c_2$ belong to the same orbit. Since $A, B$ are disjoint, $a \neq b$ and so $a^{-1} b$ cannot  be the identity, and hence cannot have any fixed points. Thus, $c_1 \neq c_2$, and $C$ contains more than one element from an orbit, which is a contradiction on our construction of $C$. 

    Now we wish to show that $Y, Z$ form a paradoxical decomposition of $X$. It only remains to check that $X \sim_G Y$ and $X \sim_G Z$. Let's do $X \sim_G Y$ first. Since $G \sim_G A$, by definition, there exists decompositions 
    \begin{equation}
      G = \bigcup_{i=1}^n G_i, \quad A = \bigcup_{i=1}^n A_i
    \end{equation}
    with $g_1, \ldots, g_n \in G$, such that $A_i = g_i G_i$. Now, from our previous construction, we can define the decompositions 
    \begin{align}
      X & = GC = \bigg( \bigcup_{i=1}^n G_i \bigg) C = \bigcup_{i=1}^n (G_i C) = \bigcup_{i=1}^n X_i \\ 
      Y & = AC = \bigg( \bigcup_{i=1}^n A_i \bigg) C = \bigcup_{i=1}^n (A_i C) = \bigcup_{i=1}^n Y_i
    \end{align} 
    and now, we can easily verify the paradoxicality by showing that $Y_i = g_i X_i$ for all $i = 1, 2, \ldots, n$. For each $i$, since $A_i = g_i G_i$, we have 
    \begin{align}
      Y_i = A_i C = (g_i G_i) C & = \{hc \mid h \in g_i G_i, c \in C\} \\ 
                                & = \{g_i g^\prime c \mid g^\prime \in G_i, c \in C \} \\
                                & = \{g_i x \mid x \in G_i C \} = g_i (G_i C) = g_i X_i
    \end{align}
    So $X \sim_G Y$, and similarly, we can verify that $X \sim_G Z$, establishing paradoxicality of $X$. 
  \end{proof}

  Note that the full strength of AC is needed since the number of orbits is uncountably infinite. 

  \begin{theorem}[Simplified Hausdorff Paradox][thm:hausdorff]
    Let $S^2$ be the unit sphere in $\mathbb{R}^3$. There is a countable subset $D \subset S^2$ such that $S^2 \setminus D$ is $\mathrm{SO}(3)$-paradoxical.
  \end{theorem}
  \begin{proof}
    Let's \hyperref[thm:free-subgroup]{extract a free group $G$ of rank 2 from $\mathrm{SO}(3)$}, which we can view as acting on $S^2$. We know that \hyperref[thm:rank2-paradox]{$G$ is $G$-paradoxical}, and our goal is use the \hyperref[thm:lift]{theorem above} to lift the paradoxicality of $G$ onto the $G$-set $S^2$. 

    The problem is that $S^2$ contains fixed points for elements of $G$ that are not the identity. We wish to construct $D$ such that $S^2 \setminus D$ doesn't contain these fixed points \textit{and} still remains closed under $G$. This is pretty straightforward. Since every rotation in $\mathrm{SO}(3)$ is a rotation around some line through the origin\footnote{See Euler's rotation theorem, or consider the fact that such a matrix must have 1 real eigenvalue (which must be $1$) and 2 complex conjugate eigenvalues.}, every element of $G$ has two fixed points. But $G$ is countable, so the set of all fixed points---which we denote as $D$---must also be countable. 

    Now it remains to show that $S^2 \setminus D$ is closed under $G$. Assume that it wasn't, i.e. there exists a $p \in S^2 \setminus D$ and $\rho \in G$ such that $\rho p \in D$. But by definition of $D$, $\rho p$ must be a fixed point for some other nontrivial rotation $\gamma \in G$. That is, 
    \begin{equation}
      \gamma \rho p = \rho p
    \end{equation} 
    Now applying the inverse rotation $\rho^{-1}$ to both sides gives $\rho^{-1} \gamma \rho p = p$, which indicates that $\rho^{-1} \gamma \rho$ has $p$ as a fixed point. But $p$ is not in $D$, and so $p$ cannot be a fixed point for any rotation except the identity, indicating that $\rho^{-1} \gamma \rho = e$, which implies that $\gamma = \rho \rho^{-1} = e$. This contradicts that $\gamma$ is nontrivial. Therefore, $S^2 \setminus D$ is $G$-paradoxical, and since $G$ is a subset of $\mathrm{SO}(3)$, $S^2 \setminus D$ is also $\mathrm{SO}(3)$-paradoxical. 
  \end{proof} 

  The next result formalize the phenomena on how you can add or remove points simply by rotating a set. That is, if we have an irrational rotation relative to a countable set $D$, then the rotated sets $\rho^n D$ will never overlap. 

  \begin{lemma}[Irrational Rotation Relative to Points]
    Let $D \subset \mathbb{R}^3$ be at most countably infinite. If there is a line $\ell$ not passing through any point in $D$, then there exists a rotation $\rho \in G_3$ with $\ell$ as its axis, such that for $A \coloneqq \cup_{n=0}^\infty \rho^n D$, we have 
    \begin{equation}
      \rho A = A \setminus D
    \end{equation}
    If $\ell$ passes through the origin, then $\rho \in \mathrm{SO}(3)$.  
  \end{lemma}
  \begin{proof}
    We focus on the case when $\ell$ passes through the origin, since its extension to $G_3$ is straightforward. Denote the rotation of angle $\theta \in (0, 2\pi]$ by $\rho_\theta$ around $\ell$. Since $D$ is at most countable, it follows that only a countable number of angles can give $\rho_\theta D \cap D \neq \emptyset$. Similarly, for each $n \in \mathbb{N}$, the set of angles 
    \begin{equation}
      \{ \theta \in (0, 2 \pi] \colon \rho_\theta^n D \cap D \neq \emptyset \}
    \end{equation} 
    is at most countable. Since we can choose $\theta$ from an uncountable set, it turns out that we can choose such a $\rho = \rho_\theta$ such that $\{\rho^n D\}_{n=1}^\infty$ are disjoint. Let $A \coloneqq \cup_{n=0}^\infty \rho^n D$. By disjointness, we have 
    \begin{equation}
      \rho A = \rho \bigg( \bigcup_{n=0}^\infty \rho^n \bigg) = \bigcup_{n=0}^\infty \rho^{n+1} D = \bigcup_{n=1}^\infty \rho^n D = \bigg( \bigcup_{n=0}^\infty \rho^n D \bigg) \setminus D = A \setminus D
    \end{equation}
  \end{proof}

  Then the following theorem effectively allows us to add certain points to a paradoxical set to obtain a larger set that remains paradoxical, sort of like a Hilbert's Hotel logic to geometry. It essentially says that if you have a shape $X$ and you remove a small (countable) set of "troublesome" points $D$, the remaining set $X \setminus D$ is still "the same size" (equidecomposable) as the original $X$.

  \begin{theorem}[Equidecomposability by Irrational Rotation][thm:equi-irrational]
    Let $X \subset \mathbb{R}^3$ with $D \subset X$ at most countably infinite. If there is a line $\ell$ not passing through any point in $D$, and $D$ remains in $X$ after any rotation around $\ell$, then $X \setminus D$ is $G_3$-equidecomposable with $X$. If $\ell$ passes through the origin, then $X \setminus D$ is also $\mathrm{SO}(3)$-equidecomposable with $X$. 
  \end{theorem}
  \begin{proof}
    By the lemma, there exists a rotation $\rho$ around $\ell$ such that for all rotated points $A \coloneqq \cup_{n=0}^\infty \rho^n D$, we have $\rho A = A \setminus D$. Since $\rho^n D \subset X$ for all $n \in \mathbb{N}$, it follows that $A \subset X$. 

    Now let $B \coloneqq X \setminus A$ be the rest of the points we are not shuffling. Now we can see
    \begin{equation}
      B \cup \rho A = (X \setminus A) \cup (A \setminus D) = X \setminus D
    \end{equation}
    But $X = (B \cup A) \sim (B \cup \rho A)$, so by transitivity, it follows that $X \sim X \setminus D$. 
  \end{proof}

  \begin{theorem}[Paradoxical Sphere]
    $S^2$ is $SO(3)$-paradoxical. 
  \end{theorem} 
  \begin{proof}
    According to the \hyperref[thm:hausdorff]{Hausdorff paradox}, we can find a countable subset $D \subset S^2$ such that $S^2 \setminus D$ is $\mathrm{SO}(3)$-paradoxical. Now, select a line $\ell$ passing through the origin but not intersecting any point in $D$.\footnote{This is always possible since $D$ is a countable subset of uncountable set $S^2$.} Since rotations $\rho$ of $D$ around $\ell$ keeps $\rho D$ inside $S^2$. Therefore, by the \hyperref[thm:equi-irrational]{previous theorem}, we know that 
    \begin{equation}
      S^2 \sim S^2 \setminus D
    \end{equation}
    Since $S^2 \setminus D$ is $\mathrm{SO}(3)$-paradoxical, \hyperref[thm:equi-paradox]{it follows} that $S^2$ must also be $\mathrm{SO}(3)$-paradoxical. 
  \end{proof}

  Now, we want to turn the paradoxicality of the sphere into paradoxicality of the entire ball. This is pretty straightforward since we just consider all the points ``under'' the set on the surface. 

  \begin{theorem}[Paradoxical Punctured Ball]
    Let $B^3$ be the closed unit ball in $\mathbb{R}^3$. Then, $B^3 \setminus \{0\}$ is $\mathrm{SO}(3)$-paradoxical. 
  \end{theorem}
  \begin{proof}
    For each $E \subset S^2$, define 
    \begin{equation}
      c(E) \coloneqq \{ t x \mid x \in E, t \in (0, 1]\}
    \end{equation}
    Note that $c(S^2) = B^3 \setminus \{0\}$, and that $A, B \subset E$ disjoint implies that $c(A) \cap c(B)$ are also disjoint. Since $S^2$ is paradoxical, let $S^2 = C \sqcup D$ be its paradoxical decomposition. Note that this makes $c(S^2) = s(C \sqcup D) = s(C) \sqcup s(D)$ a decomposition of $B^3 \setminus \{0\}$. 

    Since $S^2 \sim C$, there exists a decomposition $S^2 = E_1 \sqcup \ldots \sqcup E_n$ and $C = F_1 \sqcup \ldots \sqcup F_n$ with $g_1, \ldots, g_n \in \mathrm{SO}(3)$ such that $F_i = g_i E_i$. This defines a bijective function $f: S^2 \to C$ that is piecewise rotational. We can extend $f$ to a mapping $g: c(S^2) \to c(C)$ by defining 
    \begin{equation}
      g(x) \coloneqq \|x\| \cdot f(x/\|x\|)
    \end{equation}
    which can be checked to be indeed an extension . It is surjective since 
    \begin{equation}
      g(c(S^2)) = \{t f(x) \mid x \in S^2, 0 < t \leq 1 \} = \{t y \mid y \in C, 0 < t \leq 1 \} = c(C)
    \end{equation}
    and it is injective since if $g(x) = g(y)$, then $\|x\| = \|y\|$ and $f(x/\|x\|) = f(y/\|x\|)$. This implies that $x / \|x\| = y / \|x\| \implies x = y$. Therefore, 
    \begin{equation}
      B^3 \setminus \{0\} = c(S^2) \sim c(C)
    \end{equation}
    Similarly, we can show that $(B^3 \setminus \{0\}) \sim c(D)$. Therefore, $B^3 \setminus \{0\}$ is equidecomposable with both $c(C)$ and $c(D)$, which partitions it, and so $B^3 \setminus \{0\}$ is $\mathrm{SO}(3)$-paradoxical. 
  \end{proof}

  Using the same steps we did in proving \hyperref[thm:equi-irrational]{equidecomposablity by irrational rotations}, the origin point can also be absorbed through equidecomposablity. 

  \begin{corollary}[Banach-Tarski Paradox]
    $B^3$ is $G_3$-paradoxical. 
  \end{corollary}
  \begin{proof}
    We basically want to define some at most countable set $D \subset B^3$ such that we can invoke our \hyperref[thm:equi-irrational]{previous theorem on equidecomposability}. We just proved that $B^3 \setminus \{0\}$ is $\mathrm{SO}(3)$-paradoxical. Let $\ell$ be a line that passes within distance $1/2$ from $0$ but not intersecting it (e.g. intersecting at $(1/3, 0, 0)$). Let $D = \{0\}$. Then, for any rotation in $G_3$\footnote{Note that these are rotations in $G_3$, not $\mathrm{SO}(3)$, since $\ell$ does not pass through the origin.} around $\ell$, $0$ will stay within $B^3$. Therefore, now we can invoke our theorem to give us our result that 
    \begin{equation}
      B^3 \sim_{G_3} B^3 \setminus \{0\} 
    \end{equation}
  \end{proof}

  \begin{theorem}[Strong Banach-Tarski Paradox]
    Let $A, B \subset \mathbb{R}^3$ be two bounded sets with nonempty interiors. Then, $A$ and $B$ are $G_3$-equidecomposable. 
  \end{theorem}

\subsection{Predicting Random Real Numbers} 

  Another weird result is the following riddle. 

  There is a house with 100 rooms, and each room contains countably many boxes indexed with the natural numbers. Each box contains a random real number, which is the same over all the rooms (that is, box n contains the same real number in every room). 100 set theorists play a game. Each person will go into a unique room and open as many boxes as they like (perhaps countably many) as long as they leave at least one box in their room unopened. Then, each of them need to pick an unopened box in their room, and guess what real number is inside of it.

  In order to win, 99 of them need to guess correctly. The mathematicians can discuss a strategy beforehand, but after they go into their respective rooms, no more communication is allowed. What is a winning strategy for this seemingly impossible task? 

  At first glance, a solution seems to be impossible, but here is one that uses AC. 
  \begin{enumerate}
    \item Let $S$ be the set of all sequences of real numbers $(x_i \in \mathbb{R}) \in S$. Let $\sim$ be an equivalence relation on $S$ where $(x_i) \sim (y_i)$ if the sequences differ on finitely many terms. Using axiom of choice, the mathematicians agree on a representative sequence from each equivalence class of $S$. 

    \item The mathematicians go into their respective rooms. For $1 \leq n \leq 100$, let $(s^{(n)}_i)_i$ denote the sequence of reals in the contents of the boxes as 
      \begin{equation}
        s^{(n)} = n, 100 + n, 200 + n, 300 + n, \ldots 
      \end{equation}
      Now, let player $n$ open every box except for those in $s^{(n)}$. In this way, player $p$ opens up 99 sequences of boxes $s^{(n)}$ for $n \neq p$.  

    \item Each player looks at the 99 sequences they can see, identifies which equivalence class each of them belongs to, and recalls the chosen representative sequence for every one of them. 

    \item For each player, they compare each of the 99 sequences $s^{(n)}$ with their respective representative sequence, and writes down the greatest index at which each observed sequence does not agree with its corresponding representative (which exists by the definition of $\sim$). Therefore, player $p$ will have written down 99 integers $\{x_n\}_{n \neq p, 1 \leq n \leq 100}$. Note that between any two players, the 98 of the integers will overlap since they are looking at the same sequences. 

    \item Now, each player $p$ takes the maximum $X_p \coloneqq \max \{ x_n\}_{n \neq p, 1 \leq n \leq 100}$. Out of the remaining boxes in player $p$'s room (which are precisely the indices that are congruent to $p$ mod 100), they leave the first $X_p + 1$ of them closed but opens every box beyond that. Since they opened up all but a finite number of boxes, each player $p$ can determine the equivalence class of $s^{(p)}$ and furthermore recall the representative sequence $[s^{(p)}]$. 

    \item For each player, they choose the highest index unopened box in their room---which is the $(X_p + 1)$th box in $s^{(p)}$ and guess it according to the corresponding element in $[s^{(p)}]$. 
  \end{enumerate}

  We claim that $X_p$ agrees for at least 99 of $p = 1, \ldots 100$. Let the maximum of all 100 $x_n$'s be denoted $x_{n^\ast}$. If $n^\ast$ is unique, for $p \neq n^\ast$, $X_p = n^\ast$, and for $p = n^\ast$, $X_p$ will be the next greatest number. If it is not unique, then $X_p = n^\ast$ for all 100 $p$'s. Therefore, for at least 99 of the players $p$, 
  \begin{equation}
    X_p \coloneqq \max \{ x_n \}_{n \neq p, 1 \leq n \leq 100} = \max \{ x_n \}_{1 \leq n \leq 100} 
  \end{equation}
  Remember that each $x_n$ represents the greatest index at which $s^{(n)}$ doesn't agree with $[s^{(n)}]$, and $X_p$ is the true maximum for at least 99 of them. So for 99 players, when they pick the $(X_p + 1)$th index, by definition, $s^{(p)}$ and $[s^{(p)}]$ must be guaranteed to match, since $X_p + 1 > X_p \geq x_p$. 

\subsection{Nonmeasurable Sets}

\subsection{Countable Choice} 

\subsection{Dependent Choice}

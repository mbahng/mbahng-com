\section{Riemann Integration}
  
  Now we will construct the theory of integration, which can be informally thought of as an ``summation for uncountable sets.'' Note that as of now, integration is a completely independent construction from the derivative. That is, we could have established integration first before differentiation. The unification of the two comes from the fundamental theorem of calculus. 

  If you have taken high school calculus, we can do this by defining the ``Riemann sums'' which is just the sum of the areas of a bunch of rectangles. By taking increasingly finer and finer rectangles, we can approximate the actual function. Note that this notion of ``approximation'' is not just a colloquial term. We will precisely characterize this, since we already established our theory of limits and suprema/infima. Let's begin. 

  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.9]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Rectangles and patterns
        \draw[blue] (0,0) rectangle (2,1.2);
        \draw[blue] (2,0) rectangle (4,2.2);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=blue!40] (0,0) rectangle (2,1.2);
        \fill[pattern=north east lines, pattern color=blue!40] (2,0) rectangle (4,2.2);
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1.5,1.2) (2.5,1.8) (4,2.8)};
        
        % Label f (no arrow)
        \node at (4.2,2.6) {$f$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.9]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Rectangles and patterns
        \draw[blue] (0,0) rectangle (1,0.8);
        \draw[blue] (1,0) rectangle (2,1.5);
        \draw[blue] (2,0) rectangle (3,2);
        \draw[blue] (3,0) rectangle (4,2.5);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=blue!40] (0,0) rectangle (1,0.8);
        \fill[pattern=north east lines, pattern color=blue!40] (1,0) rectangle (2,1.5);
        \fill[pattern=north east lines, pattern color=blue!40] (2,0) rectangle (3,2);
        \fill[pattern=north east lines, pattern color=blue!40] (3,0) rectangle (4,2.5);
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1.5,1.2) (2.5,1.8) (4,2.8)};
        
        % Label f (no arrow)
        \node at (4.2,2.6) {$f$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.9]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Rectangles and patterns
        \draw[blue] (0,0) rectangle (0.5,0.7);
        \draw[blue] (0.5,0) rectangle (1,0.9);
        \draw[blue] (1,0) rectangle (1.5,1.1);
        \draw[blue] (1.5,0) rectangle (2,1.4);
        \draw[blue] (2,0) rectangle (2.5,1.7);
        \draw[blue] (2.5,0) rectangle (3,2);
        \draw[blue] (3,0) rectangle (3.5,2.3);
        \draw[blue] (3.5,0) rectangle (4,2.6);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=blue!40] (0,0) rectangle (0.5,0.7);
        \fill[pattern=north east lines, pattern color=blue!40] (0.5,0) rectangle (1,0.9);
        \fill[pattern=north east lines, pattern color=blue!40] (1,0) rectangle (1.5,1.1);
        \fill[pattern=north east lines, pattern color=blue!40] (1.5,0) rectangle (2,1.4);
        \fill[pattern=north east lines, pattern color=blue!40] (2,0) rectangle (2.5,1.7);
        \fill[pattern=north east lines, pattern color=blue!40] (2.5,0) rectangle (3,2);
        \fill[pattern=north east lines, pattern color=blue!40] (3,0) rectangle (3.5,2.3);
        \fill[pattern=north east lines, pattern color=blue!40] (3.5,0) rectangle (4,2.6);
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1.5,1.2) (2.5,1.8) (4,2.8)};
        
        % Label f (no arrow)
        \node at (4.2,2.6) {$f$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \caption{Approximating an integral with increasingly fine partitions}
    \label{fig:partition-refinement}
  \end{figure}

\subsection{Darboux Integration}

  \begin{definition}[Partition]
    Let $[a, b]$ be an interval. A \textbf{partition} $P$ of $[a, b]$ is a finite set of $P = \{x_0, \ldots, x_n\}$ s.t. 
    \begin{equation}
      a = x_0 \leq x_1 \leq \ldots \leq x_{n-1} \leq x_n = b
    \end{equation}
    with $\Delta x_i = [x_{i-1}, x_i]$ for $i = 1, \ldots, n$. 
  \end{definition} 

  The cleanest way is to simply look at the set of all partitions along with the set of the corresponding upper and lower Riemann sums, and then hope that they behave nicely with each other. This is the approach we will take. 

  \begin{definition}[Darboux Sums with Respect to Partition]
    Let $P$ be a partition of $[a, b]$ and $f: [a, b] \to \mathbb{R}$ be bounded. Then, the \textbf{upper and lower Darboux sum} is defined 

    \begin{align}
      U(P, f) & = \sum_{i=1}^n \Big( \sup_{[x_{i-1}, x_i]} f \Big) \big[ x_i - x_{i-1} \big] \\ 
      L(P, f) & = \sum_{i=1}^n \Big( \inf_{[x_{i-1}, x_i]} f \Big) \big[ x_i - x_{i-1} \big] 
    \end{align}

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[scale=0.6]
          % Define axes
          \draw[->] (-0.5,0) -- (10.5,0) node[right] {$x$};
          \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};
          
          % Function curve
          \draw[thick] plot[domain=0:10, samples=100, smooth] 
              coordinates {(0,2.5) (2,1.8) (4,1.5) (6,2) (8,3.2) (10,4.5)};
          
          % f label
          \node at (10.5,4.5) {$f$};
          
          % Partition points on x-axis
          \foreach \x/\label [count=\i from 0] in {
            0/a=x_0, 2/x_1, 4/x_2, 6/x_3, 8/x_4, 10/b=x_5
          } {
            \fill (\x,0) circle (0.07);
            \node[black, below, font=\footnotesize] at (\x,-0.35) {$\label$};
          }
          
          % Rectangles for Riemann sum
          \foreach \xstart/\xend/\y [count=\i from 1] in {
            0/2/1.8, 2/4/1.5, 4/6/1.5, 6/8/2, 8/10/3.2
          } {
            % Rectangle with red border and pattern
            \draw[red] (\xstart,0) rectangle (\xend,\y);
            \fill[pattern=north east lines, pattern color=red!40] (\xstart,0) rectangle (\xend,\y);
          }
        \end{tikzpicture}
        \caption{Lower Riemann sum.}
        \label{fig:lower_riemann_sum}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[scale=0.6]
          % Define axes
          \draw[->] (-0.5,0) -- (10.5,0) node[right] {$x$};
          \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};
          
          % Function curve
          \draw[thick] plot[domain=0:10, samples=100, smooth] 
              coordinates {(0,2.5) (2,1.8) (4,1.5) (6,2) (8,3.2) (10,4.5)};
          
          % f label
          \node at (10.5,4.5) {$f$};
          
          % Partition points on x-axis
          \foreach \x/\label [count=\i from 0] in {
            0/a=x_0, 2/x_1, 4/x_2, 6/x_3, 8/x_4, 10/b=x_5
          } {
            \fill (\x,0) circle (0.07);
            \node[black, below, font=\footnotesize] at (\x,-0.35) {$\label$};
          }
          
          % Rectangles for Riemann sum
          \foreach \xstart/\xend/\y [count=\i from 1] in {
            0/2/2.5, 2/4/1.8, 4/6/2, 6/8/3.2, 8/10/4.5
          } {
            % Rectangle with red border and pattern
            \draw[red] (\xstart,0) rectangle (\xend,\y);
            \fill[pattern=north east lines, pattern color=red!40] (\xstart,0) rectangle (\xend,\y);
          }
        \end{tikzpicture}
        \caption{Upper Riemann sum. }
        \label{fig:upper_riemann_sum}
      \end{subfigure}
      \caption{}
    \end{figure}
  \end{definition}

  \begin{definition}[Darboux Integral][def:riemann-integral]
    Let $f: [a, b] \to \mathbb{R}$ be bounded. Then, the \textbf{upper and lower Darboux integrals} of $f(x)$ are defined 
    \begin{equation}
      \underline{\int_a^b} f \coloneqq \inf_P U(P, f), \qquad \overline{\int_a^b} f \coloneqq \sup_P L(P, f)
    \end{equation}
    If the upper and lower Riemann integrals are equal, then $f$ is said to be \textbf{Darboux integrable} over $[a, b]$, denoted $f \in \mathcal{R}([a, b])$, and we write the integral as 
    \begin{equation}
      \int_a^b f
    \end{equation}
  \end{definition} 
  \begin{proof}
    Note that $f$ is bounded by assumption, so it must satisfy $m \leq f \leq M$ on $[a, b]$. Therefore, it is not hard to see that 
    \begin{equation}
      m (b - a) \leq \int \underline{\int_a^b} f, \qquad \overline{\int_a^b} f \leq M (b - a)
    \end{equation}
    Since every upper (lower) bounded set in $\mathbb{R}$ has a least upper (greatest lower) bound, it is Darboux integrable. 
  \end{proof}

  Note that we prefer to write $\int_a^b f$ rather than $\int_a^b f(x) \,dx$, which contains the variable of integration. The integral depends on $a, b, f$, but not $x$, and so the role played by $x$ is analogous to that of the index of summation ($\sum_i c_i = \sum_j c_j$). 

  Just from a manipulation of definition, we would like to characterize conditions for integrability in a way that is easy to present. This culminates in the Cauchy criterion for integrability. 

  \begin{definition}[Refinement]
    $P^\ast$ is a \textbf{refinement} of $P$ if $P \subset P^\ast$. If $P_1, P_2$ are two partitions, then their \textbf{common refinement} $P^\ast = P_1 \cup P_2$. 
  \end{definition}

  \begin{lemma}[Fundamental Lemma]
    If $P^\ast$ is a refinement of $P$ and $f: [a, b] \to \mathbb{R}$ is bounded, then 
    \begin{equation}
      L(P, f) \leq L(P^\ast, f) \leq U(P^\ast, f) \leq U(P, f) 
    \end{equation}
  \end{lemma}
  \begin{proof} 
    By induction on the number of points we add to $P$ to get $P^\ast$, we might as well assume that $P^\ast = P \cup \{x_\ast\}$. So, 
    \begin{align}
      P & = \{a = x_0, x_1, \ldots, x_{n-1}, x_n \} \\
      P^\ast & = \{a = x_0, x_1, \ldots, x_{i-1}, x_i, x_\ast, x_{i+1}, \ldots, x_{n-1}, x_n \} \\
    \end{align}
    Now let's compute $L(f, P^\ast) - L(f, P)$. Since the only intervals affected are $[x_i, x_{i+1}]$, we have 
    \begin{align}
      L(f, P^\ast) - L(f, P) & = \inf_{[x_i, x_{\ast}]} f(x) (x_{\ast} - x_i) + \inf_{[x_\ast, x_{i+1}]} f(x) (x_{i+1} - x_\ast) - \inf_{[x_{i}, x_{i+1}]} f(x) (x_{i+1} - x_i) \\ 
                             & = \big( \underbrace{\inf_{[x_i, x_{\ast}]} f(x) - \inf_{[x_{\ast}, x_{i+1}]} f(x)}_{> 0} \big) (x_\ast - x_i) + \big( \underbrace{\inf_{[x_\ast, x_{i+1}]} f(x) - \inf_{[x_i , x_{i+1}]}}_{> 0} \big) (x_{i+1} - x_\ast) 
    \end{align}
    which is therefore greater than $0$. 
  \end{proof}

  \begin{theorem}
    We claim
    \begin{equation}
      \underline{\int_{a}^b} f \leq \overline{\int_{a}^{b}} f
    \end{equation}
  \end{theorem}
  \begin{proof}
    Given $P_1, P_2$ partitions, let $P^\ast = P_1 \cup P_2$ be their common refinement. Then, from the theorem above, 
    \begin{equation}
      L(P_2, f) \leq L(P^\ast, f) \leq U(P^\ast, f) \leq U(P, f) 
    \end{equation}
    So taking the supremum over all partitions $P_2$ and fixing $P_1$ gives 
    \begin{equation}
      \underline{\int_a^b} f = \sup_{P_2} L(P_2, f) \leq \sup_{P_2} U(P_1, f) = U(P_1, f)
    \end{equation}
    Then taking the infimum over all partitions $P_1$ gives us 
    \begin{equation}
      \underline{\int_a^b} f(x) = \inf_{P_1} \underline{\int_a^b} f(x) \leq \inf_{P_1} U(P_1, f) = \overline{\int_a^b} f(x) 
    \end{equation}
    where we note that the infimum does not affect the terms that do not depend on $P_1$. 
  \end{proof}

  We have seen some bounds of the upper and lower integrals, and defined the Riemann integral. However, checking Riemann integrability is quite tedious, since we have to take the supremum and infimum over all possible partitions. The following theorem is extremely useful as it only requires us to find \textit{one} partition given some $\epsilon$. This is because that the Riemann integral, as complicated as the formula is, is still a limit of a function. That means that we can apply the Cauchy criterion to it to determine convergence. 

  \begin{theorem}[Cauchy Criterion for Riemann Integrability][thm:cauchy-riemann-integrability]
    $f \in \mathcal{R}$ iff $\forall \epsilon > 0$, there exists partition $P$ such that $U(P, f) - L(P, f) < \epsilon$. 
  \end{theorem}
  \begin{proof}
    We prove bidirectionally. The reverse implication is easy, but for the forward direction you must use refinements. 
    \begin{enumerate}
      \item $(\leftarrow)$. Pick any partition $P$. Since
        \begin{align}
          L(f, P) \leq \underline{\int_a^b} f \leq \overline{\int_a^b} f \leq U(f, P)
        \end{align}
        This implies that 
        \begin{equation}
          0 \leq \overline{\int_a^b} f - \underline{\int_a^b} f \leq U(f, P) - L(f, P) < \epsilon 
        \end{equation}
        and since any nonnegative number less than any positive number must be $0$ (since there are no infinitesimals in $\mathbb{R}$), the LHS is $0$, and the result is proven.  

      \item $(\rightarrow)$. $f$ is Riemann integrable, so  
        \begin{equation}
          \overline{\int_a^b} f = \underline{\int_a^b} f \iff \inf_P U(f, P) = \sup_{Q} L(f, Q) 
        \end{equation}
        for partitions $P, Q$. So we can find $P$ that gets really close to the infimum and same for $Q$ close to the supremum, i.e. there exists a $P, Q$, such that
        \begin{equation}
          U(f, P) < \overline{\int_a^b} f + \frac{\epsilon}{2}, \qquad L(f, Q) > \underline{\int_a^b} f - \frac{\epsilon}{2}
        \end{equation}
        Now take the common refinement $P^\ast = P \cup Q$, and so by the fundamental lemma, 
        \begin{equation}
          \underline{\int_a^b} f - \frac{\epsilon}{2} < L(f, Q) \leq L(f, P^\ast) \leq U(f, P^\ast) \leq U(f, P) < \overline{\int_a^b} f + \frac{\epsilon}{2}
        \end{equation} 
        which implies that $0 \leq U(f, P^\ast) - L(f, P^\ast) < \epsilon$. 
    \end{enumerate}
  \end{proof}  

  Here is a classic example of a non-integrable function.  

  \begin{example}[Non-Integrability of the Dirichlet Function]
    The Dirichlet function
    \begin{equation}
      \mathcal{D}(x) \coloneqq \begin{cases}
        1, & \text{ for } x \in \mathbb{Q} \\
        0, & \text{ for } x \in \mathbb{R} \setminus \mathbb{Q}
      \end{cases}
    \end{equation}
    on the interval $[0,1]$ is not integrable on that interval. For any partition $P$ of $[0,1]$ we can find in each interval $(x_{i-1}, x_i)$ both a rational point $\xi^\prime_i$ and an irrational point $\xi_i^{\prime\prime}$. Then, we can see that the lower and upper Darboux sums do not necessarily converge to each other since
    \begin{equation}
      \sigma(f; P, \xi^\prime) = \sum_{i=1}^n 1 \cdot (x_i - x_{i-1}) = 1, \qquad \sigma(f;P, \xi^{\prime\prime}) = \sum_{i=1}^n 0 \cdot (x_i - x_{i-1}) = 0
    \end{equation}
    as $\lambda(P) \rightarrow 0$. 
  \end{example}

  The most important properties of integrable functions is linearity, monotonicity, and additivity. 

  \begin{theorem}[Axiomatic Properties of Darboux Integral]
    Let $f, g$ be real-valued bounded functions over bounded interval $[a, b]$. Then, the Darboux integral satisfies the following. 
    \begin{enumerate}
      \item \textit{Linearity}. Let $c \in \mathbb{R}$ be a constant. Then
        \begin{equation}
          \int_a^b f + \int_a^b g = \int_a^b (f + g), \qquad \int_a^b c f = c \int_a^b f
        \end{equation}
      \item \textit{Monotonicity}. If $f \leq g$ on $[a, b]$, then 
        \begin{equation}
          \int_a^b f \leq \int_a^b g
        \end{equation}
      \item \textit{Additivity}. For $a < c < b$, 
        \begin{equation}
          \int_a^c f + \int_c^b f = \int_a^b f
        \end{equation}
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    Listed. 
    \begin{enumerate}
      \item \textit{Linearity}. We prove the two properties. 
        \begin{enumerate}
          \item If $c \in \mathbb{R}$ and $f \in \mathcal{R}$, then we wish to show that $cf \in \mathcal{R}$ and $\int c f = c \int f$. 
            \begin{enumerate}
              \item If $c > 0$, then $U(cf, P) = c U(f, P)$, and $L(cf, P) = c L(f, P)$. 
              \item If $c < 0$, then $U(cf, P) = c L(f, P)$, and $L(cf, P) = c U(f, P)$. 
            \end{enumerate} 
            So, for all $\epsilon > 0$, we can find $P$ s.t. 
            \begin{equation}
              U(f, P) - L(f, P) < \frac{\epsilon}{c} \implies U(cf, P) - L(cf, P) < \epsilon
            \end{equation} 
            and so $cf \in \mathcal{R}$  

          \item If $f_1, f_2 \in \mathcal{R}$, then 
            \begin{equation}
              \osc_E (f_1 + f_2) \leq \osc_E (f_1) + \osc_E (f_2) \text{ since } \begin{cases} 
                \sup_E (f_1 + f_2) \leq \sup_E (f_1) + \sup_E (f_2) \\
                \inf_E (f_1 + f_2) \geq \inf_E (f_1) + \inf_E (f_2)
              \end{cases}
            \end{equation} 
            for all $E \subset [a, b]$, which implies that $f_1 + f_2 \in \mathcal{R}$. 
        \end{enumerate}

      \item \textit{Monotonicity}. 

      \item \textit{Additivity}. Let $P$ be a partition of $[a, b]$. If $c \in P$, then we can view $P = P_1 \cup P_2$. If $c \not\in P$, consider $P \cup \{c\}$. Then we have 
        \begin{align}
          U(f, P) & = U(f, P_1) + U(f, P_2) \\ 
          U(f, P) & = L(f, P_1) + L(f, P_2) 
        \end{align}
        So $f \in \mathcal{R}([a, c])$, $f \in \mathcal{R}([c, b])$. 
    \end{enumerate}
  \end{proof}
  \begin{proof}
    Removing the $a, b$ for convenience, we first show that $\int f_1 + f_2 = \int f_1 + \int f_2$. Let $\epsilon > 0$. Then there exists $P_i$ s.t. 
    \begin{equation}
      U(f_i, P_i) < \int f_i + \epsilon
    \end{equation}
    for $i = 1, 2$. Define $P = P_1 \cup P_2$ as the common refinement. Then 
    \begin{equation}
      U(f_i, P) < \int f_i + \epsilon
    \end{equation} 
    and so 
    \begin{align}
      \int f_1 + f_2 \leq U(f_1 + f_2, P) & \leq U(f_1, P) + U(f_2, P) \\ 
                                          & \leq 2 \epsilon + \int f_1 + \int f_2
    \end{align}
    which implies $\int f_1 + f_2 \leq \int f_1 + \int f_2$. To prove the other way, we see that 
    \begin{equation}
      \int (-f_1) + (-f_2) \leq \int (-f_1) + \int (-f_2) 
    \end{equation}
    and so 
    \begin{equation}
      - \int f_1 + f_2 \leq - \bigg( \int f_1 + \int f_2 \bigg) \implies \int f_1 + f_2 \geq \int f_1 + \int f_2
    \end{equation}
    For scalar multiplication, we can do similarly. 
  \end{proof}

  Note that by monotonicity, this immediately implies that given constants $m, M$ such that $m \leq f(x) \leq M$ at each $x \in [a, b]$, we have
  \begin{equation}
    m \cdot (b - a) \leq \int_a^b f(x) \leq M \cdot (b-a)
  \end{equation}
  In particular, if $0 \leq f(x)$ on $[a, b]$, then $0 \leq \int_a^b f(x)$. 
  
  \begin{theorem}[Restrictions of Integrable Functions]
    The restriction of $f$ in any $[c, d] \subset [a, b]$, denoted $f \big|_{[c,d]}$, is in $\mathcal{R}[c,d]$
  \end{theorem}
  \begin{proof}
    We can prove this by proving that the integral satisfies \ref{thm:cauchy-riemann-integrability}. 
  \end{proof}

\subsection{Riemann Integration}

  The rest of this section is not really necessary, but it's good to know for historical reasons and because some textbooks still default to the Riemann integral. Historically, a slightly earlier form of the integral invented by Riemann is properly known as the \textit{Riemann integral}. This is constructed using a tagged partition. 

  \begin{definition}[Tagged Partition]
    A \textbf{tagged partition} $(P, \xi)$ of interval $[a, b]$ is a partition $P$ with distinguished points $\xi_i \in (x_{i-1}, x_i)$ that lands in each interval. 
  \end{definition}

  \begin{definition}[Riemann Sums with Respect to Tagged Partition]
    Let $f: [a, b] \to \mathbb{R}$ be bounded and $(P, \xi)$ be a tagged partition of $[a, b]$. Then, the \textbf{Riemann sum with respect} to $P$ is 
    \begin{equation}
      S(f, P) = \sum_{i=1}^n f(\xi_i) (x_i - x_{i-1})
    \end{equation}

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[scale=0.8]
        % Define axes
        \draw[->] (-0.5,0) -- (10.5,0) node[right] {$x$};
        \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};
        
        % Function curve
        \draw[thick] plot[domain=0:10, samples=100, smooth] 
            coordinates {(0,2.5) (2,1.8) (4,1.5) (6,2) (8,3.2) (10,4.5)};
        
        % f label
        \node at (10.5,4.5) {$f$};
        
        % Partition points on x-axis
        \foreach \x/\label [count=\i from 0] in {
          0/a=x_0, 2/x_1, 4/x_2, 6/x_3, 8/x_4, 10/b=x_5
        } {
          \fill (\x,0) circle (0.07);
          \node[black, below, font=\footnotesize] at (\x,-0.35) {$\label$};
        }
        
        % Sample points ξᵢ (blue)
        \foreach \x/\label [count=\i from 1] in {
          1.1/\xi_1, 2.5/\xi_2, 5.4/\xi_3, 7.7/\xi_4, 9.5/\xi_5
        } {
          \fill[blue] (\x,0) circle (0.05);
          \node[blue, below, font=\footnotesize] at (\x,0) {$\label$};
          
        }
        \draw[blue, thin] (1.1,0) -- (1.1,2.1);
        \draw[blue, thin] (2.5,0) -- (2.5,1.7);
        \draw[blue, thin] (5.4,0) -- (5.4,1.8);
        \draw[blue, thin] (7.7,0) -- (7.7,3);
        \draw[blue, thin] (9.5,0) -- (9.5,4.2);
        
        % Rectangles for Riemann sum
        \foreach \xstart/\xend/\y [count=\i from 1] in {
          0/2/2.1, 2/4/1.7, 4/6/1.8, 6/8/3, 8/10/4.2
        } {
          % Rectangle with red border and pattern
          \draw[red] (\xstart,0) rectangle (\xend,\y);
          \fill[pattern=north east lines, pattern color=red!40] (\xstart,0) rectangle (\xend,\y);
          
          % Function value labels
          \node[red] at ({(\xstart+\xend)/2},{\y+0.3}) {$f(\xi_{\i})$};
        }
      \end{tikzpicture}
      \caption{Riemann sum approximation using sample points $\xi_i$ within each subinterval. This is known as a Riemann sum of a partition with distinguished points. The Riemann sum is a mapping that takes in a partition with distinguished points $p = (P, \xi)$ on the closed interval $[a, b]$ and outputs a number representing the total area of the Riemann sums. }
      \label{fig:riemann-sum-xi}
    \end{figure}
  \end{definition}

  Note that the natural way to define the Riemann integral is as the limit of the finite Riemann sums as partitions gets finer and finer. But we must be careful in saying what ``finer'' means. It is not simply as the number of partitions $n \rightarrow \infty$, since this may lead to multiple subsequential values of convergence by increasing the partition within different subsets of $[a,b]$. 

  \begin{figure}[H]
    \centering
    % First row - upper sequence (red)
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1,0.9) (2,1.5) (3,2.2) (4,2.8)};
        
        % Arrow at left end of curve
        \draw[->] (-0.2,0.6) -- (-0.4,0.6);
        % Arrow at right end of curve
        \draw[->] (3.8,2.7) -- (4.2,3.0);
        
        % Rectangles and patterns - rightmost is fixed
        \draw[red] (0,0) rectangle (1.33,0.9);
        \draw[red] (1.33,0) rectangle (2.67,1.5);
        \draw[red] (2.67,0) rectangle (4,2.8);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=red!40] (0,0) rectangle (1.33,0.9);
        \fill[pattern=north east lines, pattern color=red!40] (1.33,0) rectangle (2.67,1.5);
        \fill[pattern=north east lines, pattern color=red!40] (2.67,0) rectangle (4,2.8);
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1,0.9) (2,1.5) (3,2.2) (4,2.8)};
        
        % Arrow at left end of curve
        \draw[->] (-0.2,0.6) -- (-0.4,0.6);
        % Arrow at right end of curve
        \draw[->] (3.8,2.7) -- (4.2,3.0);
        
        % Rectangles and patterns - rightmost is fixed
        \draw[red] (0,0) rectangle (0.67,0.7);
        \draw[red] (0.67,0) rectangle (1.33,0.9);
        \draw[red] (1.33,0) rectangle (2,1.3);
        \draw[red] (2,0) rectangle (2.67,1.7);
        \draw[red] (2.67,0) rectangle (4,2.8);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=red!40] (0,0) rectangle (0.67,0.7);
        \fill[pattern=north east lines, pattern color=red!40] (0.67,0) rectangle (1.33,0.9);
        \fill[pattern=north east lines, pattern color=red!40] (1.33,0) rectangle (2,1.3);
        \fill[pattern=north east lines, pattern color=red!40] (2,0) rectangle (2.67,1.7);
        \fill[pattern=north east lines, pattern color=red!40] (2.67,0) rectangle (4,2.8);
        
        % Red arrow showing refinement
        \draw[->, red, thick] (4.3,1.5) -- (4.8,1.5);
        \node[red] at (4.55,1.7) {$n\to\infty$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1,0.9) (2,1.5) (3,2.2) (4,2.8)};
        
        % Arrow at left end of curve
        \draw[->] (-0.2,0.6) -- (-0.4,0.6);
        % Arrow at right end of curve
        \draw[->] (3.8,2.7) -- (4.2,3.0);
        
        % Rectangles and patterns - rightmost is fixed
        \draw[red] (0,0) rectangle (0.33,0.65);
        \draw[red] (0.33,0) rectangle (0.67,0.7);
        \draw[red] (0.67,0) rectangle (1,0.8);
        \draw[red] (1,0) rectangle (1.33,0.95);
        \draw[red] (1.33,0) rectangle (1.67,1.2);
        \draw[red] (1.67,0) rectangle (2,1.4);
        \draw[red] (2,0) rectangle (2.33,1.6);
        \draw[red] (2.33,0) rectangle (2.67,1.8);
        \draw[red] (2.67,0) rectangle (4,2.8);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=red!40] (0,0) rectangle (0.33,0.65);
        \fill[pattern=north east lines, pattern color=red!40] (0.33,0) rectangle (0.67,0.7);
        \fill[pattern=north east lines, pattern color=red!40] (0.67,0) rectangle (1,0.8);
        \fill[pattern=north east lines, pattern color=red!40] (1,0) rectangle (1.33,0.95);
        \fill[pattern=north east lines, pattern color=red!40] (1.33,0) rectangle (1.67,1.2);
        \fill[pattern=north east lines, pattern color=red!40] (1.67,0) rectangle (2,1.4);
        \fill[pattern=north east lines, pattern color=red!40] (2,0) rectangle (2.33,1.6);
        \fill[pattern=north east lines, pattern color=red!40] (2.33,0) rectangle (2.67,1.8);
        \fill[pattern=north east lines, pattern color=red!40] (2.67,0) rectangle (4,2.8);
        
        % Red arrow showing refinement with dots
        \draw[->, red, thick] (4.3,1.5) -- (4.8,1.5);
        \node[red] at (5.1,1.5) {$\cdots$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    
    % Second row - lower sequence (blue)
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1,0.9) (2,1.5) (3,2.2) (4,2.8)};
        
        % Arrow at left end of curve
        \draw[->] (-0.2,0.6) -- (-0.4,0.6);
        % Arrow at right end of curve
        \draw[->] (3.8,2.7) -- (4.2,3.0);
        
        % Rectangles and patterns - leftmost is fixed
        \draw[blue] (0,0) rectangle (1.33,0.6);
        \draw[blue] (1.33,0) rectangle (2.67,1.2);
        \draw[blue] (2.67,0) rectangle (4,2.2);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=blue!40] (0,0) rectangle (1.33,0.6);
        \fill[pattern=north east lines, pattern color=blue!40] (1.33,0) rectangle (2.67,1.2);
        \fill[pattern=north east lines, pattern color=blue!40] (2.67,0) rectangle (4,2.2);
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1,0.9) (2,1.5) (3,2.2) (4,2.8)};
        
        % Arrow at left end of curve
        \draw[->] (-0.2,0.6) -- (-0.4,0.6);
        % Arrow at right end of curve
        \draw[->] (3.8,2.7) -- (4.2,3.0);
        
        % Rectangles and patterns - leftmost is fixed
        \draw[blue] (0,0) rectangle (1.33,0.6);
        \draw[blue] (1.33,0) rectangle (2,1.2);
        \draw[blue] (2,0) rectangle (2.67,1.5);
        \draw[blue] (2.67,0) rectangle (3.33,2.0);
        \draw[blue] (3.33,0) rectangle (4,2.5);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=blue!40] (0,0) rectangle (1.33,0.6);
        \fill[pattern=north east lines, pattern color=blue!40] (1.33,0) rectangle (2,1.2);
        \fill[pattern=north east lines, pattern color=blue!40] (2,0) rectangle (2.67,1.5);
        \fill[pattern=north east lines, pattern color=blue!40] (2.67,0) rectangle (3.33,2.0);
        \fill[pattern=north east lines, pattern color=blue!40] (3.33,0) rectangle (4,2.5);
        
        % Blue arrow showing refinement
        \draw[->, blue, thick] (4.3,1.5) -- (4.8,1.5);
        \node[blue] at (4.55,1.7) {$n\to\infty$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.32\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (4.5,0) node[right] {};
        \draw[->] (0,0) -- (0,3) node[above] {};
        
        % Origin label
        \node[below] at (0,0) {$0$};
        \node[below] at (4,0) {$4$};
        
        % Function curve
        \draw[thick] plot[domain=0:4, samples=100, smooth] coordinates {(0,0.6) (1,0.9) (2,1.5) (3,2.2) (4,2.8)};
        
        % Arrow at left end of curve
        \draw[->] (-0.2,0.6) -- (-0.4,0.6);
        % Arrow at right end of curve
        \draw[->] (3.8,2.7) -- (4.2,3.0);
        
        % Rectangles and patterns - leftmost is fixed
        \draw[blue] (0,0) rectangle (1.33,0.6);
        \draw[blue] (1.33,0) rectangle (1.67,1.1);
        \draw[blue] (1.67,0) rectangle (2,1.3);
        \draw[blue] (2,0) rectangle (2.33,1.5);
        \draw[blue] (2.33,0) rectangle (2.67,1.7);
        \draw[blue] (2.67,0) rectangle (3,1.9);
        \draw[blue] (3,0) rectangle (3.33,2.1);
        \draw[blue] (3.33,0) rectangle (3.67,2.3);
        \draw[blue] (3.67,0) rectangle (4,2.5);
        
        % Fill with diagonal pattern
        \fill[pattern=north east lines, pattern color=blue!40] (0,0) rectangle (1.33,0.6);
        \fill[pattern=north east lines, pattern color=blue!40] (1.33,0) rectangle (1.67,1.1);
        \fill[pattern=north east lines, pattern color=blue!40] (1.67,0) rectangle (2,1.3);
        \fill[pattern=north east lines, pattern color=blue!40] (2,0) rectangle (2.33,1.5);
        \fill[pattern=north east lines, pattern color=blue!40] (2.33,0) rectangle (2.67,1.7);
        \fill[pattern=north east lines, pattern color=blue!40] (2.67,0) rectangle (3,1.9);
        \fill[pattern=north east lines, pattern color=blue!40] (3,0) rectangle (3.33,2.1);
        \fill[pattern=north east lines, pattern color=blue!40] (3.33,0) rectangle (3.67,2.3);
        \fill[pattern=north east lines, pattern color=blue!40] (3.67,0) rectangle (4,2.5);
        
        % Blue arrow showing refinement with dots
        \draw[->, blue, thick] (4.3,1.5) -- (4.8,1.5);
        \node[blue] at (5.1,1.5) {$\cdots$};
      \end{tikzpicture}
      \caption{}
    \end{subfigure}
    
    \caption{Upper (top row) and lower (bottom row) Riemann sums with refinement of partition. In the upper row, the rightmost rectangle remains fixed while other rectangles become thinner. In the lower row, the leftmost rectangle remains fixed while other rectangles become thinner.}
    \label{fig:upper-lower-refinement}
  \end{figure}

  \begin{definition}[Mesh of a Partition]
    Given a partition $P$, the \textbf{mesh} $\lambda(P)$ is the length of the largest subinterval. 
  \end{definition}

  An alternative way is to have the partitions all converge ``uniformly'' as in the maximum length of an interval in a partition must go to $0$. 

  This allows for extra degrees of freedom for choosing points, but it is generally not needed here. 

  \begin{theorem}[Equivalence of Riemann and Darboux Integrals]
    Let $f: [a, b] \to \mathbb{R}$ be a bounded function. Then, $f$ is Riemann integrable iff it is Darbox integrable. Furthermore, if $f$ is integrable, then its Riemann and Darboux integrals are equal. 
  \end{theorem}
  \begin{proof}
    
  \end{proof}

\subsection{Riemann-Stieltjes Integration} 

  The Riemann-Stieltjes integral is a less popular but still useful integration method that generalizes the Riemann integral. The construction is exactly the same, but now we consider a \textit{second} function $\varphi$ that determines the size of these intervals. This is generally used in physics a lot, and it is a must-know if you are doing physics. 

  \begin{definition}[Riemann-Stieltjes Sums with Respect to Partition]
    Let $P$ be a partition of $[a, b]$, $f: [a, b] \to \mathbb{R}$ be bounded, and $\varphi$ be a monotonically increasing function on $[a, b]$. Then, the \textbf{upper and lower Riemann-Stieltjes sums} are defined 
    \begin{align}
      U(P, f, \varphi) & = \sum_{i=1}^n \Big( \sup_{[x_{i-1}, x_i]} f \Big) \big[ \varphi(x_i) - \varphi(x_{i-1}) \big] \\ 
      L(P, f, \varphi) & = \sum_{i=1}^n \Big( \inf_{[x_{i-1}, x_i]} f \Big) \big[ \varphi(x_i) - \varphi(x_{i-1}) \big] 
    \end{align}
  \end{definition}

  \begin{definition}[Riemann-Stieltjes Integral]
    Let $f: [a, b] \to \mathbb{R}$ be bounded and $\varphi$ monotonically increasing on $[a, b]$. Then, the \textbf{upper and lower Riemann-Stieltjes integrals} of $f$ are defined 
    \begin{equation}
      \underline{\int_a^b} f \coloneqq \inf_P U(P, f, \varphi), \qquad \overline{\int_a^b} f \coloneqq \sup_P L(P, f, \varphi)
    \end{equation}
    If the upper and lower Riemann integrals are equal, then $f$ is said to be \textbf{Riemann-Stieltjes integrable} over $[a, b]$, denoted $f \in \mathcal{R}([a, b], \varphi)$, and we write the integral as 
    \begin{equation}
      \int_a^b f \,d\varphi
    \end{equation}
  \end{definition}

  We rederive the same properties again.   

  \begin{lemma}[Fundamental Lemma]
    If $P^\ast$ is a refinement of $P$ and $f: [a, b] \to \mathbb{R}$ is bounded, then 
    \begin{equation}
      L(P, f) \leq L(P^\ast, F) \leq U(P^\ast, F) \leq U(P, f) 
    \end{equation}
  \end{lemma}
  \begin{proof}
    Ommitted, since it is exactly the same as before. 
  \end{proof}

  \begin{theorem}
    We claim
    \begin{equation}
      \underline{\int_{a}^b} f \leq \overline{\int_{a}^{b}} f
    \end{equation}
  \end{theorem}
  \begin{proof}
    Ommitted, since it is exactly the same as before. 
  \end{proof}

  \begin{theorem}[Cauchy Criterion for Riemann-Stieltjes Integrability][thm:cauchy-riemann-stieltjes-integrability]
    $f \in \mathcal{R}$ iff $\forall \epsilon > 0$, there exists partition $P$ such that $U(P, f) - L(P, f) < \epsilon$. 
  \end{theorem}
  \begin{proof}
    Ommitted. 
  \end{proof}

  \begin{theorem}[Axiomatic Properties of Riemann-Stieltjes Integral]
    Let $f, g$ be real-valued bounded functions over bounded interval $[a, b]$, and $g$ a monotonic function over $[a, b]$. Then, the Riemann-Stieltjes satisfies the following. 
    \begin{enumerate}
      \item \textit{Linearity}. Let $c \in \mathbb{R}$ be a constant. Then, 
      \item \textit{Monotonicity}. 
      \item \textit{Additivity}. 
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    Listed. 
    \begin{enumerate}
      \item \textit{Linearity}.
      \item \textit{Monotonicity}. 
      \item \textit{Additivity}. 
    \end{enumerate}
  \end{proof}

\subsection{Conditions for Riemann Integrability}

  Note that a necessary condition of $f$ being Riemann integrable is that $f$ is bounded. In fact it is defined that way. You may know that a sufficient condition of integrability is that it is continuous, but we can prove something slightly weaker. 

  \begin{definition}[Oscillation]
    Given an interval $I$, the \textbf{oscillation} of $f$ on $I$ is defined 
    \begin{equation}
      \mathop{\osc}_{I} (f) \coloneqq \sup_I (f) - \inf_I (f)
    \end{equation}
  \end{definition}

  Intuitively, a function $f$ is Riemann integrable if we can make $U(f, P) - L(f, P)$ as small as we wish. This is the case if we can find a sufficiently refined partition $P$ such that the oscillation on $f$ on each interval is small. 

  \begin{lemma}[Functions with Vanishing Osillations are Riemann Integrable]
    Let $f$ be a bounded on a closed interval $[a, b]$. If, for every $\epsilon > 0$, there exists a partition $P$ such that
    \begin{equation}
      \sum_{i=0}^{n-1} \mathop{\osc}_{[x_i, x_{i+1}]} f < \epsilon
    \end{equation}
    then $f$ is Riemann integrable. 
  \end{lemma}
  \begin{proof}
    Given $\epsilon > 0$, choose $\epsilon/(b-a)$. By assumption we can find a partition $P$ in which the total oscillation is bounded above by $\epsilon/(b-a)$. Therefore, 
    \begin{align}
      U(P, f) - L(P, f) & = \sum_{i=0}^{n-1} \sup_{[x_i, x_{i+1}]} f(x) \Delta x_i - \sum_{i=0}^{n-1} \inf_{[x_i, x_{i+1}]} f(x) \Delta x_i \\ 
                        & = \sum_{i=0}^{n-1} (\sup_{[x_i, x_{i+1}]} f(x) - \inf_{[x_i, x_{i+1}]} f(x) ) \Delta x_i \\ 
                        & < \sum_{i=0}^{n-1} \mathop{\osc}_{[x_i, x_{i+1}]} f \Delta x_i \\ 
                        & \leq \sum_{i=0}^{n-1} \frac{\epsilon}{b-a} \Delta x_i \\ 
                        & = \frac{\epsilon}{b-a} \sum_{i=0}^{n-1} \Delta x_i \\
                        & = \frac{\epsilon}{b-a} (b-a) = \epsilon
    \end{align}
  \end{proof} 

  With this, we can use the uniform continuity of continuous functions over a compact set to place a bound on the oscillation of each subinterval---and thus a bound on the oscillation of the whole interval. 

  \begin{theorem}[Continuous Functions are Riemann Integrable][thm:continuous-riemann]
    $f$ continuous on $[a, b] \implies f$ is Riemann integrable on $[a, b]$. 
  \end{theorem}
  \begin{proof}
    If $f$ is continuous, then by EVT it is bounded and uniformly continuous. Therefore we can take the evenly-partitioned intervals of $[a, b]$ and by uniform continuity, the oscillation tends to $0$, and we are done. 

    Perhaps more explicitly, we wish to show that for all $\epsilon > 0$, there exists partition $P$ s.t. $U(P, f) - L(P, f) < \epsilon$. Now let $\epsilon > 0$, and since it's uniformly continuous, take $\delta > 0$ s.t. 
    \begin{equation}
      |x - y| < \delta \implies |f(x) - f(y)| < \frac{\epsilon}{2(b-a)}
    \end{equation}
    Let $N \in \mathbb{N}$ be so large that $\frac{b-a}{N} < \delta$. Now consider the partition of $[a, b]$ given by $x_i = a + \frac{b-a}{N} i$ for $0 \leq i < N$. Intuitively, we want these subintervals to be so small that $f$ will not deviate too widely. So it better be the case that $\frac{b - a}{N} < \delta$. So, we have
    \begin{align}
      U(P, f) - L(P, f) & = \sum_{i=1}^n \sup_{[x_{i-1}, x_{i}]} f(x) (x_i - x_{i-1}) - \sum_{i=1}^n \inf_{[x_{i-1}, x_{i}]} f(x) (x_i - x_{i-1}) \\ 
                        & = \sum_{i=1}^n (\sup_{[x_{i-1}, x_{i}]} f(x) - \inf_{[x_{i-1}, x_{i}]} f(x) ) (x_i - x_{i-1}) \\ 
                        & < \sum_{i=0}^{N-1} \frac{\epsilon}{2 (b - a)} (x_i - x_{i-1}) \\
                        & = \frac{\epsilon}{2 (b - a)} \cdot (b - a) < \frac{\epsilon}{2} < \epsilon
    \end{align}
  \end{proof}

  We can actually make a stronger claim. 

  \begin{corollary}[Integrability of Discontinuous Functions]
    If a bounded function $f$ on a closed interval $[a, b]$ is continuous everywhere except at a finite set of points, then $f \in \mathcal{R}[a, b]$. 
  \end{corollary}

  \begin{corollary}[Integrability of Monotonic Functions]
    A bounded monotonic function on a closed interval is integrable on that interval. 
  \end{corollary} 

  \begin{theorem}[Continuous Compositions of Integrable Functions are Integrable]
    Let $f \in \mathcal{R}([a, b])$. Assume $\phi: \mathbb{R} \to \mathbb{R}$ is continuous. Then $\phi \circ f \in \mathcal{R}([a, b])$. 
  \end{theorem}
  \begin{proof}
    Since $f \in \mathcal{R}([a, b])$ is bounded, let $|f(x)| \leq M$ for all $x \in [a, b]$ for some $M \geq 0$. Now let $K = \sup_{t \in [-M, M]} \phi(t)$, which exists since $[-M, M]$ is compact and $\phi$ is continuious. $\phi$ is also uniformly continiuous on $[-M, M]$. 

    Now let $\epsilon > 0$. Then there exists a $\delta > 0$ s.t. $|t - s| < \delta \implies |\phi(t) - \phi(s)| < \epsilon$. Consequently, 
    \begin{equation}
      |f(x) - f(y)| < \delta \implies |\phi(f(x)) - \phi(f(y))| < \epsilon
    \end{equation} 
    Since $f \in \mathcal{R}([a, b])$, we can find a partition $P$ of $[a, b]$ s.t. 
    \begin{equation}
      U(f, P) - L(f, P) < \delta^2 \implies \sum_{i=1}^{n-1} \big( \sup_{[x_i, x_{i+1}]} f - \inf_{[x_i, x_{i+1}]} f \big) \Delta x_i < \delta^2
    \end{equation} 
    Let 
    \begin{align}
      A & = \{ i \mid \sup_{[x_i, x_{i+1}]} f - \inf_{[x_i, x_{i+1}]} f < \delta \} \\ 
      B & = \{ i \mid \sup_{[x_i, x_{i+1}]} f - \inf_{[x_i, x_{i+1}]} f \geq \delta \} 
    \end{align} 
    Colloquially, we can think of $A$ as the ``good'' intervals with small oscillations, and $B$ as the ``bad'' intervals with larger oscillations. So, 
    \begin{equation}
      \sum_{i \in B} \Delta x_i = \frac{1}{\delta} \sum_{i \in B} \delta \Delta x_i \leq \frac{1}{\delta} \sum_{i \in B} \mathop{\osc}_{[x_i, x_{i+1}]} \Delta x_i < \frac{1}{\delta} \delta^2 = \delta
    \end{equation}
    Now, compute 
    \begin{align}
      U(\phi(f), P) - L(\phi(f), P) & = \sum_i \osc_{[x_i, x_{i+1}]} (\phi(f)) \Delta x_i  \\ 
                                    & = \sum_{i \in A} \osc_{[x_i, x_{i+1}]} (\phi(f)) \Delta x_i + \sum_{i \in B} \osc_{[x_i, x_{i+1}]} (\phi(f)) \Delta x_i 
    \end{align}
    In the good sets, if $f(x)$'s are within $\delta$ of each other, the oscillation by uniform continuity implies $\osc(\phi(f)) < \epsilon$. In the bad set, we have $\osc_{[x_i, x_{i+1}]} (\phi(f)) < 2K$, so the above can be bounded by 
    \begin{align}
      '' & \leq \epsilon \sum_{i \in A} \Delta x_i + \sum_{i \in B} 2K \Delta x_i \\
         & \leq \epsilon (b - a) + 2K \delta \\
         & < \epsilon (b - a + 2K)
    \end{align}
    where the penultimate step is due to $\sum_{i \in B} \Delta x_i < \delta$. 
  \end{proof}

  \begin{theorem}[Triangle Inequality for Riemann Integrals]
    If $f \in \mathcal{R}[a, b]$, then $|f| \in \mathcal{R}[a, b]$. Furthermore, 
    \begin{equation}
      \bigg| \int_a^b f \bigg| \leq \int_a^b |f| 
    \end{equation}
  \end{theorem}
  \begin{proof}
    $\phi(x) = |x|$ is continuous, so $\phi(f) \in \mathcal{R}$. Note that if $f \geq 0$, then $\int_a^b f \geq 0$. Consider $|f| - f$ and $|f| + f$, both $\geq 0$. They are integrable as the image of $f$ composed with continuous functions. So we have 
    \begin{align}
      \int |f| + f \geq 0 & \implies \int |f| \geq - \int f \\ 
      \int |f| - f \geq 0 & \implies \int |f| \geq \int f
    \end{align}
    and so taking the maximum of the right hand side gives $\int |f| \geq | \int f|$. 
  \end{proof}

  However, contrary to intuition, $f, g$ both integrable does not imply that $g \circ g$ is integrable. We present a counterexample. 

  \begin{example}[Composition of Integrable Functions May Not be Integrable]
    Consider the functions
    \begin{equation}
      |\mathrm{sgn}|(x) \coloneqq \begin{cases}
        1 & x \neq 0 \\
        0 & x = 0
      \end{cases}
    \end{equation}
    and the Riemann function 
    \begin{equation}
      \mathcal{R}(x) \coloneqq \begin{cases}
        \frac{1}{n} & x = \frac{m}{n} \in \mathbb{Q}, \gcd(m, n) = 1 \\
        0 & x \in \mathbb{R} \setminus \mathbb{Q}
      \end{cases}
    \end{equation}
    We can see that $\mathcal{R}$ is continuous at all irrational points and discontinuous at all rational points except $0$, meaning that it is integrable ($\mathbb{Q}$ has measure zero). Then, the composition of these two functions is precisely the Dirichlet function
    \begin{equation}
      \mathcal{D}(x) = |\mathrm{sgn}| \circ \mathcal{R}
    \end{equation}
    which is not integrable. 
  \end{example}

  \begin{theorem}[Products of Riemann Integrable Functions are Riemann Integrable]
    If $f, g \in \mathcal{R}[a, b]$, then $fg \in \mathcal{R}[a, b]$. 
  \end{theorem}
  \begin{proof}
    A nice trick is that 
    \begin{equation}
      fg = \frac{1}{4} \big( (f + g)^2 - (f - g)^2 \big) 
    \end{equation}
    which is in $\mathcal{R}([a, b])$ since the sum, difference, and squaring functions are all continuous, and hence the composition $\phi(f, g)$ is Riemann integrable. 
  \end{proof}

\subsection{The Fundamental Theorem of Calculus} 

  \begin{theorem}[Mean Value Theorem of the Integral]
    Given $f \in \mathcal{R}[a, b]$, with 
    \begin{equation}
      m = \inf_{x \in [a, b]} f(x), \qquad M = \sup_{x \in [a, b]} f(x)
    \end{equation}
    Then 
    \begin{enumerate}
      \item there exists a number $\mu \in [m, M]$ such that
      \begin{equation}
        \int_a^b f = \mu \cdot (b - a)
      \end{equation}

      \item Furthermore, if $f \in C[a, b]$, it there exists a point $\xi \in [a, b]$ such that
      \begin{equation}
        \int_a^b f = f(\xi) (b - a)
      \end{equation}
    \end{enumerate}
  \end{theorem}

  \begin{theorem}[Bonnet's Formula]
    If $f, g \in \mathcal{R}[a, b]$ and $g$ is a monotonic function on $[a, b]$, then there exists a point $\xi \in [a, b]$ such that
    \begin{equation}
      \int_a^b (f \cdot g) (x)\,dx = g(a) \int_a^\xi f(x)\,dx + g(b) \int_\xi^b f(x)\,dx
    \end{equation}
  \end{theorem}

  Let $f \in \mathcal{R}[a, b]$, and let us choose an $x \in [a, b]$ in order to construct the function
  \begin{equation}
    F(x) \coloneqq \int_a^x f(t)\,dt
  \end{equation}
  which is called an integral with a variable upper limit. By doing this, we can ``upgrade'' a Riemann integrable function $f$ to a continuous function $F$. 

  \begin{theorem}[First Fundamental Theorem of Calculus]
    Define $F: [a, b] \to \mathbb{R}$ by 
    \begin{equation}
      F(x) \coloneqq \int_a^x f(t) \,dt 
    \end{equation}
    Then 
    \begin{enumerate}
      \item $F$ is continuous. 
      \item If $F$ is continuous at $x_0$, then $F^\prime (x_0) = f(x_0)$. 
    \end{enumerate}

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[scale=1]
        % Define axes
        \draw[->] (-0.5,0) -- (6,0) node[right] {$t$};
        \draw[->] (0,-0.5) -- (0,3) node[above] {$y$};
        
        % Draw vertical lines for a and x (renamed from c and b)
        \draw[thick, dashed] (0.5,0) node[below] {$a$} -- (0.5,1.4);
        \draw[thick, dashed] (4,0) node[below] {$x$} -- (4,2);
        
        % Blue pattern only
        \begin{scope}
          \clip (0.5,-0.5) rectangle (4,4);
          \fill[pattern=north east lines, pattern color=blue!60] 
              plot[smooth, tension=0.7] coordinates {(0,0.5) (1,2) (2,1.5) (3,2.5) (4,2) (5,3)} 
              -- (5,0) -- (0.5,0) -- cycle;
        \end{scope}
        
        % Draw the function curve on top of everything
        \draw[thick] 
            plot[smooth, tension=0.7] coordinates {(0,0.5) (1,2) (2,1.5) (3,2.5) (4,2) (5,3)};
        
        % Draw 3 blue arrows vertically stacked to the right of the blue pattern
        \draw[->, blue, thick] (4.5-0.3,0.8) -- (5.2-0.3,0.8);
        \draw[->, blue, thick] (4.5-0.3,1.2) -- (5.2-0.3,1.2);
        \draw[->, blue, thick] (4.5-0.3,1.6) -- (5.2-0.3,1.6);
        
        % Add a red point at (4,2) and label it with f(x)
        \fill[red] (4,2) circle (0.08);
        \node[above, red] at (4,2.2) {$f(x)$};
        
        % Add label F'(x) = f(x) to the right of the blue arrows
        \node[blue] at (5.8,1.2) {$F'(x) = f(x)$};
        
        % Add F(x) label above the curve
        \node[blue] at (2,2.5) {$F(x)$};
      \end{tikzpicture}
      \caption{This theorem amazingly tells us that the rate at which the integral $F$ is increasing at $x$ (represented by the increasing area under the curve of $f$) is equal to the value of $f$ at the point $x$ itself! } 
      \label{fig:ftc1-illustration}
    \end{figure}
  \end{theorem}
  \begin{proof} 
    Listed. 
    \begin{enumerate}
      \item Since $f \in \mathcal{R}([a, b])$, let $M = \sup_{x \in [a, b]} |f(x)| < + \infty$. WLOG let $x, y \in [a, b]$ with $x < y$. Then, we can use the ``trick'' by writing the difference of $F$ as an integral, which follows from linearity of the integral over an interval. So, we have 
      \begin{align}
        |F(x) - F(y)| = \bigg| \int_x^y f(t) \, dt \bigg| & \leq \int_x^y |f(t)| \,dt \\
                                                          & \leq \int_x^y M \,dt  = M |y - x|
      \end{align}
      So given $\epsilon > 0$, we can take $\delta = \epsilon/M$ and $F$ is continuous. 

      \item Now let's claim 
        \begin{equation}
          \lim_{h \to 0} \frac{1}{h} \big( F(x_0 + h) - F(x_0) - f(x_0) h \big) = 0 \iff F^\prime (x_0) = f(x_0)
        \end{equation} 
        since if the limit exists, we can add $f(x_0)$ to both sides. The term in the limit is 
        \begin{equation}
          \frac{1}{h} \bigg| \int_a^{x_0 + h} f(t) \,dt - \int_a^{x_0} f(t) \,dt - f(x_0) h \bigg| \leq \frac{1}{h} \bigg| \int_{x_0}^{x_0 + h} f(t) \,dt - h f(x_0) \bigg|
        \end{equation}
        Now we do a trick that is simple but powerful. Notice that $h f(x_0) = \int_{x_0}^{x_0 + h} f(x_0) \,dt$, so we can join it with the integral.\footnote{Elgindi talked about how simple tricks can go a long way, e.g. the guy who was a master of Cauchy-Schwarz inequality.} So, 
        \begin{align}
          '' & = \frac{1}{h} \bigg| \int_{x_0}^{x_0 + h} f(t) - f(x_0) \,dt \bigg| \\ 
             & \leq \frac{1}{h} \int_{x_0}^{x_0 + h} \big| f(t) - f(x_0) \big| \,dt \\ 
             & \leq \frac{1}{h} \int_{x_0}^{x_0 + h} \sup_{t \in [x_0, x_0 + h]} \big| f(t) - f(x_0) \big| \,dt 
        \end{align} 
        Note that the supremum term in the integral is just a number, so evaluating it and taking the limit as $h \to 0$ gives 
        \begin{equation}
          \sup_{t \in [x_0, x_0 + h]} |f(t) - f(x_0)| \to 0 \text{ as } h \to 0
        \end{equation}
        since $f$ is continuous at $x_0$. 
    \end{enumerate}
  \end{proof}

  \begin{corollary}
    Every bounded function $f: [a, b] \longrightarrow \mathbb{R}$ on the closed interval $[a, b]$ and has only a finite number of points of discontinuity has a primitive, and every primitive of $f$ on $[a, b]$ has the form 
    \begin{equation}
      F(x) \coloneqq \int_a^x f(t)\,dt + c
    \end{equation}
    where $c$ is a constant. 
  \end{corollary}

  \begin{theorem}[Second Fundamental Theorem of Calculus]
    Let $f$ be a real-valued function on a closed interval $[a, b]$ with $F$ any primitive of $f$ on $[a, b]$. If $f$ is Riemann-integrable (i.e. $f$ bounded with finite points of Lebesgue measure zero) on $[a, b]$, then 
    \begin{equation}
      \int_a^b f  = F(b) - F(a)
    \end{equation}

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[scale=1]
        % Define axes
        \draw[->] (-0.5,0) -- (6,0) node[right] {$t$};
        \draw[->] (0,-0.5) -- (0,3) node[above] {$y$};
        
        % Draw vertical lines for c, a, and b
        \draw[thick, dashed] (0.5,0) node[below] {$c$} -- (0.5,1.4);
        \draw[thick, dashed] (2,0) node[below] {$a$} -- (2,1.5);
        \draw[thick, dashed] (4,0) node[below] {$b$} -- (4,2);
        
        % Add borders to make areas clearer - using exact same coordinates as function
        \begin{scope}
          \clip (0.5,-0.5) rectangle (2,4);  % Clip to only show x from 0.5 to 5
          % Shade the area from c to a (F(a)) with red pattern
          \fill[pattern=north west lines, pattern color=red!60] 
              plot[smooth, tension=0.7] coordinates {(0,0.5) (1,2) (2,1.5) (3,2.5) (4,2) (5,3)} 
              -- (5,0) -- (0.5,0) -- cycle;
        \end{scope}

        \begin{scope}
          \clip (0.5,-0.5) rectangle (4,4);  % Clip to only show x from 0.5 to 5
          % Shade the area from c to a (F(a)) with red pattern
          \fill[pattern=north east lines, pattern color=blue!60] 
              plot[smooth, tension=0.7] coordinates {(0,0.5) (1,2) (2,1.5) (3,2.5) (4,2) (5,3)} 
              -- (5,0) -- (0.5,0) -- cycle;
        \end{scope}
        
        % Draw the function curve on top of everything
        \draw[thick] 
            plot[smooth, tension=0.7] coordinates {(0,0.5) (1,2) (2,1.5) (3,2.5) (4,2) (5,3)};
        
        % Label the curve
        \node[font=\bfseries] at (5.5,3) {$f(t)$};
        
        % Add labels for the areas with background
        \node[fill=white, text=red!80!black, font=\bfseries, inner sep=2pt] at (1.25,0.5) {$F(a)$};
        \node[fill=white, text=blue!80!black, font=\bfseries, inner sep=2pt] at (3,0.7) {$F(b)$};
      \end{tikzpicture}
      \caption{Graphical illustration of the Fundamental Theorem of Calculus, showing how the definite integral equals the difference of antiderivative values.} 
      \label{fig:ftc2-illustration}
    \end{figure}
  \end{theorem}
  \begin{proof}
    We already know that a bounded function on a closed interval having a finite number of discontinuities is integrable, and by the corollary, we are guaranteed an existence of a primitive $F(x)$ of the function $f$ on $[a, b]$ with the form 
    \begin{equation}
      F (x) \coloneqq \int_a^x f(t)\,dt + c
    \end{equation}
    Setting $x = a$, we find that $c = F(a)$, and so 
    \begin{equation}
      F(x) \coloneqq \int_a^x f(t)\,dt + F(a)
    \end{equation}
    Evaluating $F$ at $x = b$ gives
    \begin{equation}
      \int_a^b f(t)\,dt = F(b) - F(a)
    \end{equation}
  \end{proof}

  Since we have established a bunch of derivative rules for polynomials, exponential/logarithmic, trigonometric functions, we can invoke the second fundamental theorem of calculus to derive the cheat sheet rules of integration. 

  \begin{corollary}[Power Rule of Integration]

  \end{corollary}

  \begin{corollary}[Integration of Exponential and Logarithmic Functions]
    
  \end{corollary}

  \begin{corollary}[Integration of Trigonometric Functions]
    
  \end{corollary}

  \begin{theorem}[Integral Form of the Remainder]
    If $f: E \longrightarrow \mathbb{R}$ has continuous derivatives up to order $n$ on the closed interval $[a, x]$, then Taylor's formula holds
    \begin{equation}
      f(x) = f(a) + \frac{f^\prime (a)}{1!} (x - a) + \ldots + \frac{f^{(n-1)}(a)}{(n-1)!} (x - a)^{n-1} + r_{n-1}(a; x)
    \end{equation}
    where 
    \begin{equation}
      r_{n-1} (a;x) = \frac{1}{(n-1)!} \int_a^x f^{(n)} (t) (x - t)^{n-1} \,dt
    \end{equation}
    This form is called \textbf{Taylor's formula with the integral form of the remainder}. 
  \end{theorem}
  \begin{proof}
    Using the 2nd fundamental theorem and the definite integration by parts formula, we can carry out the following chain of transformations, assuming continuity and differentiability when needed. 
    \begin{align*}
      f(x) - f(a) & = \int_a^x f^\prime (t) \,dt \\
      & = - \int_a^x f^\prime(t) (x - t)^\prime \,dt \\
      & = -f^\prime (t) (x - t)\big|_a^x + \int_a^x f^{\prime\prime} (t) (x - t) \,dt \\
      & = f^\prime (a) (x - a) - \frac{1}{2} \int_a^x f^{\prime\prime} (t) \big( (x - t)^2\big)^\prime \,dt \\
      & = f^\prime (x - a) - \frac{1}{2} f^{\prime\prime} (t) (x - t)^2 \big|_a^x + \frac{1}{2} \int_a^x f^{\prime\prime\prime} (t) (x - t)^2\,dt \\
      & = f^\prime(a) (x - a) + \frac{1}{2} f^{\prime\prime} (a) (x - a)^2 - \frac{1}{2 \cdot 3} \int_a^x f^{\prime\prime\prime} (t) \big((x - t)^3\big)^\prime\,dt \\
      & = \ldots \\
      & = f^\prime (a) (x - a) + \ldots + \frac{1}{(n-1)!} f^{(n-1)} (a)(x - a)^{n-1} + r_{n-1}(a;x)
    \end{align*}
    where $r_{n-1}(a;x)$ is given by the integral formula mentioned. 
  \end{proof}

\subsection{Change of Variable}

  We now show and prove the method what we call ``u-substitution'' for definite integration. We first start off with a change of variable induced by a monotonic continuous function, and then generalize it for $C^1$ functions.  

  \begin{theorem}[Change of Variable for Monotonic Functions]
    If
    \begin{enumerate}
      \item $f \in \mathcal{R}([a, b])$ and 
      \item $\varphi$ is continuous and strictly increasing on $[a, b]$, 
    \end{enumerate}
    then 
    \begin{equation}
      \int_a^b f(\varphi(x)) \cdot \varphi^\prime (x) \,dx = \int_{\varphi(a)}^{\varphi(b)} f(u) \,du
    \end{equation}
  \end{theorem}
  \begin{proof}
    
  \end{proof}

  \begin{theorem}[Change of Variable]
    If
    \begin{enumerate}
      \item $f \in C([a, b])$\footnote{Note that we strengthen our assumption to continuous, not just Riemann integrable $f$!}, and 
      \item $\varphi$ is continuously differentiable on $[a, b]$, 
    \end{enumerate}
    then 
    \begin{equation}
      \int_a^b f(\varphi(x)) \cdot \varphi^\prime (x) \,dx = \int_{\varphi(a)}^{\varphi(b)} f(u) \,du
    \end{equation}
  \end{theorem}
  \begin{proof}
  \end{proof}

  Note that we have made the additional assumption that continuity is needed. 

  \begin{example}[Counterexample when $f$ is Not Continuous]
    If $f$ is Riemann integrable, ...
  \end{example}

\subsection{Integration by Parts}

  Now a direct application of the fundamental theorem of calculus is the integration by parts. By the product rule of differentiation, we have
  \begin{equation}
    (u \cdot v)^\prime (x) = (u^\prime \cdot v)(x) + (u \cdot v^\prime) (x)
  \end{equation}
  where by hypothesis, $u^\prime \cdot v, u \cdot v^\prime$ are continuous and hence integrable on $[a, b]$. Using the linearity of the integral and the 2nd fundamental theorem of calculus, we get
  \begin{equation}
    (u \cdot v) (x) \big|^b_a = \int_a^b (u^\prime \cdot v) + \int_a^b (u \cdot v^\prime) 
  \end{equation}

  \begin{theorem}[Integration by Parts]
    Suppose $F, G: [a, b] \to \mathbb{R}$ are differentiable, with $F^\prime = f, G^\prime = g \in \mathcal{R}([a, b])$. Then 
    \begin{equation}
      \int_a^b Fg = (FG) \big|_a^b - \int_a^b fG
    \end{equation}
  \end{theorem} 
  \begin{proof}
    
  \end{proof}

\subsection{Improper Integrals}

  Note that \hyperref[def:riemann-integral]{by definition of the Riemann integral}, it makes sense to talk about integrability over \textit{bounded} functions over \textit{closed and bounded intervals}. This is in a sense quite restrictive, since we cannot integrate over ``singularities'' where either the interval or the function is unbounded. We develop the tools of improper integration to deal with this problem; there are two types of improper integrals. 

  \begin{definition}[Improper Integral of Unbounded Interval]
    Let $f$ be bounded on its domain. 
    \begin{enumerate}
      \item If it is defined on $[a, +\infty)$ and is integrable on every closed interval $[a, b] \subset [a, +\infty)$, then we define 
        \begin{equation}
          \int_a^{+\infty} f \coloneqq \lim_{b \rightarrow + \infty} \int_a^b f
        \end{equation}

      \item If it is defined on $(-\infty, b]$ and is integrable on every closed interval $[a, b] \subset (-\infty, b]$, then we define 
        \begin{equation}
          \int_{-\infty}^b f \coloneqq \lim_{a \rightarrow -\infty} \int_a^b f
        \end{equation} 

      \item If it is defined on $\mathbb{R}$ and is integrable on every closed interval $[a, b] \subset \mathbb{R}$, then we define\footnote{Small technicality is that we have to prove that this is independent of the order in which we take the limits.} 
        \begin{equation}
          \int_{-\infty}^{+\infty} f \coloneqq \lim_{b \rightarrow +\infty} \lim_{a \rightarrow -\infty} \int_a^b f
        \end{equation} 
    \end{enumerate}
    If the limit exists, then we say that the integral \textbf{converges} and \textbf{diverges} otherwise. 
  \end{definition}

  \begin{example}[Gaussian Integral]
    The integral 
    \begin{equation}
      \int_{-\infty}^{+\infty} e^{-x^2}\,dx = \sqrt{\pi}
    \end{equation}
  \end{example}

  \begin{definition}[Improper Integral of Unbounded Function]
    Let $f: [a, b] \to \mathbb{R}$ be unbounded at some point $\omega$ in its domain and is integrable on any closed interval $[c, d] \subset [a, b]$ not containing $\omega$. 
    \begin{enumerate}
      \item If $\omega = a$, then we define 
        \begin{equation}
          \int_a^b f \coloneqq \lim_{c \rightarrow a^+} \int_c^b f
        \end{equation}

      \item If $\omega = b$, then we define 
        \begin{equation}
          \int_a^b f \coloneqq \lim_{d \rightarrow b^-} \int_a^d f
        \end{equation}

      \item If $\omega \in (a, b)$, then we define 
        \begin{equation}
          \int_a^b f = \lim_{d \to s^+} \int_a^d f + \lim_{c \to s^-}\int_c^b f 
        \end{equation}
    \end{enumerate}
  \end{definition}

  \begin{lemma}[Properties of the Improper Integral]
    Suppose $f, g$ are functions defined on interval $[a, \omega)$ (without loss of generality, we let $\omega$ be the upper limit of integration) and integrable on every closed interval $[a, b] \subset [a, \omega)$. Suppose the improper integrals 
    \begin{equation}
      \int_a^\omega f \text{ and } \int_a^\omega g
    \end{equation}
    are well-defined. 
    \begin{enumerate}
      \item For any $\lambda_1, \lambda_2 \in \mathbb{R}$ the function $(\lambda_1 f + \lambda_2 g)(x)$ is integrable in the improper sense on $[a, \omega)$ and
        \begin{equation}
          \int_a^\omega \lambda_1 f + \lambda_2 g = \lambda_1 \int_a^\omega f + \lambda_2 \int_a^\omega g
        \end{equation}

      \item For any $c \in [a, \omega)$, 
        \begin{equation}
          \int_a^\omega f = \int_a^c f + \int_c^\omega f
        \end{equation}

      \item If $\varphi: [\alpha, \gamma) \longrightarrow [a, \omega)$ is a smooth strictly monotonic mapping with $\varphi(\alpha) = a$ and $\varphi(\beta) \rightarrow \omega$ as $\beta \rightarrow \gamma^-$, then the improper integral of the function $t \mapsto (f \circ \varphi)(t) \varphi^\prime (t)$ over $[\alpha, \gamma)$ exists and 
        \begin{equation}
          \int_a^\omega f(x)\,dx = \int_\alpha^\gamma (f \circ \varphi)(t) \varphi^\prime (t)\,dt
        \end{equation}
    \end{enumerate}
  \end{lemma}

  Note that by definition, an improper integral $\int_a^\omega f \coloneqq \lim_{b \rightarrow \omega} \int_a^b f$ is a limit of the function $F(b) \coloneqq \int_a^b f$ as $b \rightarrow \omega$. This means that we can use the Cauchy criterion to determine the convergence of this limit, and hence, existence of this improper integral. 

  \begin{theorem}[Cauchy Criterion for Convergence of an Improper Integral]
    If the function $x \mapsto f(x)$ is defined on the interval $[a, \omega)$ and integrable on every closed interval $[a, b] \subset [a, \omega)$, then the integral 
    \begin{equation}
      \int_a^\omega f
    \end{equation}
    converges if and only if for every $\epsilon > 0$ there exists $B \in [a, \omega)$ such that the relation
    \begin{equation}
      \Bigg| \int_{b_1}^{b_2} f \bigg| < \epsilon
    \end{equation}
    holds for any $b_1, b_2 \in [a, \omega)$ satisfying $B < b_1$ and $B < b_2$. 
  \end{theorem}
  \begin{proof}
    We have
    \begin{equation}
      \int_{b_1}^{b_2} f = \int_a^{b_2} f - \int_a^{b_1} f = F(b_2) - F(b_1)
    \end{equation}
    and therefore the condition is simply the Cauchy criterion for the existence of a limit for the function $\mathcal{F}(b)$ as $b \rightarrow \omega$. 
  \end{proof}

  \begin{definition}[Absolute Convergence of an Improper Integral]
    The improper integral 
    \begin{equation}
      \int_a^\omega f
    \end{equation}
    \textbf{converges absolutely} if the integral
    \begin{equation}
      \int_a^\omega |f|
    \end{equation}
    converges. Clearly, the inequality
    \begin{equation}
      \Bigg| \int_{b_1}^{b_2} f \Bigg| \leq \Bigg| \int_{b_1}^{b_2} |f| \Bigg|
    \end{equation}
    implies that if an improper integral converges absolutely, then it converges. 
  \end{definition}

  This study of absolute convergence reduces to the study of convergence of integrals of nonnegative functions. The following lemma is useful in determining convergence of such functions. 

  \begin{lemma}
    Let there be a function $f$ defined on interval $[a, \omega)$ that is also integrable over every closed interval $[a, b] \subset [a, \omega)$. If $f(x) \geq 0$ on $[a, \omega)$, then the improper integral 
    \begin{equation}
      \int_a^\omega f
    \end{equation}
    exists if and only if the function 
    \begin{equation}
      \mathcal{F}(b) \coloneqq \int_a^b f
    \end{equation}
    is bounded on $[a, \omega)$. 
  \end{lemma}
  \begin{proof}
    It is clear that 
    \begin{equation}
      \int_a^\omega f = \lim_{b \rightarrow \omega} \mathcal{F}(b)
    \end{equation}
    If $f(x)\geq 0$, then the function $\mathcal{F}(b)$ is nondecreasing on $[a, \omega)$ and therefore has a limit as $b \rightarrow \omega$ only if it is bounded (since every monotonically increasing sequence that is bounded always converges). 
  \end{proof}

  This leads to the familiar integral test for convergence of a series. 

  \begin{theorem}[Integral Test for Convergence of a Series]
    If the function $x \mapsto f(x)$ is defined on the interval $[1, +\infty)$, nonnegative, nonincreasing, and integrable on each closed interval $[1, b] \subset [1, +\infty)$, then the series 
    \begin{equation}
      \sum_{n=1}^\infty f(n) = f(1) + f(2) + \ldots
    \end{equation}
    and the integral 
    \begin{equation}
      \int_a^{+\infty} f
    \end{equation}
    either both converge or both diverge. 
  \end{theorem}

  We can use the comparison test analogue to determine convergence of improper integrals. 

  \begin{theorem}[Comparison Test for Convergence of Improper Integrals]
    Suppose the functions $f(x), g(x)$ are defined on the interval $[a, \omega)$ and integrable on any closed interval $[a, b] \subset [a, \omega)$. If 
    \begin{equation}
      0 \leq f \leq g
    \end{equation}
    on $[a, \omega)$, then 
    \begin{equation}
      \int_a^\omega g \text{ converges} \implies \int_a^\omega f \text{ converges}
    \end{equation}
    and the inequality 
    \begin{equation}
      \int_a^\omega f \leq \int_a^\omega g
    \end{equation}
    holds. Also, 
    \begin{equation}
      \int_a^\omega f \text{ diverges} \implies \int_a^\omega g \text{ diverges}
    \end{equation}
  \end{theorem}

\subsection{Integration over Paths}

  \begin{definition}[Integration For Vector Valued Functions]
    A function $f: [a, b] \to R^d$ is Riemann integrable if $f = (f_1, \ldots, f_d)$ and each component $f_i: [a, b] \to \mathbb{R}$ is in $\mathcal{R}([a, b])$. The integral is defined 
    \begin{equation}
      \int_a^b f = \bigg(\int_a^b f_1, \ldots, \int_a^b f_d \bigg)
    \end{equation}
  \end{definition}

  Now since the codomain is $\mathbb{R}^d$, we can use the Euclidean norm $|v| \coloneqq \big( \sum_i v_i^2 \big)^{1/2}$ on it. 

  \begin{theorem}
    If $f \in \mathcal{R}([a, b], \mathbb{R}^d)$, then $|f| \in \mathcal{R}([a, b], \mathbb{R}^d)$ and 
    \begin{equation}
      \bigg| \int f \bigg| \leq \int |f|
    \end{equation}
  \end{theorem}
  \begin{proof}
    If $f \in \mathcal{R}([a, b], \mathbb{R}^d)$, then $f_i \in \mathcal{R}([a, b])$, and so 
    \begin{equation}
      |f| = \sqrt{f_1^2 + \ldots f_d^2} \in \mathcal{R}
    \end{equation}
    since $x \mapsto x^2$ and $x \mapsto \sqrt{x}$ are continuous. Now consider the vector $v = \int_a^b f$. Then 
    \begin{align}
      |v| = \bigg| \int_a^b f \bigg| \implies |v|^2 = \sum_{j=1}^d v_j^2 & = \sum_{j=1}^d v_j \int_a^b f_j \\ 
                                                                         & = \int_a^b \sum_{j=1}^d v_j f_j \\ 
                                                                         & = \int_a^b \sum_{j=1}^d v_j f_j \\
                                                                         & = \int_a^b \langle v, f(t) \rangle \,dt \\ 
                                                                         & \leq  \int_a^b |v|\, |f(t)| \,dt
    \end{align}
    and so 
    \begin{equation}
      |v|^2 \leq |v| \cdot \int_a^b |f(t)| \,dt \implies |v| \leq \int_a^b |f(t)| \,dt 
    \end{equation}
  \end{proof}

  \begin{definition}[Curve]
    A \textbf{curve} is a function $\gamma: [0, 1] \to \mathbb{R}^d$. 
    \begin{enumerate}
      \item If $\gamma(0) = \gamma(1)$, then it is a \textbf{closed curve}. 
      \item If $\gamma$ is injective, then it is called a \textbf{simple curve}. 
    \end{enumerate}
  \end{definition}

  Curves are usually continuous but does not have to be. 

  \begin{example}
    The curve can have different parameterizations and/or image. For example, the two are different curves with the image in $S^1 \subset \mathbb{R}^2$. 
    \begin{align}
      \gamma(t) & = (\cos(2 \pi t), \sin(2 \pi t)) \\ 
      \Tilde{\gamma}(t) & = (\cos(4 \pi t), \sin(4 \pi t))
    \end{align} 
  \end{example}

  \begin{definition}[Length of a Curve]
    Given a curve $\gamma: [0, 1] \to \mathbb{R}^d$ and partition $P$ of $[0, 1]$, let 
    \begin{equation}
      \Lambda(\gamma, P) = \sum_{i=1}^N | \gamma(x_i) - \gamma(x_{i-1})| 
    \end{equation}
    i.e. the sum of the straight line distances between the curves. The \textbf{length} of the curve is defined as 
    \begin{equation}
      \Lambda(\gamma) \coloneqq \sup_P \Lambda(\gamma, P)
    \end{equation}
    If the length is finite, then we call this a \textbf{rectifiable curve}. 
  \end{definition}

  \begin{example}
    Consider the curve given by 
    \begin{equation}
      \gamma(t) = \bigg( t, t \sin \frac{1}{t} \bigg)
    \end{equation}
    $\gamma$ is continuous but $\gamma(t) < +\infty$. 
  \end{example}

  For most continuous curves, this is not finite, but there is a sufficient condition for it to be finite. 

  \begin{theorem}[$C^1$ Curves are Rectifiable]
    If $\gamma: [0, 1] \to \mathbb{R}^d$ is continuously differentiable, then $\gamma$ is rectifiable, and 
    \begin{equation}
      \Lambda(\gamma) = \int_0^1 |\gamma^\prime (t)| \,dt
    \end{equation}
  \end{theorem}
  \begin{proof}
    Since $\gamma^\prime (t)$ is continuous, then $|\gamma^\prime (t)|$ is continuous and $|\gamma^\prime (t)|$ is Riemann integrable. Now is $P$ is any partition of $[0, 1]$, then 
    \begin{align}
      \Lambda(x, P) = \sum_{i=1}^n |\gamma(t_i) - \gamma(t_{i-1})| & = \sum_{i=1}^n \bigg| \int_{t_{i-1}}^{t_i} \gamma^\prime (s) \,ds \bigg| \tag{Fund. Thm. of Calc.}\\ 
                                                                   & \leq \sum_{i=1}^n \int_{t_{i-1}}^{t_i} |\gamma^\prime (s)| \,ds \\ 
                                                                   & = \int_{t_0}^{t_n} |\gamma^\prime (s)| \,ds
    \end{align}
    So we've proved one inequality. Now we prove the other. Let $\epsilon > 0$ be given. Then since $\gamma^\prime (t)$ is continuous on compact $[0, 1]$, it must be uniformly continuous on $[0, 1]$. So $\exists \delta > 0$ s.t. 
    \begin{equation}
      |s - t| < \delta \implies |\gamma^\prime (s) - \gamma^\prime (t)| < \epsilon
    \end{equation} 
    Now take a partition $P$ of $[0, 1]$ s.t. $|t_i - t_{i-1}| < \delta$ for each $1 \leq i \leq N$. ...
  \end{proof}

  \begin{figure}[H]
    \centering 
    \includegraphics[scale=0.25]{img/arc_length_integral.png}
    \caption{We can visualize this by partitioning the interval $[a, b]$ into the intervals $\Delta_i$, each with point $\xi_i \in \Delta_i$. This would partition the path to $\Gamma(\Delta_i)$, each with points $\Gamma(\xi_i)$, and at each point $\Gamma(\xi_i)$, we can imagine the velocity vector of the curve. By taking the magnitude of this vector $\Gamma^\prime (\xi_i)$, we multiply it by the length of the interval $\Delta x_i$ to get one rectangle, creating an approximation for one partition of the path. } 
    \label{fig:Arc_Length_Integral}
  \end{figure}

  \begin{corollary}[Length of the Graph of a $C^1$ Function]
    An immediate result of this formula is the formula for the length of a graph of a function $f: [a, b] \longrightarrow \mathbb{R}$ in $\mathbb{R}^2$, by looking at the paramaterization $t \mapsto (t, f(t)$. 
    \begin{equation}
      \Lambda(\gamma) = \int_a^b \sqrt{1 + (f^\prime (t))^2}\,dt
    \end{equation}
  \end{corollary}

  The question on the effect of paramaterization on the integral now arises. 

  \begin{definition}[Admissible Change of Parameter]
    The path $\Tilde{\Gamma}: [\alpha, \beta] \longrightarrow \mathbb{R}^3$ is obtained from $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ by an \textbf{admissible change of parameter} if there exists a smooth mapping 
    \begin{equation}
      T: [\alpha, \beta] \longrightarrow [a, b]
    \end{equation}
    such that $T(\alpha) = a, T(\beta) = b$, $T^\prime (\tau) > 0$ (that is, the reparamaterization $T$ is monotonic) on $[\alpha, \beta]$, and 
    \begin{equation}
      \Tilde{\Gamma} = \Gamma \circ T
    \end{equation}
    The series of mappings can be represented with the following commutative diagram, where $I_{\alpha, \beta} = [\alpha, \beta] \subset \mathbb{R}$ and $I_{a, b} = [a, b] \subset \mathbb{R}$. 
    \begin{equation}
      \begin{tikzcd}
        I_{\alpha, \beta} \arrow{r}{T} \arrow{rd}{\Tilde{\Gamma}}& I_{a, b} \arrow{d}{\Gamma}\\
         & \mathbb{R}^3
      \end{tikzcd}
    \end{equation}

    \begin{figure}[H]
      \centering 
      \includegraphics[scale=0.25]{img/admissible_change_of_parameter.png}
      \caption{Note that the points are labeled $0, 1, 2, 3, 4, 5$ do not represent numerical values, but rather the order in which the points are paramaterized. We can see from this ordering that $T$ is monotonic. } 
      \label{fig:Admissible_Change_of_Parameter}
    \end{figure}
  \end{definition}

  \begin{theorem}[Invariance of Arclength Integral under Admissible Change of Parameters]
    If a smooth path $\Tilde{\Gamma}: [\alpha, \beta] \longrightarrow \mathbb{R}^3$ is obtained from a smooth path $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ by an admissible change of parameter, then the lengths of the two paths are equal. That is, a
    \begin{equation}
      \int_a^b |\Gamma^\prime (t) |\,dt = \int_\alpha^\beta |\Tilde{\Gamma}^\prime (t)|\,dt \coloneqq \int_\alpha^\beta |(\Gamma \circ T)^\prime (t)|\,dt
    \end{equation}
  \end{theorem}

\subsection{Exercises}

  \begin{example}
    Consider the space $X = C([a, b])$. Define $d: X \times X \to \mathbb{R}_0^+$ as 
    \begin{equation}
      d(f, g) \coloneqq \int_a^b |f - g|
    \end{equation}
    Then $d$ is a metric. Note that in $\mathcal{R}([a, b])$, it is \textit{not} a metric since $d(f, g) = 0 \centernot\implies f = g$. Consider two functions that are different in $1$ point. 
  \end{example}

  \begin{exercise}[Rudin 6.1]
    Suppose $\alpha$ increases on $[a, b]$, $a \le x_0 \le b$, $\alpha$ is continuous at $x_0$, $f(x_0) = 1$, and $f(x) = 0$ if $x \ne x_0$. Prove that $f \in \mathscr{R}(\alpha)$ and that $\int f \, d\alpha = 0$.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.2]
    Suppose $f \ge 0$, $f$ is continuous on $[a, b]$, and $\int_a^b f(x) \, dx = 0$. Prove that $f(x) = 0$ for all $x \in [a, b]$. (Compare this with Exercise 1.)
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.3]
    Define three functions $\beta_1, \beta_2, \beta_3$ as follows: $\beta_j(x) = 0$ if $x < 0$, $\beta_j(x) = 1$ if $x > 0$ for $j = 1, 2, 3$; and $\beta_1(0) = 0, \beta_2(0) = 1, \beta_3(0) = \frac{1}{2}$. Let $f$ be a bounded function on $[-1, 1]$.
    \begin{enumerate}
      \item[(a)] Prove that $f \in \mathscr{R}(\beta_1)$ if and only if $f(0+) = f(0)$ and that then
      \begin{equation}
        \int f \, d\beta_1 = f(0).
      \end{equation}
      \item[(b)] State and prove a similar result for $\beta_2$.
      \item[(c)] Prove that $f \in \mathscr{R}(\beta_3)$ if and only if $f$ is continuous at 0.
      \item[(d)] If $f$ is continuous at 0 prove that
      \begin{equation}
        \int f \, d\beta_1 = \int f \, d\beta_2 = \int f \, d\beta_3 = f(0).
      \end{equation}
    \end{enumerate}
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.4]
    If $f(x) = 0$ for all irrational $x$, $f(x) = 1$ for all rational $x$, prove that $f \notin \mathscr{R}$ on $[a, b]$ for any $a < b$.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.5]
    Suppose $f$ is a bounded real function on $[a, b]$, and $f^2 \in \mathscr{R}$ on $[a, b]$. Does it follow that $f \in \mathscr{R}$? Does the answer change if we assume that $f^3 \in \mathscr{R}$?
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.6]
    Let $P$ be the Cantor set constructed in Sec. 2.44. Let $f$ be a bounded real function on $[0, 1]$ which is continuous at every point outside $P$. Prove that $f \in \mathscr{R}$ on $[0, 1]$. \textit{Hint:} $P$ can be covered by finitely many segments whose total length can be made as small as desired. Proceed as in Theorem 6.10.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.7]
    Suppose $f$ is a real function on $(0, 1]$ and $f \in \mathscr{R}$ on $[c, 1]$ for every $c > 0$. Define
    \begin{equation}
      \int_0^1 f(x) \, dx = \lim_{c \to 0} \int_c^1 f(x) \, dx
    \end{equation}
    if this limit exists (and is finite).
    \begin{enumerate}
      \item[(a)] If $f \in \mathscr{R}$ on $[0, 1]$, show that this definition of the integral agrees with the old one.
      \item[(b)] Construct a function $f$ such that the above limit exists, although it fails to exist with $|f|$ in place of $f$.
    \end{enumerate}
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.8]
    Suppose $f \in \mathscr{R}$ on $[a, b]$ for every $b > a$ where $a$ is fixed. Define
    \begin{equation}
      \int_a^\infty f(x) \, dx = \lim_{b \to \infty} \int_a^b f(x) \, dx
    \end{equation}
    if this limit exists (and is finite). In that case, we say that the integral on the left converges. If it also converges after $f$ has been replaced by $|f|$, it is said to converge absolutely.
    \par Assume that $f(x) \ge 0$ and that $f$ decreases monotonically on $[1, \infty)$. Prove that
    \begin{equation}
      \int_1^\infty f(x) \, dx
    \end{equation}
    converges if and only if
    \begin{equation}
      \sum_{n=1}^\infty f(n)
    \end{equation}
    converges. (This is the so-called "integral test" for convergence of series.)
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.9]
    Show that integration by parts can sometimes be applied to the "improper" integrals defined in Exercises 7 and 8. (State appropriate hypotheses, formulate a theorem, and prove it.) For instance show that
    \begin{equation}
      \int_0^\infty \frac{\cos x}{1 + x} \, dx = \int_0^\infty \frac{\sin x}{(1 + x)^2} \, dx.
    \end{equation}
    Show that one of these integrals converges \textit{absolutely}, but that the other does not.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.10]
    Let $p$ and $q$ be positive real numbers such that
    \begin{equation}
      \frac{1}{p} + \frac{1}{q} = 1.
    \end{equation}
    Prove the following statements.
    \begin{enumerate}
      \item[(a)] If $u \ge 0$ and $v \ge 0$, then
      \begin{equation}
        uv \le \frac{u^p}{p} + \frac{v^q}{q}.
      \end{equation}
      Equality holds if and only if $u^p = v^q$.
      \item[(b)] If $f \in \mathscr{R}(\alpha)$, $g \in \mathscr{R}(\alpha)$, $f \ge 0$, $g \ge 0$, and
      \begin{equation}
        \int_a^b f^p \, d\alpha = 1 = \int_a^b g^q \, d\alpha,
      \end{equation}
      then
      \begin{equation}
        \int_a^b fg \, d\alpha \le 1.
      \end{equation}
      \item[(c)] If $f$ and $g$ are complex functions in $\mathscr{R}(\alpha)$, then
      \begin{equation}
        \left| \int_a^b fg \, d\alpha \right| \le \left\{ \int_a^b |f|^p \, d\alpha \right\}^{1/p} \left\{ \int_a^b |g|^q \, d\alpha \right\}^{1/q}.
      \end{equation}
      This is H\"{o}lder's inequality. When $p = q = 2$ it is usually called the Schwarz inequality. (Note that Theorem 1.35 is a very special case of this.)
      \item[(d)] Show that H\"{o}lder's inequality is also true for the "improper" integrals described in Exercises 7 and 8.
    \end{enumerate}
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.11]
    Let $\alpha$ be a fixed increasing function on $[a, b]$. For $u \in \mathscr{R}(\alpha)$, define
    \begin{equation}
      \|u\|_2 = \left\{ \int_a^b |u|^2 \, d\alpha \right\}^{1/2}.
    \end{equation}
    Suppose $f, g, h \in \mathscr{R}(\alpha)$, and prove the triangle inequality
    \begin{equation}
      \|f - h\|_2 \le \|f - g\|_2 + \|g - h\|_2
    \end{equation}
    as a consequence of the Schwarz inequality, as in the proof of Theorem 1.37.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.12]
    With the notations of Exercise 11, suppose $f \in \mathscr{R}(\alpha)$ and $\epsilon > 0$. Prove that there exists a continuous function $g$ on $[a, b]$ such that $\|f - g\|_2 < \epsilon$.
    \par \textit{Hint:} Let $P = \{x_0, \dots, x_n\}$ be a suitable partition of $[a, b]$, define
    \begin{equation}
      g(t) = \frac{x_i - t}{\Delta x_i} f(x_{i-1}) + \frac{t - x_{i-1}}{\Delta x_i} f(x_i)
    \end{equation}
    if $x_{i-1} \le t \le x_i$.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.13]
    Define
    \begin{equation}
      f(x) = \int_x^{x+1} \sin (t^2) \, dt.
    \end{equation}
    \begin{enumerate}
      \item[(a)] Prove that $|f(x)| < 1/x$ if $x > 0$. \textit{Hint:} Put $t^2 = u$ and integrate by parts, to show that $f(x)$ is equal to
      \begin{equation}
        \frac{\cos(x^2)}{2x} - \frac{\cos [(x+1)^2]}{2(x+1)} - \int_{x^2}^{(x+1)^2} \frac{\cos u}{4u^{3/2}} \, du.
      \end{equation}
      Replace $\cos u$ by $-1$.
      \item[(b)] Prove that
      \begin{equation}
        2xf(x) = \cos(x^2) - \cos[(x+1)^2] + r(x)
      \end{equation}
      where $|r(x)| < c/x$ and $c$ is a constant.
      \item[(c)] Find the upper and lower limits of $xf(x)$, as $x \to \infty$.
      \item[(d)] Does $\int_0^\infty \sin(t^2) \, dt$ converge?
    \end{enumerate}
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.14]
    Deal similarly with
    \begin{equation}
      f(x) = \int_x^{x+1} \sin (e^t) \, dt.
    \end{equation}
    Show that
    \begin{equation}
      e^x |f(x)| < 2
    \end{equation}
    and that
    \begin{equation}
      e^x f(x) = \cos(e^x) - e^{-1} \cos(e^{x+1}) + r(x),
    \end{equation}
    where $|r(x)| < Ce^{-x}$, for some constant $C$.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.15]
    Suppose $f$ is a real, continuously differentiable function on $[a, b]$, $f(a) = f(b) = 0$, and
    \begin{equation}
      \int_a^b f^2(x) \, dx = 1.
    \end{equation}
    Prove that
    \begin{equation}
      \int_a^b xf(x) f^\prime(x) \, dx = -\frac{1}{2}
    \end{equation}
    and that
    \begin{equation}
      \int_a^b [f^\prime(x)]^2 \, dx \cdot \int_a^b x^2 f^2(x) \, dx > \frac{1}{4}.
    \end{equation}
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.16]
    For $1 < s < \infty$, define
    \begin{equation}
      \zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}.
    \end{equation}
    (This is Riemann's zeta function, of great importance in the study of the distribution of prime numbers.) Prove that
    \begin{enumerate}
      \item[(a)] $\zeta(s) = s \int_1^\infty \frac{[x]}{x^{s+1}} \, dx$
      \item[(b)] $\zeta(s) = \frac{s}{s-1} - s \int_1^\infty \frac{x - [x]}{x^{s+1}} \, dx$,
    \end{enumerate}
    where $[x]$ denotes the greatest integer $\le x$.
    \par Prove that the integral in (b) converges for all $s > 0$.
    \par \textit{Hint:} To prove (a), compute the difference between the integral over $[1, N]$ and the $N$th partial sum of the series that defines $\zeta(s)$.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.17]
    Suppose $\alpha$ increases monotonically on $[a, b]$, $g$ is continuous, and $g(x) = G^\prime(x)$ for $a \le x \le b$. Prove that
    \begin{equation}
      \int_a^b \alpha(x) g(x) \, dx = G(b)\alpha(b) - G(a)\alpha(a) - \int_a^b G \, d\alpha.
    \end{equation}
    \par \textit{Hint:} Take $g$ real, without loss of generality. Given $P = \{x_0, x_1, \dots, x_n\}$, choose $t_i \in (x_{i-1}, x_i)$ so that $g(t_i) \Delta x_i = G(x_i) - G(x_{i-1})$. Show that
    \begin{equation}
      \sum_{i=1}^n \alpha(x_i) g(t_i) \Delta x_i = G(b)\alpha(b) - G(a)\alpha(a) - \sum_{i=1}^n G(x_{i-1}) \Delta \alpha_i.
    \end{equation}
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.18]
    Let $\gamma_1, \gamma_2, \gamma_3$ be curves in the complex plane, defined on $[0, 2\pi]$ by
    \begin{equation}
      \gamma_1(t) = e^{it}, \quad \gamma_2(t) = e^{2it}, \quad \gamma_3(t) = e^{2\pi it \sin(1/t)}.
    \end{equation}
    Show that these three curves have the same range, that $\gamma_1$ and $\gamma_2$ are rectifiable, that the length of $\gamma_1$ is $2\pi$, that the length of $\gamma_2$ is $4\pi$, and that $\gamma_3$ is not rectifiable.
  \end{exercise}
  \begin{solution}

  \end{solution}

  \begin{exercise}[Rudin 6.19]
    Let $\gamma_1$ be a curve in $R^k$, defined on $[a, b]$; let $\phi$ be a continuous 1-1 mapping of $[c, d]$ onto $[a, b]$, such that $\phi(c) = a$; and define $\gamma_2(s) = \gamma_1(\phi(s))$. Prove that $\gamma_2$ is an arc, a closed curve, or a rectifiable curve if and only if the same is true of $\gamma_1$. Prove that $\gamma_2$ and $\gamma_1$ have the same length.
  \end{exercise}
  \begin{solution}

  \end{solution}

\section{Hierarchical Modeling}

  Given a training data set $\mathcal{D} = (\mathbf{X}, \mathbf{Y})$ comprised of $N$ pairs of observations with corresponding target variables $\{(x_i, y_i)\}_{i=1}^N$ ($x_i \in \mathbb{R}^D, y_i \in \mathbb{R}$), the goal is to predict the value of $y$ for a new value of $x$. We first construct a \textit{statistical model} (more explained in next next subsection) by assuming that there exists some function $f(x)$ of some form such that the $y_i$'s have been generated by inputting the $x_i$'s into $f$, followed by a random residual term. We assume that the data $\mathcal{D}$ has been sampled independently, but this may not always be a justifiable assumption in practice. Under this model, which we denote $\mathcal{M}_i$, we further assume that $f$ can be parameterized by a vector $\theta$, so therefore, we assume that
  \begin{equation}
    y = f(x, \theta) + \epsilon, \;\;\;\;\;\; \epsilon \sim \text{Residual} (\beta)
  \end{equation}
  where $\beta$ is some collection of parameters that determine the error function.

  \begin{itemize}
    \item The frequentist perspective reduces this problem to finding the value of $\theta$ that maximizes the likelihood. That is, we must find
    \begin{equation}
      \theta^* = \text{arg}\, \max_{\theta} p(\mathcal{D}\,|\,\theta) = \text{arg}\, \max_{\theta} \prod_{i=1}^N p(y_i \,|\,x_i, \theta)
    \end{equation}
    and claiming that $y = f(x, \theta^*)$ is the function of best fit. This is a quite straightforward (hopefully convex) optimization problem, which can be done in many ways (e.g. batch/sequential gradient descent, solving normal equations, etc.).

    \item The Bayesian approach attempts to construct a \textit{distribution} of the values of $\theta$. Clearly, this vector $\theta$ would be an element in some multidimensional Euclidean space, and we want to define a posterior density $p(\theta\,|\,\mathcal{D})$ across this space that tells us the probability of $\theta$. Using Bayes rule,
    \begin{equation}
      p(\theta\,|\,\mathcal{D}) \propto p(\mathcal{D}\,|\,\theta) \, p(\theta)
    \end{equation}
    we see that we must define some prior distribution $p(\theta)$ on $\theta$. We can assume that this prior is defined with some distribution
    \begin{equation}
      \theta \sim \text{Dist}_\theta (\gamma)
    \end{equation}
    where $\gamma$ is a collection of parameters on $\theta$. Knowing this prior of $\theta$ will allow us to get the posterior of $\theta\,|\,\mathcal{D}$. The not-so-complete Bayesian treatment would treat this $\gamma$ as a known constant. But note that there is still uncertainty of whether $\theta$ comes from $\text{Dist}_\theta (\gamma)$ for one value of $\gamma$, compared to another value of $\gamma$. This uncertainty requires us to treat $\gamma$ as now a \textbf{hyperparameter}, that is a parameter for the distribution of a parameter, and this distribution of $\gamma$, which we can denote
    \begin{equation}
      \gamma \sim \text{Dist}_\gamma (\xi)
    \end{equation}
    is called a \textbf{hyperprior}. We can construct higher and higher level hyperpriors on top of this as much as we want, which will lead to more flexibility in our model (but more computationally expensive). This is known as \textbf{hierarchical priors}. Generally, we will only go up to the level of one hyperparameter.
  \end{itemize}

  Let us summarize how we would conduct the Bayesian method step by step. We first have to determine how many levels of hierarchical priors we are accounting for. Say that we will treat $\xi$ as a constant, and consider the parameter $\theta$ along with its hyperparameter $\gamma$. Our goal is to compute the posterior $p(\theta\,|\,\mathcal{D})$.

  \begin{enumerate}
    \item Since there is uncertainty over the value of $\theta$ depending on $\gamma$, we can marginalize over $\gamma$ to get
    \begin{equation}
      p(\theta\,|\,\mathcal{D}) = \int p(\theta\,|\,\mathcal{D}, \gamma)\, p(\gamma\,|\,\mathcal{D})\; d\gamma
    \end{equation}
    If the situation calls for it, we could also compute the posterior by doing Bayes rule first to get $p(\theta\,|\,\mathcal{D}) \propto p(\mathcal{D}\,|\,\theta)\; p(\theta)$, but then we would have to calculate both $p(\mathcal{D}\,|\,\theta)$ and $p(\theta)$ by marginalizing each over $\gamma$, which would lead to complications.

    \item To calculate $p(\theta\,|\,\mathcal{D}, \gamma)$, note that the formula for the posterior density of $\theta$ given $\mathcal{D}$ is $p(\theta\,|\,\mathcal{D}) \propto p(\mathcal{D}\,|\,\theta) p(\theta)$, where $p(\theta)$ is a density function of $\theta$ and parameter $\gamma$, which means that $p(\theta\,|\,\mathcal{D})$ would be a density function of $\theta$ and parameter $\gamma$. But since $\gamma$ is fixed, the posterior
    \begin{equation}
      p(\theta\,|\,\mathcal{D}, \gamma) \propto p(\mathcal{D}\,|\,\theta, \gamma) p(\theta\,|\,\gamma)
    \end{equation}
    is a density function of $\theta$ with fixed constant $\gamma$. This can be easily calculated because the prior $p(\theta\,|\,\gamma)$ is of distribution $\text{Dist}_\theta (\gamma)$ and the likelihood $p(\mathcal{D}\,|\,\theta, \gamma)$ is the product of densities of $y$ given fixed $\theta$.

    \item To calculate $p(\gamma\,|\,\mathcal{D})$, we first use Bayes rule to get
    \begin{equation}
      p(\gamma\,|\,\mathcal{D}) \propto p(\mathcal{D}\,|\,\gamma)\, p(\gamma)
    \end{equation}
    This can be easily calculated because the prior $p(\gamma)$ is of distribution $\text{Dist}_\gamma (\xi)$ of given $\xi$. The likelihood can be marginalized over $\theta$ to get
    \begin{equation}
      p(\mathcal{D}\,|\,\gamma) = \int p(\mathcal{D}\,|\,\theta, \gamma)\, p(\theta\,|\, \gamma)\; d\theta
    \end{equation}
    where $p(\theta\,|\,\gamma)$ is a function of $\theta$ with given parameter $\gamma$, and $p(\mathcal{D}\,|\,\theta)$ is the product of the individual likelihoods.
  \end{enumerate}

  But remember that this was all assumed under model $\mathcal{M}_i$, so the posterior density $p(\theta^i \,|\,\mathcal{D})$ of the $\theta^i$ parameterizing our best-fit function is really
  \begin{equation}
    p(\theta^i \,|\,\mathcal{D}, \mathcal{M}_i)
  \end{equation}
  where we index the parameter of model $\mathcal{M}_i$ to be $\theta^i$, with a superscript (since we may mistake subscript indices to be the components of $\theta$).


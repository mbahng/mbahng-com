\section{Multi-Dimensional Scaling}

  Again, we want to reduce our dimension, but the goal is slightly different from PCA. 

  \begin{definition}[Multi-Dimensional Scaling]
    Given our data $X \in \mathbb{R}^d$, we want to construct a linear map $T: \mathbb{R}^d \rightarrow \mathbb{R}^k$ such that it preserves the pairwise differences between the data points. That is, we want to minimize the following loss function 
    \begin{equation}
      \min_{T} \sum_{i \neq j} \big( d_{\mathbb{R}^k}(T(x_i), T(x_j)) - d_{\mathbb{R}^d}(x_i, x_j) \big)
    \end{equation}
    where $d_{V}$ is a distance metric in the space $V$. 
  \end{definition}

  Note that we can easily modify this formulation to preserve other structures, such as dot products, weights between distances, or different types of metrics in each space. It turns out that when the distance metric is the Euclidean L2 distance, then the solution to this linear map turns out to be PCA. This may be a more intuitive way to think about PCA, since we're trying to preserve the pairwise distances between the data points. 

  \begin{theorem}[Equivalence of Classical MDS and PCA]
    If the distance metric is the Euclidean L2 distance, then the solution to the MDS problem is equivalent to PCA. That is, 
    \begin{equation}
      T_k = \argmin_{T} \sum_{i \neq j} \big( ||T(x_i) - T(x_j)||^2 - ||x_i - x_j||^2 \big)
    \end{equation}
  \end{theorem}

  Generally, if you don't use classical MDS, then you will get a different answer than PCA and there doesn't exist a closed form solution, so you'll have to minimize this numerically. 

  \begin{example}[Non Classical MDS]
    The loss 
    \begin{equation}
      \sum_{i \neq j}  \big( ||T(x_i) - T(x_j)|| - ||x_i - x_j|| \big)^2 
    \end{equation}
    does not give the same solution as PCA. 
  \end{example}


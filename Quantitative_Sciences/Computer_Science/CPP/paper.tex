\documentclass{article}

% packages
  % basic stuff for rendering math
  \usepackage[letterpaper, top=1in, bottom=1in, left=1in, right=1in]{geometry}
  \usepackage[utf8]{inputenc}
  \usepackage[english]{babel}
  \usepackage{amsmath} 
  \usepackage{amssymb}
  % \usepackage{amsthm}

  % extra math symbols and utilities
  \usepackage{mathtools}        % for extra stuff like \coloneqq
  \usepackage{mathrsfs}         % for extra stuff like \mathsrc{}
  \usepackage{centernot}        % for the centernot arrow 
  \usepackage{bm}               % for better boldsymbol/mathbf 
  \usepackage{enumitem}         % better control over enumerate, itemize
  \usepackage{hyperref}         % for hypertext linking
  \usepackage{fancyvrb}          % for better verbatim environments
  \usepackage{newverbs}         % for texttt{}
  \usepackage{xcolor}           % for colored text 
  \usepackage{listings}         % to include code
  \usepackage{lstautogobble}    % helper package for code
  \usepackage{parcolumns}       % for side by side columns for two column code
  

  % page layout
  \usepackage{fancyhdr}         % for headers and footers 
  \usepackage{lastpage}         % to include last page number in footer 
  \usepackage{parskip}          % for no indentation and space between paragraphs    
  \usepackage[T1]{fontenc}      % to include \textbackslash
  \usepackage{footnote}
  \usepackage{etoolbox}

  % for custom environments
  \usepackage{tcolorbox}        % for better colored boxes in custom environments
  \tcbuselibrary{breakable}     % to allow tcolorboxes to break across pages

  % figures
  \usepackage{pgfplots}
  \pgfplotsset{compat=1.18}
  \usepackage{float}            % for [H] figure placement
  \usepackage{tikz}
  \usepackage{tikz-cd}
  \usepackage{circuitikz}
  \usetikzlibrary{arrows}
  \usetikzlibrary{positioning}
  \usetikzlibrary{calc}
  \usepackage{graphicx}
  \usepackage{algorithmic}
  \usepackage{caption} 
  \usepackage{subcaption}
  \captionsetup{font=small}

  % for tabular stuff 
  \usepackage{dcolumn}

  \usepackage[nottoc]{tocbibind}
  \pdfsuppresswarningpagegroup=1
  \hfuzz=5.002pt                % ignore overfull hbox badness warnings below this limit

% New and replaced operators
  \DeclareMathOperator{\Tr}{Tr}
  \DeclareMathOperator{\Sym}{Sym}
  \DeclareMathOperator{\Span}{span}
  \DeclareMathOperator{\std}{std}
  \DeclareMathOperator{\Cov}{Cov}
  \DeclareMathOperator{\Var}{Var}
  \DeclareMathOperator{\Corr}{Corr}
  \DeclareMathOperator{\pos}{pos}
  \DeclareMathOperator*{\argmin}{\arg\!\min}
  \DeclareMathOperator*{\argmax}{\arg\!\max}
  \newcommand{\ket}[1]{\ensuremath{\left|#1\right\rangle}}
  \newcommand{\bra}[1]{\ensuremath{\left\langle#1\right|}}
  \newcommand{\braket}[2]{\langle #1 | #2 \rangle}
  \newcommand{\qed}{\hfill$\blacksquare$}     % I like QED squares to be black

% Custom Environments
  \newtcolorbox[auto counter, number within=section]{question}[1][]
  {
    colframe = orange!25,
    colback  = orange!10,
    coltitle = orange!20!black,  
    breakable, 
    title = \textbf{Question \thetcbcounter ~(#1)}
  }

  \newtcolorbox[auto counter, number within=section]{exercise}[1][]
  {
    colframe = teal!25,
    colback  = teal!10,
    coltitle = teal!20!black,  
    breakable, 
    title = \textbf{Exercise \thetcbcounter ~(#1)}
  }
  \newtcolorbox[auto counter, number within=section]{solution}[1][]
  {
    colframe = violet!25,
    colback  = violet!10,
    coltitle = violet!20!black,  
    breakable, 
    title = \textbf{Solution \thetcbcounter}
  }
  \newtcolorbox[auto counter, number within=section]{lemma}[1][]
  {
    colframe = red!25,
    colback  = red!10,
    coltitle = red!20!black,  
    breakable, 
    title = \textbf{Lemma \thetcbcounter ~(#1)}
  }
  \newtcolorbox[auto counter, number within=section]{theorem}[1][]
  {
    colframe = red!25,
    colback  = red!10,
    coltitle = red!20!black,  
    breakable, 
    title = \textbf{Theorem \thetcbcounter ~(#1)}
  } 
  \newtcolorbox[auto counter, number within=section]{proposition}[1][]
  {
    colframe = red!25,
    colback  = red!10,
    coltitle = red!20!black,  
    breakable, 
    title = \textbf{Proposition \thetcbcounter ~(#1)}
  } 
  \newtcolorbox[auto counter, number within=section]{corollary}[1][]
  {
    colframe = red!25,
    colback  = red!10,
    coltitle = red!20!black,  
    breakable, 
    title = \textbf{Corollary \thetcbcounter ~(#1)}
  } 
  \newtcolorbox[auto counter, number within=section]{proof}[1][]
  {
    colframe = orange!25,
    colback  = orange!10,
    coltitle = orange!20!black,  
    breakable, 
    title = \textbf{Proof. }
  } 
  \newtcolorbox[auto counter, number within=section]{definition}[1][]
  {
    colframe = yellow!25,
    colback  = yellow!10,
    coltitle = yellow!20!black,  
    breakable, 
    title = \textbf{Definition \thetcbcounter ~(#1)}
  } 
  \newtcolorbox[auto counter, number within=section]{example}[1][]
  {
    colframe = blue!25,
    colback  = blue!10,
    coltitle = blue!20!black,  
    breakable, 
    title = \textbf{Example \thetcbcounter ~(#1)}
  } 
  \newtcolorbox[auto counter, number within=section]{code}[1][]
  {
    colframe = green!25,
    colback  = green!10,
    coltitle = green!20!black,  
    breakable, 
    title = \textbf{Code \thetcbcounter ~(#1)}
  } 
  \newtcolorbox[auto counter, number within=section]{algo}[1][]
  {
    colframe = green!25,
    colback  = green!10,
    coltitle = green!20!black,  
    breakable, 
    title = \textbf{Algorithm \thetcbcounter ~(#1)}
  } 

  \BeforeBeginEnvironment{example}{\savenotes}
  \AfterEndEnvironment{example}{\spewnotes}
  \BeforeBeginEnvironment{lemma}{\savenotes}
  \AfterEndEnvironment{lemma}{\spewnotes}
  \BeforeBeginEnvironment{theorem}{\savenotes}
  \AfterEndEnvironment{theorem}{\spewnotes}
  \BeforeBeginEnvironment{corollary}{\savenotes}
  \AfterEndEnvironment{corollary}{\spewnotes}
  \BeforeBeginEnvironment{proposition}{\savenotes}
  \AfterEndEnvironment{proposition}{\spewnotes}
  \BeforeBeginEnvironment{definition}{\savenotes}
  \AfterEndEnvironment{definition}{\spewnotes}
  \BeforeBeginEnvironment{exercise}{\savenotes}
  \AfterEndEnvironment{exercise}{\spewnotes}
  \BeforeBeginEnvironment{proof}{\savenotes}
  \AfterEndEnvironment{proof}{\spewnotes}
  \BeforeBeginEnvironment{solution}{\savenotes}
  \AfterEndEnvironment{solution}{\spewnotes}
  \BeforeBeginEnvironment{question}{\savenotes}
  \AfterEndEnvironment{question}{\spewnotes}
  \BeforeBeginEnvironment{code}{\savenotes}
  \AfterEndEnvironment{code}{\spewnotes}
  \BeforeBeginEnvironment{algo}{\savenotes}
  \AfterEndEnvironment{algo}{\spewnotes}

  \definecolor{dkgreen}{rgb}{0,0.6,0}
  \definecolor{gray}{rgb}{0.5,0.5,0.5}
  \definecolor{mauve}{rgb}{0.58,0,0.82}
  \definecolor{darkblue}{rgb}{0,0,139}
  \definecolor{lightgray}{gray}{0.93}
  \renewcommand{\algorithmiccomment}[1]{\hfill$\triangleright$\textcolor{blue}{#1}}

  % default options for listings (for code)
  \lstset{
    autogobble,
    frame=ltbr,
    language=C++,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    columns=fullflexible,
    keepspaces=true,
    basicstyle={\small\ttfamily},
    numbers=left,
    firstnumber=1,                        % start line number at 1
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    stringstyle=\color{mauve},
    backgroundcolor=\color{lightgray}, 
    breaklines=true,                      % break lines
    breakatwhitespace=true,
    tabsize=3, 
    xleftmargin=2em, 
    framexleftmargin=1.5em, 
    stepnumber=1
  }

  \lstdefinelanguage{CMake}{
    keywords={
      if, else, elseif, endif,
      foreach, endforeach,
      while, endwhile,
      function, endfunction,
      macro, endmacro,
      set, unset,
      project,
      cmake_minimum_required,
      add_executable,
      add_library,
      target_link_libraries,
      include_directories,
      add_subdirectory,
      file,
      find_package,
      option
    },
    sensitive=false,
    comment=[l]{\#},
    morestring=[b]",
    morestring=[b]',
  }

% Page style
  \pagestyle{fancy}
  \fancyhead[L]{C++}
  \fancyhead[C]{Muchang Bahng}
  \fancyhead[R]{Winter 2024} 
  \fancyfoot[C]{\thepage / \pageref{LastPage}}
  \renewcommand{\footrulewidth}{0.4pt}          % the footer line should be 0.4pt wide
  \renewcommand{\thispagestyle}[1]{}  % needed to include headers in title page

\begin{document}

\title{C++}
\author{Muchang Bahng}
\date{Winter 2024}

\maketitle
\tableofcontents
\pagebreak

\section{Objects}

    We define a bunch of terms. This may seem unnecessary, but it becomes very useful when getting into the weeds of C++. 

    \begin{definition}[Statements]
      A \textbf{statement} is an instruction that causes the program to perform some action. Statements are the smallest independent unit of computation in the C++ language, and they are ended with a semicolon. 
      \begin{lstlisting}
        int x; //  declaration statement 
        int y = 2; // initialization statements  
        int z = 2 + 3;
      \end{lstlisting}
    \end{definition}

  \subsection{Types}

    \begin{definition}[Type]
      A \textbf{type} is a protocol that defines the set of possible values and a set of operations that can be performed on those values.\footnote{This is similar to a mathematical set endowed with some operations. This definition is quite abstract, but it suffices.} There are several categorizations for types. 
      \begin{enumerate}
        \item At the very basic level, we have \textbf{primitive types}, which are always built-in types that come with C++ or the standard library (e.g. int, double, boolean). 
        \item \textbf{Compound types} are types that are built in by primitive types. In here, we have 
          \begin{enumerate}
            \item \textbf{Built-in types} which come with C++ or the standard library (e.g. functions) 
            \item \textbf{User-defined types} which the user defines (e.g. enums\footnote{Since they are implemented with integral types.}, classes, structs)
          \end{enumerate}
      \end{enumerate}
      Note that the protocols for each type is dependent on the version of C++, the computer architecture, and the compiler. Therefore we have to be careful to accommodate them. 
    \end{definition}

    Great, now let's see what primitive types are supported in C++.  
    
    \begin{definition}[Integral Types]
      \textbf{Integral types} represent a proper subset of $\mathbb{Z}$. 
      \begin{enumerate}
        \item The signed numbers include \texttt{int}, \texttt{long}, \texttt{long long} and are stored in two's complement representation. 

        \begin{figure}[H]
          \centering 
          \begin{lstlisting}
            * thread #1, queue = 'com.apple.main-thread', stop reason = instruction step over
                frame #0: 0x0000000100003fa0 a.out`main + 28
            a.out`main:
            ->  0x100003fa0 <+28>: add    sp, sp, #0x10
                0x100003fa4 <+32>: ret    
                0x100003fa8:       udf    #0x1
                0x100003fac:       udf    #0x1c
            Target 0: (a.out) stopped.
            (lldb) x/4xb $sp+4
            0x16fdfec44: 0xff 0xff 0xff 0xff
            (lldb) x/4xb $sp+8
            0x16fdfec48: 0x01 0x00 0x00 0x00
          \end{lstlisting}
          \caption{Two's complement representation of $\pm1$ on my machine from inspecting memory in \texttt{lldb}. Note that this is little endian, with the least significant hex coming first.} 
          \label{fig:signed_rep}
        \end{figure} 

        \item The unsigned numbers include \texttt{unsigned int}, \texttt{unsigned long}, \texttt{unsigned long long} and are stored regularly. 

        \begin{figure}[H]
          \centering 
          \begin{lstlisting}
            * thread #1, queue = 'com.apple.main-thread', stop reason = instruction step over
                frame #0: 0x0000000100003fa0 a.out`main + 28
            a.out`main:
            ->  0x100003fa0 <+28>: add    sp, sp, #0x10
                0x100003fa4 <+32>: ret    
                0x100003fa8:       udf    #0x1
                0x100003fac:       udf    #0x1c
            Target 0: (a.out) stopped.
            (lldb) x/4xb $sp+4
            0x16fdfec44: 0x00 0x01 0x00 0x00
            (lldb) x/4xb $sp+8
            0x16fdfec48: 0x01 0x00 0x00 0x00
          \end{lstlisting}
          \caption{Regular representation of unsigned integers \texttt{256 = 0x1000} and \texttt{1 = 0x01}. }
          \label{fig:unsigned_rep}
        \end{figure} 
      \end{enumerate}
    \end{definition} 

    \begin{definition}[Floating Point Types]
      \textbf{Floating point types} represent a proper subset of $\mathbb{R}$. 
    \end{definition}

    \begin{definition}[Char]
      \texttt{Character types} represent the extended ASCII character set and is always 1 Byte. Some nice facts to know. 
      \begin{enumerate}
        \item The numbers 0-9 take characters \texttt{48} to \texttt{57}.
        \item The uppercase letters A-Z take \texttt{65} to \texttt{90}. 
        \item The lowercase letters a-z take \texttt{97} to \texttt{122}. 
      \end{enumerate}
    \end{definition}

    \begin{definition}[Boolean]
      A \textbf{boolean} stores 1 bit of memory, but in practice it takes up 1 Byte since a Byte is the smallest addressable unit of memory in most computer architectures. 
    \end{definition}

    \begin{definition}[Void]
      The \textbf{void} type is the analogous to the null or none type in other languages. It is a type that does not represent a type, stating that an object has no type. 
    \end{definition} 

    \begin{example}[Types with \texttt{\_t} Suffix?]
      Some types have the \texttt{\_t} suffix, which just represents type. Some types have this and others don't. In C++, there is no exact size for each fundamental type (except for \texttt{char}, which is always 1 byte). There is however a lower bound, so you should always use the lower bound and for maximum portability, never assume that a type can store more bytes. 
    \end{example}

    \subsubsection{Casting}

      \begin{definition}[Typecasting]
        The action of converting one type to another type is called \textbf{typecasting}. 
        \begin{enumerate}
          \item The programmer can \textbf{explicitly typecast} by calling an operator to change an objects type. 
          \item If two objects are relatively similar,\footnote{defined very loosely here} then the C++ implementation may do an \textbf{implicit typecast} to convert it automatically. 
        \end{enumerate}
      \end{definition} 

      Here we list some situations when there is implicit typecasting. 

      \begin{lemma}[Variable Initialization]
        When initializing (or assigning a value to) a variable with a value of a different type. 
        \begin{lstlisting}
          double d = 3; // int value 3 implicitly converted to type double 
          d = 6; 
        \end{lstlisting}
      \end{lemma}

      \begin{lemma}[Function and Operators]
        Function calls and operators will implicitly typecast between char and signed int. This can both be convenient and a pain to work with. 
        \begin{lstlisting}
          int main() { 
            char x = 'a';         // 97 in ASCII
            std::cout << x + 4;   // 101
            std::cout << x - 200; // -103
            return 0; 
          }
        \end{lstlisting}
      \end{lemma}

      \begin{lemma}[Return Types]
        When the type of a return value is different from the function's declared return type. 
        \begin{lstlisting}
          float func() {
            return 3.0; // double value 3.0 implicitly converted to float
          }
        \end{lstlisting}
      \end{lemma}

      \begin{lemma}[Truthy and Falsy Values]
        When we use a non-Boolean value in an if-statement. 
        \begin{lstlisting}
          if (5) { // int value 5 implicitly converted to true
            ...
          }
        \end{lstlisting}
      \end{lemma}

      \begin{lemma}[Returning Structs]
        Say that we have a function that returns a struct (an anonymous object with no name). 
        \begin{lstlisting}
          strict Point3d {
            int x; 
            int y; 
            int z; 
          };
        \end{lstlisting}

        We can actually return a list, which will be implicitly typecasted to be of the struct type. 

        \noindent\begin{minipage}{.5\textwidth}
          \begin{lstlisting}[]{Code}
            Point3d getZeroPoint() {
              return Point3d {0.0, 0.0, 0.0}; 
            }
          \end{lstlisting}
          \end{minipage}
          \hfill
          \begin{minipage}{.49\textwidth}
          \begin{lstlisting}[]{Output}
            Point3d getZeroPoint() {
              return {0.0, 0.0, 0.0}; 
            }
          \end{lstlisting}
        \end{minipage}
      \end{lemma}

      How do we explicitly typecast? C++ defines a few operators (not functions! explained later) that does this. 

      \begin{definition}[C Style Cast]
        Similar to typecasting in C, we can do the following. 
        \begin{lstlisting}
          (T)foo
        \end{lstlisting}
      \end{definition}
      
      \begin{definition}[Static Cast]
        We can conduct a static typecast, which happens during compile time. 
        \begin{lstlisting}
          static_cast<T>(foo)
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Dynamic Cast]
        \begin{lstlisting}
          dynamic\_cast<T>(foo)
        \end{lstlisting}
      \end{definition}

  \subsection{Variables}

      \begin{definition}[Value]
        The definition of a \textbf{value} is quite abstract. It is simply some data with a \textbf{type}. In computers, the value gets \textit{encoded} into some sequence of bits. The \textbf{identity} of a value is purely determined by the abstract concept it represents. 
      \end{definition}

      \begin{definition}[Objects and Variables]
        An \textbf{object} represents a memory of storage (typically RAM or CPU cache) that can hold a value. It has 4 properties. 
        \begin{enumerate}
          \item Like a value, it has a type representing the type of value it holds. 
          \item It has an \textbf{address} representing where the value is stored.  
          \item The identity is determined not just by the value that it stores, but also its address. 
          \item It \textit{may} have a \textbf{name}.\footnote{Typically some alphanumeric string like \texttt{x}.} Objects with a name are called \textbf{variables}, and those without a name are called \textbf{anonymous}. The \textbf{linkage} of the variable determines which address the variable refers to. 
        \end{enumerate}
        Note that in C++, the definition of an object slightly differs than in more general contexts. 
      \end{definition} 

      \begin{definition}[Literal]
        A \textbf{literal} is a value that is directly inserted into code, e.g. \texttt{5}, \texttt{3.2}, \texttt{'a'}. It is not a variable since it does not have an name, and it is not an object either since it doesn't have an address. 
      \end{definition} 

      \begin{theorem}[Types are not Objects!]
        If a type defines the protocol, then wouldn't this be stored in memory? No, this is for the compiler.  
      \end{theorem}

    \subsubsection{Scope and Duration} 

      Now that we've established variables, we can talk about their scope. 
      
      \begin{definition}[Block]
        A \textbf{block} is a portion of code that is within curly braces $\texttt{\{ ...\}}$. Note that C++ is not line sensitive.
      \end{definition}

      You probably know that there are two types of variables: \textbf{local variables} and \textbf{global variables}, along with their general properties. Let's specify them a bit, starting with the two most important ones: scope and duration.  

      \begin{definition}[Duration]
        The \textbf{duration} of an identifier governs how it will be constructed and destroyed, over its \textbf{lifetime}. 
        \begin{enumerate}
          \item \textbf{Automatic duration} means that their lifetime begins at the start of the block (at \texttt{\{}) and is destroyed at the end of the block \texttt{\}}. 
          \item \textbf{Static duration} means they are created when the program starts (before \texttt{main()}) and destroyed when it ends. Variables with static duration, both local and global, are 0-intialized by default. (e.g. \texttt{static int x;} is really \texttt{static int x = 0;}). It is conventional to prefix static local variables with a \texttt{s\_}. 
        \end{enumerate}
      \end{definition} 

      \begin{definition}[Scope]
        The \textbf{scope} of an identifier refers to where it is accessible by. 
        \begin{enumerate}
          \item \textbf{Block scope} refers to a variable being accessible within a certain block. 
          \item \textbf{Global scope} refers to a variable being accessible from everywhere.  
        \end{enumerate}
      \end{definition} 

      It may seem like the scope and duration are related, but you can have any combination of automatic local variables (just called local variables), static local variables, and global variables. The duration talks about \textit{when} a variables is allowed to live while the scope talks about \textit{where} it is accessible from. Just like local variables, global variables can be const as well, and like all const variables, must be initialized. 

      \begin{definition}[Local Variables]
        \textbf{Local variables} are variables constructed inside a \textbf{block scope} and are accessible only within that block. They have automatic duration by default. 
      \end{definition}

      \begin{definition}[Static Local Variables]
        If we talk about \textbf{static local variables}, they are variables with block scope but having static duration. 

        This may be a bit counterintuitive, but say that there is a variable that you want to persist for the entire program, but you only want to modify that value within a function. 
        \begin{lstlisting}
          void increment() {
            static int val = 1;  // static duration. Initializer only executed once. 
            ++val; 
            std::cout << val << "\n";
          } // val is not destroyed here, but becomes inaccessible 

          int main() {
            increment(); 
            increment(); 
            return 0; 
          }
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Global Variables]
        \textbf{Global variables} live within the \textbf{global scope} of the global or a local namespace and therefore can be accessible from anywhere. They are static variables by definition. Usually it is preferred to define global variables in a namespace. It is conventional to prefix global variables with \texttt{g\_}. 
      \end{definition}

      \begin{example}[Automatic Duration]
        You can see that every block contains its own scope with its own local variables. When the block ends all variables in this block are destroyed on the stack. 

        \begin{lstlisting}
          int main() {  
            int x = 2; 
            std::cout << x << std::endl; // 2
            {
              int y = 1;
              std::cout << x << std::endl; // 2
              std::cout << y << std::endl; // 1
            }
            return 0; 
          }
        \end{lstlisting}
      \end{example}

      \begin{example}[Accessing Parent Block Scope]
        Local variables in a nested block have access to the parent block's scope. Both of these programs are valid. The left accesses the parent block's \texttt{x} while the right one access \texttt{x} newly created in the local scope. 

        \noindent\begin{minipage}{.5\textwidth}
          \begin{lstlisting}[]{Code}
            int main() {  
              int x = 2; 
              for (int i = 0; i < 10; i++) {
                x += 1;
              }
              std::cout << x << std::endl; // 12
              return 0; 
            }
            .
          \end{lstlisting}
          \end{minipage}
          \hfill
          \begin{minipage}{.49\textwidth}
          \begin{lstlisting}[]{Output}
            int main() {  
              int x = 2; 
              for (int i = 0; i < 10; i++) {
                int x = 1;
                x += 1;
              }
              std::cout << x << std::endl; // 2
              return 0; 
            }
          \end{lstlisting}
        \end{minipage}
      \end{example}

      \begin{example}[Variable Shadowing]
        You can see that the \texttt{x} is initialized in the \texttt{main()} block scope, but it gets ``shadowed'' by the \texttt{x} in the nested block. Once the block terminates, then it is ``revealed'' again. 

        \begin{lstlisting}
          int main() {  
            int x = 2; 
            std::cout << x << std::endl; // 1
            {
              int x = 1;
              std::cout << x << std::endl; // 1
            }
            std::cout << x << std::endl; // 2 
            return 0; 
          }
        \end{lstlisting}
      \end{example} 

      Static local variables are good for id generation, since they are not accessible beyond a block but still have a persistent state that does not get reset. Another good use is to use const static local variables for functions that needs to use a const value, but initializing that object is expensive. Using a local variable would instantiate it every time the function is called, but a static local variable requires us to create it once. 

    \subsubsection{Internal and External Linkage} 

      Remember that given a name, its \textit{linkage} determines whether other declarations of that name refer to the same object or not. 

      \begin{definition}[Static Global Variables]
        When \texttt{static} is applied to a global variable, it has a completely unrelated effect than that applied on a local variable. It means that the global variable now has internal linkage, meaning that the variable cannot be exported to other files. 
      \end{definition}

  \subsection{Operators and Functions} 

    In Python, there is no difference between functions and operators since every operator (e.g. \texttt{+}) gets mapped to a dunder method (e.g. \texttt{\_\_add()\_\_}). In C++, there are differences. Operators and functions are similar in behavior, but we should know that operators are more like \textit{keywords} while function are \textit{compound types}. 
    
    \begin{definition}[Function]
      A \textbf{function} is a set of statements enclosed in a block, which uses a sequence of \textbf{parameters} and a \textbf{return type}. It has the following properties. 
      \begin{enumerate}
        \item It \textit{may} have a name (e.g. \texttt{foo()}). Those without a name are called \textbf{anonymous functions}. 
        \item By default, a call to a function requires us to jump to a separate piece of code. 
      \end{enumerate}
    \end{definition}

    \begin{definition}[Operations]
      An \textbf{operator} is a keyword with a fixed syntax which also does some operation. An \textbf{operation} consists of an operator (\texttt{+}) and one or more \textbf{operands} (\texttt{3}, \texttt{4.3}).  
      \begin{enumerate}
        \item Operators come as a part of C++ (\texttt{sizeof}, \texttt{+}) or the C++ standard library (\texttt{std::cout <<}). 
        \item Unlike a function, an operator does not jump to another sequence in the code and is compiled to a sequence of instructions by the compiler. 
        \item Operators usually have a fixed number of parameters, while functions can use different sets of operands (overloading). 
        \item Operators have built-in precedence rules (e.g. multiplication before addition) 
      \end{enumerate}
    \end{definition}

    \begin{definition}[\texttt{sizeof} Operator]
      The \texttt{sizeof} operator returns the size (in bytes) of its operand. 
      \begin{enumerate}
        \item \texttt{sizeof(short) = 4}
        \item \texttt{sizeof(int) = 4}
        \item \texttt{sizeof(long) = 4}
        \item \texttt{sizeof(long long) = 8}
        \item \texttt{sizeof(float) = 4}
        \item \texttt{sizeof(double) = 8}
        \item \texttt{sizeof(long double) = 8}
      \end{enumerate} 
    \end{definition}

  \subsection{Declaration vs Definition} 

    Variables can be \textbf{constructed} in two ways. 
    \begin{enumerate}
      \item We first \textbf{declare} a variable, which tells the compiler about the existence of the variable (\texttt{int x;}). Then, we can \textbf{define} the variable, which assigns it a literal (\texttt{x = 4;}). 
      \item We can \textbf{initialize} a variable, which both declares it and defines it at once (\texttt{int x = 4;}).
    \end{enumerate}

    \begin{enumerate}
      \item The \textbf{declaration} of a function states the existence of the function. 
        \begin{lstlisting}
          double foo(int x, double y); // one way 
          double foo(int, double); // another way 
        \end{lstlisting}
        This declaration is also called the \textbf{function prototype}, or the \textbf{function identifier}. 

      \item The \textbf{definition} of a function tells us the actual implementation. 
        \begin{lstlisting}
          double foo(int x, double y) {
            ...
          }
        \end{lstlisting}
    \end{enumerate}

  \subsection{Expressions}

    \begin{definition}[Expression]
      An \textbf{expression} is simply a line of code containing variables, operations, literals, and function names/calls. The process of executing an expression is called \textbf{evaluation}. The \textbf{type category} is simply the type of the value, object, or function that results from the evaluated expressions. The \textbf{value category} indicates whether the expression resolves to a value, an object, a function, or nothing (this list is exhaustive). 
    \end{definition}

\section{Translation} 

    Now that we've gotten the basics, we should learn more about the translation process so that we can avoid definition conflicts and know how to work with multi-file programs. 

    \begin{definition}[Translation]
      \textbf{Translating} C++ code to a binary consists of multiple steps: 
      \begin{enumerate}
        \item Preprocessing the code. 
        \item Compiling each file independently. 
        \item Linking all the files. 
      \end{enumerate}
      Conventionally, all of these are called \textit{compiling}, but it really isn't. 
    \end{definition}

  \subsection{Preprocessing} 

    When preprocessing, we do some boring stuff like removing comments. However, the main job is to take care of \textbf{preprocessing directives}, which are expressions with the \texttt{\#} symbol. The most obvious is the \texttt{\#include} directives, which \textbf{replaces the include directive with the contents of the included file}. That is, \texttt{\#include} is really just a way to substitute code.  
    \begin{enumerate}
      \item including with angle brackets, e.g. \texttt{\#include <iostream>}, means that the compiler is looking for this file in the standard library files. 
      \item including with double quotes, e.g. \texttt{\#include "tensor.h"}, means that the compiler is looking for this file locally in your project directory. It means you've written it. 
    \end{enumerate}
    
    Other directives is the \texttt{\#define} directive. 
    \begin{enumerate}
      \item You can define it to substitute text. It is conventionally in all upper-case.  
        \begin{lstlisting}
          #define NAME "Muchang"  // all instances of NAME will be replaced with "Muchang"
        \end{lstlisting}
      \item Or you can define it without substitution text, where further occurrences of \texttt{NAME} will be replaced by nothing. 
        \begin{lstlisting}
          #define NAME 
        \end{lstlisting}
    \end{enumerate}

    The second isn't used for substitution, but rather for \textbf{conditional compilation}, which can be useful. You just wrap C++ statements around as such.

    \noindent\begin{minipage}{.5\textwidth}
    \begin{lstlisting}[]{Code}
      #ifdef NAME 
      ... 
      #endif
    \end{lstlisting}
    \end{minipage}
    \hfill
    \begin{minipage}{.49\textwidth}
    \begin{lstlisting}[]{Output}
      #ifndef NAME 
      ... 
      #endif
      
    \end{lstlisting}
    \end{minipage} 

    To see the output after preprocessing, use the \texttt{-E} flag. 
    \begin{lstlisting}
      g++ main.cpp -E
    \end{lstlisting}

  \subsection{Compilation} 

    We only compile files one at a time and independently. When the compiler compiles a file, it goes through each line sequentially. Therefore, we must ensure that all functions/variables/classes are \textit{declared} first before they are called. \textit{Forward declaration} makes this a lot easier. 

    There is a difference between a declaration and a definition. 

    \begin{definition}[ODR]
      Remember the ODR (One Definition Rule): 
      \begin{enumerate}
        \item Within a file, each function, variable, type, or template in a given scope can only have one definition. Definitions occurring in different scopes (e.g. local variables defined inside different functions, or functions defined inside different namespaces) do not violate this rule. 

        \item Within a program, each function or variable in a given scope can only have one definition.\footnote{This rule exists because programs can have more than one file. For example, if you have two definitions of \texttt{int add(int, int)} in two different files, the linker does not know which one to connect the declaration to.}
      \end{enumerate}
      To be honest, ODR 2 really implies ODR 1, since once the directives are preprocessed or the object files are linked, we are really left with one executable file. 
    \end{definition} 

    \begin{example}[ODR 1 Violation] 
      The following shows that in the same file, there are multiple variables defined in the function scope of \texttt{main}, and there are two definitions of \texttt{foo} in the global scope. 
      
      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code}
          int main() {
            int x; 
            int x;

            return 0;
          } 
          .
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          int foo() { return 5; }
          int foo() { return 5; }

          int main() {
            std::cout << foo();
            return 0;
          } 
        \end{lstlisting}
      \end{minipage}
    \end{example}

    \begin{example}[ODR 2 Violation]
      Say that \texttt{main.cpp} has the \texttt{main()} method that calls on \texttt{int add(int x, int y)}, which is forward declared. However, say that we define add in two places. 

      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code}
          // foo.cpp 
          int add(int x, int y) {
            return x + y; 
          }
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          // bar.cpp 
          int add(int x, int y) {
            return x + y; 
          }
        \end{lstlisting}
      \end{minipage}
      Then, if we run \texttt{g++ main.cpp foo.cpp bar.cpp}, the linker will complain that there is a function redefinition. 
    \end{example}

  \subsection{Linking} 

    Remember, declaration is not the same thing as definition. When we do the linking, we go through all the source files in our project and match all the declarations with our definitions. The source files must all be written in the compile command. 

    \begin{lstlisting}
      g++ main.cpp add.cpp
      g++ add.cpp main.cpp
    \end{lstlisting}

    This should not be order dependent. The source files can be 

    \noindent\begin{minipage}{.5\textwidth}
      \begin{lstlisting}[]{Code}
        // main.cpp 
        int add(int x, int y); // declaration

        int main() {  
          int z = add(2, 3); 
          return 0; 
        }
      \end{lstlisting}
      \end{minipage}
      \hfill
      \begin{minipage}{.49\textwidth}
      \begin{lstlisting}[]{Output}
        // add.cpp
        // definition
        int add(int x, int y) { 
          return x + y;
        }
        .
        .
      \end{lstlisting}
    \end{minipage}

  \subsection{Header Files} 

    To be honest, we can just include forward declarations everywhere, but this does not scale well to large projects. If we had a set of declarations that we wanted to use over a bunch of files, we can package them nicely using a \textbf{header file}. 
    
    If we have a bunch of functions and classes written in \texttt{foo.cpp}, then it is conventional to write a \texttt{foo.h} that contains all the declarations of these expressions. Then, whenever we need to write a new file \texttt{bar.cpp} that uses functions from \texttt{foo.cpp}, we can just \texttt{\#include "foo.h"}, which replaces this directive (by the preprocessor) with all the forward declarations in \texttt{foo.h}. Boom easy. 

    \noindent\begin{minipage}{.5\textwidth}
      \begin{lstlisting}[]{Code}
        // add.cpp
        int add(int x, int y) { 
          return x + y;
        }
      \end{lstlisting}
      \end{minipage}
      \hfill
      \begin{minipage}{.49\textwidth}
      \begin{lstlisting}[]{Output}
        // add.h 
        int add(int x, int y); 
        .
        .
      \end{lstlisting}
    \end{minipage}

    Therefore when we call \texttt{add} in \texttt{main.cpp}, we can just \texttt{\#include "add.h"} to put in the declarations, making everything good. Conventionally, it is best practice for a source file to also include its paired header (e.g. \texttt{add.cpp} should also contain \texttt{\#include "add.h"} at the top). This allows the compiler to discover inconsistencies between the two files, and this extra cost is negligible.\footnote{\href{here}{https://www.learncpp.com/cpp-tutorial/cpp-faq/\#pairedheader}} 

    \begin{example}[Definitions inside Header Files]
      You should not add definitions (only declarations) to header files since if they are included in multiple header files, then we would have different definitions of the same function, leading to ODR 2 violation. Take a look at the following. 
      
      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code}
          // square.h
          int getSquareSides() {
              return 4;
          } 
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          // wave.h 
          #include "square.h"
        \end{lstlisting}
      \end{minipage}

      With the following. 
      \begin{lstlisting}
        #include "square.h"
        #include "wave.h" 
        int main() {
          return 0;
        }
      \end{lstlisting}
      This won't compile since 
      \begin{enumerate}
        \item by including \texttt{square.h}, we have defined \texttt{getSquareSides()} in the global scope of \texttt{main.cpp}. 
        \item by including \texttt{wave.h}, we have included \texttt{square.h} which then substitutes this line with the definition of \texttt{getSquareSides()} again. 
      \end{enumerate}
      This is an ODR 1 violation. 
    \end{example} 

    The simple fix to the above is to just remove the \texttt{\#include "wave.h"}, but what if we needed some other function from \texttt{wave.h}? Resolving this issue is not trivial if say, half of the functions in \texttt{square.h} is needed in \texttt{wave.h} and the other half is needed in \texttt{main.cpp}. We must include both of them in \texttt{main.cpp}, but then we have an inevitable redefinition. Without separating \texttt{square.h} into separate files, solving this is impossible. 

    Even if we didn't have definitions in header files in the first place (which is bad practice in general), repeated declarations, which are still fine, are also not really ideal either. Furthermore, custom types are typically defined in header files, so redefining them leads to an ODR violation. 
    
    \begin{definition}[Header Guards]
      Fortunately, we have \textbf{header guards}, which are conditional compilation directives that tell the compiler to include a header file at most once to the main file. You can do this in two ways. 
      \begin{enumerate}
        \item Just put this to the top of the header file. The compiler will take care of redeclaration/redefinitions for you. This isn't always fail-safe. 
        \begin{lstlisting}
          #pragma once
        \end{lstlisting} 

      \item More manually, we can use a conditional compilation directive. Put this on the top of the header. 
        \begin{lstlisting}
          #ifndef HEADERFILE_H
          #define HEADERFILE_H 
          
          ...Header Contents...

          #endif 
        \end{lstlisting}
        In the beginning, \texttt{HEADERFILE\_H} is not defined, so we include all of this. In a second inclusion though, \texttt{HEADERFILE\_H} is defined, so the preprocessor removes this. 
      \end{enumerate}

      Note that header guards limit the number of times a header can be included in a single given file, but the header may still be repeated across separate project files. This is what we want. 
    \end{definition}

  \subsection{Namespaces} 

    Perhaps we want to have two functions of the same name, but we get a redefinition error. This is where namespaces come in. 

    \begin{definition}[Namespace]
      We can wrap each function around a \textbf{namespace}, which is written with an upper-case letter. 
      \begin{lstlisting}
        namespace Foo {
          int bar() {}
        }
      \end{lstlisting}
      To access identifiers defined in the namespace, we must use the \textbf{scope resolution operator} \texttt{::}. If no scope resolution is given, or an empty one is given, then we look for the identifier in the global namespace. 
      \begin{lstlisting}
        int x = Foo::bar();   // Foo namespace
        int y = bar();        // global namespace
        int z = ::bar();      // global namespace 
      \end{lstlisting}
    \end{definition} 

    \begin{example}[Namespace]
      Say that we have two files with the same-name function in different namespaces. 
      
      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code}
          namespace Foo {
            int doSomething(int x, int y) {
              return x + y;
            }
          }
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          namespace Goo {
            int doSomething(int x, int y) {}
              return x - y;
            }
          }
        \end{lstlisting}
      \end{minipage}

      When we put our forward declarations, we must make sure to add the namespace using the scope resolution operator. If the namespace is not included, then the linker will look for the function in the global namespace rather than the user-defined namespace. 

      \begin{lstlisting}
        int doSomething(int x, int y); // this results in an error 
        int Foo::doSomething(int x, int y); // correct
        int Goo::doSomething(int x, int y); // correct

        int main() {
            std::cout << Foo::doSomething(4, 3) << '\n'; 
            std::cout << Goo::doSomething(4, 3) << '\n'; 
            return 0;
        }
      \end{lstlisting}
    \end{example} 

    Let's talk about a few properties of namespaces. 

    \begin{lemma}[Identifiers in Parent Namespaces]
      If an identifier $A$ in a namespace uses another identifier $B$ without a scope resolution, then $A$ will look for $B$ within $A$'s namespace. If no matching identifier for $B$ is found, then the compiler will then check each containing namespace in sequence to see if a match is found, with the global namespace being checked last. 

      \begin{lstlisting}
        #include <iostream>
        void print() // this print() lives in the global namespace
        {
          std::cout << " there\n";
        }

        namespace Foo {
          void print() // this print() lives in the Foo namespace
          {
            std::cout << "Hello";
          }

          void printHelloThere()
          {
            print();   // calls print() in Foo namespace
            ::print(); // calls print() in global namespace
          }
        }

        int main() {
          Foo::printHelloThere(); // prints "Hello there" 
          return 0;
        } 
      \end{lstlisting}
    \end{lemma}

    \begin{lemma}[Nested Namespaces]
      Namespaces can be nested as well, either of 2 ways. 

      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code}
          namespace Foo {
            namespace Goo{
              ... 
            }
          }
          .
          .
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          namespace Foo {

          }

          namespace Foo::Goo {

          }
        \end{lstlisting}
      \end{minipage}
    \end{lemma}

    \begin{lemma}[Namespace aliases]
      You can shorten namespaces using \textbf{namespace aliases}. 
      \begin{lstlisting}
        namespace Active = Foo::Goo; 
        int x = Active::doSomething(); 
      \end{lstlisting}
    \end{lemma}

    \begin{lemma}[Using Namespace]
      The \textbf{using namespace} is a directive that allows access to all members of a namespace. 
    \end{lemma}

  \subsection{Building and Makefiles}
    
      Most computer come with a built-in C or C++ compiler out of the box. There are generally two types. 
      \begin{enumerate}
        \item \textbf{gcc} (GNU compiler collection) is primarily a C compiler. \texttt{g++} is a C++ compiler built on top of gcc. When compiling C++ code, g++ automatically links the C++ standard library and enables C++ specific features. This is generally considered the old standard that supports more platforms and architectures.  
        \item \textbf{clang} is the C compiler and \textbf{clang++} is the C++ one. It is generally considered a more modern version, with better error messages. 
      \end{enumerate} 

      Generally, when you run these compiler commands, you must specify a huge number of options to go along with it. For example, here is my compiler commands for a personal project I am working on. 

      \begin{figure}[H]
        \centering 
        \begin{lstlisting}
          /Library/Developer/CommandLineTools/usr/bin/c++ \
          -Daten_python_EXPORTS \
          -I/Users/mbahng/Development/pyember/aten/src \
          -I/Users/mbahng/Development/pyember/aten/bindings \
          -isystem /opt/miniconda3/envs/ember/include/python3.12 \
          -isystem /Users/mbahng/Development/pyember/build/_deps/pybind11-src/include \
          -std=gnu++17 \
          -arch x86_64 -arch arm64 \
          -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX14.4.sdk \
          -fPIC -fvisibility=hidden -flto 
        \end{lstlisting}
        \caption{Note that \texttt{c++} is a symlink to either \texttt{g++} or \texttt{clang++}.} 
        \label{fig:com_code}
      \end{figure} 

      Let's parse some of these flags. 

      \begin{definition}[Optimization Flags]
        We can optimize our compilation process at different levels. 
        \begin{enumerate}
          \item \texttt{-O0}: No optimization, with fastest compilation and best for debugging. 
          \item \texttt{-O1}: Basic optimization 
          \item \texttt{-O2}: Moderate optimization, with best balance and most commonly used. 
          \item \texttt{-O3}: Aggressive optimization, which can make code larger/slower in some cases. 
          \item \texttt{-Os}: Optimize for size of the final binary. 
          \item \texttt{-Ofast}: Like \texttt{-O3} but can break standards compliance for speed. 
        \end{enumerate}
      \end{definition}

      \begin{definition}[Debugging Flags]
        The various flags for debugging information are: 
        \begin{enumerate}
          \item \texttt{-g}: Include debugging information. 
          \item \texttt{-Wall}: Enable all common warnings. 
          \item \texttt{-Wextra}: Enable extra warnings beyond \texttt{-Wall} 
          \item \texttt{-Werror}: Treat warnings as errors. 
          \item \texttt{-fsanitize=undefined}: Check for undefined behavior. 
        \end{enumerate}
      \end{definition} 

      \begin{definition}[Language Standards]
        The language standards are simple. 
        \begin{enumerate}
          \item \texttt{-std=c++17}: Use C++17 standard. 
          \item \texttt{-std=c++20}: Use C++20 standard. 
          \item \texttt{-std=gnu++17}: Use C++17 with GNU extensions. 
        \end{enumerate}
      \end{definition}

      \begin{definition}[Architecture/Platform]
        \begin{enumerate}
          \item \texttt{-fPIC}: Generate position-independent code (needed for shared libraries). 
          \item \texttt{-m32} or \texttt{-m64}: Compile for 32/64-bit used mainly in traditional Unix/Linux environments.\footnote{This isn't needed when you have the \texttt{-arch} flag.}
          \item \texttt{-arch}: Specify the CPU architecture for compatibility across OSes. You can specify \texttt{x86\_64}, \texttt{arm64}, and others. You can specify multiple architectures to make it portable with all of them, e.g. \texttt{-arch x86\_64 -arch arm64}. 
          \item \texttt{-march native}: On a known CPU architecture, this tells to use all available instructions for this CPU, which optimizes performance of instruction sets at the cost of portability. If you want to ensure maximum compatibility \textit{across} architectures, you don't want this flag since it will use instructions that other CPUs do not support. 
          \item \texttt{-mtune=generic} however optimizes for a CPU but doesn't use instructions unique to it. This is good for widely distributed software. 
        \end{enumerate}
      \end{definition}

      \begin{definition}[Include Paths and Linking]
        These final ones are probably the ones you will directly interact with the most. 
        \begin{enumerate}
          \item \texttt{-c source.cpp}: Tells to create an object file from the source file \texttt{source.cpp}. 
          \item \texttt{-I<path>}: Add include directory, which is a directory where the compiler looks for header files that are referenced in your source code. It tells the compiler to also look in this directory for headers. 
          \item \texttt{-L<path>}: Add library search directory, which tells the compiler to look for library files (like \texttt{.so}, \texttt{.dylib}, \texttt{.pyd}, or \texttt{.a} files) in a certain directory during the linking phase. 
          \item \texttt{-l<library>}: Link against library. 
          \item \texttt{-D<macro>}: Define preprocessor macro. 
        \end{enumerate}
      \end{definition}

    \subsubsection{Makefiles} 
    
      \begin{definition}[Makefiles]
        As we've seen above, we probably don't want to rewrite out an entire set of arguments every time we compile something. Perhaps we can make another script that automatically generates these commands, called \textbf{build files}. These are \textbf{Makefiles} and they exist literally with the name \texttt{Makefile} in a directory. If we run the \texttt{make} command with an argument, also called a \textbf{target}, it automatically compiles with the flags that we set in the Makefile. The general structure of a makefile is 
        \begin{lstlisting}
          target: dependencies 
            commands # This must be a tab, not a space
        \end{lstlisting}
        In here, you can define commands for compiling, linking, translation, and cleaning.  
      \end{definition}

      \begin{example}[Representative Makefile]
        Here is an example, where we can call 
        \begin{enumerate}
          \item \texttt{make} or \texttt{make all} 
          \item \texttt{make program}
          \item \texttt{make main.o} 
          \item \texttt{make utils.o}
        \end{enumerate}
        \begin{lstlisting}
          # Define arguments 
          CXX = g++
          CXXFLAGS = -Wall -O2

          # Default: generate the binary directly
          all: main.cpp utils.cpp 
              $(CXX) $(CXXFLAGS) main.cpp utils.cpp

          # Link the object files
          program: main.o utils.o
              $(CXX) $(CXXFLAGS) main.o utils.o -o program

          # Create object file from source file main.cpp
          main.o: main.cpp
              $(CXX) $(CXXFLAGS) -c main.cpp

          # Create object file from source file utils.cpp
          utils.o: utils.cpp
              $(CXX) $(CXXFLAGS) -c utils.cpp        
        \end{lstlisting}
      \end{example}

  \subsection{CMake}

      Even with Makefiles, they have some disadvantages. 
      \begin{enumerate}
        \item They can get extremely complex with thousands of lines in a single Makefile. 
        \item Makefiles are primarily designed for Unix-like systems, so cross-platform development is hard. 
        \item The dependencies may be complex, with different libraries stored in different locations on different platforms. Coding this all into a Makefile is error prone. 
      \end{enumerate}

      \begin{definition}[CMake]
        Therefore, we have a further abstraction called CMake, which automatically generates Makefiles, which themselves generate the actual compiler commands. They are stored in a text file called \texttt{CMakeLists.txt}. Conventionally, you would make a \texttt{build/} directory \texttt{cd} into it, and run 
        \begin{lstlisting}
          cmake <path-to-cmakelists> 
        \end{lstlisting} 
        which will automatically generate a Makefile along with other build files for you. 
      \end{definition} 

      Let's talk about what options CMake supports. 

    \subsubsection{Standards}

      \begin{definition}[Version]
        CMake is a software, and it has versions that are important to have a general knowledge of. 
        \begin{enumerate}
          \item \textit{CMake 3.0} (2014). Major transition from CMake 2.x by Kitware. Has target-based dependency management. 
          \item \textit{CMake 3.6} (2016). Enhanced C++11/14/17 support. 
          \item \textit{CMake 3.10} (2017). Added CUDA language support and Visual Studio 2017 support. 
          \item \textit{CMake 3.20} (2021). Improved C++20 support. 
          \item \textit{CMake 3.27} (2023). Improved build system integration. 
        \end{enumerate}
        We can set the minimum version. If a user tries to compile with a CMake version that is less than that required, compilation fails. 
        \begin{lstlisting}[language=CMake]
          # Requires CMake 3.10 or higher 
          cmake_minimum_required(VERSION 3.10)  

          # This sets policies to 3.10 but requires at least 3.5
          cmake_minimum_required(VERSION 3.5...3.10)
        \end{lstlisting}
      \end{definition} 

      \begin{definition}[CMake Options and Variables]
        CMake variables are variables that are either set manually or automatically. They are conventionally uppercase. 
        \begin{enumerate}
          \item To set one manually in \texttt{CMakeLists.txt}, we write 
          \begin{lstlisting}[language=CMake]
            # basic variable setting 
            set(MY_VARIABLE "value") 
            # list variable 
            set(MY_LIST "item1" "item2" "item3") 
            # path variable 
            set(MY_PATH "${PROJECT_SOURCE_DIR}/include")
          \end{lstlisting}

          \item We can actually set them directly in the command line when calling \texttt{cmake}. You should first set an option for it in \texttt{CMakeLists.txt} and then call it with the option argument having a prefix of \texttt{D}, which tells cmake that this is a variable definition. 
            
          \noindent\begin{minipage}{.47\textwidth}
            \begin{lstlisting}[language=CMake]{Code}
              # CMakeLists.txt
              option(MY VARIABLE "Documentation" ON)
            \end{lstlisting}
            \end{minipage}
            \hfill
            \begin{minipage}{.46\textwidth}
            \begin{lstlisting}[]{Output}
              # Command Line 
              cmake -DMY_VARIABLE=value ..
            \end{lstlisting}
          \end{minipage}

        \end{enumerate}
      \end{definition} 

      \begin{definition}[Message]
        You can output logs as a part of your build process such as the following. 
        \begin{lstlisting}[language=CMake]
          message("Hello world") 
          message("my variable is ${MY_VARIABLE}")
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Project Name]
        The project name defines the name of your project and automatically sets certain CMake variables. 
        \begin{enumerate}
          \item \texttt{PROJECT\_NAME} contains the name you specified in \texttt{project()}. 
          \item \texttt{PROJECT\_SOURCE\_DIR} is the full path to the directory containing your main \texttt{CMakeLists.txt} 
          \item \texttt{PROJECT\_BINARY\_DIR} is the full path to the build directory where CMake generates build files. 
        \end{enumerate}
        \begin{lstlisting}[language=CMake]
          project(aten)

          # Sets these variables
          message("Project name: ${PROJECT_NAME}")
          message("Source dir: ${PROJECT_SOURCE_DIR}")
          message("Build dir: ${PROJECT_BINARY_DIR}") 
        \end{lstlisting}
      \end{definition}

      \begin{definition}[C++ Standards]
        We can set the C++ standard as such
        \begin{lstlisting}[language=CMake]
          set(CMAKE_CXX_STANDARD 17)
        \end{lstlisting}
        which is equivalent to using compiler flags like \texttt{-std=c++17}. If we also set 
        \begin{lstlisting}[language=CMake]
          set(CMAKE_CXX_STANDARD_REQUIRED ON)
        \end{lstlisting}
        then this forces CMake to always use the specified standard and will fail if the compiler does not support C++17. 
      \end{definition}

      \begin{definition}[Operating Systems]
        CMake also automatically defines which operating system it is running on through the following cmake variables. With these, we can use conditionals to set extra configuration depending on the system. 
        \begin{lstlisting}[language=CMake]
          if(UNIX)        # Linux, macOS, BSD, etc.
              # UNIX-specific settings
          endif()

          if(APPLE)       # macOS, iOS
              # Apple-specific settings
          endif()

          if(WIN32)       # Windows
              # Windows-specific settings
          endif()

          if(LINUX)       # Linux specifically
              # Linux-specific settings
          endif() 
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Architecture]
        The \texttt{CMAKE\_OSX\_ARCHITECTURES} is similar to the \texttt{-arch} flag. 
        \begin{lstlisting}[language=CMake]
          set(CMAKE_OSX_ARCHITECTURES "x86_64;arm64")
        \end{lstlisting}
      \end{definition} 

    \subsubsection{Compiling}

      \begin{definition}[Build Type]
        \texttt{CMAKE\_BUILD\_TYPE} sets the type of build configuration, which controls compiler optimization levels and debug information. The options are 
        \begin{enumerate}
          \item \texttt{Debug}. No optimization (\texttt{-O0}), includes debug symbols (\texttt{-g}). Produces larger binaries and slower execution. 
          \item \texttt{Release}. Max optimization (\texttt{-O3}), no debug symbols. Has fastest execution and smaller binaries, but harder to debug. 
          \item \texttt{RelWithDebInfo}\footnote{Stands for \textit{Release with Debug Info}}. High optimization (\texttt{-O2}), includes debug symbols (\texttt{-g}).  
          \item \texttt{MinSizeRel}\footnote{Minimum size release.}. Size optimization \texttt{-Os}, no debug symbols, and smallest possible binaries, which are good for embedded systems. 
        \end{enumerate}
        We can set it either in the file or in the command line. 
        \begin{lstlisting}[language=CMake]
          # Set during cmake configuration
          cmake -DCMAKE_BUILD_TYPE=Release ..

          # Or in CMakeLists.txt 
          set(CMAKE_BUILD_TYPE Debug)
          set(CMAKE_CXX_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_DEBUG} -g")
        \end{lstlisting}
      \end{definition} 

      \begin{definition}[Add Executable]
        \texttt{add\_executable} tells CMake to create an executable program from source files. 
        \begin{lstlisting}
          # Creates executable named 'myapp' from main.cpp
          add_executable(myapp main.cpp)  

          # Multiple source files 
          add_executable(myapp2 
              main.cpp
              utils.cpp
              helper.cpp
          )
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Include Directories] 
        We can tell cmake to look into specific include directories to look for header files, similar to the \texttt{-I} flag. 
        \begin{lstlisting}
          target_include_directories(myapp PRIVATE include)
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Link Libraries]
        We can tell cmake to look into certain library directories to look for library files (\texttt{.so}, \texttt{.a}, etc.) during linking, similar to the \texttt{-L} flag. 
        \begin{lstlisting}
          target_link_libraries(myapp PRIVATE somelib)
        \end{lstlisting}
      \end{definition}

    \subsubsection{Subdirectories}
  
      \begin{example}[Motivation for Multiple CMake Files]
        Sometimes, you may have multiple \texttt{CMakeList.txt} in different subdirectories. Look at this directory structure. 
        \begin{lstlisting}
          .
          |-- CMakeLists.txt
          |-- README.md
          |-- bindings
          |   |-- CMakeLists.txt
          |   |-- ...
          |   |-- common.hpp
          |-- main.cpp
          |-- src
          |   |-- CMakeLists.txt
          |   |-- ...
          |   |-- Util
          |-- test
              |-- CMakeLists.txt
              |-- ...
              |-- Tensor
        \end{lstlisting}
        \begin{enumerate}
          \item It has a main cmake file. 
          \item If we want to compile the source files, there \texttt{src/CMakeLists.txt} that will do it for us. 
          \item Same with the bindings cmake file. 
          \item Same with the test cmake file. 
        \end{enumerate}
        This nested structure allows for more flexibility, since by setting certain cmake parameters, we can control which parts of this project get compiled. 
      \end{example}

      \begin{definition}[Subdirectories]
        \texttt{add\_subdirectory} tells CMake to enter a subdirectory and process the \texttt{CMakeLists.txt} file there. 
        \begin{lstlisting}[language=CMake]
          add_subdirectory(src)
        \end{lstlisting}
      \end{definition}

      \begin{definition}[Conditionals]
        We can implement conditionals. 
        \begin{lstlisting}[language=CMake]
          if (BUILD_DEV) 
            message(STATUS "Development mode ON")
            ...
            add_subdirectory(test)
          else()
            message(STATUS "Development mode OFF")
          endif()
        \end{lstlisting}
      \end{definition}
    
    \subsubsection{External Libraries} 

      When you install CMake, it also comes with a set of \texttt{Find<Package>.cmake} files, which are basic finders located in CMake's modules directory. This on my mac is located in \texttt{/opt/homebrew/share/cmake/modules/}, which contains files like \texttt{FindZLIB.cmake} or \texttt{FindOpenSSL.cmake}. These are also cmake files and contain variables that tell you where to find these packages. 

      However, just because the cmake finders are there does not mean that the actual package is installed. Therefore, \texttt{Find<Package>.cmake} will run but fail to find the package. When you install an external library through a system package manager like apt/brew/pacman or by building it yourself, it creates a package configuration file. 

      \begin{definition}[Package Config Files]
        The package creates a file called \texttt{<Package>Config.cmake} (also a cmake file) which serves to tell other projects how to use the installed library. They are usually found in paths like 
        \begin{lstlisting}
          /user/lib/cmake/XXX/XXXConfig.cmake
        \end{lstlisting}
      \end{definition}

      \begin{example}
        \begin{lstlisting}
          # When you install CMake, you get basic finders like:
          /opt/homebrew/share/cmake/Modules/FindZLIB.cmake
          /opt/homebrew/share/cmake/Modules/FindOpenSSL.cmake

          # When you install Boost, you get:
          /opt/homebrew/lib/cmake/Boost-1.82.0/BoostConfig.cmake

          # When you install OpenCV, you get:
          /opt/homebrew/lib/cmake/opencv4/OpenCVConfig.cmake 
        \end{lstlisting}
      \end{example} 

      \begin{definition}[Find Package]
        Therefore, if we want to use an external package, we must first take the cmake finder file, find the package config file, and locate the existing package binaries. This is all done by the \texttt{find\_package} command. 

        \begin{lstlisting}[language=CMake]
          # Simple find
          find_package(OpenSSL)

          # Require the package - CMake will error if not found
          find_package(Boost REQUIRED)

          # Find specific components of a package
          find_package(Boost REQUIRED COMPONENTS filesystem system)

          # Specify minimum version
          find_package(OpenSSL 1.1.1 REQUIRED) 
        \end{lstlisting}

        So how does it know where to look for packages? It looks at the following in order. 
        \begin{enumerate}
          \item Package-specific hints, e.g. \texttt{BOOST\_ROOT} for Boost to see if any package-specific paths are defined. 

          \item \texttt{CMAKE\_PREFIX\_PATH}, which is a cmake variable that you can specify manually. 
            \begin{lstlisting}[language=CMake]
              # In CMakeLists.txt
              set(CMAKE_PREFIX_PATH 
                  "/custom/path/to/library"
                  "/another/path"
              ) 
            \end{lstlisting}

          \item System paths, which differ for each operating system. 
            \begin{lstlisting}
              # On macOS (with Homebrew/M1,M2,M3)
              /opt/homebrew/lib/cmake/
              /usr/local/lib/cmake/

              # On Linux
              /usr/lib/cmake/
              /usr/local/lib/cmake/
              /usr/share/cmake/
            \end{lstlisting}
        \end{enumerate}

        If a package is not found, it will report an error (if REQUIRED). When a package is found, it typically provides 
        \begin{lstlisting}[language=CMake]
          # Common variables set by find_package
          ${PACKAGE_NAME}_FOUND        # Was it found?
          ${PACKAGE_NAME}_INCLUDE_DIRS # Headers location
          ${PACKAGE_NAME}_LIBRARIES    # Library locations 
        \end{lstlisting}
      \end{definition}

      While \texttt{find\_package} looks for the system's pre-built binaries, we can also get the source code from a library directly and compile/link it along with our program. This is what \texttt{FetchContent\_Declare} does. 

      \begin{definition}[Fetch Content]
        The \texttt{FetchContent\_Declare} downloads code during CMake configuration and builds the library from source as a part of my project. If you have your own project A and it requires dependency B, it downloads and compiles B, compiles A, and then links the object files of A and B together to get the final binary. In your cmake file, you must first 
        \begin{lstlisting}[language=CMake]
          include(FetchContent)
        \end{lstlisting}
        and then 
        \begin{lstlisting}[language=CMake]
          # First declare what you want
          FetchContent_Declare(
              googletest
              GIT_REPOSITORY https://github.com/google/googletest.git
              GIT_TAG main
          )

          # Then make it available (downloads & builds)
          FetchContent_MakeAvailable(googletest)
        \end{lstlisting}
        It will have slower builds than finding a package since it compiles everything. In the backend, it is really just doing an \texttt{add\_subdirectory} of the downloaded repository's source and binary directories, with their own cmake files, and processing them. 
      \end{definition}

\section{Constants and Constant Expressions}

    One of the greatest advantages of C++ is that it is compiled, which allows us to reduce the runtime by offloading computations into compile time. This is particularly important for speed-sensitive programs such as algorithmic trading. Therefore, we should be familiar with consts and constexprs. 

  \subsection{Compiler Optimization} 

    By default, all expressions are evaluated at runtime, but compilers have different levels of optimization. Here are some methods in which it optimizes, which follow the \textbf{as-if rule} that states that a compiler can modify a program however it likes in order to produce more optimized code, so long as those modification do not affect a program's observable behavior. 

    \begin{definition}[Constant Folding] 
      The compiler replaces expressions that have literal operands with the result of the operation, e.g. \texttt{3 + 4} automatically gets evaluated to \texttt{7}. 
    \end{definition}

    \begin{definition}[Constant Propagation]
      In the code below, \texttt{x} is initialized to be \texttt{7} and will be stored in the memory allocated for \texttt{x}. On the next line, the program will go out to memory to fetch the same value to print. This is redundant. Therefore, the compiler will realize that \texttt{x} always has the constant value \texttt{7} and will replace all instances of \texttt{x} with \texttt{7}. 
      \begin{lstlisting}
        #include <iostream>

        int main() {
          int x { 7 };
          std::cout << x << '\n';
          return 0;
        } 
      \end{lstlisting}
    \end{definition}

    \begin{definition}[Dead Code Elimination]
      The compiler removes all code that has no noticeable effect on the program's behavior. Note that this is not a preprocessing step. 
      \begin{lstlisting}
        #include <iostream>
        int main() {
          int x { 7 }; // this line is removed. 
          std::cout << 7 << '\n';
          return 0;
        } 
      \end{lstlisting}
    \end{definition} 

    A slightly higher level optimization evaluates certain expressions during compile time. 

    \begin{definition}[Compile-Time Expression]
      A \textbf{compile-time expression} is an expression that must always be capable of being evaluated at compile-time. 
    \end{definition}

    \begin{example}
      Say we have the following code. 
      \begin{lstlisting}
        const double x { 1.2 };
        const double y { 3.4 };
        const double z { x + y }; 
      \end{lstlisting} 
      \texttt{z} may or may not be evaluated to \texttt{4.6} at runtime. By default it is evaluated at runtime, but it depends on the compiler and level of optimization. 
    \end{example}

    Shifting some of the evaluation from runtime to compile time makes your code faster, though it may make it more difficult to debug since the compiler might rearrange the logic of your program (though in an equivalent way). Therefore, at runtime, the compiled code no longer correlates with the original source code. 
  
  \subsection{Constants}

    Now we talk about a seemingly separate, but very related concept. 

    \begin{definition}[Constant Variables]
      \textbf{Named constants} are variables that cannot change. 
      \begin{enumerate}
        \item They cannot be declared and must be initialized since they cannot change. This is called \textbf{constant expression initialization}.
        \item If a variable can be made constant, it should be. It reduces bugs and gives more opportunity for compiler optimization, effectively reducing runtime and increasing compile time. 
        \item Function parameters that are \texttt{const} just tells the compiler that it won't be changed during the function execution. But since the variable is thrown away after the body, it doesn't really matter anyways. You can also return const types, but this is again a temporary copy and may impede compiler optimizations so it not recommended. 
        \item In a way, consts are just like object-like directives with substitution text, but consts follow scoping, so use consts whenever you can rather than macros. 
      \end{enumerate}
    \end{definition}

    \begin{theorem}
      All compiler-time expressions must be consts. However, a const variable does not guarantee that it will be evaluated in compile time. With only consts, only const \textit{integral} variables can be a part of a constant expression. No other const variable is allowed.
    \end{theorem}
    \begin{proof}
      It is not surprising to see that if an expression can be evaluated at compile time, it must be a const variable. Consider the contrapositive: if it wasn't a const variable, then it may be initialized or changed during runtime and therefore the expression cannot be evaluated at compile time. However, the converse is not true. 
    \end{proof}

  \subsection{Compile-Time Programming}  
    
    Notice that when we really want a section of code to be evaluated at compile-time, the best we can do is use const variables and hope that the compiler executes it. In other words, we are dependent on the sophistication of the compiler, which is not ideal. To allow more explicit control over which parts of code we want to execute at compile-time, we can use \textbf{compile-time programming}. In C++11, compile-time programming was introduced with constant expressions, or \textbf{constexpr}s.

    \begin{definition}[Constant Expression]
      A \textbf{constant expression} is an expression that must be entirely evaluatable at compile-time.\footnote{along with rules that determine how the compiler should handle these expressions.} They generally contain the following: 
      \begin{enumerate}
        \item Literals 
        \item Most operators with constant expression operands, e.g. \texttt{3 + 4}, \texttt{2 * sizeof(int)} 
        \item Constexpr variables  
        \item Constexpr function calls with constant expression arguments. 
      \end{enumerate}
      Any expression not a constant expression is called a \textbf{runtime expression}. The following cannot be used in a constant expression. 
      \begin{enumerate}
        \item Non-const variables (e.g. \texttt{int x = 3;}) 
        \item Const non-integral variables, even when they have a constant expression initializer (e.g. \texttt{const double d = 1.2}). To use such variables, we need to define them with \texttt{constexpr}. 
        \item Function parameters. 
      \end{enumerate}
      There is a complex list of literals, operators, and variables that can and cannot be used in constant expressions. 
    \end{definition}

    There are still two problems. First, the limitations of constant expressions not being able to contain const non-integral variables is quite restricting. Second, even if we did have a constant expression, the compiler will by default evaluate it at runtime. Fortunately, constexpr addresses both problems. 

    \begin{definition}[constexpr Keyword]
      The \textbf{constexpr} variable is always a compile-time constant. As a result, a constexpr variable must be initialized with a constant expression, otherwise a compilation error will result. Here are some examples. 
      \begin{lstlisting}
        constexpr double gravity = 9.8; // works for doubles now 
      \end{lstlisting} 
      Since a constexpr variable is really a constant expression, it is implicitly a const variable. 
    \end{definition} 

\section{Lvalue and Rvalues} 

  \subsection{Lvalues and Rvalues}
  
    There are two types of a value expressions prior to C++11. 
    \begin{enumerate}
      \item An \textbf{lvalue} expression evaluates to a named object (variable) or function. A \textbf{modifiable lvalue} can be modified, while a \textbf{non-modifiable lvalue} cannot be modified (because it is const or constexpr). 
      \item An \textbf{rvalue} expression evaluates to everything else, such as unnamed objects (values), literals, or unnamed functions (anonymous functions). They are not identifiable (meaning they have to be used immediately) and only exist within the scope of the expression in which they are used. 
    \end{enumerate}

    \begin{example}[Assignment Statement]
      An \textbf{assignment statement} requires the use of the \textbf{assignment operator} and two subexpressions, which are the operands. Note that the whole statement is also an expression. 
      \begin{lstlisting}
        int x = 2; 
      \end{lstlisting}
      \begin{enumerate}
        \item It requires the left operand to be a modifiable lvalue expression, and
        \item the right operand to be an rvalue expression. 
      \end{enumerate}
    \end{example} 

    \begin{lemma}[Implicit Conversion of lvalue to rvalue]
      It turns out that in assignment statements, lvalues can also be on the right side since they are implicitly converted to rvalues. 
    \end{lemma}

    This gets very important when learning about references later on.

\section{Control Flow and Error Handling}  

    We are probably familiar with for loops and if statements, but C++ gives us a much wider suite of keywords and operators to choose from. In here, we revisit three things: 
    \begin{enumerate}
      \item \textit{Conditional statements}. We visit them by comparing if and switch statements, along with seeing how they may be evaluated at compile time when using constexprs. 
      \item \textit{Loops}. We can approach them more formally now that we know about scope and duration. 
      \item \textit{Assert and exit statements}. 
    \end{enumerate}

  \subsection{If Statements} 

    Constexpr if statements can be evaluated at compile time, so we end up compiling only the block under the condition that evaluates to true.   

  \subsection{Switch Statements}

  \subsection{Assert and Static Assert} 

    Assert statements can be turned off with the \texttt{\#NDEBUG} directive. \texttt{static\_assert} checks at compile time, so the condition must be a constant expression. 

  \subsection{Halt Statements}

\section{Named Functions} 

    Now we revisit named functions (as opposed to anonymous functions, which we need to know about structs for), and explore it a bit more. This is our first compound type that we will delve into. 

    \begin{definition}[Named Functions]
      Note that when a function is called, it creates a new stack and \textit{copies} the arguments into the new stack frame. It does the evaluation and returns whatever expression by again \textit{copying}, and all the variables in the stack are destroyed. It is a \textit{compound type} of form 
      \begin{lstlisting}
        T funcName(T arg1, T arg2, ...)
      \end{lstlisting}
    \end{definition}

    This picture of a function is especially important when dealing with its nuances. 
  
  \subsection{Inline Functions} 

    When we make a call to a function, we add another frame to our call stack, store the address of our stack pointer, and then execute the function body in the new stack frame. This is known as the \textbf{function overhead}. 

    \begin{definition}[Inline Functions]
      We can avoid this by using the \texttt{inline} keyword to define \textbf{inline functions}. 
      \begin{lstlisting}
        inline int add(int x, int y) {
          return x + y; 
        }
      \end{lstlisting}
      As the name suggests, the compiler essentially replaces the function call with the function body, treating as it if it were all on the same stack frame. 
    \end{definition}

    We get the benefits of no function overhead while still maintaining modularity of our code. However, abusing this increases the size of our compiled executable, which may make our program slower. Most of the time, the compiler is better at optimizing this.  

  \subsection{Overloading} 

    Functions can be overloaded based on their parameters, and the compiler will try to match the function call to the appropriate overload based on the arguments, called \textbf{overload resolution}. The number of parameters and types of parameters are used in differentiating, but not the return type. 

  \subsection{Deleting}

    Sometimes, functions may use implicit type conversion to call. For example, look at the code. 

    \begin{lstlisting}
      #include <iostream>

      void printInt(int x) {
        std::cout << x << '\n';
      }

      int main() {
        printInt(5);    // okay: prints 5
        printInt('a');  // prints 97 -- does this make sense?
        printInt(true); // print 1 -- does this make sense?
        return 0;
      }
    \end{lstlisting}

    \begin{definition}[Function Deleting]
      If we want to enforce that a function cannot take other parameters, we can define that function as deleted using the \texttt{= delete} specifier. A call to a deleted function will halt compilation. 
      \begin{lstlisting}
        #include <iostream>

        void printInt(int x) {
            std::cout << x << '\n';
        }

        void printInt(char) = delete; // calls to this function will halt compilation
        void printInt(bool) = delete; // calls to this function will halt compilation

        int main() {
          printInt(97);   // okay

          printInt('a');  // compile error: function deleted
          printInt(true); // compile error: function deleted

          printInt(5.0);  // compile error: ambiguous match

          return 0;
        } 
      \end{lstlisting}
    \end{definition}

  \subsection{Default Arguments} 

    Explicit arguments must all come before any default argument. 

    Default arguments can not be redeclared, and must be declared before use. Therefore, for forward declarations, the default argument can be declared in either the forward declaration or the function definition, but not both.   

    However, note that default arguments can lead to ambiguous matches. 

  \subsection{Template Functions}

    \begin{definition}[Template Functions]
      Let's talk about the syntax. We start with the keyword \texttt{template}, which tells the compiler that we're creating a template. Next we specify all the template parameters that our template will use inside the brackets. For each type template parameter, we use the keyword \texttt{template} or \texttt{class}, followed by the name of the type template parameter (e.g. \texttt{T}). 
      \begin{lstlisting}
        template <typename T> 
        T add(T x, T y) {
          return x + y; 
        } 
      \end{lstlisting}
      Function templates are not actually functions. Their code isn't compiled or executed directly. Instead, function templates have one job: to generate functions (that are compiled and executed), called \textbf{function instantiation}. The instantiated functions are called \textbf{function instances}, and they are \textit{implicitly inline}. When we call a function with a new template argument, it gets instantiated during translation. Therefore, if we called \texttt{add} with arguments \texttt{int} and \texttt{double}, the result of our compilation would look as if we had explicitly defined the following functions. 
      \begin{lstlisting}
        template<>
        int max<int>(int x, int y) // the generated function max<int>(int, int)
        {
            return (x < y) ? y : x;
        }

        template<>
        double max<double>(double x, double y) // the generated function max<double>(double, double)
        {
            return (x < y) ? y : x;
        }
      \end{lstlisting}
    \end{definition}

    Here are some properties. 

    \begin{lemma}[Normal Function Call Priority]
      Template functions can be called in several ways. However, a normal function call syntax will prefer a non-template function over an equally viable function instantiated from a template. 

      \begin{lstlisting}
        template <typename T>
        T max(T x, T y)
        {
            std::cout << "called max<int>(int, int)\n";
            return (x < y) ? y : x;
        }

        int max(int x, int y)
        {
            std::cout << "called max(int, int)\n";
            return (x < y) ? y : x;
        }

        int main()
        {
            std::cout << max<int>(1, 2) << '\n'; // calls max<int>(int, int)
            std::cout << max<>(1, 2) << '\n';    // deduces max<int>(int, int) (non-template functions not considered)
            std::cout << max(1, 2) << '\n';      // calls max(int, int)

            return 0;
        } 
      \end{lstlisting}
    \end{lemma} 

    \begin{lemma}[Static Local Variables]
      If a static local variable is defined in a template function, every function instance will have its own copy of the static local variable. 
      \begin{lstlisting}
        #include <iostream>

        template <typename T>
        void printIDAndValue(T value) {
          static int id{ 0 };
          std::cout << ++id << ") " << value << '\n';
        }

        int main() {
          printIDAndValue(12);    // 1) 12
          printIDAndValue(13);    // 2) 13 
          printIDAndValue(14.5);  // 1) 14.5
          return 0;
        } 
      \end{lstlisting}
    \end{lemma} 

    \begin{lemma}[No Implicit Type Conversions]
      Unlike explicit functions, function instances are strict in that they will not do any implicit type conversions. In the left, the call to \texttt{max} is okay since the int will be converted to a double. On the right, however, will generate an error. 

      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code}
          double max(double x, double y) {
            return (x < y) ? y : x;
          }

          int main() {
            std::cout << max(2, 3.5) << '\n'; // okay
            return 0;
          }
          .
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          template <typename T>
          T max(T x, T y) {
            return (x < y) ? y : x;
          }

          int main() {
            std::cout << max<double>(2, 3.5) << '\n'; // error
            return 0;
          }
        \end{lstlisting}
      \end{minipage}
    \end{lemma} 

    \begin{definition}[Multiple Template Type Parameters]
      
    \end{definition}

    \begin{definition}[Overloading Function Templates]
      
    \end{definition}

    \begin{lemma}[Function Templates in Multiple Files]
      When we forward declare a function template, we cannot just define the template function in another file. 

      \noindent\begin{minipage}{.5\textwidth}
        \begin{lstlisting}[]{Code} 
          // main.cpp
          template <typename T>
          T addOne(T x); // template forward declaration

          int main() {
              std::cout << addOne(1) << '\n';
              std::cout << addOne(2.3) << '\n';
              return 0;
          }
        \end{lstlisting}
        \end{minipage}
        \hfill
        \begin{minipage}{.49\textwidth}
        \begin{lstlisting}[]{Output}
          // add.cpp
          template <typename T>
          T addOne(T x) {
            return x + 1;
          }
          .
          .
          .
          .
          .
        \end{lstlisting}
      \end{minipage}

      This would get a linker error since the linker cannot see the definitions of all the \textit{function instances}. There are two solutions to this. 
      \begin{enumerate}
        \item We can use a header file that contains the function template definition and add that along with a header guard. This is recommended. 

        \noindent\begin{minipage}{.45\textwidth}
          \begin{lstlisting}[]{Code}
            // main.cpp
            template <typename T> 
            T add(T x, T y); 

            int main() { 
              std::cout << add(1, 2) << "\n";
              std::cout << add('1', 'a') << "\n";
              return 0; 
            }
          \end{lstlisting}
          \end{minipage}
          \hfill
          \begin{minipage}{.44\textwidth}
          \begin{lstlisting}[]{Output}
            // add.cpp
            template <typename T>
            T add(T x, T y) {
              return x + y;
            }
            template int add<int>(int x, int y);
            template char add<char>(char x, char y);
            .
          \end{lstlisting}
        \end{minipage}

        \item We can explicitly define all the necessary function instances.\footnote{Before C++20, only integral, enumeration type, or constexpr can be a template parameter.} This might be okay if we are using enum types. 

        \noindent\begin{minipage}{.45\textwidth}
          \begin{lstlisting}[]{Code}
            // main.cpp
            #include "add.h"

            int main() {
              std::cout << add(1, 2) << "\n";
              std::cout << add('a', 'b') << "\n";
              return 0;
            }
          \end{lstlisting}
          \end{minipage}
          \hfill
          \begin{minipage}{.44\textwidth}
          \begin{lstlisting}[]{Output}
            // add.cpp
            #pragma once

            template <typename T>
            T add(T x, T y) {
              return x + y;
            }
            .
          \end{lstlisting}
        \end{minipage}
      \end{enumerate}
    \end{lemma}

  \subsection{Non-Type Template Parameters} 

    As of C++20, function parameters cannot be constexpr. Therefore, we cannot enforce that these parameters should be fixed at compile time. There may be times where we would like to build a constexpr from the function parameters (say, to do a \texttt{static\_assert} check on some value), but function parameters cannot be constexpr and therefore this is impossible. 

    \begin{definition}[Non-Type Template Parameters]
      It turns out that non-type template parameters can indeed be constexpr, so they can indeed be used to build constexpr and therefore evaluate at compile time. Again, function instantiations are inline. 
    \end{definition}

    \begin{example}[Motivation]
      Say that we have this code. 

      \begin{lstlisting}
        double getSqrt(double d) {
          assert(d >= 0.0 && "getSqrt(): d must be non-negative");
          return std::sqrt(d);
        }

        int main() {
            std::cout << getSqrt(5.0) << '\n';
            std::cout << getSqrt(-5.0) << '\n';
            return 0;
        } 
      \end{lstlisting}

      When we run \texttt{getSqrt(-5.0)}, we will runtime assert out. While this is better than nothing, because \texttt{-5.0} is a literal (and implicitly constexpr), it would be better if we could \texttt{static\_assert} so that errors such as this one would be caught at compile-time. However, \texttt{static\_assert} requires a constant expression, and function parameters can’t be constexpr... However, if we change the function parameter to a non-type template parameter instead, then we can do exactly as we want. The following will fail to compile. 
      \begin{lstlisting}
        template <double D> 
        double getSqrt() {
          static_assert(D >= 0.0, "getSqrt(): D must be non-negative");
          return std::sqrt(D);
        }

        int main() {
            std::cout << getSqrt<5.0>() << '\n';
            std::cout << getSqrt<-5.0>() << '\n';
            return 0;
        } 
      \end{lstlisting}
    \end{example}

    Template parameters can't always be used over regular parameters since the parameter itself may not be a constant expression, so regular parameters are still necessary for runtime evaluation. Here are some other properties. 

    \begin{lemma} 
      Non-type template parameters can be implicitly type-casted. 
    \end{lemma}

    \begin{lemma} 
      We can use type-deduction for non-type template parameters using \texttt{auto}. 
      \begin{lstlisting}
        template <auto N> // deduce non-type template parameter from template argument
        void print() {
          std::cout << N << '\n';
        }

        int main() {
          print<5>();   // N deduced as int `5`
          print<'c'>(); // N deduced as char `c`
          return 0;
        } 
      \end{lstlisting}
    \end{lemma} 

\section{References} 

    References and pointers are the next compound types that we will look at. While the language we have explained so far is pretty good, there is a problem. We've said that a variable is simply an object with a name. Since it's an object, it has an address where it stores some value at that address. Say that we want to create two separate variables that has the same address, so that we can have two paths to modify the value. We cannot do this since the new initialized variable stores a copy of the value at a different address. 
    \begin{lstlisting}
      int x = 2; // stores 2 at address A
      int y = y; // stores 2 at address B
    \end{lstlisting}
    Therefore modifying \texttt{y} will not modify \texttt{x}. This problem of not being able to create two names that bind to the same object is problematic, and this is a generalization of two more specific problems. 

    \begin{example}[Copying During Functions Calls May Be Expensive]
      We have explained that when calling a function, it copies all of the arguments in the stack to the new stack frame. This may be good for isolation, but this is a double-edged sword. If we have a large object to copy to do some read operations on, this may be inefficient. 
    \end{example}

    \begin{example}[In-Place Modification]
      If we want a function to modify the value of one of its arguments, this is impossible since it just copies the argument in a new variable, modifies this, and then gets deleted. We could have it return the modified object to override the old one in the parent frame, but this copying of the return value is again slow.   
    \end{example}

    This is where references and pointers come into the rescue. They are similar in that they mainly serve the same purpose, but their behaviors can differ. Generally, references are considered safe while pointers are considered dangerous. There are things that pointers can do that references cannot, and vice versa. 

  \subsection{Lvalue References}
  
    \begin{definition}[Lvalue Reference]
      A \textbf{reference} is an \textit{alias} for an existing variable (we say it is \textbf{bound} to the variable), not a variable (and therefore not an object) itself.\footnote{If possible, the reference may be replaced with the variable name by the compiler. This isn't always possible, so perhaps references may require storage.} However, whatever we do to the reference will persist in the original variable. There are two types of references. 
      \begin{enumerate}
        \item \texttt{lvalue references} are references that refer to an lvalue. 99\% of the time we work with lvalue references. 
        \begin{lstlisting}
          int x = 2; 
          int& y = x; 
        \end{lstlisting}

        \item \texttt{rvalue references} are references that refer to an rvalue. 
      \end{enumerate} 
      A reference evaluates to the variable when used in an expression. 
    \end{definition}

    Here we list a few important properties. 

    \begin{lemma}[Typechecking]
      Lvalue references will (usually) only bind to an object matching its referenced type. 
    \end{lemma}

    \begin{lemma}[Initialization]
      Lvalue references must be initialized. They cannot be declared. 
    \end{lemma}

    \begin{lemma}[No Reseating]
      Lvalue references can't be reseated (changed to refer to another object). 
    \end{lemma}

    \begin{lemma}[Scope and Duration]
      Lvalue references follow the same scoping and duration rules that normal variables do. 
    \end{lemma} 

    \begin{lemma}[References of References]
      You cannot have references of references, since the right-expression in the assignment statement will evaluate to the variable. 
      \begin{lstlisting}
        int x = 5; 
        int &y = x; 
        int &z = y;   // y evaluates to x, so z is still a reference to int
      \end{lstlisting}
    \end{lemma}

    \begin{lemma} 
      Lvalue references and referents have independent lifetimes. An lvalue reference should always be initialized after the referent. However, one can by destroyed before the other. 
      \begin{enumerate}
        \item If the reference is destroyed before the referent, this is fine. 
        \item If the referent is destroyed before the reference, this results in a \textbf{dangling reference}. 
      \end{enumerate}
    \end{lemma}

  \subsection{Rvalue References}

    Rvalue references are useful in that they can extend the lifespan of the object they are initialized with to the lifespan of the rvalue reference. 

    \begin{definition}[Rvalue Reference]
      
    \end{definition}

  \subsection{Pass and Return by Reference}

    \begin{theorem}[Object must outlive Function]
      The programmer must be sure that the object being referenced outlives the function returning the reference. Otherwise, the reference will be let dangling. 
    \end{theorem}

\section{Pointers} 

    \begin{definition}[Pointer]
      A \textbf{pointer} is an object that holds a memory address as its value. Given an address, we can \textbf{dereference} them with \texttt{*} and get their address using \texttt{\&}. 
      \begin{lstlisting}
        int x = 4; 
        int* y = &x; 
        std::cout << y << '\n'; 
        std::cout << *x << '\n'; 
      \end{lstlisting} 
      We can modify what the value that the pointer points to by dereferencing the pointer. If we have a const variable, then we must use a const pointer, which must be initialized. 
      \begin{lstlisting}
        const int x = 4;  
        const int *p = &x;  // good
        int *p = &x;        // compilation error
      \end{lstlisting}
    \end{definition} 

    Immediately this seems extremely similar to lvalue references. Here we list a few properties which help differentiate them. 

    \begin{lemma}[Typechecking]
      Pointers will (usually) only bind to an object matching its pointed type. 
    \end{lemma}

    \begin{lemma}[Declaration is Okay]
      Pointers can be declared rather than initialized. If it is, then it is known as a \textbf{wild pointer}. Rather, we should initialize it to null to make it a \textbf{null pointer}. We can use the \texttt{nullptr} literal. 
      \begin{lstlisting}
        int* p; 
        int* q = nullptr // null pointer since it's not holding address
      \end{lstlisting}
      Dereferencing both a wild and null pointer leads to undefined behavior. Null pointers are falsy, so we can use them to evaluate whether we have a null pointer. 
    \end{lemma}

    \begin{lemma}[Reseating Allowed]
      Pointers can be reseated, meaning that we can change the address that the pointer is pointing to. 
      \begin{lstlisting}
        int x = 3; 
        int y = 4; 
        int *p = &x; 
        *p = &y;      // points now to &y from &x
      \end{lstlisting}
    \end{lemma} 

    We can see that through both references and pointers, we can indirectly access an object. References may be more convenient since the dereferencing happens implicitly while for pointers, we must explicitly use the \texttt{*} operator. 

    It's worth noting that the address of operator doesn't return a literal, but rather a pointer variable that stores the address. 
    \begin{lstlisting}
      int x = 5; 
      std::cout << &x // returns pointer, not address literal
    \end{lstlisting}

    Again, if you destroy the object that the pointer is pointing to, then we get a \textbf{dangling pointer}, which leads to undefined behavior. It is easy to test whether a pointer is null or not, but if it isn't, there is no easy way to determine if it's dangling. 

  \subsection{Pass and Return by Address} 

    In addition to pass by value and reference, we can pass in the address of an object as an argument into a function. 

    \begin{definition}[Pass by Address]
      Given a function that takes in a pointer $p$, we can interpret it as 
      \begin{enumerate}
        \item a pass by address of the object type $p$ is pointing to. 
        \item a pass by value of the pointer $p$
      \end{enumerate}
      Therefore, the address will be copied, but the actual object will not be. 

      \begin{lstlisting}
        int doSomething(int* p);  
      \end{lstlisting}
    \end{definition}  

  \subsection{Smart, Shared, and Unique Pointers} 

  \subsection{Function Pointers}

\section{Enumerations} 

  If we wanted to define a new type that takes values in some discrete space, then we can use an enum. 

  \begin{definition}[Unscoped Enumerations]
    An \textbf{enumeration} is a compound data type whose values are restricted to a set of symbolic constants, called \textbf{enumerators}. These enumerators will implicitly convert to integral values as such. 
    \begin{lstlisting}
      enum Color {
        red,    // 0
        green,  // 1 
        blue    // 2
      };

      int main() {
        Color shirt = red; 
        std::cout << shirt; // prints 0
      }
    \end{lstlisting}
    They must be fully defined before we can use it. A forward declaration is not sufficient. Enumerations are implicitly constexpr. Unscoped enumerations have the same scope as where they are defined in. If they are defined in the global namespaces, then they have global scope. 
  \end{definition}

  \begin{theorem}[Integral Labels can be Explicitly Assigned]
    We can actually explicitly label. 
    \begin{lstlisting}
      enum Animal {
        cat = -3,    // values can be negative
        dog,         // -2
        pig,         // -1
        horse = 5,
        giraffe = 5, // shares same value as horse
        chicken,     // 6
      };
    \end{lstlisting}
  \end{theorem} 

\section{Structs} 

  \begin{definition}[Structs]
    \textbf{Structs} are compound types that allow you to store multiple values of different types. We can define them as such. 
    \begin{lstlisting}
      struct Employee {
        int id {};
        int age {};
        double wage {};
      };
    \end{lstlisting}
    We can also initialize them in two ways: 
    \begin{enumerate}
      \item By defining their component data types, called \textbf{aggregate initialization}. 
        \begin{lstlisting}
          int main() {
            Employee frank = { 1, 32, 60000.0 }; // copy-list initialization using braced list
            Employee joe { 2, 28, 45000.0 };     // list initialization using braced list
            Employee bob {2, 28}                 // bob.wage value-initialized to 0.0
            return 0;
          } 
        \end{lstlisting}

      \item With another struct of the same type. 
        \begin{lstlisting}
          int main() {
            Employee frank = { 1, 32, 60000.0 }; 
            Employee bob = frank;  // copied
            return 0;
          } 
        \end{lstlisting}
    \end{enumerate}
  \end{definition} 

  Like functions, the initialization behaves similarly. 

  \begin{lemma}[Missing Initialization Values]
    When doing aggregate initialization, if we do not give the struct enough values in our list to cover all attributes, the remaining attributes are value-initialized (e.g. ints are initialized to 0, floats to 0.0, etc.). 
    \begin{lstlisting}
      int main() {
        Employee frank = { 1, 32 }; // no double for salary given 
        std::cout << frank.salary << std::endl; // prints 0
        return 0; 
      }
    \end{lstlisting}
  \end{lemma}

  \begin{lemma}[Default Initialization Values]
    We can add default values in our definition of the struct. It is always recommended to. 
    \begin{lstlisting}
      struct Employee {
        int id = 0;
        int age = 1;
        double wage = 10000.0;
      };
    \end{lstlisting}
  \end{lemma}

\section{Classes} 

  \subsection{Basics} 

    \begin{definition}[Class]
      A \textbf{class} is a keyword that is used to make a user-defined compound type. 
    \end{definition}

  \subsection{Functors} 

      \begin{definition}[Functors]
        Functors are callable objects. 
      \end{definition}

      This is similar to Python's \texttt{\_\_call\_\_()} dunder method. 

    \subsubsection{Anonymous Functions and Captures} 

      It's a bit weird that we talk about anonymous functions in the class, but this is exactly because lambda functions are implemented as classes under the hood. j

      \begin{definition}[Anonymous Functions]
        
      \end{definition} 

  \subsection{Inheritance}

\section{Virtual Functions} 

  

\section{Standard Library} 

    Now that we've built up the basics, we can go into the implementation of the data structures and algorithms in the standard library. 

  \subsection{String}

  \subsection{Array}

  \subsection{Vector}

\section{Dynamic Memory Allocation} 

  So far, we've worked only in the stack, where our variables were limited to its scope and were destroyed after the block ends. If we want to keep objects in a more persistent memory location, we use the heap.  

\section{Operator Overloading} 

\section{Building}

\end{document}

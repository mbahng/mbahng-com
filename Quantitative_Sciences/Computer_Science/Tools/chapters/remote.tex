\section{Remote Access and Cluster Computing with SSH} 

  This is about remote accessing, mainly with SSH. 

  \begin{definition}[SSH Configuration File]
    In \texttt{\$HOME/.ssh/}, you will see some public-private key files. You may be logging into remote servers as such. 

    \begin{lstlisting}
      > ssh username@123.123.123.123 
      > ssh username@login.duke.edu
    \end{lstlisting}

    This can be quite tedious, so you can create a \texttt{\$HOME/.ssh/config} file to store shortcuts. 
    \begin{lstlisting}
      Host server1
        HostName 123.123.123.123
        User username
    \end{lstlisting}
    and then you can connect as such. 
    \begin{lstlisting}
      > ssh server1
    \end{lstlisting}
  \end{definition}

  \begin{definition}[Installing Packages without Sudo]
    Most likely when you are SSHing into a remote server, it is a computing cluster that you do not have admin access to, and you cannot thus include global packages. Therefore, the default method of installing binaries is by building them from source. You should therefore have a designated directory where you put all of your binaries in (I use \texttt{\$HOME/.local/bin}) and include it in \texttt{\$PATH}. 
  \end{definition}

\subsection{Clipboard}

  Clipboards have been a pain in the ass for me. Say that you connect to a remote server from your local machine, and then you open neovim in your remote machine. You can use \texttt{y} or \texttt{d} to copy/cut things and \texttt{p} to paste them in other buffers within the server, but you cannot easily copy/paste between your local machine and remote server. This becomes a pain when you need to paste some code on the remote server to GPT or when you take a code snippet from github and try to paste it on the buffer in the remote session. To fix this, you need a clipboard provider on the remote server. Do the following. I did this when my local machine has MacOS with ARM64 architecture, connecting to a remote machine running Ubuntu 22.04 with x86. Given the differences, the following steps should work. 

  \begin{enumerate}
    \item \textit{You may not have to do this step, but I did this while troubleshooting}. Install \texttt{xclip} on the remote server. If you don't have sudo access, then just build it from source. Then add the binary to somewhere in \texttt{\$PATH}. 

    \item Install \texttt{lemonade} on both your local machine and the remote server. Make sure they are both in your \texttt{\$PATH}. 

    \item Make a script on your local machine for sanity checking, call it \texttt{remote} or something, and add it to path. It should have the following. Note that the \texttt{-R}flag is important.\footnote{https://gist.github.com/bketelsen/27c2cd5b1376e72e240321baa0fbc81a} 

    \begin{lstlisting}
      #!/bin/bash
      ps cax | grep lemonade> /dev/null
      if [ $? -eq 0 ]; then
        echo "lemonade is running."
      else
        echo "lemonade is not running."
        nohup lemonade server &
      fi
      ssh -R 2489:127.0.0.1:2489 mb625@123.123.123.123
    \end{lstlisting}

    \item Make sure to put the following in your \texttt{config} file. I put it in both your local and remote.\footnote{https://github.com/neovim/neovim/issues/8028} 

    \begin{lstlisting}
      ForwardX11 yes
      ForwardX11Trusted yes
    \end{lstlisting}

    \item You may also have to set \texttt{clipboard=unnamedplus}. I had this on by default. 

    \item Make sure that you do not have the keymaps \texttt{y} to \texttt{+y} enabled. 
  \end{enumerate}

  We are done. Run \texttt{:checkhealth} on neovim in your remote server and confirm that lemonade is detected. 

\subsection{Process Management with Slurm}

  A cluster has different partitions, and each partition has different nodes. In each node, there is a specific number of CPUs and GPUs available. 

  \begin{enumerate}
    \item \textbf{idle} - Node is completely free and available for new jobs.
    \item \textbf{alloc} - Node is fully allocated/occupied by running jobs.
    \item \textbf{mix} - Node is partially allocated (some CPUs/GPUs free, some busy). You can potentially get resources on these nodes.
    \item \textbf{mix-} - Mixed state with some issue (the minus indicates a problem). Node has available resources but may have hardware issues.
    \item \textbf{drain} - Node is being drained (no new jobs accepted, finishing current jobs). Jobs can finish but no new jobs will start.
    \item \textbf{drng} - Node is currently draining (actively finishing jobs before maintenance).
    \item \textbf{down*} - Node is offline/broken (asterisk indicates it's not responding).
    \item \textbf{drain*} - Node is drained with issues (asterisk indicates problems).
    \item \textbf{plnd} - Node is in planned maintenance.
  \end{enumerate}

  \begin{definition}[\texttt{sinfo}]
    To view information about slurm nodes and partitions, use \texttt{sinfo}.
    \begin{enumerate}
      \item \texttt{sinfo} lists all partitions. 

        \begin{lstlisting}
          >>> sinfo
          PARTITION    AVAIL  TIMELIMIT  NODES  STATE NODELIST
          compsci         up 90-00:00:0      1 drain* linux23
          compsci         up 90-00:00:0      4    mix linux[31,35-37]
          compsci         up 90-00:00:0     21  alloc linux[1-7,9-10,21-22,24-30,32-34]
          compsci         up 90-00:00:0     13   idle linux[11-20,38-40]
          compsci-gpu*    up 90-00:00:0      3   mix- compsci-cluster-fitz-[06,08,20]
          compsci-gpu*    up 90-00:00:0      1  down* gpu-compute7
          compsci-gpu*    up 90-00:00:0      7   drng compsci-cluster-fitz-[04,19,29],gpu-compute4,linux[52-54]
          compsci-gpu*    up 90-00:00:0     40  drain compsci-cluster-fitz-[01-03,09-18,21-28,30-34],gpu-compute5,linux[45-51,55-60]
          compsci-gpu*    up 90-00:00:0      4    mix compsci-cluster-fitz-[05,07],gpu-compute6,linux44
          compsci-gpu*    up 90-00:00:0      3  alloc linux[41-43]
          grisman         up 60-00:00:0      1   plnd grisman-37
          grisman         up 60-00:00:0      2    mix fennario-[02,04]
          grisman         up 60-00:00:0      5  alloc grisman-40,jerry[1,3,6-7]
          grisman         up 60-00:00:0      7   idle fennario-[01,03,05-06],jerry[2,4-5]
          wiseman         up 60-00:00:0      1    mix wiseman-01
          nlplab          up 60-00:00:0      1    mix nlplab-01
          nlplab-core     up 90-00:00:0      1    mix nlplab-core-01
          bhuwan          up 90-00:00:0      1    mix bhuwan-01
          rudin           up 90-00:00:0      1   mix- rudin-01
          skynet          up 90-00:00:0      1   idle skynet-02
          wills           up 90-00:00:0      1   idle olympus 
        \end{lstlisting}
      \item \texttt{sinfo -N} views it in node-centric format. 

        \begin{lstlisting}
          >>> sinfo -N     
          NODELIST                 NODES    PARTITION STATE 
          bhuwan-01                    1       bhuwan mix   
          compsci-cluster-fitz-01      1 compsci-gpu* drain 
          compsci-cluster-fitz-02      1 compsci-gpu* drain 
          compsci-cluster-fitz-03      1 compsci-gpu* drain 
          compsci-cluster-fitz-04      1 compsci-gpu* drng  
          compsci-cluster-fitz-05      1 compsci-gpu* mix   
          compsci-cluster-fitz-06      1 compsci-gpu* mix-  
          compsci-cluster-fitz-07      1 compsci-gpu* mix   
          compsci-cluster-fitz-08      1 compsci-gpu* mix-  
          compsci-cluster-fitz-09      1 compsci-gpu* drain 
          compsci-cluster-fitz-10      1 compsci-gpu* drain 
          compsci-cluster-fitz-11      1 compsci-gpu* drain 
          compsci-cluster-fitz-12      1 compsci-gpu* drain 
          compsci-cluster-fitz-13      1 compsci-gpu* drain 
          compsci-cluster-fitz-14      1 compsci-gpu* drain
          ...
        \end{lstlisting}
    \end{enumerate}
  \end{definition}

  To go even deeper, we can check the GPUs available in each node. \textbf{GRES} (Generic Resources) specifies the actual GPU hardware installed on each node, using the format \texttt{gpu:type:count}, such as \texttt{gpu:a6000:4} for four A6000 GPUs. \textbf{AVAIL\_FEATURES} provides simple text labels like \texttt{a6000} that can be used as job constraints to target specific node types. While GRES defines what hardware exists, AVAIL\_FEATURES offers convenient tags for job submission using 
  \begin{enumerate}
    \item \texttt{--gres=gpu:a6000:1} for direct resource requests, or
    \item \texttt{--constraint=a6000} for feature-based node selection.
  \end{enumerate}

  \begin{lstlisting}
    >>> sinfo -N -o "%.25N %.6t %.4c %.4X %.8m %.20G %.15f"
    NODELIST  STATE CPUS SOCK   MEMORY                 GRES  AVAIL_FEATURES
    bhuwan-01    mix   64    2  1010955   gpu:a6000:8(S:0-1)          (null)
    compsci-cluster-fitz-01  drain   48    2   768414   gpu:a5000:4(S:0-1)           a5000
    compsci-cluster-fitz-02  drain   48    2   768414   gpu:a5000:4(S:0-1)           a5000
    compsci-cluster-fitz-03  drain   48    2   768414   gpu:a5000:4(S:0-1)           a5000
    compsci-cluster-fitz-04   drng   48    2   768414   gpu:a5000:4(S:0-1)           a5000
    compsci-cluster-fitz-05    mix   48    2   768414   gpu:a6000:4(S:0-1)           a6000 
  \end{lstlisting}


  To see which jobs you have, use \texttt{squeue --me}. To cancel all jobs, use \texttt{scancel --me}. 
  

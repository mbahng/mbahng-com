A lot of this is based off of \cite{2009hoff}. We have seen that Bayesian statistics depends on having some initial belief about an event. Upon some observation, we can gain some sort of information about the event, allowing us to \textit{modify} our prior distribution to a new one, called the posterior distribution. This simple property is the reason why Bayesian statistics is so useful for machine learning. The way we do this is through \textbf{Bayes' Rule}, which states
\begin{equation}
  p(H\,|\,D) = \frac{p(D\,|\,H) \; p(H)}{p(D)}
\end{equation}

Note that:
\begin{enumerate}
  \item $H$ is the \textbf{hypothesis} whose probability may be affected by \textbf{data} $D$, also called \textbf{evidence}.
  \item $p(H)$ is the \textbf{prior distribution}, our initial hypothesis of what the distribution would have been.
  \item $p(H\,|\,D)$ is the \textbf{posterior distribution}, which was determined upon observing the event $B$.
  \item $p(D\,|\,H)$ is the \textbf{likelihood}. If you were to assume that $A$ is true, then the likelihood tells you the probability of getting result $B$.
  \item $p(D)$ is the \textbf{marginal likelihood}, which is calculated by conditioning on $A$
  \begin{equation}
    p(D) = \sum_H p(D\,|\,H)\; p(H) \text{ or } p(D) \int_H p(D\,|\,H)\; p(H) \, dH
  \end{equation}
\end{enumerate}

When computing our prior, the outcomes $H$ are the \textbf{hypotheses}. We can assume that hypotheses are mutually exclusive and exhaustive (if one of these is true, it can't be some undefined third option). These assumptions are reasonable since it is almost always possible to redefine an arbitrary set of hypotheses into a set of hypotheses that \textit{are} mutually exclusive and exhaustive.

There are multiple ways to write Bayes rule. When attempting to calculate the posterior, we can see that $p(D)$ is really just a normalization constant and therefore does not affect the type of distribution the posterior is. So, we can in effect write the above as
\begin{equation}
  p(H\,|\,D) \propto p(D\,|\,H)\; p(H)
\end{equation}
or
\begin{equation}
  \text{Posterior } \propto \text{ Prior } \times \text{ Likelihood}
\end{equation}
where the $\propto$ symbol means ``proportional to.'' We use this notation more often when calculating posteriors since the normalizing constant isn't as important as finding the shape of the posterior density.


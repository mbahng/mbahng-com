Principal component analysis (PCA) and factor analysis (FA) originated independently by Pearson in 1901 and Spearman in 1904 \cite{1901pearson, 1904spearman}. Pearson gave the first formal treatment of it not to compute principal components, but to give a new measure of what a ``best fit'' line means, while Spearman---frustrated by the lack of rigorous analyses on nontrivial in  psychology---attempted to model the correlation between mental aptitude and sensory tasks. 

Though their discoveries were independent, the similarity of their models had inevitably caused their developments to coincide. 

Note that PCA is similar to linear regression that it fits some line (or hyperplane) of best fit to some data. However, linear regression---as a model that tries to use the covariates $x$ to predict the response $y$---attempts to minimize the \textit{residual} $(y - \hat{y})^2$. If we were to flip the model and try to predict $x$ with $y$, then the best fit line would not be the same. As Pearson puts it, \textit{the most probable stature of a man with a given length of leg $l$ being $s$, the most probable length of a leg for a man of stature $s$ will not be $l$} \cite{1901pearson}. This is further motivated by the fact that in many data collecting procedures, you do not collect a perfect measurement of $x$ first and then a noisy measurement of $y$. Rather, you are usually collecting both $x$ and $y$ together at the same time, at which they may both be perceptive to error. 



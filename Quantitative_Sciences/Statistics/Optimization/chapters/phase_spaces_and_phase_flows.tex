\section{Phase Spaces and Phase Flows}

    An ordinary differential equation describes the evolutional trajectory of some system as a function of time. Numerical methods are used to approximate this trajectory within a certain polynomial error bound. Given the (possibly vectored-valued) differential equation 
    \begin{equation}
      \mathbf{\dot{z}} = \mathbf{f}(\mathbf{z})
    \end{equation}
    with initial value $\mathbf{z}(0) = \boldsymbol{\zeta}$, the exact solution would be a function $\mathbf{z}: \mathbb{R} \longrightarrow \mathcal{M}$ from time to some phase manifold (s.t. $\mathbf{z}(0) = \zeta$). We can write this solution as a flow map $\Phi$
    \begin{equation}
      \Phi_t (\boldsymbol{\zeta}) = \mathbf{z}(t, \zeta)
    \end{equation}
    Numerically solving this differential equation relies on the idea of a discretization with a finite stepsize $h$, and an iterative procedure $\hat{\Phi}$ that computes, starting from $\mathbf{z}_0 = \boldsymbol{\zeta}$, a sequence $\mathbf{z}_1, \mathbf{z}_2, \ldots$, where $\mathbf{z}_n \approx \mathbf{z}(n h)$. The simplest scheme is simply Euler's method which advances the solution from timestep to timestep by the formula 
    \begin{equation}
      \mathbf{z}_{n+1} = \mathbf{z}_n + h \mathbf{f}(\mathbf{z}_n)
    \end{equation}
    which is based on the observation that $\mathbf{z}(t + h) \approx \mathbf{z}(t) + h\, \boldsymbol{\dot{z}}(t)$, i.e. the beginning of a Taylor series expansion in powers of $h$, and the further observation that the solution satisfies the differential equation, hence $\boldsymbol{\dot{z}}(t)$ may be replaced by $\mathbf{f}(\mathbf{z}(t))$. The discretized, approximate flow map will be denoted $\hat{\Phi}: \mathbf{z}_n \mapsto \mathbf{z}_{n+1}$. 

    Let us talk about the convergence of these schemes. The \textbf{order of accuracy} is the exponent in the power law by which the local error in the method is related to the stepsize. For example, when we say that a scheme is of third order, we mean that the local error (on a fixed finite-time interval) can be bounded by $K h^3$, where $h$ is a sufficiently small timestep and $K$ is a number which depends on the length of the time interval and the features of the problem, but which is independent of $h$. It is known that the Euler method is a first order method. That is, let the length of the time interval be $\tau$, with the step size $h$ and number of steps $\nu$. Then, $\nu h = \tau$, and defining the error at step $n$ to be $e_n \coloneqq ||\mathbf{z}_n - \mathbf{z}(t_n)||$, where $t_n = n h$, the maximum error of the Euler method at step $\nu$ satisfies
    \begin{equation}
      \bar{e} \coloneqq \max_{0 < n \leq \nu} e_n \leq C(\tau) h
    \end{equation}

    Using the order notation, we have $\bar{e} = \mathcal{O}(h)$. Summing this over an interval gives a $0$th order global error. For discretizations, local errors of order $n$ correspond to global errors of order $n+1$. In simulations, it is apparent that the errors are larger at the end of the interval than at earlier times. We know that molecular dynamics trajectories need to be very long compared to the time-step used in order for them to be useful, so how the error grows in long simulations is quite important. 

  \subsection{Higher Order Methods}

    One approach to higher accuracy is to to decrease the step size, but a more efficient way is to use a higher order method, which must satisfy a global error estimate (for finite time intervals) of the form 
    \begin{equation}
      \bar{e} \approx C(\tau) \, h ^r
    \end{equation}
    For example, the Taylor series expansion of the solution may be written 
    \begin{equation}
      \mathbf{z}(t + h) = \mathbf{z}(t) + h \boldsymbol{\dot{z}} (t) + \frac{1}{2} h^2 \boldsymbol{\ddot{z}}(t) + \ldots
    \end{equation}
    and while truncating after the first term leads to Euler's method, truncating after the second order term leads to 
    \begin{equation}
      \mathbf{z}_{n+1} = \mathbf{z}_n + h\boldsymbol{\dot{z}}_n + \frac{1}{2} h^2 \boldsymbol{\ddot{z}}_n
    \end{equation}
    In this formula, the second derivative is obtained by differentiating the differential equation itself: 
    \begin{equation}
      \boldsymbol{\ddot{z}}(t) = \frac{d}{dt} \boldsymbol{\dot{z}}(t) = \frac{d}{dt} \mathbf{f}^\prime \big( \mathbf{z}(t)\big) = \mathbf{f}^\prime\big( \mathbf{z}(t)\big) \, \mathbf{f}\big(\mathbf{z}(t)\big)
    \end{equation}
    So we can write the Taylor series method as below, which describes the flow map approximation: 
    \begin{equation}
      \hat{\Phi} (\mathbf{z}_{n}) = \mathbf{z}_{n+1} = \mathbf{z}_n + h\, \mathbf{f}(\mathbf{z}_n) + \frac{1}{2} h^2 \mathbf{f}^\prime (\mathbf{z}_n) \, \mathbf{f}(\mathbf{z}_n)
    \end{equation}

  \subsection{Convergence and the Order of Accuracy}

    A typical integrator computes successive steps (of stepsize $h$) from the formulas 
    \begin{equation}
      \mathbf{z}_{n+1} = \hat{\Phi}_h (\mathbf{z}_n), \;\;\;\;\;\; \mathbf{z}_0 = \boldsymbol{\zeta}
    \end{equation}
    Assume that $\hat{\Phi}_h$ is a smooth map for all $h > 0$. The exact solution $\mathbf{z}$ satisfies
    \begin{equation}
      \mathbf{z} (t_{n+1}) = \Phi_h (\mathbf{z}(t_n))
    \end{equation}
    since $\Phi_h$ simply takes point $\mathbf{z}(t_n)$ and flows it for time period $h$. Therefore to each $h > 0$ we can associate a finite set of space points $\mathbf{z}_0, \mathbf{z}_1, \ldots, \mathbf{z}_\nu$, which represents the numerical solutions at $t_0 = 0, t_1 = h, t_2 = 2h, \ldots, t_\nu = \nu h = \tau$. Taking the difference of the numerical and exact solutions, we have 
    \begin{equation}
      \mathbf{z}_{n+1} - \mathbf{z}(t_{n+1}) = \hat{\Phi}(\mathbf{z}_n) - \Phi_h \big(\mathbf{z}(t_n) \big) \label{2.1} \tag{2.1}
    \end{equation}
    We first assume that $\hat{\Phi}_h$ is an $\mathcal{O}(h^{p+1})$ approximation of $\Phi$ in the sense that there is a constant $K \geq 0$ and a constant $\Delta > 0$ such that, for $t \in [0, \tau]$, we have 
    \begin{equation}
      || \Phi_t\big(\mathbf{z}(t)\big) - \hat{\Phi}_h \big(\mathbf{z}(t)\big) || \leq K h^{p+1}, \;\;\;\;\; h < \Delta
    \end{equation}
    This assumption is usually verified by expanding the numerical and exact solutions in powers of $h$, using Taylor series expansions. To tackle the question of growth of error, we make an additional assumption on $\hat{\Phi}_h$, namely that is satisfies a \textbf{Lipshitz condition} of the form 
    \begin{equation}
      ||\hat{\Phi}_h (\mathbf{u}) - \hat{\Phi}_h (\mathbf{w})|| \leq (1 + h L) || \mathbf{u} - \mathbf{w}||
    \end{equation}
    for all $\mathbf{u}, \mathbf{w} \in D$, where $D$ is some subdomain of $\mathbb{R}^{6N}$ that contains the exact solution for $[0, \tau]$, and $h \leq \Delta$. This stability assumption, in words, says that the method does not increase the separation between two nearby trajectories by more than a factor of the form $1 + hL$. Therefore, from \eqref{2.1}, we can write 
    \begin{equation}
      \mathbf{z}_{n+1} - \mathbf{z}(t_{n+1}) = \hat{\Phi}(\mathbf{z}_n) - \hat{\Phi}_h \big(\mathbf{z}(t_n)\big) + \hat{\Phi}_h \big(\mathbf{z}(t_n)\big) - \Phi_h \big(\mathbf{z}(t_n) \big)
    \end{equation}
    and take norms with the triangle inequality to get the following, where $\varepsilon_n = ||\mathbf{z}_n - \mathbf{z}(t_n)||$. 
    \begin{equation}
      \varepsilon_{n+1} \leq (1 + L h) \varepsilon_n + \bar{K} h^{p+1}
    \end{equation}
    and from this, we can calculate the bound 
    \begin{equation}
      \varepsilon_n \leq \frac{\bar{K}}{L} e^{L n h} h^p
    \end{equation}


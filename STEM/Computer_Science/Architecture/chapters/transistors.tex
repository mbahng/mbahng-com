\section{Transistors}

  Note that \textit{computation} is an abstract notion (a process) that is distinct from its physical \textit{implementations} (how the progress is run). While most modern computing devices are obtained by mapping logical gates to semiconductor-based transistors, throughout history people have computed using a huge variety of mechanisms, including mechanical systems, gas and liquid (known as fluidics), biological and chemical processes, and even living creatures. 

  \begin{example}[Biological Computing]
    Computation can be based on biological or chemical systems. For example the lac-operon produces the enzymes needed to digest lactose only if the conditions $x \wedge (\lnot y)$ hold, where $x$ is ``lactose is present'' and $y$ is ``glucose is present.''
  \end{example}

  \begin{example}[Cellular Automata and the Game of Life]
    Cellular automata is a model of a system composed of a sequence of cells, each of which can have a finite state. At each step, a cell updates its state based on the states of its neighboring cells and some simple rules. As we will discuss later in this book, cellular automata such as Conway’s \textit{Game of Life} can be used to simulate computation gates.
  \end{example}

  \begin{example}[Neural Network]
    Another computation device is the brain. Even though the exact working of the brain is still not fully understood, one common mathematical model for it is a (very large) \textbf{neural network}. A neural network can be thought of as a circuit that---instead of AND/OR/NOT---uses other gates as the basic basis. One particular basis we can use are \textbf{threshold gates}, which exist through action potentials n neurons. Approximations of this simulation have been made through artificial netural networks: For every vector $w \in \mathbb{R}^k, t \in \mathbb{Z}$, the threshold function corresponding to $w, t$ is the function 
    \begin{equation}
      T_{w, t} :\{0,1\}^k \longrightarrow \{0,1\}, \qquad T_{w, t}(x) = 1 \text{ iff } \langle w, x \rangle \geq t
    \end{equation}
    where $\langle \cdot, \cdot \rangle$ represents the dot product. To a first approximation, a neuron has $k$ inputs and a single output, and the neurons “fires” or “turns on” its output when those signals pass some threshold. 
  \end{example}

  A transistor can be thought of as an electric circuit with two inputs, known as the source and the gate and an output, known as the sink. The gate controls whether current flows from the source to the sink. In a standard transistor, if the gate is “ON” then current can flow from the source to the sink and if it is “OFF” then it can’t. In a complementary transistor this is reversed: if the gate is “OFF” then current can flow from the source to the sink and if it is “ON” then it can’t. 

  We can use transistors to implement various Boolean functions such as and AND, OR, and NOT. For each a two-input gate $G: \{0,1\}^2 \longrightarrow \{0,1\}$, such an implementation would be a system with two input wires $x, y$ and one output wire $z$, such that if we identify high---as in passes a \textbf{threshold voltage}---voltage with $1$ and low voltage with $0$, then the wire $z$ will equal to $1$ if and only if applying $G$ to the values of the wires $x$ and $y$ is $1$. 

\subsection{Semiconductors}

  Okay, basic electronic construction and physics. Some substances are able to easily gain or lose electrons. These allow electricity to flow well, as electrical current is simply electrons moving around. These are "conductors." Other substances are highly resistant to gaining or losing electrons, which means they do not allow electricity to flow well. These are called "insulators."

  There is a third kind of substance that falls in between them, that holds on to its electrons harder than conductors but not as hard as insulators. They are called "semiconductors," of which silicon is the most important one. 

  Since everything that happens here is on the atomic level, it is very easy to make transistors on the small scale. A mechanical switch with copper contacts would have to be much larger than a transistor. Copper is a conductor, one of the best ones we have, so electrons can jump from one contact to another over a "decent distance." A gap of a couple millimeters is enough to break the circuit, but compared to transistors, that's a massive gulf. Plus, you need something to mechanically move the contacts. Usually an electromagnet is used. Put an electromagnet in a formation that it will cause contacts to open or close when the magnet is energized, and you have a "relay." That's what we used before transistors, and are often used today, though we no longer use them for "thinking" in electronics.

  But with semiconductors, they can change from being a conductor to being an insulator very easily. The trick is to add just the right amount of impurities in just the right structure. This is called "doping," and in the world of electronics, it's a good thing. All it takes is a single atom to switch a properly doped piece of silicon from an insulator to conductor and back again. Plus the process is purely electronic. There are no moving parts, so no mechanical components are needed. All you need to do is apply an electrical current to the third leg of a transistor, and the other two legs will go from "open" to "closed." Once the current on the third leg stops, the transistor "opens" again and electricity can't pass through. 

  You want semiconductors since. 

  You first make silicon wafers. 

\subsection{Doping}

\subsection{Implementation of NAND} 



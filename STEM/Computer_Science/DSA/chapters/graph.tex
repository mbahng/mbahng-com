\section{Graph Algorithms}

\subsection{Directed Acyclic Graphs and Topological Sorting}

  Now we move onto a specific type of directed graphs that are \textit{acyclic}. Let's introduce what they are first. 

  \begin{definition}[Directed Acyclic Graph]
    A DAG is a directed graph that has no cycles. Note that a DAG must have a node that has no in-edges. 

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[
          scale=0.8,
          node/.style={circle, draw, thick, minimum size=1.0cm},
          edge/.style={->, black, thick}
        ]
        
        % Center and bottom nodes
        \node[node] (n3) at (0,0) {3};
        \node[node] (n5) at (0,-2) {5};

        % Left side nodes
        \node[node] (n1) at (-2,1) {1};
        \node[node] (n2) at (-1.5,-1) {2};

        % Right side nodes
        \node[node] (n4) at (2,1) {4};
        \node[node] (n6) at (1.5,-1) {6};

        % Directed edges ensuring unique topological order
        \draw[edge] (n1) -- (n2);
        \draw[edge] (n1) -- (n3);
        \draw[edge] (n1) -- (n4);
        \draw[edge] (n2) -- (n5);
        \draw[edge] (n3) -- (n5);
        \draw[edge] (n3) -- (n6);
        \draw[edge] (n4) -- (n6);
        \draw[edge] (n2) -- (n6);
      \end{tikzpicture}
      \caption{An example of a directed acyclic graph.} 
      \label{fig:dag}
    \end{figure}
  \end{definition} 

  To determine if a graph is a DAG, then we can brute force it by taking a node $s \in V$, running DFS/BFS, and if a neighbor is already in visited, return False. Then go through this for all starting nodes $s \in V$. This again has quadratic runtime. Can we do better? This introduces us to topological\footnote{This has nothing to do with topology in mathematics, but rather the etymology came from the word ``topology'' in describing the structure of networks.} sorting. 

  It may be helpful to take a graph $G(V, E)$ and induce some partial order on the set of nodes $V$ based off of $E$. It turns out that we can do this for a specific type of graph. 
  
  \begin{definition}[Topological Sort]
    Given a directed acyclic graph (DAG), a linear ordering of vertices such that for every directed edge $u-v$, vertex $u$ comes before $v$ in the ordering is called a \textbf{topological sort}. It satisfies the facts: 
    \begin{enumerate}
      \item The first vertex must have an in-degree of $0$. 
      \item A topological sort is not unique. 
    \end{enumerate}

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, thick, minimum size=1.0cm}, 
          edge/.style={->, black, thick}
        ]

        % Center node
        \node[node] (n0) at (0,0) {0};

        % Upper nodes
        \node[node] (n5) at (-1.5,1.5) {5};
        \node[node] (n4) at (1.5,1.5) {4};

        % Lower nodes
        \node[node] (n2) at (-2,-1.5) {2};
        \node[node] (n1) at (2,-1.5) {1};
        \node[node] (n3) at (0,-2.5) {3};

        % Directed edges
        \draw[edge] (n5) -- (n0);
        \draw[edge] (n4) -- (n0);
        \draw[edge] (n5) -- (n2);
        \draw[edge] (n4) -- (n1);
        \draw[edge] (n2) -- (n3);
        \draw[edge] (n1) -- (n3);
      \end{tikzpicture}
      \caption{This graph can have the two (not exhaustive) topological sortings $[5, 4, 2, 3, 1, 0]$ and $[4, 5, 2, 3, 1, 0]$.}
      \label{fig:top_sort_not_unique}
    \end{figure}
  \end{definition}

  To determine if a graph is a DAG, note the following theorem. 

  \begin{theorem}[Topological Order and DAGs]
    $G$ has a topological order if and only if it is a DAG. 
  \end{theorem}
  \begin{proof}
    To prove that a DAG has a topological order, we use induction. Pick a $v$ such that its indegree is $0$. Then, delete $v$, and therefore $G \setminus v$ is also a DAG with a topological order since we are only deleting edges. We keep going. 
  \end{proof}

  Therefore, if we can successfully topologically sort, we know it is a DAG. So we can kill two birds with one stone. Let's see how this is implemented. We can do it iteratively and recursively (the proof above should hint that this can be recursive). 

  \begin{algo}[Iterative Topological Sort, Determine If Graph is DAG]
    The general idea is that we first find the node that as $0$ in-degree. From here, we can do DFS, and when we run out of neighbors to explore, then we push this into a queue. This is essentially a post-order traversal, where at the end are going to be the end nodes with no more neighbors, and the node we started from will be added last. Then we loop through and do this for all start nodes. We first need a slightly modified form of DFS. 

    \begin{algorithm}[H]
      \label{alg:iterative_top_sort}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, adjacency list $E$}
        \State visited $\gets$ set()
        \State res $\gets$ stack() 
        \State is\_acyclic $\gets$ True

        \Function{DFS}{$v \in V$}
          \If{$v \neq $ visited}
            \State add $v$ to visited 
            \State $N_v \gets$ neighbors of $v$ 
            \For{$n \in N_v$}
              \If{$n \in $ visited} 
                \State is\_acyclic $\gets$ False 
              \EndIf
              \State \Call{DFS}{$n$}
            \EndFor 
            \State push $v$ onto res
          \EndIf
        \EndFunction

        \State 

        \Function{TopologicalSort}{V, E}
          \For{$v \in V$} 
            \State DFS($v$)
          \EndFor
          \If{! is\_acyclic}
            \State \Return{False}
          \EndIf
          \State \Return{reversed of res}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    Note that this runtime is $O(|V| + |E|)$ since we are just running DFS with a constant amount of work on top of each call. 
  \end{algo}

  \begin{algo}[Recursive Topological Sort]
    We want to see that while $G$ is nonempty, we want to find the $v \in V$ such that it has indegree $0$. Then place $v$ next in order, and then delete $v$ and all edges out of $v$. The problem is finding which vertex has indegree $0$ (if we brute force it by looking through all remaining nodes and edges, you have quadratic runtime). To do this fast, the idea is 
    \begin{enumerate}
      \item initially scan over all edges to store the indegrees of every node to a list \texttt{indeg}. 
      \item store all nodes with indegree $0$ to a queue. 
      \item Run through the queue, and during each loop, when we remove a node, we look at all of its out-nodes $s$ and decrement \texttt{indeg[s]}. If \texttt{indeg[s] = 0}, then add it to the queue. 
    \end{enumerate}
    \begin{algorithm}[H]
      \label{alg:recursive_top_sort}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, Edges $E$}
        \State $q \gets$ queue() 
        \State indeg $\gets$ list() 
        \State visited $\gets$ 0
        \Function{Recur}{x}
          \State initialize the indeg and $q$ 

          \While{q is nonempty} 
            \State $v \gets$ pop(q) 
            \State visited += 1 
            \For{each $w \in E[v]$} 
              \State indeg[w] -= 1 
              \If{indeg[w] = 0} 
                \State push w into q 
              \EndIf
            \EndFor
          \EndWhile

          \If{visited != |V|} 
            \State \Return{False}
          \EndIf

          \State \Return{True}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    Notice that the inner for loop is $O(d(v) + 1)$, while we run over all $n$. So really, we are doing $O(n(d(v) + 1)) = O(m + n)$, where the plus $n$ comes from the constant work we are doing for each node. Note that if we have a non-DAG, then at some point the queue will be empty but we haven't processed all the vertices, at which point we can declare failure. 
  \end{algo}

  To end this, we can make a general statement about all directed graphs. 

  \begin{theorem}
    Every directed graph is a DAG of strongly connected components (SCC). 
  \end{theorem}

  This gives us a way to represent a directed graph with a collection of DAGs.\footnote{In fact, this Kosaraju's algorithm, can be done in linear time, though it is highly nontrivial.} An extension of topological sort is making a \textit{BFS tree}, which partitions a graph into layers that represent the number of steps required to go from a source vertex to a node. 

  \begin{algo}[BFS Tree]
    To construct a BFS tree, we just need to slightly modify the original BFS code.
    \begin{algorithm}[H]
      \label{alg:bfs_tree}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, adjacency list $E$}
        \State visited = set() 
        \State layers = $\{v : 0 \mid v \in V \}$
        \Function{BFS}{start}
          \State layer $\gets 0$ 
          \State toExplore $\gets$ queue() 
          \State add (start, layer) to toExplore 
          \State add start to visited
          \While{toExplore} 
            \State curr, layer = pop from toExplore 
            \State layers[curr] = layer 
            \For{$n \in$ neighbors of curr} 
              \If{$n \not\in$ visited} 
                \State add $n$ to visited 
                \State add $(n, layer+1)$ to visited 
              \EndIf
            \EndFor
          \EndWhile 
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    This is simply BFS with constant extra work so it is $O(n + m)$. 
  \end{algo}

  So, a BFS tree is really just another way to topologically sort. Note the following properties. 
  \begin{enumerate}
    \item In a directed graph, no nodes can jump from layer $i$ to layers $j > i+1$, since if it could, then it would be in layer $i+1$. However, nodes can jump from layer $j$ back to any layer $i < j$, even skipping layers. 
    \item In a directed graph, going forward is the same as going back, so nodes can jump at most one layer forwards or backwards. 
  \end{enumerate}

\subsection{Bipartite Graphs}

  Now we shall see a further application of BFS trees. 

  \begin{definition}[Bipartite Graph]
    A \textbf{bipartite graph} is an undirected graph $G(V, L)$ where we can partition $V = L \sqcup R$ such that for all $e = \{u, v\} \in E$, we have $u \in L, v \in R$.  
  \end{definition}

  We would like to devise some method to determine if an arbitrary graph is bipartite. 

  \begin{theorem}
    $G$ is bipartite if and only if all cycles in $G$ are even length. 
  \end{theorem}
  \begin{proof}
    Proving $(\implies)$ is quite easy since if we suppose $G$ has an odd length cycle, then we start packing vertices of a cycle into $L, R$, but by the time we came back to the start, we are forced to pack it into the wrong partition! 

    The converse is quite hard to prove, and we'll take it at face value. 
  \end{proof}

  Now in practice, how would we determine if all cycles are even length? This is where BFS shines. 

  \begin{algo}[Determine Bipartite On All Cycles of Even Length]
    The general idea is we first run BFS on the graph starting at $s \in V$, which divides it up into layers $L_1, \ldots, L_l$ representing the shortest path from $s$. Then for each layer $L_i \subset V$, we check if there are connections between two vertices $x, y \in L_i$. If there are connections, then this is not bipartite. If there are none, then this is bipartite since we can then color it. 

    \begin{algorithm}[H]
      \label{alg:determine_bipartite}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, adjacency list $E$}
        \State visited = set() 
        \State layers = $\{v : 0 \mid v \in V \}$
        \Function{BFS}{start}
          \State layer $\gets 0$ 
          \State toExplore $\gets$ queue() 
          \State add (start, layer) to toExplore 
          \State add start to visited
          \While{toExplore} 
            \State curr, layer = pop from toExplore 
            \State layers[curr] = layer 
            \For{$n \in$ neighbors of curr} 
              \If{$n \not\in$ visited} 
                \State add $n$ to visited 
                \State add $(n, layer+1)$ to visited 
              \EndIf
            \EndFor
          \EndWhile 
        \EndFunction

        \State 

        \Function{Bipartite}{V, E}
          \State BFS(v) for some $v \in V$ 
          \For{$(u, v) \in E$} 
            \If{layers[u] == layers[v]} 
              \State \Return{False} 
            \EndIf 
          \EndFor 
          \State \Return{True}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    Therefore, we run BFS, which is $O(n+m)$, and then to compare the edges, it is $O(m)$. 
  \end{algo}

  Bipartiteness is actually a special case of \textit{coloring problems}. Given a graph with $k$ colors, can I color it so that every neighbor has a different color than the original node? It may seem like at first glance that we can do the same method and look at the layers again, but it turns out that 3-coloring is hard. More specifically it is an NP-complete problem, which colloquially means that there isn't much of a better way than a brute-force solution. However, it turns out that according to the \textit{4 color theorem}, any map can be colored with 4 colors. 

\subsection{Strongly Connected Graphs}

  Now how do we find out if a directed graph is strongly connected? The straightforward solution would be to take each vertex $v \in V$, run BFS to find the set of vertices reachable from $v$, and do this for every vertex. The total running time is $O(n(n+m))$, which is quadratic. Note that for an undirected graph this is trivial since we just run DFS/BFS once. 

  \begin{definition}[Strongly Connected Graph]
    A graph $G$ is \textbf{strongly connected} if and only if for any $v \in V$, 
    \begin{enumerate}
      \item all of $V$ is reachable from $v$. 
      \item $v$ is reachable from any $s \in V$
    \end{enumerate}

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}
          % Define the five nodes in a circular arrangement
          \def\n{5}
          \def\radius{2}
          
          % Place the nodes
          \foreach \i/\name in {1/A, 2/B, 3/C, 4/D, 5/E} {
            \node[draw, circle] (\name) at ({\radius*cos((\i-1)*360/\n+90)}, {\radius*sin((\i-1)*360/\n+90)}) {\name};
          }
          
          % Connect the nodes in a cycle
          \draw[->] (A) -- (B);
          \draw[->] (B) -- (C);
          \draw[->] (C) -- (D);
          \draw[->] (D) -- (E);
          \draw[->] (E) -- (A);
        \end{tikzpicture}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}
          % Define the five nodes in a circular arrangement
          \def\n{5}
          \def\radius{2}
          
          % Place the nodes
          \foreach \i/\name in {1/A, 2/B, 3/C, 4/D, 5/E} {
            \node[draw, circle] (\name) at ({\radius*cos((\i-1)*360/\n+90)}, {\radius*sin((\i-1)*360/\n+90)}) {\name};
          }
          
          % A connects to all others
          \draw[<->] (A) -- (B);
          \draw[<->] (A) -- (C);
          \draw[<->] (A) -- (D);
          \draw[<->] (A) -- (E);
          
          % B connects to remaining nodes (not A, already handled)
          \draw[<->] (B) -- (C);
          \draw[<->] (B) -- (D);
          \draw[<->] (B) -- (E);
          
          % C connects to remaining nodes (not A or B, already handled)
          \draw[<->] (C) -- (D);
          \draw[<->] (C) -- (E);
          
          % D connects to remaining node (not A, B or C, already handled)
          \draw[<->] (D) -- (E);
        \end{tikzpicture}
      \end{subfigure}
      \caption{Two examples of strongly connected components.}
      \label{fig:scc}
    \end{figure}
  \end{definition}

  \begin{algo}[Determine if Graph is Strongly Connected]
    Using the theorem above, we can run BFS/DFS twice: one on the original graph and one on the reversed graph, consisting of all edges directed in the opposite direction. 
    \begin{algorithm}[H]
      \label{alg:strongly_connected}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, Adjacency list $E$}
        \Function{StronglyConnected}{$s \in V$}
          \State visited $\gets$ set() 
          \State BFS(s) 
          \If{visited != $V$} 
            \State \Return{False}
          \EndIf
          \State visited $\gets$ set() 
          \State reverse all edges in $E$ 
          \State BFS(s) 
          \If{visited != $V$} 
            \State \Return{False}
          \EndIf
          \State \Return{True}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    The running time is just running BFS twice plus the time to reverse the edges, so it is $O(n+m)$. 
  \end{algo} 

  One way to decompose an arbitrary graph is into its strongly connected \textit{component graphs}. Since we know that all nodes in a \textit{strongly connected component (SCC)} is reachable from each other, we can treat each component as a node in a \textit{condensation graph}. 

  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.52\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.7]
        % First copy - top left
        \begin{scope}[scale=0.6, shift={(-2,2)}]
          % Define the three nodes in a triangular arrangement
          \node[draw, circle] (A1) at (0,0) {A1};
          \node[draw, circle] (B1) at (4,0) {B1};
          \node[draw, circle] (C1) at (2,3) {C1};
          % Connect the nodes with double arrows
          \draw[<->, >=Stealth, double] (A1) -- (B1);
          \draw[<->, >=Stealth, double] (B1) -- (C1);
          \draw[<->, >=Stealth, double] (C1) -- (A1);
        \end{scope}

        % Second copy - top right
        \begin{scope}[scale=0.6, shift={(6,2)}]
          % Define the three nodes in a triangular arrangement
          \node[draw, circle] (A2) at (0,0) {A2};
          \node[draw, circle] (B2) at (4,0) {B2};
          \node[draw, circle] (C2) at (2,3) {C2};
          % Connect the nodes with double arrows
          \draw[<->, >=Stealth, double] (A2) -- (B2);
          \draw[<->, >=Stealth, double] (B2) -- (C2);
          \draw[<->, >=Stealth, double] (C2) -- (A2);
        \end{scope}

        % Third copy - bottom center
        \begin{scope}[scale=0.6, shift={(2,-3)}]
          % Define the three nodes in a triangular arrangement
          \node[draw, circle] (A3) at (0,0) {A3};
          \node[draw, circle] (B3) at (4,0) {B3};
          \node[draw, circle] (C3) at (2,3) {C3};
          % Connect the nodes with double arrows
          \draw[<->, >=Stealth, double] (A3) -- (B3);
          \draw[<->, >=Stealth, double] (B3) -- (C3);
          \draw[<->, >=Stealth, double] (C3) -- (A3);
        \end{scope}
        
        % Connections between graphs
        \draw[<-, >=Stealth, double] (A2) -- (B1);
        \draw[->, >=Stealth, double] (A1) -- (A3);
        \draw[->, >=Stealth, double] (B3) -- (B2);
      \end{tikzpicture}
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.44\textwidth}
      \centering
      \begin{tikzpicture}[scale=0.7]
        % Define the three nodes
        \node[draw, circle] (1) at (0,0) {1};
        \node[draw, circle] (2) at (3,0) {2};
        \node[draw, circle] (3) at (1.5,-2) {3};
        
        % Draw the directed edges
        \draw[->] (1) -- (2);
        \draw[->] (1) -- (3);
        \draw[->] (3) -- (2);
      \end{tikzpicture}
      \caption{}
      \label{fig:}
    \end{subfigure}
    \caption{A graph with 3 strongly connected components, along with its condensation graph. } 
    \label{fig:scc_condensation}
  \end{figure}

  \begin{algo}[Kosaraju's SCC Algorithm]
    Kosaraju's algorithm finds strongly connected components (SCCs) in a directed graph.
    An SCC is a maximal subgraph where every vertex is reachable from every other vertex.
    The algorithm works in two phases: Perform DFS on original graph to get finishing order of vertices. Perform DFS on transposed graph in reverse order of finishing times. 
    \begin{algorithm}[H]
    \caption{Kosaraju's Algorithm for Strongly Connected Components}
    \label{alg:kosaraju}
    \begin{algorithmic}[1]
      % General explanation of the algorithm
      % Kosaraju's algorithm finds strongly connected components (SCCs) in a directed graph.
      % An SCC is a maximal subgraph where every vertex is reachable from every other vertex.
      % The algorithm works in two phases:
      % 1. Perform DFS on original graph to get finishing order of vertices
      % 2. Perform DFS on transposed graph in reverse order of finishing times
      % Time complexity: O(V+E), Space complexity: O(V)
    
      \Procedure{Kosaraju}{$G(V,E)$}
        \Require{A directed graph $G$ with vertices $V$ and edges $E$}
        \Ensure{A list of strongly connected components in $G$}
        
        \State $L \gets $ empty list \Comment{To store vertices in order of finish time}
        \State $visited \gets $ set of all vertices initialized to false \Comment{Track visited status for first DFS}
        
        \ForAll{$v \in V$} \Comment{First DFS pass to get finishing order}
          \If{$visited[v] = $ false} \Comment{Only start DFS from unvisited vertices}
            \State Perform DFS from $v$ in $G$, mark vertices as visited, and add each vertex to the beginning of $L$ after its exploration is complete \Comment{First DFS builds vertex ordering based on finish times}
          \EndIf
        \EndFor
        
        \State $G^T \gets $ transpose of $G$ \Comment{Create a new graph with all edges reversed}
        \State $visited \gets $ set of all vertices initialized to false \Comment{Reset for second DFS}
        \State $SCC \gets $ empty list \Comment{Final result: list of SCC groups}
        
        \ForAll{$v \in L$ in order} \Comment{Process vertices by decreasing finish time (L is already in reverse finish order)}
          \If{$visited[v] = $ false} \Comment{Each unvisited vertex starts a new SCC}
            \State $component \gets $ empty list \Comment{To collect vertices in current SCC}
            \State Perform DFS from $v$ in $G^T$, mark vertices as visited, and add each visited vertex to $component$ \Comment{Second DFS identifies all vertices in current SCC}
            \State add $component$ to $SCC$ \Comment{Store the identified component}
          \EndIf
        \EndFor
        
        \State \Return $SCC$ \Comment{Return all strongly connected components}
      \EndProcedure
    \end{algorithmic}
    \end{algorithm}
  \end{algo}

\subsection{Shortest Positive Path with Dijkstra's}

  In the shortest path, you are given a \textit{weighted} (positive integer) directed graph and your goal is to find a path from $s$ to $t$ with the smallest length. So how would we do this? 

  The first brute force idea is just replace a edge with length $k$ to $k$ edges of length $1$, and we run BFS on this. However, this has two disadvantages. First, we cannot do this for non-discrete weights since there may be no way to discretize the weights (but if they were integers, we can take the gcd of all edge weights and use this). Second, it may not be efficient since the weights can be unbounded, and so you may end up splitting 1 edge into 1 million edges. However, if we know that the weights are bounded (and discrete) by a factor of $K$, we can use this method to run in $O(K (M + N)) = O(M + N)$. 

  The second is a greedy approach, where we explore as if we were doing BFS, but we greedily choose which edge to explore next by taking the minimum weight in our queue. We can simply do a linear scan to find the minimum, but this may be too slow, leading to quadratric runtime. However, we can use a priority queue (e.g. a min-heap), and so by replacing the queue in BFS with a priority queue (with minimum weights popped off first), we can \textit{Dijkstra's algorithm}. 

  Note that the expensive operation is to push and pop from the heap, and so we would like to minimize this. Therefore, whenever we find a new candidate, we can check with the current shortest distances and not have to push at all if the current path to node $X$ is longer than the already recorded shortest path to $X$. 

  \begin{algo}[Dijkstra's Algorithm]
    The general idea is to run a graph traversal like BFS but when you reach a new vertex $v$, you can store the accumulated time it took to get to $v$ and store for all neighbors the accumulated time it will take to get to each of those neighbors. If it is less than what we have currently, then we have found a shorter path and we should update this. 
    \begin{algorithm}[H]
      \label{alg:dijkstra}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, Edges $E$}
        \Function{Dijkstra}{s}
          \State dist $\gets$ list of size $|V|$ with $+\infty$ \Comment{Initialize list of big nums representing shortest distances}
          \State dist[$s$] $\gets$ 0 \Comment{The starting node has dist $0$}
          \State predecessors $\gets$ $\{v : None \mid v \in V \}$ \Comment{predecessors of each node for path tracking}
          \State toExplore $\gets$ minheap() \Comment{A priority queue of (weight, node)}
          \State add $(0, s)$ to toExplore \Comment{You want to explore this first}

          \While{toExplore} 
          \State (curr\_dist, curr\_node) $\gets$ pop from toExplore  \Comment{pop from toExplore}
            \If{curr\_dist > dist[curr\_node]}  \Comment{If this distance is greater than what}
              \State continue \Comment{I already have then not worth exploring}
            \EndIf 

            \For{neighbor, weight $\in$ E[curr\_node]} \Comment{Look at each neighbor}
              \State new\_dist $\gets$ curr\_dist + weight \Comment{The distance to getting to neighbor from now}
              \If{new\_dist < dist[neighbor]} \Comment{If this new dist is shorter than what we have}
                \State dist[neighbor] = new\_dist \Comment{Update best distance}
                \State predecessors[neighbor] = curr\_node \Comment{Update its predecessor}
                \State push (new\_dist, neighbor) onto toExplore \Comment{Should prob explore from here}
              \EndIf
            \EndFor
          \EndWhile
          \State \Return{distances, predecessors}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}

    You essentially push $n$ times and pop $m$ times, and the time per push and pop is $\log_2 (n)$. Therefore, the total time to push is $n \log(n)$ and to pop is $m \log (n)$, making the total runtime $O(log(n) (n+m))$. 
  \end{algo}

  \begin{example}[Dijkstra's Walkthrough]
    Let's conduct Dijkstra's on the following graph. We set our \texttt{dist} list to contain the shortest discovered paths $[+\infty, +\infty, +\infty, +\infty]$ and initialize our priority queue (min-heap) with our starting node $\langle (0, A) \rangle$.
    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes
          \node[node, red] (A) at (0,0) {A};
          \node[node, blue] (B) at (3,0) {B};
          \node[node, blue] (C) at (3,-2) {C};
          \node[node] (D) at (0,-2) {D};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow, red] (A) -- node[above] {5} (B);
          \draw[arrow] (B) -- node[right] {3} (C);
          \draw[arrow] (C) -- node[below] {3} (D);
          \draw[arrow] (D) -- node[left] {2} (A);
          \draw[arrow, red] (A) -- node[above, pos=0.8] {7} (C);
          \draw[arrow] (B) -- node[above, pos=0.8] {6} (D);
        \end{tikzpicture}
        \caption{You first pop $A$ from priority queue and have current weight $0$. You see that you can explore $B$ with weight $5$ and $C$ with weight $7$, so you immediately update the shortest paths to $B$ and $C$ and visually mark the edges as visited. You then add the nodes to your minheap, which is $\langle (7, C), (5, B) \rangle$. Our shortest path for the start node is updated to $[0, 5, 7, +\infty]$.}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes
          \node[node, red] (A) at (0,0) {A};
          \node[node, red] (B) at (3,0) {B};
          \node[node, blue] (C) at (3,-2) {C};
          \node[node, blue] (D) at (0,-2) {D};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow, red] (A) -- node[above] {5} (B);
          \draw[arrow, red] (B) -- node[right] {3} (C);
          \draw[arrow] (C) -- node[below] {3} (D);
          \draw[arrow] (D) -- node[left] {2} (A);
          \draw[arrow, red] (A) -- node[above, pos=0.8] {7} (C);
          \draw[arrow, red] (B) -- node[above, pos=0.8] {6} (D);
        \end{tikzpicture}
        \caption{You pop $B$ off the priority queue and have current weight $5$. You see that you can explore $C$ with weight $3$, so total weight $3+5 = 8$, but this is already longer than the recorded shortest path of 7, so skip this. You also see that you can explore $D$ with weight $4$, so total weight $4+5=9$. You add $(11, D)$ to your priority queue: $\langle (11, D), (7, C)\rangle$. $[0, 5, 7, 11]$.}
      \end{subfigure}

      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes
          \node[node, red] (A) at (0,0) {A};
          \node[node, red] (B) at (3,0) {B};
          \node[node, red] (C) at (3,-2) {C};
          \node[node, blue] (D) at (0,-2) {D};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow, red] (A) -- node[above] {5} (B);
          \draw[arrow, red] (B) -- node[right] {3} (C);
          \draw[arrow, red] (C) -- node[below] {3} (D);
          \draw[arrow] (D) -- node[left] {2} (A);
          \draw[arrow, red] (A) -- node[above, pos=0.8] {7} (C);
          \draw[arrow, red] (B) -- node[above, pos=0.8] {6} (D);
        \end{tikzpicture}
        \caption{You pop $C$ off the priority queue with weight $7$. You can explore $D$ with weight $3$, so total weight $3+7=10$. You add $(10, D)$ to the priority queue and update the shortest distance. $\langle (11, D), (10, D) \rangle$. You can alternatively use the decrease-key operation of a min-heap to directly modify $(11, D)$ to $(10, D)$ in $\log(n)$ time to get $\langle (10, D) \rangle$. Note that both requires $2 \log(n)$ operations $[0, 5, 7, 10]$}.
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes
          \node[node, red] (A) at (0,0) {A};
          \node[node, red] (B) at (3,0) {B};
          \node[node, red] (C) at (3,-2) {C};
          \node[node, red] (D) at (0,-2) {D};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow, red] (A) -- node[above] {5} (B);
          \draw[arrow, red] (B) -- node[right] {3} (C);
          \draw[arrow, red] (C) -- node[below] {3} (D);
          \draw[arrow, red] (D) -- node[left] {2} (A);
          \draw[arrow, red] (A) -- node[above, pos=0.8] {7} (C);
          \draw[arrow, red] (B) -- node[above, pos=0.8] {6} (D);
        \end{tikzpicture}
        \caption{Assuming you haven't used decrease-key, you pop $D$ off the priority queue with current weight $10$. $\langle (11, D) \rangle$ and $[0, 5, 7, 10]$. You can reach $A$ from $D$, but it has a weight of $2$ for a total weight of $12$, which is greater than $0$, so skip this. If you have not used the decrease-key operation, you must pop off $D$ once more with current weight of $11$, but this is already larger than $10$, so skip this. the priority queue is empty and our shortest distances is finished. }
      \end{subfigure}

      \caption{Walkthrough of Dijkstra on a small graph. Red represents the nodes/edges you have explored, and blue represents the ones in your priority queue. }
      \label{fig:dijkstra_algo}
    \end{figure}

    Note that the decrease-key operation is needed to ensure that we only push and pop off exactly once. Otherwise we may have a long line of unnecessary pushes for a single node, especially if $D$ has in-edges from every other node.  
  \end{example}

  Note that the number of pushes and pops in the heap can change depending on the order in which you check. In general, updating the shortest path list as you push onto the heap (rather than when you pop off the heap) allows you to save the most computation. However, whether we use the decrease-key operation or push/pop the same node another time from the heap does not affect the fact that we have an extra $\log(n)$ operation. However, if we use a heap with $d$ children, we can modify the runtime to $d \log_d (n)$. Therefore, the total runtime with tunable parameter $d$ is 
  \begin{equation}
    O\big( (m + nd) \log_d (n)\big)
  \end{equation}
  which can be minimized if we set $d = m/n$, so $O(m \log_{m/n} n)$, where for dense graphs $m/n$ is large and so it can behave roughly in linear time $\Theta(m)$. 

\subsection{Negative Weighted Graphs with Bellman Ford} 

  Now let's extend this problem to find the shortest path in negative weighted graphs. Before we think of a solution, we must make sure that there is no cycle that has a negative accumulated path. Otherwise, this problem becomes ill-defined, so we first assume that such a shortest path exists. 

  This seems like a very similar problem to Dijkstra, but it turns out that in many computer science problems---including this one---a slight modification to a problem can drastically affect the best method to solve it, or even if it is efficiently solvable at all. Let's try to just run Dijkstra, but we can construct a counterexample where this wouldn't work. 

  \begin{figure}[H]
    \centering 
    \begin{tikzpicture}[
      node/.style={circle, draw, minimum size=0.8cm},
      arrow/.style={-Stealth, thick}
      ]
      % Define the nodes in a diamond arrangement
      \node[node] (A) at (0,0) {$A$};
      \node[node] (B) at (3,0) {$B$};
      \node[node] (C) at (1.5,2) {$C$};
      \node[node] (D) at (1.5,-2) {$D$};
      
      % Connect the nodes with directed edges and weights
      \draw[arrow] (A) -- node[above] {1} (B);
      \draw[arrow] (A) -- node[above, left] {0} (C);
      \draw[arrow] (A) -- node[left] {99} (D);
      \draw[arrow] (B) -- node[above, right] {1} (C);
      \draw[arrow] (D) -- node[below right] {-300} (B);
    \end{tikzpicture}
    \caption{When you pop off the starting node $A$, we have $[0, 1, 0, 99]$. Then you expand out node $C$, which has no changes since there's no outgoing nodes. Then you expand out node $B$, which has no effect. Then you expand out $D$, which changes $[0, -299, 0, 99]$. However, the shortest path to $C$ is $A \rightarrow D \rightarrow B \rightarrow C$ of weight $-200$.}
  \end{figure} 

  We can see that for Dijkstra, its greedy nature doesn't allow it to forsee far into the future. Somewhere along a path where Dijkstra may not think is shortest, may exist an edge with a very negative weight that just kills your accumulator. Therefore, a greedy solution may not work. 

  These pesky negative weights are the root of this problem, so we may think of adding $\min(v)$, the minimum weight to every edge so that this now just becomes a regular positive graph and run Dijkstra on it. However, this does not work since we are not adding a constant number over all paths (it is proportional to the number of nodes in the path). 

  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \begin{tikzpicture}[
        node/.style={circle, draw, minimum size=0.8cm},
        arrow/.style={-Stealth, thick}
        ]
        % Define the nodes in a row
        \node[node] (A) at (0,0) {A};
        \node[node] (B) at (3,0) {B};
        \node[node] (C) at (6,0) {C};
        
        % Draw straight arrows with weight -2
        \draw[arrow] (A) -- node[above] {-2} (B);
        \draw[arrow] (B) -- node[above] {-2} (C);
        
        % Draw curved arrow from A to C with weight -3
        \draw[arrow] (A) to[bend left=40] node[above] {-3} (C);
      \end{tikzpicture}
      \caption{The shortest path from $A$ to $C$ is $A \rightarrow B \rightarrow C$ with weight $-4$. }
    \end{subfigure}
    \hfill 
    \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \begin{tikzpicture}[
        node/.style={circle, draw, minimum size=0.8cm},
        arrow/.style={-Stealth, thick}
        ]
        % Define the nodes in a row
        \node[node] (A) at (0,0) {A};
        \node[node] (B) at (3,0) {B};
        \node[node] (C) at (6,0) {C};
        
        % Draw straight arrows with weight -2
        \draw[arrow] (A) -- node[above] {1} (B);
        \draw[arrow] (B) -- node[above] {1} (C);
        
        % Draw curved arrow from A to C with weight -3
        \draw[arrow] (A) to[bend left=40] node[above] {0} (C);
      \end{tikzpicture}
      \caption{The shortest path from $A$ to $C$ is $A \rightarrow C$ with weight $0$, which is not the true solution.}
    \end{subfigure}
    \caption{Shortest negative paths may not be the same after adding constants to every edge, since paths of different lengths get different added weights.}
    \label{fig:dij_not_for_bellman}
  \end{figure}

  So it's pretty clear that we can't use Dijkstra, and we must develop a completely new way. In fact, there is a 50-year conjecture that this cannot be improved to linear time. To develop our new method, we can use the Bellman equations.

  \begin{theorem}[Bellman Equations]
    We write the \textbf{Bellman equations}. 
    \begin{align}
      d[v] & = \min_{w} \{ d[w] + l_{w v}\}
    \end{align}
    with $d[s] = 0$ for the starting vertex. The solution has a unique solution that finds the shortest path from $s$ to any $v \in V$.    
  \end{theorem}
  \begin{proof}
    Note that $d[w] + l_{wv}$ is the length from some path from $s \mapsto v$ that goes through $w$. The minimum of it must be the shortest path over all $w \in V$. Suppose the shortest path goes through fixed $x$. If there exists a shorter path from $s \mapsto x$, then replace $d[x]$ by this shortest path. Therefore, 
    \begin{equation}
      d[v] = d[x] + l_{xv} \leq d[w] + l_{wv} \implies d[v] = \min_{w} \{d[w] + l_{w v}\}
    \end{equation}
    To prove uniqueness, suppose there are some other solutions $\pi$ where $\pi[v] \neq d[v]$ for some $v$. But this cannot be the case by definition since $d[v] <= \pi[v]$ for all $v$. 
  \end{proof}

  \begin{theorem}
    Given the shortest paths, we can lay out this graph like a tree where $l_{ab} = l_{a a_1} + l_{a_1 a_2} + \ldots + l_{a_l b}$. 
  \end{theorem}

  To implement this theory, we should think of an iterative update that checks for all paths that may be of length $N-1$ (since length $N$ paths are guaranteed to be cycles). 

  \begin{algo}[Bellman Ford]
    The general idea is that we want to keep a list of the shortest paths to each node, and we iterate through the whole graph $N-1$ times. Within each iteration, we loop through all of the nodes, look at each node's outgoing edges, and try to update the minimum distance to each path. Therefore, by the end of the $i$th iteration, we can find all shortest paths up to length $i$, which is why by the end of the $N-1$ iteration, we will have seen all the non-cycle paths.    
    \begin{algorithm}[H]
      \label{alg:neg_weighted_short_path}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, Edges $E$}
        \Function{ShortPath}{V, E}
          \State res $\gets$ list(0) of large numbers of size $|V|$. 
          \State res[$s$] = 0
          \State predecessors $\gets \{v : None | v \in V\}$

          \While{$\exists (u, v)$ s.t. res[v] > res[u] + $l_{u v}$ } 
            \State res[$v$] $\gets$ res[u] + $l_{uv}$
            \State predecessor[v] $\gets$ u
          \EndWhile

        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    This is guaranteed to converge and stop after a finite number of steps since at every iteration, a path will either 
    \begin{enumerate}
      \item get updated from infinity to a path length 
      \item get reduced from a path length to a shorter path length
    \end{enumerate} 
    And we will have to reach the shortest path length at which point we can't reduce it further.\footnote{This algorithm is also called \textit{policy iteration} in reinforcement learning and is analogous to gradient descent.} 

    Computing the runtime is a bit tricky, since we can look at the same edge twice since minimum paths may have been updated in the middle. Therefore this list \texttt{res} may reduce very slowly. For example, let the length of each edge $|l_e| \leq L$. Then in the worst case, res[s] can be initialized to $(n-1) L$ representing the max path across all nodes, and we can decrease by $1$ in each step. So over all nodes, we can decrease so that each res[s] becomes $-(n-1)L$, meaning that we are doing on the order of $2 n^2 L$ iterations. This is too slow, especially for non-distributed settings. 
  \end{algo}

  A better way is to not be so random about how we choose the $(u, v)$ in the while loop. Notice how we can lay out the shortest paths like a tree, so we can work in layers. The next algorithm implements this. 

  \begin{algo}[Bellman Ford with Smart Ordering]
    We think of going in rounds indexed by $t$, and at every round, we are iterating through all the nodes and updating the shortest path of $v$ using the shortest path of $w$ included in all in-neighbors of $v$. At most, we will need to update this at most $n$ times, which will guarantee convergence.  
    \begin{algorithm}[H]
      \label{alg:bellman_ford}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, Edges $E$}
        \State $\pi \gets$ list(0) of large numbers of size $|V|$. 
        \State $\pi[s] = 0$

        \Function{BellmanFord}{x}
          \For{$t = 1, \ldots, n-1$}
            \For{$v \in V$} 
              \State $\pi^{(t)} [v] \gets \min_w \{ \pi^{(k-1)} [v], \pi^{(k-1)}[w] + l_{wv}\}$
            \EndFor 
          \EndFor
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    The runtime is easier to see. 
    \begin{enumerate}
      \item The step in the inner loop looks over the set of nodes of size $\mathrm{indeg}(v)$. 
      \item Looping over all the nodes in the inner for loop means that we are going over all edges, so $O(m)$. 
      \item The outer for loop goes through $n-1$ times, so the total runtime is $O(nm)$. 
    \end{enumerate}
  \end{algo}

  \begin{example}[Bellman-Ford Walkthrough]
    Let's conduct Bellman-Ford on the following graph. Thanks to this \href{https://www.youtube.com/watch?v=obWXjtg0L64&ab_channel=MichaelSambol}{youtube video}. Note that the graph below has a cycle $A \rightarrow C \rightarrow B \rightarrow A$, but it has a positive total weight, so this is fine. 

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes based on the hand-drawn graph layout
          \node[node, red] (S) at (2,3) {$S$};
          \node[node] (E) at (0,2) {$E$};
          \node[node] (A) at (4,2) {$A$};
          \node[node] (D) at (0,0) {$D$};
          \node[node] (B) at (4,0) {$B$};
          \node[node] (C) at (2,-1) {$C$};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow] (S) -- node[above, left] {8} (E);
          \draw[arrow] (S) -- node[above, right] {10} (A);
          \draw[arrow] (E) -- node[left] {1} (D);
          \draw[arrow] (D) -- node[above, pos=0.4] {-4} (A);
          \draw[arrow] (D) -- node[below, left] {-1} (C);
          \draw[arrow] (A) -- node[right, pos=0.6] {2} (C);
          \draw[arrow] (C) -- node[below, right] {-2} (B);
          \draw[arrow] (B) -- node[right] {1} (A);
        \end{tikzpicture}
        \caption{We set $\pi = [0, \infty, \infty, \infty, \infty, \infty]$. Since there are 6 nodes, we will have 5 iterations and will go through the nodes expanding out from $S$ of the order $S, A, B, C, D, E$, though we can go through in any order. That is, for each iteration, we will look at node $X$ and all of its outgoing edges to its out neighbors $Y$, and we will update $\pi[Y]$ accordingly. Doing this at iteration $i$ will allow us to compute the shortest path to node $Y$ up to length $i$. }
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes based on the hand-drawn graph layout
          \node[node, red] (S) at (2,3) {$S$};
          \node[node] (E) at (0,2) {$E$};
          \node[node] (A) at (4,2) {$A$};
          \node[node] (D) at (0,0) {$D$};
          \node[node] (B) at (4,0) {$B$};
          \node[node] (C) at (2,-1) {$C$};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow] (S) -- node[above, left] {8} (E);
          \draw[arrow] (S) -- node[above, right] {10} (A);
          \draw[arrow] (E) -- node[left] {1} (D);
          \draw[arrow] (D) -- node[above, pos=0.4] {-4} (A);
          \draw[arrow] (D) -- node[below, left] {-1} (C);
          \draw[arrow] (A) -- node[right, pos=0.6] {2} (C);
          \draw[arrow] (C) -- node[below, right] {-2} (B);
          \draw[arrow] (B) -- node[right] {1} (A);
        \end{tikzpicture}
        \caption{1st Iteration. The outgoing edges of $S$ is $A$ and $E$ with total cost $0+10 = 10$ and $0+8=8$ and update $\pi$. For $A$, its out neighbors is $C$ with total cost of $10+2=12$, so update $\pi$. Then for $B$ we don't know how to reach it yet, so skip. For $C$, its out neighbors is $B$ with total cost $12 - 2 = 10$. For $D$, we don't know how to reach it yet so skip. For $E$, its out neighbors is $D$ with cost $8+1$, so update $\pi$. We have $\pi = [0, 10, 10, 12, 9, 8]$. }
      \end{subfigure}

      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes based on the hand-drawn graph layout
          \node[node, red] (S) at (2,3) {$S$};
          \node[node] (E) at (0,2) {$E$};
          \node[node] (A) at (4,2) {$A$};
          \node[node] (D) at (0,0) {$D$};
          \node[node] (B) at (4,0) {$B$};
          \node[node] (C) at (2,-1) {$C$};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow] (S) -- node[above, left] {8} (E);
          \draw[arrow] (S) -- node[above, right] {10} (A);
          \draw[arrow] (E) -- node[left] {1} (D);
          \draw[arrow] (D) -- node[above, pos=0.4] {-4} (A);
          \draw[arrow] (D) -- node[below, left] {-1} (C);
          \draw[arrow] (A) -- node[right, pos=0.6] {2} (C);
          \draw[arrow] (C) -- node[below, right] {-2} (B);
          \draw[arrow] (B) -- node[right] {1} (A);
        \end{tikzpicture}
        \caption{2nd Iteration. For $S$ its outgoing edges are $A$ and $E$, but there are no updates to do since it doesn't improve our distances. Same with $A, B, C$. For $D$, we can reach $A$ with cost $9-4=5$ and $C$ with cost $9-1=8$, so update $\pi$. For $E$, there are no improvements, so skip this. $\pi = [0, 5, 10, 8, 9, 8]$.}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes based on the hand-drawn graph layout
          \node[node, red] (S) at (2,3) {$S$};
          \node[node] (E) at (0,2) {$E$};
          \node[node] (A) at (4,2) {$A$};
          \node[node] (D) at (0,0) {$D$};
          \node[node] (B) at (4,0) {$B$};
          \node[node] (C) at (2,-1) {$C$};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow] (S) -- node[above, left] {8} (E);
          \draw[arrow] (S) -- node[above, right] {10} (A);
          \draw[arrow] (E) -- node[left] {1} (D);
          \draw[arrow] (D) -- node[above, pos=0.4] {-4} (A);
          \draw[arrow] (D) -- node[below, left] {-1} (C);
          \draw[arrow] (A) -- node[right, pos=0.6] {2} (C);
          \draw[arrow] (C) -- node[below, right] {-2} (B);
          \draw[arrow] (B) -- node[right] {1} (A);
        \end{tikzpicture}
        \caption{3rd Iteration. For $S$, there are no updates. For $A$, we can reach $C$ with a cost of $5+2=7$, so update $\pi$. For $B$, there are no updates. For $C$, we can reach the out neighbor $B$ with a cost of $7-2=5$, so update $\pi$. There are no more updates for the rest of the nodes $C, D, E$. So we have $\pi = [0, 5, 5, 7, 9, 8]$.}
      \end{subfigure}

      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes based on the hand-drawn graph layout
          \node[node, red] (S) at (2,3) {$S$};
          \node[node] (E) at (0,2) {$E$};
          \node[node] (A) at (4,2) {$A$};
          \node[node] (D) at (0,0) {$D$};
          \node[node] (B) at (4,0) {$B$};
          \node[node] (C) at (2,-1) {$C$};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow] (S) -- node[above, left] {8} (E);
          \draw[arrow] (S) -- node[above, right] {10} (A);
          \draw[arrow] (E) -- node[left] {1} (D);
          \draw[arrow] (D) -- node[above, pos=0.4] {-4} (A);
          \draw[arrow] (D) -- node[below, left] {-1} (C);
          \draw[arrow] (A) -- node[right, pos=0.6] {2} (C);
          \draw[arrow] (C) -- node[below, right] {-2} (B);
          \draw[arrow] (B) -- node[right] {1} (A);
        \end{tikzpicture}
        \caption{4th Iteration. We go through all the nodes and see that none of the weights have been updated. We are done. }
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          node/.style={circle, draw, minimum size=0.8cm},
          arrow/.style={-Stealth, thick}
          ]
          % Define the nodes based on the hand-drawn graph layout
          \node[node, red] (S) at (2,3) {$S$};
          \node[node] (E) at (0,2) {$E$};
          \node[node] (A) at (4,2) {$A$};
          \node[node] (D) at (0,0) {$D$};
          \node[node] (B) at (4,0) {$B$};
          \node[node] (C) at (2,-1) {$C$};
          
          % Connect the nodes with directed edges and weights
          \draw[arrow] (S) -- node[above, left] {8} (E);
          \draw[arrow] (S) -- node[above, right] {10} (A);
          \draw[arrow] (E) -- node[left] {1} (D);
          \draw[arrow] (D) -- node[above, pos=0.4] {-4} (A);
          \draw[arrow] (D) -- node[below, left] {-1} (C);
          \draw[arrow] (A) -- node[right, pos=0.6] {2} (C);
          \draw[arrow] (C) -- node[below, right] {-2} (B);
          \draw[arrow] (B) -- node[right] {1} (A);
        \end{tikzpicture}
        \caption{The 5th iteration is not needed but it is needed in general. }
      \end{subfigure}
      \caption{}
      \label{fig:bellman_walkthrough}
    \end{figure}
  \end{example}

\subsubsection{All Pairs Shortest Graphs with Floyd Warshall}

  Now what if we want to find the minimum distance between all $u, v \in V$? We can just use $|V|$ Dijkstras or Bellman-Fords to get the appropriate runtimes of $O(EV + V^2 \log{V})$ or $O(EV^2)$, respectively, but for negative weighted graphs, there is a way to do this in $O(V^3)$.\footnote{Note that if the graph is sparse, then $|E| < |V|$ and just running $|V|$ Bellman Fords may be optimal.}

\subsection{Minimum Spanning Trees} 

  \begin{definition}[Spanning Tree]
    Given an undirected graph $G(V, E)$, a \textbf{spanning tree} is a subgraph $T(V, E^\prime \subset E)$ that is 
    \begin{enumerate}
      \item a tree, and 
      \item spans the graph, i.e. is connected 
    \end{enumerate}

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[
          scale=1.2,
          node/.style={circle, draw=black, thick, minimum size=0.6cm},
          regular_edge/.style={line width=1pt},
          highlighted_edge/.style={blue, line width=2pt}
      ]

      % Create a 4x4 grid of nodes
      \foreach \i in {0,...,3} {
          \foreach \j in {0,...,3} {
              \node[node] (n\i\j) at (\i,\j) {};
          }
      }

      % Regular edges (brown)
      % Horizontal edges
      \draw[regular_edge] (n00) -- (n10);
      \draw[regular_edge] (n01) -- (n11);
      \draw[regular_edge] (n02) -- (n12);
      \draw[regular_edge] (n03) -- (n13);
      \draw[regular_edge] (n20) -- (n30);
      \draw[regular_edge] (n23) -- (n33);

      % Vertical edges
      \draw[regular_edge] (n10) -- (n11);
      \draw[regular_edge] (n11) -- (n12);
      \draw[regular_edge] (n12) -- (n13);
      \draw[regular_edge] (n20) -- (n21);
      \draw[regular_edge] (n21) -- (n22);
      \draw[regular_edge] (n30) -- (n31);
      \draw[regular_edge] (n31) -- (n32);
      \draw[regular_edge] (n32) -- (n33);

      % Highlighted edges (blue) - spanning tree
      % Horizontal edges
      \draw[highlighted_edge] (n12) -- (n22);
      \draw[highlighted_edge] (n01) -- (n11);
      \draw[highlighted_edge] (n10) -- (n20);
      \draw[highlighted_edge] (n20) -- (n30);
      \draw[highlighted_edge] (n23) -- (n33);

      % Vertical edges
      \draw[highlighted_edge] (n00) -- (n01);
      \draw[highlighted_edge] (n01) -- (n02);
      \draw[highlighted_edge] (n02) -- (n03);
      \draw[highlighted_edge] (n10) -- (n11);
      \draw[highlighted_edge] (n11) -- (n12);
      \draw[highlighted_edge] (n30) -- (n31);
      \draw[highlighted_edge] (n31) -- (n32);
      \draw[highlighted_edge] (n32) -- (n33);

      \end{tikzpicture}
      \caption{A spanning tree on a $4 \times 4$ grid graph. } 
      \label{fig:spanning_tree}
    \end{figure}
  \end{definition}

  Note that an unconnected graph will never have a spanning tree, but what about a connected graph? 

  \begin{theorem}[Spanning Trees of Connected Graphs]
    A connected graph will always have at least one spanning tree, not necessarily unique. 
  \end{theorem}

  Given a connected undirected weighted graph, we may want to find the \textbf{minimum spanning tree (MST)}, i.e. the spanning tree with edges $E^\prime$ such that the sum of the weights of all $e \in E^\prime$ is minimized.\footnote{An application of this is when we generally want to make sparse graphs. In a datacenter, wires can be expensive, so how I can minimize the length of wires to buy to construct a spanning subgraph?} How do we do this? There are two well-known algorithms to solve this. Prim's and Kruskal's algorithm.  

\subsubsection{Prim's Algorithm with Cuts}

  Let's try to apply what we already know: Dijkstra. If we run Dijkstra on the graph starting at $s \in V$, we can get the shortest path from $s$ to every other node in the graph. This will give us a tree, but it may not be minimum. 

  \begin{figure}[H]
    \centering 
    \begin{tikzpicture}[
        node/.style={circle, draw, minimum size=1cm, thick},
        edge/.style={-,thick}
    ]

    % Define node positions
    \node[node] (s) at (0,2) {s};
    \node[node] (a) at (-1.5,0) {a};
    \node[node] (b) at (0,-0.5) {b};
    \node[node] (c) at (1.5,0) {c};

    % Draw edges with weights
    \draw[edge] (s) -- node[left,near start] {100} (a);
    \draw[edge] (s) -- node[right] {100} (b);
    \draw[edge] (s) -- node[right,near start] {100} (c);
    \draw[edge] (a) -- node[below] {1} (b);
    \draw[edge] (b) -- node[below] {1} (c);

    \end{tikzpicture}
    \caption{If we run Dijkstra on $s$, then our output will be a tree of cost $300$, even when the actual MST can be of cost $102$ starting from $a$.} 
    \label{fig:dik_mst_prob}
  \end{figure}

  It may seem like this is just a problem of where we start, but even this is not the case. 

  \begin{figure}[H]
    \centering 
    \begin{tikzpicture}[
        node/.style={circle, draw, minimum size=1cm, thick},
        edge/.style={-,thick}
    ]

    % Define node positions
    \node[node] (d) at (0,2) {d};
    \node[node] (a) at (-1.5,0) {a};
    \node[node] (b) at (0,-0.5) {b};
    \node[node] (c) at (1.5,0) {c};

    % Draw edges with weights
    \draw[edge] (d) -- node[left,near start] {4} (a);
    \draw[edge] (d) -- node[right] {5} (b);
    \draw[edge] (d) -- node[right,near start] {4} (c);
    \draw[edge] (a) -- node[below] {4} (b);
    \draw[edge] (b) -- node[below] {4} (c);

    \end{tikzpicture}
    \caption{No matter where we start from, we will never output the MST. The MST has cost $12$. If  we start from $b$ or $d$, we will get a tree of cost $13$. If we start from $a$ or $c$, we will get a tree of cost $16$.}
    \label{fig:dik_mst_prob2}
  \end{figure}

  \begin{definition}[Cuts]      
    Given graph $G(V, E)$, a \textbf{cut} is a partitioning of $V$ into $(S, V \setminus S)$. Furthermore, let $\mathrm{Cut}(S)$ be the number of edges with exactly one endpoint in $S$ and the other in $V \setminus S$. 
  \end{definition}

  \begin{theorem}[Cycles and Cuts]
    Given cycle $C \subset E$ in a graph and a cut $S \subset V$, 
    \begin{equation}
      | C \cap \mathrm{Cut}(S) | 
    \end{equation}
    is even. We can intuit this by visualizing the cycle as a long piece of looped string and a cut is a circle. The intersection between this circle and the string must be even since every time the cycle crosses through the cut, it must return back across the cut to the initial point.  
  \end{theorem}

  Now time for a bizarre theorem. 

  \begin{theorem}[Cut Property of MSTs]
    For all cuts $S \subset V$ of an undirected graph, the minimum cost edge in $\mathrm{Cut}(S)$ belongs to the MST. Furthermore, the converse is true: if we take all cuts and find all their minimum cost edges, these edges is precisely the MST! Therefore, an edge $e \in \mathrm{MST}$ iff $e$ is a min-cost edge for some cut. 

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          partition/.style={draw=red, thick}
        ]

        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};

        % Edges with weights
        \draw[edge] (a) -- node[above] {5} (d);
        \draw[edge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[below] {7} (c);
        \draw[edge] (c) -- node[right] {2} (d);

        % Red partition boundary - left side partition as parallelogram
        % Using the same slope as the a-b edge and a-d edge
        \draw[partition, rounded corners=10pt] (-1.5,-0.5) -- (1.5,2.5) -- (3.75,2.5) -- (0.75,-0.5) -- cycle;

        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          partition/.style={draw=red, thick}
        ]

        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};

        % Edges with weights
        \draw[edge] (a) -- node[above] {5} (d);
        \draw[edge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[below] {7} (c);
        \draw[edge] (c) -- node[right] {2} (d);

        % Red partition boundary for right diagram
        \draw[partition, rounded corners=10pt] (3.5,-0.5) -- (0.5,2.5) -- (2.5,2.5) -- (5.5,-0.5) -- cycle;

        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \label{fig:mst_cut_prop}
      \caption{In the left cut, the edges are $(a,d), (b, c), (a, c)$. The minimum weight is $5$ on the $(a, d)$ edge, so it must be in the MST. For the right cut, $(c, d)$ must be in the MST. }
    \end{figure}

    The final part is that if we have all edge costs different, then we will have a \textit{unique} MST. 
  \end{theorem}
  \begin{proof}
    We use a greedy approach and prove by contradiction. Suppose that this is not true, i.e. there exists a cut $S$ with minimum cost edge $e$, and $e \not\in \mathrm{MST}$. Then, there exists some other edge $e^\prime \in \mathrm{Cut}(S)$ that is in the MST, since the MST is spanning and it must cross over to connect the whole graph. Well if we just put $e$ in and take $e^\prime$ out, we will still have a spanning tree since it connects the left spanning tree to the right spanning tree, and we now have a cheaper tree. So the original cannot be the MST in the first place. 

    To prove the converse, consider some edge $e$ in the MST and we must prove that it is the minimum cost edge in some cut. Note that if we take $e$ out, then it divides the MST into two connected components, and we can just define the cut as these subsets of nodes. So this is in $\mathrm{Cut}(S)$ for some $S \subset V$. We can also prove that this is minimal since if it wasn't the minimum cost edge for some cut, we could have taken it out and inserted a cheaper edge $e^\prime$ to begin with, getting a cheaper spanning tree.   
  \end{proof}

  We can just brute force this logic into an algorithm by going through all possible cuts and adding the minimum cost edge to our MST set. It is clear that a cut is defined by a subset of $S$, so really the number of cuts a graph can have is $2^{|S| - 1}$, which is exponential in $n$. However, the minimum spanning tree isn't exponential since it must have $n-1$ edges, so there must be many cuts with the same minimum edge. 

  One way is to start with one vertex $a$ that contains the minimum cost edge $(a, b)$ across all edges.  This edge must be minimal and must be in the MST. Then we can look at the cut $S = \{a, b\}$ and look at that cut. We keep doing this, keeping track of the set of edges we need to look at after adding a new node to our cut. So the number of cuts I consider is equal to the number of edges in the spanning tree.

  \begin{algo}[Prim's Algorithm to Find MST]
    It turns out that we can modify Dijkstra to solve it. 
    \begin{algorithm}[H]
      \label{alg:prim}
      \begin{algorithmic}[1]
        \Require{Graph $G(E, V)$}

        \Function{Prim}{s}
          \State $S \gets \{s\}$  \Comment{Our initial cut}
          \State $\pi[v] \gets$ list of size $|V|$ of $+\infty$ \Comment{$\pi[u]$ is min cost of getting from $u$ into the $S$}
          \State $\pi[v] = w_{sv}$ for all $v \in V$ \Comment{initialize list with neighboring nodes from start $s$}

          \While{$S \neq V$}
            \State $u = \mathrm{argmin}_{v \notin S} \pi[v]$ \Comment{Find node having minimum cost to reach from $S$}
            \State $S \gets S \cup \{u\}$ \Comment{Adding this node to $S$ to expand our cut}
            \For{$u \not\in S$} \Comment{Since we expanded $S$, our min reach distances}
              \State $\pi[u] \gets \min\{\pi[u], w_{wu}\}$ \Comment{must be updated. It can only get shorter} 
            \EndFor \Comment{through a path from new $u$, so compare them}
          \EndWhile
          
        \EndFunction
      \end{algorithmic}
    \end{algorithm}

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt},
          partition/.style={draw=red, thick}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        % Edges with weights
        \draw[edge] (a) -- node[above] {5} (d);
        \draw[mstedge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[below] {7} (c);
        \draw[edge] (c) -- node[right] {2} (d);
        % Red partition boundary - around node a
        \draw[partition, rounded corners=8pt] (1.4,1.4) -- (2.6,1.4) -- (2.6,2.6) -- (1.4,2.6) -- cycle;
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt},
          partition/.style={draw=red, thick}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        % Edges with weights
        \draw[mstedge] (a) -- node[above] {5} (d);
        \draw[mstedge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[below] {7} (c);
        \draw[edge] (c) -- node[right] {2} (d);
        % Red partition boundary
        \draw[partition, rounded corners=10pt] (-1.5,-0.5) -- (1.5,2.5) -- (3.75,2.5) -- (0.75,-0.5) -- cycle;
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      
      \vspace{0.2cm}
      
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt},
          partition/.style={draw=red, thick}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        % Edges with weights
        \draw[mstedge] (a) -- node[above] {5} (d);
        \draw[mstedge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[below] {7} (c);
        \draw[mstedge] (c) -- node[right] {2} (d);
        % Red partition boundary - around node c
        \draw[partition, rounded corners=8pt] (3.4,-0.6) -- (4.6,-0.6) -- (4.6,0.6) -- (3.4,0.6) -- cycle;
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \caption{Step by step process of the method we mention above.}
      \label{fig:prim}
    \end{figure}
    
    We are really going through two loops. We add to the cut $S$ $n$ times and for each time we add, we must compute the argmin, which is also $O(n)$, so our total time complexity of $O(n^2)$.  
  \end{algo}

  However, this is not efficient, so we can introduce a minheap to get the argmin step faster. 

  \begin{algo}[Prim's Algorithm with MinHeap]
    \begin{algorithm}[H]
      \label{alg:prims}
      \begin{algorithmic}[1]
        \Require{Nodes $V$, Edges $E$}
        \Function{Prim}{V, E}
          \State mst $\gets$ [] \Comment{Initialize mst array to return}
          \State s $\gets$ 0 \Comment{Choose any starting node}
          \State visited $\gets$ set() \Comment{Our expanding set of cuts.}
          \State edges $\gets$ minheap() \Comment{The set of low-weight edges that we can explore from}
          \State add (weight, s, next\_node) for edges in E \Comment{Look for edges from s to expand our cut from.}

          \While{|visited| < |V|} \Comment{Until we have visited all cuts,}
            \State weight, frm, to $\gets$ pop from edges \Comment{Get the cheapest edge to explore}
            \If{to $\not\in$ visited} \Comment{If this isn't already in our cut, }
              \State add to $\rightarrow$ visited \Comment{Add it to our cut. From cut}
              \State add (frm, to, weight) to mst \Comment{property, this must be added to mst}

              \For{next\_to, next\_weight $\in$ E[to]} \Comment{After expanding, add newly discovered}
                \If{next\_to $\not\in$ visited} \Comment{edges for future exploration}
                  \State push (next\_weight, to, next\_to) to edges
                \EndIf
              \EndFor
            \EndIf
          \EndWhile 

          \State \Return{mst} \Comment{of form (from, to, weight)}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}

    You essentially push $n$ times and pop $m$ times, and the time per push and pop is $\log_2 (n)$. Therefore, the total time to push is $n \log(n)$ and to pop is $m \log (n)$, making the total runtime $O((n + m) log(n)) = O(m \log{n})$. 
  \end{algo}

  This can be sped up even faster if we use Fibonacci heaps or assume extra structure on the graph. 

\subsubsection{Kruskal's Algorithm}

  If we were to try and construct this algorithm from scratch, we may take a greedy approach by incrementally adding the minimum cost edge from your cut. However, there is one thing to check: have we entered a cycle? Checking whether the next added node $a$ completes a cycle in $S \cup \{a\}$ is nontrivial. 

  \begin{theorem}[Cycle Property]
    For all cycles $C$, the max cost edge of $C$ does not belong to MST. 
  \end{theorem}

  Therefore, you can take $S$ and either add to it using the cut property or delete candidates from it using the cycle property. What is the best order to do this in? Kruskal's algorithm answers this question, which takes a greedy approach. 

  \begin{algo}[General Kruskal's Algorithm]
    The general idea is that we sort $e \in E$ in increasing cost, and for each $e \in E$, we use either the cut or cycle property to decide whether $e$ goes in or out. 

    \begin{algorithm}[H]
      \label{alg:prim_kruskal}
      \begin{algorithmic}[1]
        \Require{Graph $G(V, E)$}
        \Function{Kruskal}{V, E}
          \State sort $E$ in increasing cost 
          \State $T \gets \{\}$
          \For{$e \in E$}
            \If{$T \cup \{e\}$ does not have cycle} 
              \State $T \gets T \cup \{e\}$ \Comment{Cut property}
            \Else \Comment{Cycle property} 
              \State continue \Comment{discard $e$ since from sorting, this edge is heaviest in cycle}
            \EndIf
          \EndFor
        \EndFunction
      \end{algorithmic}
    \end{algorithm}

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        \node[node] (e) at (2,-2) {e};
        
        % Edges with weights
        \draw[edge] (a) -- node[above] {5} (d);
        \draw[edge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[above] {7} (c);
        \draw[mstedge] (c) -- node[right] {2} (d);
        \draw[edge] (b) -- node[left] {9} (e);
        \draw[edge] (c) -- node[right] {10} (e);
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        \node[node] (e) at (2,-2) {e};
        
        % Edges with weights
        \draw[edge] (a) -- node[above] {5} (d);
        \draw[mstedge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[above] {7} (c);
        \draw[mstedge] (c) -- node[right] {2} (d);
        \draw[edge] (b) -- node[left] {9} (e);
        \draw[edge] (c) -- node[right] {10} (e);
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      
      \vspace{0.5cm}
      
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        \node[node] (e) at (2,-2) {e};
        
        % Edges with weights
        \draw[mstedge] (a) -- node[above] {5} (d);
        \draw[mstedge] (a) -- node[left] {4} (b);
        \draw[edge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[edge] (b) -- node[above] {7} (c);
        \draw[mstedge] (c) -- node[right] {2} (d);
        \draw[edge] (b) -- node[left] {9} (e);
        \draw[edge] (c) -- node[right] {10} (e);
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.48\textwidth}
      \centering
        \begin{tikzpicture}[
          scale=0.8, 
          node/.style={circle, draw, minimum size=0.8cm, thick},
          edge/.style={-,thick},
          mstedge/.style={-,thick,red,line width=1.5pt},
          blueedge/.style={-,thick,blue,line width=1.5pt}
        ]
        % Nodes with coordinates
        \node[node] (b) at (0,0) {b};
        \node[node] (c) at (4,0) {c};
        \node[node] (a) at (2,2) {a};
        \node[node] (d) at (6,2) {d};
        \node[node] (e) at (2,-2) {e};
        
        % Edges with weights
        \draw[mstedge] (a) -- node[above] {5} (d);
        \draw[mstedge] (a) -- node[left] {4} (b);
        \draw[blueedge] (a) -- node[right, pos=0.3] {6} (c);
        \draw[blueedge] (b) -- node[above] {7} (c);
        \draw[mstedge] (c) -- node[right] {2} (d);
        \draw[mstedge] (b) -- node[left] {9} (e);
        \draw[edge] (c) -- node[right] {10} (e);
        \end{tikzpicture}
        \caption{}
      \end{subfigure}
      \caption{Kruskal's algorithm. In the last step, we see that the next minimum cost edge of 6 and 7 forms a cycle, so we add the edge of length 9.}
      \label{fig:kruskal}
    \end{figure}

    The sorting of edges take $O(m \log{m})$ time, and after sorting, we iterate through all the edges and apply $m$ find-union algorithm, which each take at most $O(\log{n})$ time. Therefore, the overall complexity is $O(m \log{m} + m \log{n})$. However, the value of $m$ can be at most $O(n^2)$, so the two logarithms are essentially the same, arriving at the final runtime of $O(m \log{n})$. 
  \end{algo}

  The way to prove that this is correct is to show that every step you do is correct, known as \textit{structural induction}, either because of one of the two properties. Say that so far, we have some edges in $V$ which forms a partition of $V = \sqcup_i T_i$ of disjoint trees (can be trees, one edge, or just single nodes). We are looking at the next biggest edge $e = (a, b)$. There are two possibilities. 
  \begin{enumerate}
    \item If $a, b$ are both in a single $T_i$, then this forms a cycle and can be thrown away since this is the max cost edge in the cycle by the cycle property. 
    \item If $a, b$ connect $T_i$ and $T_j$ for $i \neq j$, then this edge is in $\mathrm{Cut}(T_i)$ and is the minimum cost edge since the rest of the edges in $\mathrm{Cut}(T_i)$ come next in the sorted $E$. Therefore this must be included by the cut property. 
  \end{enumerate}


  \begin{figure}[H]
    \centering 
    \includegraphics[scale=0.4]{img/sets.png}
    \caption{Each $T_i$ is a component formed by the edges chosen so far. For example, $T_1 = \{1, 2, 3, 4, 5, 6\}, \ldots$. We can either discard an edge (red) or include an edge (yellow). } 
    \label{fig:sets}
  \end{figure}

  The only bottleneck in here is line 5, where we check if $e$ does not complete a cycle in $T$. It will obviously not be efficient to do BFS, construct a tree, and see if there is a loop by checking if two points in the same layer are connected. It may help to decompose this algorithm into two steps: what is being stored and what is being checked? 

  Note that from our visual, we are really just keeping a set of these points that each make a subtree and connecting them together. How do we efficiently search for which cluster a point is a part of and efficiently merge two clusters? We could use a hashmap but this wouldn't work. We need something like a doubly linked list. 

  \begin{algo}[Kruskal's Algorithm]
    The implementation uses the Union-Find data structure. For clarity, we will not elaborate it but will show the full pseudocode. 
    \begin{algorithm}[H]
      \label{alg:kruskal}
      \begin{algorithmic}
        \Require{Nodes V. Edges $E = \{(u, v, w)\}$ where $u, v \in V$ and $w > 0$ is a weight. }
        \State 
        \Function{Kruskal}{V, E}
          \State $n \gets |V|$ 
          \State sort $E$ in increasing order of weights. \Comment{Needed for Kruskal}
          \State parent $\gets [0, \ldots, n-1]$ \Comment{Initialize the disjoint cluster each node is in}
          \State rank $\gets$ list of $0$s of size $n$ 

          \Function{Find}{x} 
            \If{parent[x] $\neq$ x} 
            \State parent[x] $\gets$ Find(parent[x]) \Comment{Path compression}
            \EndIf
            \State \Return{parent[x]}
          \EndFunction

          \Function{Union}{x, y} 
            \State px, py = find(x), find(y) 
            \If{px = py} 
              \State \Return{False}
            \EndIf
            \If{rank[px] < rank[py]} 
              \State parent[px] $\gets$ py
            \ElsIf{rank[px] > rank[py]}
              \State parent[py] $\gets$ px
            \Else{}
              \State parent[py] $\gets$ px 
              \State rank[px] $\gets$ rank[px] + 1
            \EndIf
            \State \Return{True}
          \EndFunction

          \State mst $\gets$ [] 
          \For{u, v, weight $\in$ edges} 
            \If{union(u, v)} 
              \State add (u, v, weight) to mst
            \EndIf 
            \If{len(mst) = n - 1}
              \State break
            \EndIf 
          \EndFor

          \State \Return{mst}
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
  \end{algo}
  
  To analyze the runtime of this, we define the function. 

  \begin{definition}[Ackerman Function]
    The \textbf{Ackerman function} is one of the fastest growing functions known. It is practically infinity. 
    \begin{equation}
      A(m,n) = 
      \begin{cases} 
        n+1 & \text{if } m = 0 \\
        A(m-1,1) & \text{if } m > 0 \text{ and } n = 0 \\
        A(m-1,A(m,n-1)) & \text{if } m > 0 \text{ and } n > 0
      \end{cases} 
    \end{equation}
    The inverse Ackerman function therefore grows extremely slowly. 
  \end{definition}

  If we optimize the steps in Kruskal's algorithm, we can get its runtime to 
  \begin{equation}
    O((m + n) \log^{\ast} (n))
  \end{equation}
  which is practically linear. 

\subsubsection{Applications}

  Here is a way to cluster data, a surprising way to apply MSTs. It is the most widely used application, especially in data science. The problem is that given $n$ data points $x_i \in \mathbb{R}^d$ and an integer $k$, we want to partition the points into $k$ groups $\mathbf{C} = (C_1, \ldots, C_k)$ where $\mathbf{x} = \sqcup_i C_i$. You want to distances between the points within a group to be small and the distances between groups to be large. We can think of finding the objective which takes every pair of clusters and computes the minimum distance between these clusters, and we want to maximize this distance over all pairs of clusters.  

  \begin{algo}[Single Linkage/Hierarchical Clustering]
    The general idea is to take this dense graph, find the MST, and cut off the largest edges from this MST, which will give you $k$ components. This is the answer. Or really, you can use Kruskal's algorithm and terminate earlier when $T$ has $k$ sets/components. 
    Note that as we add edges as we construct our MST, we are merging two clusters into one. So that all you are doing is finding the next pair of closest points and merging the clusters that they are a part of. 

    \begin{algorithm}[H]
      \label{alg:clustering}
      \begin{algorithmic}[1]
        \Require{Nodes $V = \{v_i\} \subset \mathbb{R}^n$}
        \Function{Cluster}{V}
          \State Run Kruskal and at each iteration, check if you have $K$ clusters. 
          \State If so, terminate and return the \texttt{parent} list. 
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
  \end{algo}

  \begin{theorem}
    The algorithm above minimizes the objective function. 
    \begin{equation}
      \argmax_{\mathbf{C}} \min_{p \in C_i, q \in C_j} \{ d(p, q) \}
    \end{equation}
  \end{theorem}
  \begin{proof}
    Let $\mathbf{C}^\ast$ be the MST clustering. We claim that for any other clustering $\mathbf{C} = \{C_1, \ldots, C_k\}$,  
    \begin{equation}
      \mathrm{min dist}(\mathbf{C}) \leq \mathrm{min dist}(\mathbf{C}^{\ast})
    \end{equation}
    Assume that this was not the case, so $\mathrm{min dist}(\mathbf{C}) > \mathrm{min dist}(\mathbf{C}^{\ast})$ and therefore there exists a $p, q \in C_i, C_j$ such that $d(p, q) = \mathrm{mindist}(\mathbf{C}) > \mathrm{min dist}(\mathbf{C}^\ast)$. Since this is a different clustering, $p, q$ must have been in the same cluster $C_i^\ast$. But note that since Kruskal adds edges in increasing length, all edges within a cluster must have length less edges that go across two clusters. 

    \begin{figure}[H]
      \centering 
      \includegraphics[scale=0.4]{img/mindist.png}
      \label{fig:mindist}
    \end{figure}

    So $d(p, q)$ must be the less than the length of all edges within a cluster in $\mathbf{C}^\ast$. But all within-cluster edges must be smaller than $\mathrm{min dist}(\mathbf{C}^\ast)$, meaning that $\mathrm{min dist}(\mathbf{C}^\ast) > d(p, q)$, contradicting the fact that is is greater, and we are done. 
  \end{proof}

  If you define the distance between two clusters to be the distance between the centroids (mean point), then this is called \textit{average linkage} (min avg distance). If we define the cluster distance as the maximum distance between two points, then it is called \textit{complete linkage} (min max distance). Kruskal's algorithm only worked for the single linkage case but may not work for these additional definitions. This is why there is usually a whole suite of clustering algorithms for a particular problem and we just find out which one fits the data the best. Furthermore, we have done \textit{bottom-up clustering}, where we took individual points to make clusters. In \textit{top-down clustering}, we take the whole set and cut it up into clusters.  

\subsection{Maximum Flows and Minimum Cuts} 

    \begin{definition}[Flow Network]
      Given a nonnegative weighted directed graph $G(V, E)$, we can define the weights to be the \textbf{capacity} $C: E \rightarrow \mathbb{R}^+$ of some commodity that can travel through the edge. Say that we have a source node $s \in V$ and a sink/destination node $t \in V$. This is called a \textbf{flow network}.
    \end{definition}

    \begin{definition}[Flow]
      Given a flow network, a \textbf{flow} is a function $f: E \rightarrow \mathbb{R}^+$ satisfying 
      \begin{enumerate}
        \item \textit{Conservation}. What flows in must always flow out. For all $v \neq s, t$, we have 
          \begin{equation}
            \sum_{(u \rightarrow v) \in E} f(u \rightarrow v) = \sum_{(v \rightarrow w) \in E} f(v \rightarrow w)
          \end{equation}

        \item \textit{Feasibility}. We cannot exceed the capacity. For all $e \in E$, 
          \begin{equation}
            0 \leq f(e) \leq C(e)
          \end{equation}
      \end{enumerate}
      The \textbf{value} of a flow represents the actual/realized amount of the commodity that we can push through the graph
      \begin{equation}
        |f| = \sum_{(s \rightarrow u) \in E}  f(s \rightarrow u) - \sum_{(u \rightarrow s) \in E}  f(u \rightarrow s) 
      \end{equation} 
      where we need to subtract the right expression to avoid loops. 
    \end{definition}

    \begin{figure}[H]
      \centering
      \begin{tikzpicture}[
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
      ]

      % Nodes with increased horizontal spacing
      \node[vertex] (s) at (0,0) {s};
      \node[vertex] (a) at (3,2) {};
      \node[vertex] (b) at (6,2) {};
      \node[vertex] (c) at (3,-2) {};
      \node[vertex] (d) at (6,-2) {};
      \node[vertex] (t) at (9,0) {t};

      % Edges with colored fraction labels
      \draw[->] (s) -- node[above] {$\frac{\color{red}10}{\color{blue}20}$} (a);
      \draw[->] (s) -- node[below] {$\frac{\color{red}0}{\color{blue}10}$} (c);
      \draw[->] (a) -- node[above] {$\frac{\color{red}0}{\color{blue}5}$} (b);
      \draw[->] (a) -- node[below] {$\frac{\color{red}10}{\color{blue}10}$} (c);
      \draw[->] (b) -- node[above] {$\frac{\color{red}5}{\color{blue}15}$} (t);
      \draw[->] (b) -- node[right] {$\frac{\color{red}5}{\color{blue}20}$} (d);
      \draw[->] (c) -- node[below] {$\frac{\color{red}10}{\color{blue}10}$} (d);
      \draw[->] (d) -- node[below] {$\frac{\color{red}5}{\color{blue}20}$} (t);
      \draw[<-] (c) -- node[above] {$\frac{\color{red}0}{\color{blue}15}$} (b);

      \end{tikzpicture}
      \caption{The red values represent the flow. The blue values represent the capacity. The value of the above flow is 10.} 
      \label{fig:flow}
    \end{figure}

    Now let's revisit cuts. 

    \begin{definition}[Cuts]
      Given a flow network, a s-t \textbf{cut} is a partition of $V = S \sqcup T$ s.t. $s \in S, t \in T$. The \textbf{value}, or \textbf{capacity}, of a cut is defined as the capacity of its edges 
      \begin{equation}
        ||S, T|| = \sum_{u in S} \sum_{v \in T} C(u \rightarrow v)
      \end{equation}
    \end{definition}

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
      ]

      % Nodes with increased horizontal spacing
      \node[vertex] (s) at (0,0) {s};
      \node[vertex] (a) at (3,2) {};
      \node[vertex] (b) at (6,2) {};
      \node[vertex] (c) at (3,-2) {};
      \node[vertex] (d) at (6,-2) {};
      \node[vertex] (t) at (9,0) {t};

      % Edges with upright colored fraction labels
      \draw[->] (s) -- node[above] {$\color{blue}20$} (a);
      \draw[->] (s) -- node[below] {$\color{blue}10$} (c);
      \draw[->] (a) -- node[above] {$\color{blue}5$} (b);
      \draw[->] (a) -- node[left] {$\color{blue}10$} (c);
      \draw[->] (b) -- node[above] {$\color{blue}15$} (t);
      \draw[->] (b) -- node[right] {$\color{blue}20$} (d);
      \draw[->] (c) -- node[below] {$\color{blue}10$} (d);
      \draw[->] (d) -- node[below] {$\color{blue}20$} (t);
      \draw[<-] (c) -- node[right] {$\color{blue}15$} (b);

      % Draw the cut (add this on background layer to appear behind nodes)
      \begin{scope}[on background layer]
          \draw[dashed, thick, gray] (4.5,-3) -- (4.5,3);
          
          % Add labels for the sets
          \node at (2,2.5) {S};
          \node at (7,2.5) {T};
      \end{scope}

      \end{tikzpicture}
      \caption{This cut has capacity 15. Note that the cut going from right to left is not included since this is a S-T cut. } 
      \label{fig:cut}
    \end{figure}

    We now introduce two related problems. 
    \begin{enumerate}
      \item Max Flow. How do we find the flow with the maximum value? This is analogous to maximizing the commodity transport from $s$ to $t$.  
      \item Min Cut. How do we find the cut with the minimum capacity? This is analogous to removing the smallest total edges that will disconnect $s$ to $t$. 
    \end{enumerate}

    \begin{theorem}[Max-Flow Min-Cut Theorem]
      For any valid $(s, t)$ flow $f$ on a flow network $G = (V, E)$ and any valid $(s, t)$-cut $S, T$, we have 
      \begin{equation}
        |f| \leq ||S, T||
      \end{equation} 
      It also turns out that equality is achieved, which immediately implies that the max-flow is the min-cut. 
    \end{theorem}
    \begin{proof}
      We can see that in order for a flow to have a value, given some cut the flow value cannot exceed the capacity through this cut from $S$ to $T$. Mathematically, we can see that the flow value is invariant due to conservation, and so  
      \begin{align}
        |f| & = \sum_{s \rightarrow v} f(s \rightarrow v) - \sum_{v \rightarrow s} f(v \rightarrow s) \\ 
            & = \sum_{u \in S} \sum_{v \in T} f(u \rightarrow v) - \sum_{v \in T} \sum_{u \in S} f(v \rightarrow u) \\ 
            & \leq \sum_{u \in S} \sum_{v \in T} c(u \rightarrow v) = ||S, T||
      \end{align}
      The fact that equality is achieved is highly nontrivial, and we will not cover it here. 
    \end{proof} 

\subsubsection{Ford Fulkerson}

  Now to compute the maximum flow itself, we use a residual graph. For now, we will assume that a flow network $G$ does not have 2-cycles (cycles of length 2), and if we do find a graph with such a 2-cycle, we modify it by adding an intermediate node. 

  \begin{figure}[H]
    \centering 
    \begin{tikzpicture}[
        vertex/.style={circle, draw, minimum size=0.6cm},
        >=Stealth
    ]

    % First pattern
    \node[vertex] (u1) at (0,0) {$u$};
    \node[vertex] (v1) at (2,0) {$v$};

    \draw[->] (u1) to[bend left=30] (v1);
    \draw[->] (v1) to[bend left=30] (u1);

    % Arrow indicating transformation
    \draw[-{Stealth[length=10pt]}, double] (3,0) -- (4,0);

    % Second pattern
    \node[vertex] (u2) at (5,0) {$u$};
    \node[vertex] (v2) at (7,0) {$v$};
    \node[vertex] (uv2) at (6,-1.5) {$uv$};

    \draw[->] (u2) -- (v2);
    \draw[->] (v2) -- (uv2);
    \draw[->] (uv2) -- (u2);

    \end{tikzpicture}
    \caption{How we modify our 2-cycle.} 
    \label{fig:cycle_mod}
  \end{figure}

  \begin{definition}[Residual Network]
    Given a flow network $G$ and a flow $f$, the \textbf{residual graph} $G_f$ is a new flow network that has edges $u \rightarrow v$ and $v \rightarrow u$, where 
    \begin{equation}
      c_f (u \rightarrow v) = \begin{cases} c (u \rightarrow v) - f(u \rightarrow v) & \text{ if } u \rightarrow v \in E \\ 
        f(u \rightarrow v) & \text{ if } v \rightarrow u \in E
      \end{cases}
    \end{equation}
    Basically, if there is some flow in an edge, we replace that edge's capacity by the residual capacity, giving us our \textit{forward edge}, and then take this flow and add it to a new opposite pointing edge, called the \textit{backwards edge}. 
  \end{definition} 

  \begin{figure}[H]
    \centering 
    \begin{tikzpicture}[
      node distance=2.5cm,
      vertex/.style={circle, draw, minimum size=0.8cm},
      auto,
      >=Stealth,
      fwd/.style={blue},
      back/.style={purple}
      ]

      % Nodes with increased horizontal spacing
      \node[vertex] (s) at (0,0) {s};
      \node[vertex] (a) at (3,2) {a};
      \node[vertex] (b) at (6,2) {b};
      \node[vertex] (c) at (3,-2) {c};
      \node[vertex] (d) at (6,-2) {d};
      \node[vertex] (t) at (9,0) {t};

      % Forward edges in blue (including zero weights)
      \draw[->, fwd] (s) -- node[above] {10} (a);
      \draw[->, fwd] (s) -- node[below] {10} (c);
      \draw[->, fwd] (a) -- node[above] {5} (b);
      \draw[->, fwd] (b) -- node[above] {15} (t);
      \draw[->, fwd] (b) -- node[right] {15} (d);
      \draw[->, fwd] (b) -- node[left] {15} (c);
      \draw[->, fwd] (d) -- node[below] {15} (t);
      \draw[->, fwd] (a) to[bend left=20] node[above] {0} (c);
      \draw[->, fwd] (c) to[bend left=20] node[below] {0} (d);

      % Backward edges in purple (including zero weights)
      \draw[->, back] (a) to[bend right=20] node[below] {10} (s);
      \draw[->, back] (c) to[bend left=20] node[left] {10} (a);
      \draw[->, back] (d) to[bend left=20] node[below] {10} (c);
      \draw[->, back] (t) to[bend left=20] node[below] {5} (b);
      \draw[->, back] (t) to[bend right=20] node[above] {5} (d);
      \draw[->, back] (d) to[bend left=20] node[right] {5} (b);
      \draw[->, back] (c) to[bend right=20] node[above] {0} (s);
      \draw[->, back] (b) to[bend right=20] node[above] {0} (a);
    \end{tikzpicture}
    \caption{Residual network. } 
    \label{fig:residual_network}
  \end{figure}

  \begin{theorem}
    If we have a flow $f$, its value $|f|$ can be improved/augmented up to the bottleneck capacity on any residual path. That is, if we find any $s \rightarrow t$ path $\pi$ on $G_f$, with a positive bottleneck capacity (minimum capacity over its edges), we can improve the flow.\footnote{For example, the capacity of the path $S, C, A, B, T$ is $5$, since $A \rightarrow B$ has weight $5$.} Given this residual path $\pi$, it may have both forward or backwards edges. To augment the original path on $G$ by value $b$, we look at each edge $(u \rightarrow v) \in E$ and 
    \begin{enumerate}
      \item If it corresponds to a forward edge (i.e. if $(u \rightarrow v)$ is in the residual path $\pi$), we add $b$. This corresponds to how much more flow you can put into this edge. 
      \item If it corresponds to a backward edge (i.e. if $(v \rightarrow u)$ is in the residual path $\pi$), we subtract $b$. The corresponds to how much flow could you reroute in the backwards direction and have it reach $t$ through another path.   
      \item If it is not in $\pi$, then we don't change it. 
    \end{enumerate}
    In summary, the new flow $f^\prime$ is defined 
    \begin{equation}
      f^\prime (u \rightarrow v) = \begin{cases} 
        f(u \rightarrow v) + b & \text{ if } (u \rightarrow v) \in \pi \\ 
        f(u \rightarrow v) - b & \text{ if } (v \rightarrow u) \in \pi \\  
        f(u \rightarrow v) & \text{ else }
      \end{cases}
    \end{equation}
  \end{theorem} 
  \begin{proof}
    We first show that $f^\prime$ is a valid flow. For feasibility, 
    \begin{enumerate}
      \item \textit{Forward}. If $(u \rightarrow  v) \in \pi$, then 
        \begin{equation}
          f^\prime (u \rightarrow v) = f(u \rightarrow v) + b \leq f(u \rightarrow v) + c_f (u \rightarrow v) = c(u \rightarrow v)
        \end{equation} 
      \item \textit{Backward}. If $(v \rightarrow u) \in \pi$, then 
        \begin{equation}
        f^\prime (u \rightarrow v) = f(u \rightarrow v) - b \geq f(u \rightarrow v) - c_f (v \rightarrow u) = 0 
        \end{equation}
    \end{enumerate}

    For conservation, there are 4 cases. 
    \begin{enumerate}
      \item Forward into node, forward out of node. $\Delta_{in} = +b, \Delta_{out} = +b$. Therefore the flows cancel out. 
      \item Forward into node, backward out of node. $\Delta_{in} = +b - b = 0$. 
      \item Backward into node, forward out of node. $\Delta_{out} = +b - b = 0$. 
      \item Backward into node, backward out of node. $\Delta_{in} = -b, \Delta_{out} = - b$. 
    \end{enumerate}
  \end{proof} 

  At this point, we're pretty much ready to give our algorithm on max-flow. 

  \begin{algo}[Ford-Fulkerson]
    We've reduced this problem to a problem of finding a positive path $\pi$ in the residual graph, which we have a lot of algorithms built for. We find such a path and augment the flow until we cannot find such a path. If we cannot find a path, then we can use BFS to look at all vertices $S \subset V$ reachable from $s$ in $G_f$, and then let $T = V \setminus S$. These two disjoint sets will give the min cut. 
    
    \begin{algorithm}[H]
      \label{alg:maxflow}
      \begin{algorithmic}
        \Require{Flow network $G(V, E)$, source/sink $s, t \in V$. Capacity $c$. }
        \State 
        \Function{MaxFlow}{G}
        \State Start with the trivial flow $f$, maybe stored as array $[0, \ldots, 0]$ of length $E$. 
          \State Construct residual graph $G_f$ for this trivial flow. 
          \While{$G_f$ has an augmenting path in $G_f$} \Comment{Maybe use BFS to find this.}
            \State Pick $\pi$ as any augmenting path 
            \State augment $f$ by bottleneck capacity 
            \State update $G_f$. 
          \EndWhile
          \State \Return{f}  
          \State Use BFS to find all nodes in $G_f$ reachable from $s$. Call this $S$.  
          \State Let $T = V \setminus S$.  
          \State $S, T$ is our min cut, and $f$ is your max flow. 
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    The inner loop is just BFS, which is $O(N + M)$, but how many iterations do we do? Well for integer capacities, we can bound it by the actual value of the max flow $|f^\ast|$ since we must improve by at least $+1$ every loop.\footnote{This is not a trivial result that if all capacities are integers, then there is an integer max-flow, despite the actual flow being dispersed as fractions across edges.} Unfortunately, $O((N+M) |f^\ast|)$ is the best we can do in generality, which is pseudopolynomial. 
  \end{algo}

  There are indeed polynomial time algorithms, e.g. Orlin's algorithm with runtime $O(NM)$, which is guaranteed to be polynomial but in practice may be slower. 

  \begin{example}[Ford-Fulkerson Walkthrough]
    Let's conduct Ford-Fulkerson on the following graph. Each row consists of one step, which is to find an augmenting path, compute the bottleneck capacity, and augment each edge and the total flow. 

    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
          ]
          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          % Edges with colored fraction labels
          \draw[->] (s) -- node[above] {$\frac{\color{red}0}{\color{blue}10}$} (a);
          \draw[->] (s) -- node[below] {$\frac{\color{red}0}{\color{blue}10}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}0}{\color{blue}4}$} (b);
          \draw[->] (a) -- node[right] {$\frac{\color{red}0}{\color{blue}2}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}0}{\color{blue}8}$} (d);
          \draw[->] (b) -- node[above] {$\frac{\color{red}0}{\color{blue}10}$} (t);
          \draw[->] (c) -- node[below] {$\frac{\color{red}0}{\color{blue}9}$} (d);
          \draw[->] (d) -- node[right] {$\frac{\color{red}0}{\color{blue}6}$} (b);
          \draw[->] (d) -- node[below] {$\frac{\color{red}0}{\color{blue}10}$} (t);
        \end{tikzpicture}
        \caption{Our initial graph with our capacity in blue and trivial flow in red.}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth,
          fwd/.style={blue},
          back/.style={purple}
          ]

          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {10} (a);
          \draw[->, back, font=\footnotesize] (a) to[bend right=20] node[above] {0} (s);

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {10} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend right=20] node[above] {0} (s);

          \draw[->, fwd, font=\footnotesize] (a) -- node[right] {2} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {4} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend right=20] node[above] {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {8} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (c) -- node[above] {9} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[below]  {0} (c);

          \draw[->, fwd, font=\footnotesize] (d) -- node[right] {6} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend left=20] node[right]  {0} (d);

          \draw[->, fwd, font=\footnotesize] (b) -- node[above] {10} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend left=20] node[below]  {0} (b);

          \draw[->, fwd, font=\footnotesize] (d) -- node[below] {10} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend right=20] node[above] {0} (d);
        \end{tikzpicture}
        \caption{Residual network, which is redundant, but is good for visualization for the first time.}
      \end{subfigure}
    \end{figure}

    \begin{figure}[H]
      \ContinuedFloat
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
          ]
          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          % Edges with colored fraction labels
          \draw[->, green!80!black] (s) -- node[above] {$\frac{\color{red}8}{\color{blue}10}$} (a);
          \draw[->] (s) -- node[below] {$\frac{\color{red}0}{\color{blue}10}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}0}{\color{blue}4}$} (b);
          \draw[->] (a) -- node[right] {$\frac{\color{red}0}{\color{blue}2}$} (c);
          \draw[->, green!80!black] (a) -- node[above] {$\frac{\color{red}8}{\color{blue}8}$} (d);
          \draw[->] (b) -- node[above] {$\frac{\color{red}0}{\color{blue}10}$} (t);
          \draw[->] (c) -- node[below] {$\frac{\color{red}0}{\color{blue}9}$} (d);
          \draw[->] (d) -- node[right] {$\frac{\color{red}0}{\color{blue}6}$} (b);
          \draw[->, green!80!black] (d) -- node[below] {$\frac{\color{red}8}{\color{blue}10}$} (t);
        \end{tikzpicture}
        \caption{We run BFS and find a path, say $s \mapsto a \mapsto d \mapsto t$. The bottleneck capacity is $8$ from min weight edge $a \mapsto d$. }
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth,
          fwd/.style={blue},
          back/.style={purple}
          ]

          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {2} (a);
          \draw[->, back, font=\footnotesize] (a) to[bend right=20] node[above] {8} (s);

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {10} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend right=20] node[above] {0} (s);

          \draw[->, fwd, font=\footnotesize] (a) -- node[right] {2} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {4} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend right=20] node[above] {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {0} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[left]   {8} (a);

          \draw[->, fwd, font=\footnotesize] (c) -- node[above] {9} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[below]  {0} (c);

          \draw[->, fwd, font=\footnotesize] (d) -- node[right] {6} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend left=20] node[right]  {0} (d);

          \draw[->, fwd, font=\footnotesize] (b) -- node[above] {10} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend left=20] node[below]  {0} (b);

          \draw[->, fwd, font=\footnotesize] (d) -- node[below] {2} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend right=20] node[above] {8} (d);
        \end{tikzpicture}
        \caption{We decrease our forward edges and increase our backwards edges along this path. We have a total flow of $8$.}
      \end{subfigure}
    \end{figure}

    \begin{figure}[H]
      \ContinuedFloat
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
          ]
          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          % Edges with colored fraction labels
          \draw[->] (s) -- node[above] {$\frac{\color{red}8}{\color{blue}10}$} (a);
          \draw[->, green!80!black] (s) -- node[below] {$\frac{\color{red}2}{\color{blue}10}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}0}{\color{blue}4}$} (b);
          \draw[->] (a) -- node[right] {$\frac{\color{red}0}{\color{blue}2}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}8}{\color{blue}8}$} (d);
          \draw[->] (b) -- node[above] {$\frac{\color{red}0}{\color{blue}10}$} (t);
          \draw[->, green!80!black] (c) -- node[below] {$\frac{\color{red}2}{\color{blue}9}$} (d);
          \draw[->] (d) -- node[right] {$\frac{\color{red}0}{\color{blue}6}$} (b);
          \draw[->, green!80!black] (d) -- node[below] {$\frac{\color{red}10}{\color{blue}10}$} (t);
        \end{tikzpicture}
        \caption{We run BFS again and find the path $s \mapsto c \mapsto d \mapsto t$, with a bottleneck capacity of $2$, from $d \rightarrow t$ which is partially full and has remaining capacity $2/10$. }
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth,
          fwd/.style={blue},
          back/.style={purple}
          ]

          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {2} (a);
          \draw[->, back, font=\footnotesize] (a) to[bend right=20] node[above] {8} (s);

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {8} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend right=20] node[above] {2} (s);

          \draw[->, fwd, font=\footnotesize] (a) -- node[right] {2} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {4} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend right=20] node[above] {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {0} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[left]   {8} (a);

          \draw[->, fwd, font=\footnotesize] (c) -- node[above] {7} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[below]  {2} (c);

          \draw[->, fwd, font=\footnotesize] (d) -- node[right] {6} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend left=20] node[right]  {0} (d);

          \draw[->, fwd, font=\footnotesize] (b) -- node[above] {10} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend left=20] node[below]  {0} (b);

          \draw[->, fwd, font=\footnotesize] (d) -- node[below] {0} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend right=20] node[above] {10} (d);
        \end{tikzpicture}
        \caption{We update our forward and backwards edges along this path, with a total flow of $10$. \\}
      \end{subfigure}
    \end{figure}

    \begin{figure}[H]
      \ContinuedFloat
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
          ]
          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          % Edges with colored fraction labels
          \draw[->] (s) -- node[above] {$\frac{\color{red}8}{\color{blue}10}$} (a);
          \draw[->, green!80!black] (s) -- node[below] {$\frac{\color{red}6}{\color{blue}10}$} (c);
          \draw[->, green!80!black] (a) -- node[above] {$\frac{\color{red}4}{\color{blue}4}$} (b);
          \draw[->] (a) -- node[right] {$\frac{\color{red}0}{\color{blue}2}$} (c);
          \draw[->, green!80!black] (a) -- node[above] {$\frac{\color{red}4}{\color{blue}8}$} (d);
          \draw[->, green!80!black] (b) -- node[above] {$\frac{\color{red}4}{\color{blue}10}$} (t);
          \draw[->, green!80!black] (c) -- node[below] {$\frac{\color{red}6}{\color{blue}9}$} (d);
          \draw[->] (d) -- node[right] {$\frac{\color{red}0}{\color{blue}6}$} (b);
          \draw[->] (d) -- node[below] {$\frac{\color{red}10}{\color{blue}10}$} (t);
        \end{tikzpicture}
        \caption{Now we run BFS and come across a path that has a backwards edge. See that $s \mapsto c \mapsto d \mapsto a \mapsto b \mapsto t$ contains the backwards edge $d \mapsto a$ which has capacity $8$. This path has capacity $4$ (from $a \rightarrow b$). }
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth,
          fwd/.style={blue},
          back/.style={purple}
          ]

          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {2} (a);
          \draw[->, back, font=\footnotesize] (a) to[bend right=20] node[above] {8} (s);

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {4} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend right=20] node[above] {6} (s);

          \draw[->, fwd, font=\footnotesize] (a) -- node[right] {2} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {0} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend right=20] node[above] {4} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {4} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[left]   {4} (a);

          \draw[->, fwd, font=\footnotesize] (c) -- node[above] {3} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[below]  {6} (c);

          \draw[->, fwd, font=\footnotesize] (d) -- node[right] {6} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend left=20] node[right]  {0} (d);

          \draw[->, fwd, font=\footnotesize] (b) -- node[above] {6} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend left=20] node[below]  {4} (b);

          \draw[->, fwd, font=\footnotesize] (d) -- node[below] {0} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend right=20] node[above] {10} (d);
        \end{tikzpicture}
        \caption{We increment the flow on all the forward edges and decrement the flow on the backwards edge $a \rightarrow d$. We are shifting the flow from $a \mapsto d$ to $a \mapsto b$, leaving space for more flow. Total flow of $14$.}
      \end{subfigure}
    \end{figure}

    \begin{figure}[H]
      \ContinuedFloat
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
          ]
          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          % Edges with colored fraction labels
          \draw[->, green!80!black] (s) -- node[above] {$\frac{\color{red}10}{\color{blue}10}$} (a);
          \draw[->] (s) -- node[below] {$\frac{\color{red}6}{\color{blue}10}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}4}{\color{blue}4}$} (b);
          \draw[->] (a) -- node[right] {$\frac{\color{red}0}{\color{blue}2}$} (c);
          \draw[->, green!80!black] (a) -- node[above] {$\frac{\color{red}6}{\color{blue}8}$} (d);
          \draw[->, green!80!black] (b) -- node[above] {$\frac{\color{red}6}{\color{blue}10}$} (t);
          \draw[->] (c) -- node[below] {$\frac{\color{red}6}{\color{blue}9}$} (d);
          \draw[->, green!80!black] (d) -- node[right] {$\frac{\color{red}2}{\color{blue}6}$} (b);
          \draw[->] (d) -- node[below] {$\frac{\color{red}10}{\color{blue}10}$} (t);
        \end{tikzpicture}
        \caption{We find the path $s \mapsto a \mapsto d \mapsto b \mapsto t$ and increment by bottlneck of $2$.}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth,
          fwd/.style={blue},
          back/.style={purple}
          ]

          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {0} (a);
          \draw[->, back, font=\footnotesize] (a) to[bend right=20] node[above] {10} (s);

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {4} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend right=20] node[above] {6} (s);

          \draw[->, fwd, font=\footnotesize] (a) -- node[right] {2} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {0} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend right=20] node[above] {4} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {2} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[left]   {6} (a);

          \draw[->, fwd, font=\footnotesize] (c) -- node[above] {3} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[below]  {6} (c);

          \draw[->, fwd, font=\footnotesize] (d) -- node[right] {4} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend left=20] node[right]  {2} (d);

          \draw[->, fwd, font=\footnotesize] (b) -- node[above] {4} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend left=20] node[below]  {6} (b);

          \draw[->, fwd, font=\footnotesize] (d) -- node[below] {0} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend right=20] node[above] {10} (d);
        \end{tikzpicture}
        \caption{This consists of all forward edges, so we don't have to do anything fancy here. Total flow of $16$.}
      \end{subfigure}
    \end{figure}

    \begin{figure}[H]
      \ContinuedFloat
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth
          ]
          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          % Edges with colored fraction labels
          \draw[->] (s) -- node[above] {$\frac{\color{red}10}{\color{blue}10}$} (a);
          \draw[->, green!80!black] (s) -- node[below] {$\frac{\color{red}9}{\color{blue}10}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}4}{\color{blue}4}$} (b);
          \draw[->] (a) -- node[right] {$\frac{\color{red}0}{\color{blue}2}$} (c);
          \draw[->] (a) -- node[above] {$\frac{\color{red}6}{\color{blue}8}$} (d);
          \draw[->, green!80!black] (b) -- node[above] {$\frac{\color{red}9}{\color{blue}10}$} (t);
          \draw[->, green!80!black] (c) -- node[below] {$\frac{\color{red}9}{\color{blue}9}$} (d);
          \draw[->, green!80!black] (d) -- node[right] {$\frac{\color{red}5}{\color{blue}6}$} (b);
          \draw[->] (d) -- node[below] {$\frac{\color{red}10}{\color{blue}10}$} (t);
        \end{tikzpicture}
        \caption{Same on the path $s \mapsto c \mapsto d \mapsto b \mapsto t$.}
      \end{subfigure}
      \hfill 
      \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}[
          scale=0.9,
          node distance=2.5cm,
          vertex/.style={circle, draw, minimum size=0.8cm},
          auto,
          >=Stealth,
          fwd/.style={blue},
          back/.style={purple}
          ]

          % Nodes with increased horizontal spacing
          \node[vertex] (s) at (1,0) {s};
          \node[vertex] (a) at (3,2) {a};
          \node[vertex] (b) at (6,2) {b};
          \node[vertex] (c) at (3,-2) {c};
          \node[vertex] (d) at (6,-2) {d};
          \node[vertex] (t) at (8,0) {t};

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {0} (a);
          \draw[->, back, font=\footnotesize] (a) to[bend right=20] node[above] {10} (s);

          \draw[->, fwd, font=\footnotesize] (s) -- node[below] {1} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend right=20] node[above] {9} (s);

          \draw[->, fwd, font=\footnotesize] (a) -- node[right] {2} (c);
          \draw[->, back, font=\footnotesize] (c) to[bend left=20] node[left]   {0} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {0} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend right=20] node[above] {4} (a);

          \draw[->, fwd, font=\footnotesize] (a) -- node[below] {2} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[left]   {6} (a);

          \draw[->, fwd, font=\footnotesize] (c) -- node[above] {0} (d);
          \draw[->, back, font=\footnotesize] (d) to[bend left=20] node[below]  {9} (c);

          \draw[->, fwd, font=\footnotesize] (d) -- node[right] {1} (b);
          \draw[->, back, font=\footnotesize] (b) to[bend left=20] node[right]  {5} (d);

          \draw[->, fwd, font=\footnotesize] (b) -- node[above] {1} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend left=20] node[below]  {9} (b);

          \draw[->, fwd, font=\footnotesize] (d) -- node[below] {0} (t);
          \draw[->, back, font=\footnotesize] (t) to[bend right=20] node[above] {10} (d);
        \end{tikzpicture}
        \caption{Increment all forward edges for total flow of $19$.}
      \end{subfigure}

      At this point, we try to find another path. The path $s \mapsto a$ is full so we cannot go through there. $s \mapsto c$ has a capacity of $1$, but from $c$, $c \mapsto d$ has a full capacity (so we cannot add to it), and $c \mapsto a$ has a backwards edge $c \mapsto a$ is empty (so we cannot remove from it). Therefore there are no more paths\footnote{We could have found this again using BFS.} and we are done. 
    \end{figure}
  \end{example} 

  \begin{example}[Edge Disjoint Paths]
    Given a directed graph $G(V, E)$ with start and end nodes $s, t \in V$, we want to find the maximum number of paths from $s \rightarrow t$ s.t. they do not share any edge, i.e. are \textit{edge-disjoint}. 
    \begin{figure}[H]
      \centering 
      \caption{This graph has two edge-disjoint paths: the top and bottom paths. } 
      \begin{tikzpicture}[
          vertex/.style={circle, draw, minimum size=0.6cm},
          >=Stealth
      ]

      % Nodes - arranging them in the shape shown
      \node[vertex] (s) at (0,0) {s};
      \node[vertex] (a) at (2,1) {};
      \node[vertex] (b) at (4,1) {};
      \node[vertex] (t) at (6,0) {t};
      \node[vertex] (c) at (2,-1) {};
      \node[vertex] (d) at (4,-1) {};

      % Upper and lower path edges
      \draw[->] (s) -- (a);
      \draw[->] (a) -- (b);
      \draw[->] (b) -- (t);
      \draw[->] (s) -- (c);
      \draw[->] (c) -- (d);
      \draw[->] (d) -- (t);

      % Cross edges between paths
      \draw[->] (a) to[bend right=20] (c);
      \draw[->] (c) -- (b);
      \draw[->] (b) to[bend right=20] (d);

      \end{tikzpicture}
      \label{fig:edge_disjoint}
    \end{figure}
    
    The idea is to reduce the maximum flow by first assigning capacity 1 to every edge. Then we compute the maximum flow $f^\ast$, and then return $|f^\ast|$. It turns out that even if we chose a path $\pi$ that went through the center node, the augmentation would push us to redirect the flows to the top and bottom outer edges. Since $|f^\ast| \leq n-1 < m$ in this example (since it can be at most the maximum indegree or outdegree of $s, t$), we should probably use Ford-Fulkerson rather than Orlin's algorithm. 
  \end{example}

  This leads to the lemma. 

  \begin{theorem}[Edge-Disjoint Paths]
    Given directed graph $G$ and its corresponding flow network $G^\prime$ of capacity $1$, the following are true: 
    \begin{enumerate}
      \item If there exists $k$ edge-disjoint paths in $G$, then there exists a flow with value $\geq k$ in $G^\prime$. 
      \item If there exists a flow of value $k$ in $G^\prime$, then there exists $k$ edge-disjoint paths in $G$. 
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    The first is trivially feasible and conservation is satisfied since for any node $u \in V \setminus \{s, t\}$, every path in $P$ (the collection of $k$ paths) that enters $u$ must exit $u$, so the total flow in equals the total flow out $\implies$ $f$ is a valid $(s, t)$-flow. Therefore, we have $k$ paths leaving $s$, so $|f| = k$. 

    For the other direction, let $f$ be the flow with value $k$, and let $P = \{\}$. Let $H$ be the subgraph of $G^\prime$ of edges with positive flow, and for every loop, we use BFS from $s$ to $t$ to get a path $\pi$. We then add $\pi$ to $P$ and remove $\pi$ from $H$, repeat this $k$ times until we get $k$ paths in $P$.  
  \end{proof} 

  The way that we have constructed a collection of paths from a flow function is very useful, and is called \textit{flow decomposition}. We can go back and forth between a flow and a collection of paths by doing what we have just done in the previous proof. 

  \begin{definition}[Flow Decomposition]
    Given a general flow $f$ on flow network $G$, we initialize our set of paths $P = \{\}$ and loop the following: 
    \begin{enumerate}
      \item Use BFS from $s$ to $t$ to get a path $\pi$. 
      \item Add $\pi$ to $P$ and rather than strictly removing the path from $H$, we need to be mindful of how much flow is left on it after removing only the bottleneck flow on the path. 
    \end{enumerate}
    This can be done in $O(NM)$ time, which loosely is because we are running BFS $O(M)$ times. 
  \end{definition}

  \begin{example}[Undirected Edge-Disjoint Paths]
    What if $G$ is undirected? In this case, we want to construct a flow network and then convert its 2 cycles into a 3 cycles by adding artificial points, taking linear time. 
  \end{example}

  \begin{example}[Undirected Edge-Disjoint Paths]
    Another problem is about vertex-disjoint paths, which is a stronger restriction than edge-disjoint ones. Each node does not have a concept of a capacity, so the general idea is for each vertex $v$, replace it with an ``in-out gadget'' with an edge of weight 1. The rest of the details follow similarly from edge-disjoint paths. 
    
    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}

      % Define styles
      \tikzset{
          voltage node/.style={
              draw,
              circle,
              minimum size=1.2cm,
              thick
          },
          arrow style/.style={
              ->,
              >=stealth,
              thick
          }
      }

      % Left figure
      % Node v with 4 in-edges and 3 out-edges
      \node[voltage node] (v1) at (0,0) {$v$};

      % In-edges
      \draw[arrow style] (-1.5, 1) -- (v1);
      \draw[arrow style] (-1.5, 0.33) -- (v1);
      \draw[arrow style] (-1.5, -0.33) -- (v1);
      \draw[arrow style] (-1.5, -1) -- (v1);

      % Out-edges
      \draw[arrow style] (v1) -- (1.5, 0.67);
      \draw[arrow style] (v1) -- (1.5, 0);
      \draw[arrow style] (v1) -- (1.5, -0.67);

      % Arrow between figures
      \draw[->, line width=1.5pt, red] (2.5,0) -- (3.5,0);

      % Right figure
      % Node v_in with 3 in-edges
      \node[voltage node, blue] (v2) at (6,0) {$v_{in}$};
      \draw[arrow style, blue] (4.5, 0.67) -- (v2);
      \draw[arrow style, blue] (4.5, 0) -- (v2);
      \draw[arrow style, blue] (4.5, -0.67) -- (v2);

      % Connection between v_in and v_out
      \draw[arrow style, red] (v2) -- (8.5,0);

      % Node v_out with 4 out-edges
      \node[voltage node, purple] (v3) at (9,0) {$v_{out}$};
      \draw[arrow style, purple] (v3) -- (10.5, 1);
      \draw[arrow style, purple] (v3) -- (10.5, 0.33);
      \draw[arrow style, purple] (v3) -- (10.5, -0.33);
      \draw[arrow style, purple] (v3) -- (10.5, -1);

      \end{tikzpicture}
      \caption{} 
      \label{fig:undirected_ex}
    \end{figure}
  \end{example}

  \begin{example}[Maximum Bipartite Matching]
    Another application is in \textbf{bipartite matching}, which for an undirected bipartite graph $G(V, E)$ with $V = A \sqcup B$, is a subset of the edges $M \subset E$ s.t. no 2 edges in $M$ share an endpoint. The goal is to find the maximum bipartite matching, i.e. the matching with the greatest total weight. 

    \begin{figure}[H]
      \centering 
      \begin{tikzpicture}[
          blue node/.style={draw, circle, fill=blue!20, minimum size=0.8cm},
          red node/.style={draw, circle, fill=red!20, minimum size=0.8cm},
          normal edge/.style={thin, black},
          matching edge/.style={very thick, green!60!black},
          normal weight/.style={black},
          matching weight/.style={green!60!black, font=\bfseries}
      ]

      % Left (blue) nodes
      \node[blue node] (a1) at (0,3) {$a_1$};
      \node[blue node] (a2) at (0,2) {$a_2$};
      \node[blue node] (a3) at (0,1) {$a_3$};
      \node[blue node] (a4) at (0,0) {$a_4$};

      % Right (red) nodes
      \node[red node] (b1) at (4,2.5) {$b_1$};
      \node[red node] (b2) at (4,1.5) {$b_2$};
      \node[red node] (b3) at (4,0.5) {$b_3$};

      % Regular edges with weights
      \draw[normal edge] (a1) -- node[above, pos=0.7] {3} (b2);
      \draw[normal edge] (a2) -- node[below, pos=0.3] {4} (b1);
      \draw[normal edge] (a3) -- node[above, pos=0.7] {2} (b2);
      \draw[normal edge] (a3) -- node[below, pos=0.6] {4} (b3);
      \draw[normal edge] (a4) -- node[below, pos=0.3] {5} (b3);

      % Maximum matching edges (highlighted in green)
      \draw[matching edge] (a1) -- node[above, pos=0.3, matching weight] {5} (b1);
      \draw[matching edge] (a2) -- node[above, pos=0.6, matching weight] {6} (b3);
      \draw[matching edge] (a4) -- node[below, pos=0.7, matching weight] {3} (b2);

      \end{tikzpicture}
      \caption{A bipartite matching} 
      \label{fig:bipartite_matching}
    \end{figure}

    The general idea is to take an undirected graph, convert it to a flow network, compute the max flow, i.e. min cut, and then translate it back into the undirected graph solution.  
    \begin{enumerate}
      \item Construct the flow network $G^\prime = (V^\prime, E^\prime)$, where $V^\prime = V \cup \{s, t\}$, with additional edges going from $s$ to $A$ and $B$ to $t$ all with weights $1$. Replace the middle edges with directed edges towards the flow with the same weight (though it can be any weight at least 1). 

      \begin{figure}[H]
        \centering 
        \begin{tikzpicture}[
            blue node/.style={draw, circle, fill=blue!20, minimum size=0.8cm},
            red node/.style={draw, circle, fill=red!20, minimum size=0.8cm},
            special node/.style={draw, circle, minimum size=0.8cm},
            edge/.style={->, >=stealth}
        ]

        % Source and sink nodes
        \node[special node] (s) at (-2,1.5) {$s$};
        \node[special node] (t) at (6,1.5) {$t$};

        % Left (blue) nodes
        \node[blue node] (a1) at (0,3) {$a_1$};
        \node[blue node] (a2) at (0,2) {$a_2$};
        \node[blue node] (a3) at (0,1) {$a_3$};
        \node[blue node] (a4) at (0,0) {$a_4$};

        % Right (red) nodes
        \node[red node] (b1) at (4,2.5) {$b_1$};
        \node[red node] (b2) at (4,1.5) {$b_2$};
        \node[red node] (b3) at (4,0.5) {$b_3$};

        % Edges from source to A nodes with weight 1
        \draw[edge] (s) -- node[above] {1} (a1);
        \draw[edge] (s) -- node[above] {1} (a2);
        \draw[edge] (s) -- node[below] {1} (a3);
        \draw[edge] (s) -- node[below] {1} (a4);

        % Edges from B nodes to sink with weight 1
        \draw[edge] (b1) -- node[above] {1} (t);
        \draw[edge] (b2) -- node[above] {1} (t);
        \draw[edge] (b3) -- node[below] {1} (t);

        % Middle edges (directed A to B) with original weights
        \draw[edge] (a1) -- node[above, pos=0.3] {5} (b1);
        \draw[edge] (a1) -- node[above, pos=0.7] {3} (b2);
        \draw[edge] (a2) -- node[below, pos=0.3] {4} (b1);
        \draw[edge] (a2) -- node[above, pos=0.6] {6} (b3);
        \draw[edge] (a3) -- node[above, pos=0.7] {2} (b2);
        \draw[edge] (a3) -- node[below, pos=0.6] {4} (b3);
        \draw[edge] (a4) -- node[below, pos=0.7] {3} (b2);
        \draw[edge] (a4) -- node[below, pos=0.3] {5} (b3);

        \end{tikzpicture}

        \label{fig:g_prime}
      \end{figure}

      \item Compute max flow $f$ in $G^\prime$. 
      \item Return $M = \{ (u \rightarrow v) \in E \mid f(u \rightarrow v) = 1 \}$. This can be done using the flow decomposition or just by looking at the edges in our flow with value $1$ and mapping it to the corresponding undirected bipartite graph. 
    \end{enumerate}
    To see correctness, we claim that there exists a matching $M$ in $G$ of size $k$ iff there exists a flow $f$ in $G^\prime$ with $|f|= k$, and therefore the max matching corresponds to the max flow. Constructing the flow network is $O(N + M)$ since $N^\prime = N + 2$ and $M^\prime = M + N$. Computing the max-flow is $O(N^\prime M^\prime)$ or $O(M^\prime |f|)$ depending on if we use Orlin's or Ford-Fulkerson, but either one is $O(NM)$. Then mapping it back to $M$ might take $O(M)$, so the total time is $O(NM)$. 
  \end{example}

\subsubsection{Edmonds Karp}

\subsection{Exercises}

  \begin{exercise}
    Prove that in any connected undirected graph $G = (V, E)$ there is a vertex $v \in V$ s.t. $G$ remains connected after removing $v$. 
  \end{exercise}
  \begin{solution}
    Let $u$ be such a leaf node of $T$, and let $G'$ be the subgraph of $G$ resulting by removing $u$ and its incident edges from $G$.
    For sake of contradiction,\footnote{We provide an alternative direct proof as follows: Since $G$ is given to be connected, $T$ contains all vertices of $G$. Let $T'$ be the BFS tree minus $u$ and its single incident edge connecting it to its parent in $T$. Since $u$ is a leaf, $T'$ remains a connected tree with all other vertices of $G$. The edges of $T'$ exist in $G'$, so $G'$ is connected.} suppose $G'$ has more than one connected component.
    Let $C$ be a connected component in $G'$ that does not contain $s$, the root of the BFS tree $T$.
    Since $G$ was connected before the removal of $u$, it must be that every path from $s$ to any vertex $v$ in $C$ includes $u$ (otherwise there would remain a path from $s$ to $v$ in $G'$ and $s$ would be in $C$).
    Then $u$ is the only vertex not in $S$ with edges to vertices in $S$, so all vertices in $C$ must be ``visited'' during BFS only after visiting $u$. Furthermore, the vertices of $S$ must be in the subtree of $T$ rooted at $u$. But $u$ is a leaf, which is a contradiction.
  \end{solution}

  \begin{exercise}
    Two parts. 
    \begin{enumerate}
      \item Give an example of a strongly connected directed graph $G = (V, E)$ s.t. that every $v \in V$, removing $v$ from $G$ gives a directed graph that is not strongly connected. 
      \item In an undirected graph with exactly two connected components, it is always possible to make the graph connected by adding only one edge. Give an example of a directed graph with two strongly connected components such that no addition of one edge can make the graph strongly connected.
    \end{enumerate}
  \end{exercise}
  \begin{solution}
    Listed. 
    \begin{enumerate}
      \item A graph whose edges form a cycle, having at least three nodes.
      \item Two strongly connected components with no edges between them.
    \end{enumerate}
  \end{solution} 

  \begin{exercise}[DPV 3.16]
    Suppose a CS curriculum consists of $n$ courses, all of them mandatory. The prerequisite graph $G = (V,E)$ has a node for each course, and an edge from course $v$ to course $w$ if and only if $v$ is a prerequisite for $w$. Note this is a directed acyclic graph (DAG). In order for a student to take a course $w$ with prerequisite $v$, they must take $v$ in an earlier semester. Find an algorithm that works directly with this graph representation, and computes the minimum number of semesters necessary to complete the curriculum, under the assumption any number of courses can be taken in one semester. The running time of your algorithm should be $O(n+m)$, where $n$ and $m$ are the numbers of vertices and edges in $G$, respectively.
  \end{exercise}
  \begin{solution}
    For each vertex, we want to find the longest path leading to it: if there is a path leading to a node, then all of the courses in the path should be taken sequentially. Perform a topological sort of $G$'s nodes and label them $1$ through $n$. Then, we go through the nodes in the resulting topological order. For each vertex, we assign the minimum number of semesters required to take it: if there are no prerequisites, we assign 1, and if there are prerequisites, we assign 1 plus the maximum value assigned to its prerequisite nodes.
    
    \textit{Implementation details}: If the input is in adjacency list format, then we do not have access to the \emph{incoming} edges to a node (its prerequisites). By exploring the entire graph with BFS calls, we can compute the list of incoming edges to every vertex in $O(n+m)$ time. These details are not required. If the input is in adjacency matrix format, for each node it takes $O(n)$ time to find its incoming edges, so the total running time is $O(n^2)$.
  \end{solution}

  \begin{exercise}[DPV 3.22] 
    Give an efficient algorithm that takes as input a directed graph $G = (V,E)$, and determines whether or not there is a vertex $s \in V$ from which all other vertices are reachable.
  \end{exercise}
  \begin{solution}
    We first build the DAG representation of the SCCs of $G$ in $O(m+n)$ time, as described in lecture. This graph is a DAG where each SCC of $G$ is represented by a single node. We return true if this DAG has exactly one node with no incoming edges (i.e., exactly one source node), and return false otherwise.

    \textit{Correctness.} Let $u$ be a vertex in an SCC that is a source node in the DAG representation. If there is a path in $G$ from a vertex $v$ not in the SCC of $u$ to $u$, then there must be an edge (corresponding to an edge in this path) into the SCC of $u$ in the DAG, which contradicts that the node has no incoming edges. Thus, if there are two source SCCs in the DAG, no vertex of $G$ can reach all vertices; in particular, no vertex can reach the vertices in both of the source SCCs. Thus we correctly return false if there are multiple source SCCs. 
    
    On the other hand, if there is a single source SCC in the DAG, we claim that every vertex in the SCC can reach every other vertex in $G$, in which case our algorithm correctly returns true. Every other SCC in the DAG is not a source, so it has an incoming edge.\footnote{The following argument can be made formal with induction.} Consider starting at an SCC in the DAG, picking an incoming edge to the SCC, and then repeating this process from the SCC from which the edge was leaving. This process stops when we reach an SCC without incoming edges. In this case there is exactly one source SCC, so this process will arrive at the single source SCC when starting from any SCC in the DAG. This implies there is a path from the unique source SCC to every other SCC in the DAG, and thus every vertex of the source SCC can reach all vertices in all SCCs of $G$; that is, all vertices of $G$.
  \end{solution}

  \begin{exercise}[DPV 3.19]
    You are given a binary tree $T = (V, E)$ with designated root node with $n = |V|$ vertices which are the integers from $1$ to $n$. In addition, there is an array $x[1..n]$ of values where $x[u]$ is the value of vertex $u \in V$. Define a new array $z[1..n]$ where, for each $u \in V$,	
    \begin{equation}
      z[u] = \max \{ x[v] \mid \text{$v$ is a descendant of $u$}\}
    \end{equation}
    That is, $z[u]$ is the maximum $x$-value of all vertices in the subtree of $T$ rooted at $u$. Note that, by definition, any node is a descendant of itself. Describe an $O(n)$-time algorithm which calculates the entire $z$-array.
  \end{exercise}
  \begin{solution}
    We propose the following recursive algorithm performs a \emph{postorder} traversal of the tree and populates the values of the $z$-array in the process:
    \begin{lstlisting}
      computeZ(u):
        maxVal = x[u]
        if u.left is not null:
          computeZ(u.left) # compute z for all descendants of u.left
          maxVal = max(z[u.left], maxVal)
        if u.right is not null:
          computeZ(u.right) # computes z for all descendants of u.right
          maxVal = max(z[u.right], maxVal)
        z[u] = maxVal
    \end{lstlisting}
    We initially call \texttt{computeZ} on the root node of $T$.        The algorithm takes $O(1)$ time per node, which is $O(n)$ overall\footnote{This algorithm can also be described as a modified version of the so-called \emph{depth-first search} (DFS) graph traversal algorithm, which is different from BFS.}
  \end{solution}

  \begin{exercise}
    Your data center needs to run a number of jobs (compute requests) numbered $1, 2, \dots, n$. These are specified in a list of $m$ tuples where $(i, k)$ means that job $i$ must be completed before job $k$ can run. A given job may have multiple dependencies; for example, you might have constraints $(1, 4), (2, 4), (3, 4)$ that all of jobs $1, 2, \mbox{ and } 3$ must be completed before $4$ can run.
    \begin{enumerate}
      \item Describe an $O(n+m)$ runtime algorithm that determines whether it is possible to execute all of the jobs, and if so, determines a valid order in which to execute the jobs one at a time. \textit{Hint. How to relate SCCs to cycles?}
      \item Suppose you have $n$ identical servers (so that if there were no constraints you could simply run each job on a separate server). Suppose every job has the same runtime $R$. Describe an $O(n+m)$ runtime algorithm to compute the total runtime that will be necessary to run all of the jobs in a valid order.
    \end{enumerate}
  \end{exercise}
  \begin{solution}
    For this question we define a graph $G = (V, E)$ where there is a vertex for every job $1, \dots, n$ and an edge from $i$ to $k$ for every listed dependency (where $k$ depends on $i$).

    \begin{enumerate}
        \item We note that a sequence of jobs can be executed if and only if there is no circular dependency. In the language of graphs, this requires that $G$ be free of cycles. To this end, it suffices to propose an algorithm that runs in $\mathcal{O}(m+n)$. We will use Kosaraju's SCC algorithm. We prove the following claim:

        \centerline{Any SCC with $\geqslant 2$ vertices contain a cycle.}
                    \vspace{5pt} 
  
        To see this, consider any distinct $u,v$ in this SCC. Let $p_{u,v}$ and $p_{v,u}$ be the paths from $u$ to $v$ and backwards, respectively. Now concatenate the paths and get a walk that starts from $u$ and ends at $u$. Note that each vertex appears at most once in $p_{u,v}$ and in $p_{v,u}$, so in the combined walk, it appears at most twice. Consider the set of vertices that are revisited in this walk --- clearly, $u$ is one of them and is the latest one to be revisited. There must exist a vertex $w$ that was the \textit{first} to be revisited. Then, the section of the walk between the two visits of $w$ form a cycle by definition: it starts from $w$, ends at $w$, and does not repeat any other vertices. This proves the claim. And to go back to our problem, the following are equivalent: 
        \begin{enumerate}
          \item jobs can be executed 
          \item no cycles in $G$ 
          \item each SCC obtained from Kosaraju is a singleton
        \end{enumerate}

        \item We first run the algorithm from part (a) to check if it is possible and to find a valid order of the jobs if so. Then define an array $L$ of length $n$. We will compute $L[k]$ as the length of the longest dependency chain prior to $k$. Loop over the $k$ jobs in topological order. For each, compute $L[k] = 0$ if $k$ has no dependencies, or $L[k] = 1 + \max_{(i, k)} L[i]$ otherwise. Finally, return $\max_{k} L[k]$. 
    \end{enumerate}
  \end{solution}

  \begin{exercise}
    Let $G=(V,E)$ be a directed graph with real-valued edge weights, where each vertex is colored in either {\color{red} red} or {\color{dkgreen} green}. Find the shortest/cheapest $s-t$ walk such that, not counting $s$, the walk visits red vertices for an even number of times and green vertices at least thrice. (Duplicates allowed and will be counted more than once.)
  \end{exercise}
  \begin{solution}
    Similar to the last problem in the previous recitation, the key insight lies in constructing a directed graph $G'=(V', E')$ that captures some additional structures. Based on the constraints, as we walk along a path in $G$, there are two things we need to take care of: 
    \begin{itemize}
      \item The number of (not necessarily distinct) red vertices we have walked past, and whether this number even or odd (this is called the \textit{parity} of that number), and
      \item The number of (not necessarily distinct) distinct green vertices we have walked past. 
    \end{itemize}
    To encode all of the information above, each vertex in $G'$ will be represented by a ``state'', or a tuple $(v, p, g)$ where
    \begin{itemize}
      \item $v\in V$ corresponds to an original vertex in $G$,
      \item $p\in \{0,1\}$ (or ``even'', ``odd'') represents the parity of the count of red vertices (not necessarily distinct) visited so far, and
      \item $g \in \{0,1,2,3+\}$ represents the number of times green vertices (not necessarily distinct) have been visited.
    \end{itemize}

    Now we will need to consider the conditions under which each of the tuple variable updates. For example, every time we visit a red vertex, the value $p$ should alternate, and every time we visit a green vertex, the value $g$ should increase until it becomes $3+$. Formally, the state transitions (i.e. edges in $E'$) can be formulated as follows. For each edge $(u,v)$ in the original graph $G$, depending on the colors of $u$ and $v$, we add the following edges, all with the same weight as $(u,v)$, to $E'$:

    \begin{enumerate}[label=(\arabic*),align=left]
        \item[($v$ red)] For every state $(u,p,g)$ [a total of $8$ such thates because $p\in \{0,1\}$ and $g \in \{0,1,2,3+\}$], add an edge to the corresponding state $(v,1-p, g)$. In other words, we flip the parity because we visited one more red vertex, but this does not affect the value of $g$.
        \item[($v$ green)]
            \leavevmode
            \begin{itemize}
                \item For every state $(u,p,g)$ with $g\in \{0,1,2\}$, add a (directed) edge to $(v,p,g+1)$ because our green counter increases given $v$ is green. (Define $2+1 $ to be ``$3+$.'')
                \item For states of form $(u,p,3+)$, add a (directed) edge to $(v,p,3+)$ because we still fall under the ``$g\geqslant 3$'' category after visiting an additional green vertex.
            \end{itemize}
    \end{enumerate}

    All of our observations on the Recitation \#2 graph modeling problem still hold: if we have a path in $G'$, we can uniquely recover a well-defined walk in $G$. Initially, we want to start from state $(s,0,0)$ because we start from vertex $s\in V$ and, per the problem, the starting point does not contribute to the red and green count. Our goal is to reach the state $(t,0,3+)$, which means (i) we arrive at $t$, and along the course we have (ii) visited an even number of red vertices and (iii) green vertices $\geqslant 3$ times. This is exactly what we want. 

    How about the runtime? The construction of $G'$ involves defining $8 \lvert V\rvert $ vertices since $p$ has $2$ possible values and $g$ has $4$, and we need to construct one state for each pair of $p$ and $g$. Similarly, for each $(u,v)$, regardless of the color of $v$, in both cases we add a total of $8$ edges. Therefore $\lvert E'\rvert  = 8 \lvert E\rvert $. Since $G, G'$ are directed graphs with real-valued weights, we need to run Bellman-Ford, which takes $\mathcal{O}(\lvert V\rvert \lvert E\rvert )$. Like shown before, other costs (e.g. the one to recover a walk in $G$ from a path in $G'$) are linear and hence dominated by the pathfinding runtime. So the final complexity is $\mathcal{O}(\lvert V\rvert \lvert E\rvert)$.
  \end{solution}

  \begin{exercise}
    Let $G = (V,E)$ be a weighted strongly connected directed graph with positive edge weights. Let $v_0$ be a specific vertex. Describe an algorithm that computes the \textbf{\textit{cost}} of the shortest walk between every pair of vertices of $G$, with the restriction that each of these walks must pass through $v_0$ (that is, for every distinct pair $u, v \in V$, among all walks from $u$ to $v$ that pass through $v_0$, compute the cost of the shortest walk). Describe the algorithm, analyze its runtime complexity, and briefly explain (not a formal proof) why it is correct. Try to give an algorithm that runs in $O (|E|\log(|V|) + |V|^2)$ time. As usual, you may use any algorithm as described in lecture without restating it or arguing for its correctness.
  \end{exercise}
  \begin{solution}
    The high level idea is to decompose any qualifying $u\to v$ walk into the combination of two paths $u\to v_0\to v$, where we try to minimize the cost of both subpaths. It's easy to compute the minimum cost of $v_0\to v$ for all $v$: running Dijkstra once over the graph suffices. The first half, $u\to v_0$, is the nuisance since we need to calculate this quantity for every $u\in V$. Solution? Observe that the destination node $v_0$ is fixed! We flip the direction, define a ``reverse graph'' $G^{-1}$ where each edge carries its original weight but points in the other direction. Then, any cheapest $v_0\to u$ path in $G^{-1}$ would correspond to the cheapest $u\to v_0$ path in $G$, with matching total costs.  
  \end{solution}

  \begin{exercise}
    Let  $G=(V, E)$ be a directed, weighted graph with $|V|= n$ and $|E|=O(n)$ (that is, the graph is sparse). Let $s$ be a vertex in $V$. How quickly can the cost of the following shortest paths be computed under the given conditions? Just note the runtime and be prepared to explain. All of these can be solved using a single call to a shortest-path algorithm if provided the correct input graph (not necessarily the given one).
    \begin{enumerate}
      \item Compute the shortest path distance from some $s$ to all other vertices in $G$ under the condition that the weight of every edge is a positive integer $\le  10$.
      \item Compute the shortest path distance \textit{to} a target $t$ from all possible source vertices $s$ in a graph with positive edge weights.
    \end{enumerate}
  \end{exercise}
  \begin{solution}
    Listed. 
    \begin{enumerate}
      \item Since all weights are integer and uniformly bounded, we convert $G$ into an unweighted graph and apply BFS. Construct unweighted $G'=(V', E')$ as follows: for each directed edge $(u\to v \in E$, put a series of dummy nodes between $u,v$ in $G'$ so that the distance from $u$ to $v$ in $G'$ is precisely the integer weight $w(u,v)$ of $u\to v$ in $E$. Now $G$ has at most $10n$ nodes and $10n$ edges. So BFS runs in $O(\lvert V'\rvert  + \lvert E'\rvert ) = O(n)$.
      \item Construct the reversed graph $G^{-1}$ and run $\mathrm{Dijkstra}(G^{-1}, t)$. This finishes in $\mathcal{O}((m+n) \log n) = O(n\log n)$ time since $G$ is sparse.
    \end{enumerate}
  \end{solution}

  \begin{exercise}
    Let $G=(V,E)$ be an undirected, weighted graph with non-negative edge weights. Let vertices $s,t\in V$ be given. Describe an algorithm that efficiently solves the following questions.
    \begin{enumerate}
      \item Find the shortest/cheapest $s-t$ walk with an even number of edges.
      \item Find the shortest/cheapest $u-v$ walk with a number of edges of form $6k+1, k\in \mathbb{N}$. 
    \end{enumerate}
  \end{exercise}
  \begin{solution}
    Listed. 
    \begin{enumerate}
      \item The key observation is that as we travel on $G$, the number of edges we have travelled along alternates between being odd and even. Furthermore, the very same vertex may correspond to both even and odd: for example if we walked along $u\to v\to w\to u$, then initially we travelled for $0$ edges, but upon return we travelled a total of $3$ edges. We need a way to distinguish them. The solution? Duplicate each vertex into two categories: ``odd'' and ``even.''

      We construct a new graph $G' = (V', E')$ by duplicating every vertex $v\in V$, labeling one of them as $v_{\text{odd}}$ and the other $v_{\text{even}}$. For each edge $(u,v)\in E$, add two edges $(u_{\text{odd}}, v_\text{even})$ and $(u_{\text{even}}, v_{\text{odd}})$ to $E'$, both with the same as $(u,v)\in E$. 

      Clearly, $\lvert V'\rvert  = 2 \lvert V\rvert $ and $\lvert E'\rvert  = 2 \lvert E\rvert $. What would edges look like in $G'$? By construction, the two endpoints of an edge in $G'$ have different subscripts, one with ``odd,'' the other ``even.'' This agrees with our previous observation on the original $G$ that as we walk along the graph, the distance we have so far travelled alternates between even and odd. It follows that, starting from $s_\text{even}$, a vertex $v_\text{even}\in V'$ (resp. $v_\text{odd}$) is only reachable via even (resp. odd) number of edges. 

      On the other hand, also notice that there is a natural correspondence between edges in $G'$ and $G$: $(u_\text{odd}, v_\text{even})\in E'$ corresponds to $(u,v)\in E$. This means a \textit{path} in $G'$ naturally corresponds to a walk in $G$, e.g.:

      \[u_\text{even} \to v_\text{odd} \to w_\text{even} \to u_{\text{odd}} \to t_\text{even} \qquad \text{corresponds to}\qquad u\to v\to w \to u\to t.\]

      Combining both observations above, there exists an $s-t$ walk in $G$ with an even number of edges if and only if there is a path in $G'$ from $s_\text{even}$ to $t_\text{even}$. The rest is simple: run a pathfinding algorithm on $G'$. The weights are non-negative, so we use Dijkstra's algorithm. 

      Total runtime? Time to construct $G'$ involves $\lvert V'\rvert = 2\lvert V\lvert$ vertices and $\lvert E'\rvert = 2\lvert E\rvert$ edges. This is dominated by running Dijkstra on $G'$, which takes $O((|V'| +\lvert E'\rvert )\log \lvert V'\rvert) = O((|V|+\lvert E\rvert)\log \lvert V\rvert)$ time. Finally, transforming the path in $G'$ back to a walk in $G$ takes linear time w.r.t. the path length (one step for each edge), which is bounded by $O(\lvert E'\rvert)$.  So overall most work is dominated by Dijkstra's algorithm and the overall algorithm runs in $O((|V|+\lvert E\rvert) \log \lvert V\rvert)$.

      \item Same idea but make 6 copies of the graph. 
    \end{enumerate}
  \end{solution}

  \begin{exercise}
    Suppose that in addition to having edge costs $\{l_e:e\in E\}$, a graph also has vertex costs $\{c_v:v\in V\}$. Now define the cost of a path to be the sum of its edge lengths, \textit{plus} the costs of all vertices on the path. Give an efficient algorithm for finding the minimum cost path from $s$ to $t$. You may assume edge costs and vertex costs are all nonnegative.
  \end{exercise}
  \begin{solution}
    Using the generic approach, we can use $\text{cost}_u(v)=\text{cost}(u)+w(u,v)+c_v$ to solve this problem. Alternatively, for each edge $(u,v)$ we can update its weight to $w(u,v)+c_v$ and run Dijkstra on this updated graph, which gives an equivalent mathematical formulation.
  \end{solution}



\section{Linear Programming}

  Basically, you want to solve a constrained optimization problem. Some examples are 
  \begin{enumerate}
    \item Shortest path: select a set of edges of minimum cost such that $s$ and $t$ are connected. 
    \item Minimum Spanning Tree: select a set of edges of minimum cost such that all vertices are connected. 
    \item Maximum Flow: select a flow on every edge such that capacity and balance constraints are respected. 
  \end{enumerate} 


  \begin{definition}[Linear Programming]
    In linear programming both the constraints and optimization objectives are linear functions. It is usually written in \textit{canonical form}, of the form 
    \begin{equation}
      \min c^T x \text{ subject to } Ax \geq b, x \geq 0
    \end{equation}
    or 
    \begin{equation}
      \max c^T x \text{ subject to } Ax \leq b, x \geq 0
    \end{equation}
    where we have $n$ variables $x \in \mathbb{R}^n$, $c \in \mathbb{R}^n$ are the optimization coefficients, and $A \in \mathbb{R}^{m \times n}$ are the matrix of $m$ constraint equations. 
  \end{definition} 

  \begin{example}[Simple LP]
    We can have the problem of maximizing $2x + y$ subject to 
    \begin{align}
      x + y & \leq 1 \\ 
      x & \geq 0  \\
      y & \geq 0
    \end{align}
    In this case, we can write it in canonical form as 
    \begin{equation}
      \max \begin{pmatrix} 2 & 1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} \text{ subject to } \begin{pmatrix} 1 & 1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} \leq 1, \begin{pmatrix} x \\ y \end{pmatrix} \geq \begin{pmatrix} 0 \\ 0 \end{pmatrix}
    \end{equation}
  \end{example}

  \begin{theorem}[Optimality of LP]
    An optimal solution to a linear program can be obtained in weakly polynomial time in the number of variables, constraints, and poly-logarithmic in the constants in the LP.\footnote{Obtaining a strongly polynomial algorithm for LPs remains a major open problem.} 
  \end{theorem} 

  This is very similar to integer programs, which solve for integer solutions rather than real, but in general we don't know of algorithms that can solve integer programs in polynomial time. However, integer programs can be ``relaxed'' to linear programs by removing the restriction on variables being integers. However, the optimal solution for the relaxed LP may be different from that of the original LP. 

  \begin{example}[Max Flow as LP]
    
  \end{example}

  \begin{example}[Bipartite Matching as LP]
    
  \end{example} 

  \begin{example}[Primal vs Dual LP]
    Now given a maximization LP problem, such as 
    \begin{equation}
      \max{2x + y} \text{ subject to } \begin{cases} x + y \leq 3 \\ x - y \leq 1 \\ x, y \geq 0 \end{cases} 
    \end{equation}
    we can just find \textit{one} solution satisfying the constraints and use it as a lower bound on the optimum. Say we find one, e.g. $x = y = 0$, which does satisfy all constraints. Now if we want to find an \textit{upper bound} on the value of the solution, we can use duality. We create new variables $a, b \geq 0$, and observe that 
    \begin{align}
      x + y \leq 3 & \implies a (x + y) \leq 3a \\
      x - y \leq 1 & \implies b (x - y) \leq b
    \end{align}
    Thus by adding the two we have $(a + b) x + (a - b) y \leq 3a + b$. 

    Now if we suppose $a + b \geq 2$ and $a - b \geq 1$ (which are the coeffients of $2x + y$), then since $x, y \geq 0$, we have 
    \begin{equation}
      2x + y \leq (a + b) x + (a - b) y \leq 3a + b
    \end{equation} 
    so any $a, b$ satisfying the above inequalities give an upper bound of $3a + b$ on the value of the optimal solution. Say we have $a = 2, b = 1$, which does satisfy. Then $3a + b = 7$ is an upper bound of $2x + y$. Therefore, to get the tightest upper bound, we can minimize the dual problem 
    \begin{equation}
      \min{3a + b} \text{ subject to } \begin{cases} a + b \geq 2 \\ a - b \geq 1 \\ a, b \geq 0 \end{cases}
    \end{equation}
    This is called the \textbf{dual LP}.
  \end{example}
  
  Generally, given the primal $\max{c^T x}$ subject to $Ax \leq b$ and $x \geq 0$, the dual problem is to compute $\min{b^T y}$ subject to $A^T y \geq c$ and $y \geq 0$. Every dual variable corresponds to a primal constraint and vice versa. If a primal has $n$ variables and $m$ constraints, the dual has $m$ variables and $n$ constraints. 

  \begin{theorem}
    The dual of a dual is the primal. 
  \end{theorem}

  \begin{theorem}[Weak Duality]
    The following properties are called \textbf{weak duality}. 
    \begin{enumerate}
      \item The optimal value for a dual maximization LP is a lower bound on the optimal value for a primal minimization LP. 
      \item The optimal value for a dual minimization LP is an upper bound on the optimal value for a primal maximization LP. 
    \end{enumerate}
  \end{theorem}

  \begin{theorem}[Strong Duality]
    The optimal value of a primal and dual LP are exactly identical, called \textbf{strong duality}. 
  \end{theorem}

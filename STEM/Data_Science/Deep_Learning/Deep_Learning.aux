\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Multi-Layered Perceptrons}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Generalized Linear Models}{3}{subsection.1.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:raw_points}{{1a}{4}{Data in space $\mathcal {X} = \mathbb {R}^2$. \relax }{figure.caption.2}{}}
\newlabel{sub@fig:raw_points}{{a}{4}{Data in space $\mathcal {X} = \mathbb {R}^2$. \relax }{figure.caption.2}{}}
\newlabel{fig:raw_trained}{{1b}{4}{Logistic fit to data in input space. \relax }{figure.caption.2}{}}
\newlabel{sub@fig:raw_trained}{{b}{4}{Logistic fit to data in input space. \relax }{figure.caption.2}{}}
\newlabel{fig:transformed_points}{{1c}{4}{Transformed data $\phi (\mathbf {x}) = ||\mathbf {x}||$. \relax }{figure.caption.2}{}}
\newlabel{sub@fig:transformed_points}{{c}{4}{Transformed data $\phi (\mathbf {x}) = ||\mathbf {x}||$. \relax }{figure.caption.2}{}}
\newlabel{fig:transformed_trained}{{1d}{4}{Logistic fit in transformed space. \relax }{figure.caption.2}{}}
\newlabel{sub@fig:transformed_trained}{{d}{4}{Logistic fit in transformed space. \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A nonlinear feature transformation $\phi $ will cause a nonlinear decision boundary when doing logistic regression. \relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:logistic_transformed}{{1}{4}{A nonlinear feature transformation $\phi $ will cause a nonlinear decision boundary when doing logistic regression. \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Architecture}{4}{subsection.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Diagram of a neuron, decomposed into its linear and nonlinear components. \relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:neuron}{{2}{5}{Diagram of a neuron, decomposed into its linear and nonlinear components. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Forward and Back Propagation}{7}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Summary}{12}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Neural Net from Scratch}{12}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Quick Start to PyTorch}{16}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}Datasets and Features/Label Transformations}{16}{subsubsection.1.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Data point from FashionMNIST\relax }}{18}{figure.caption.5}\protected@file@percent }
\newlabel{fig:fashionmnist_data}{{3}{18}{Data point from FashionMNIST\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.2}Building a Neural Net}{18}{subsubsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.3}Automatic Differentiation}{20}{subsubsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.4}Optimizing Model Parameters}{20}{subsubsection.1.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Training Stability}{22}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Weight Initialization}{22}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Optimizers}{22}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Vanishing Gradient Problem}{22}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Activation Functions}{22}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Residual Connections}{23}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Exploding Gradient Problem}{24}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Normalization Layers}{24}{subsubsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Max Norm Regularization}{25}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Regularization}{25}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Early Stopping}{25}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}L1 and L2 Regularization}{25}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Dropout}{25}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Data Augmentation}{27}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Network Pruning}{27}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Summary}{27}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Convolutional Neural Networks}{28}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Kernels}{28}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Convolution using a kernel on an image.\relax }}{29}{figure.caption.6}\protected@file@percent }
\newlabel{fig:convolution}{{4}{29}{Convolution using a kernel on an image.\relax }{figure.caption.6}{}}
\newlabel{fig:original_image}{{5a}{29}{Original image. \relax }{figure.caption.7}{}}
\newlabel{sub@fig:original_image}{{a}{29}{Original image. \relax }{figure.caption.7}{}}
\newlabel{fig:mean_blur_image}{{5b}{29}{$5 \times 5$ mean blur applied. \relax }{figure.caption.7}{}}
\newlabel{sub@fig:mean_blur_image}{{b}{29}{$5 \times 5$ mean blur applied. \relax }{figure.caption.7}{}}
\newlabel{fig:normal_blur_image}{{5c}{29}{$5 \times 5$ Gaussian blur applied. \relax }{figure.caption.7}{}}
\newlabel{sub@fig:normal_blur_image}{{c}{29}{$5 \times 5$ Gaussian blur applied. \relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of blurring kernels on image. \relax }}{29}{figure.caption.7}\protected@file@percent }
\newlabel{fig:blur}{{5}{29}{Comparison of blurring kernels on image. \relax }{figure.caption.7}{}}
\newlabel{fig:original_image_2}{{6a}{30}{Original image. \relax }{figure.caption.8}{}}
\newlabel{sub@fig:original_image_2}{{a}{30}{Original image. \relax }{figure.caption.8}{}}
\newlabel{fig:sharpened_image}{{6b}{30}{$3 \times 3$ sharpening applied. \relax }{figure.caption.8}{}}
\newlabel{sub@fig:sharpened_image}{{b}{30}{$3 \times 3$ sharpening applied. \relax }{figure.caption.8}{}}
\newlabel{fig:sharpen}{{\caption@xref {fig:sharpen}{ on input line 1201}}{30}{Sharpening}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sharpening kernels applied to image. \relax }}{30}{figure.caption.8}\protected@file@percent }
\newlabel{fig:horizontal_edge}{{7a}{30}{$3 \times 3$ horizontal edge detecting kernel applied. \relax }{figure.caption.9}{}}
\newlabel{sub@fig:horizontal_edge}{{a}{30}{$3 \times 3$ horizontal edge detecting kernel applied. \relax }{figure.caption.9}{}}
\newlabel{fig:vertical_edge}{{7b}{30}{$3 \times 3$ vertical edge detecting kernel applied. \relax }{figure.caption.9}{}}
\newlabel{sub@fig:vertical_edge}{{b}{30}{$3 \times 3$ vertical edge detecting kernel applied. \relax }{figure.caption.9}{}}
\newlabel{fig:edge_detection}{{\caption@xref {fig:edge_detection}{ on input line 1224}}{30}{Edge Detection}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Edge detecting kernels applied to image. \relax }}{30}{figure.caption.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Convolutional Layers}{31}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Pooling Layers}{33}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Backpropagation}{33}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Implementation from Scratch}{33}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Total Architecture with PyTorch}{33}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Recurrent Neural Networks}{34}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Unidirectional RNNs}{35}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Loss Functions}{36}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Backpropagation Through Time}{37}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Stacked Unidirectional RNNs}{38}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Bidirectional RNNs}{39}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}PyTorch Implementation}{39}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Long Short Term Memory (LSTMs)}{39}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Multilayer LSTMs}{42}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Gated Recurrent Units}{43}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Encoder-Decoder Models}{43}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Sequence to Sequence}{44}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Decoding Schemes}{46}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Autoencoders}{48}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Image Captioning}{48}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Attention Models}{49}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Seq2Seq with Attention}{49}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Self-Attention}{51}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Transformers}{51}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Generative Models}{51}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Variational Autoencoders}{51}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Generative Adversarial Networks (GANs)}{51}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Deep Reinforcement Learning}{51}{section.10}\protected@file@percent }
\newlabel{LastPage}{{}{51}{}{page.51}{}}
\xdef\lastpage@lastpage{51}
\xdef\lastpage@lastpageHy{51}
\gdef \@abspage@last{51}

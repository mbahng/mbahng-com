\babel@toc {english}{}\relax 
\contentsline {section}{\numberline {1}Multi-Layered Perceptrons}{3}{section.1}%
\contentsline {subsection}{\numberline {1.1}Generalized Linear Models}{3}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Architecture}{4}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Universal Approximation Theorem}{7}{subsection.1.3}%
\contentsline {subsection}{\numberline {1.4}Forward and Back Propagation}{8}{subsection.1.4}%
\contentsline {subsubsection}{\numberline {1.4.1}Summary}{13}{subsubsection.1.4.1}%
\contentsline {subsection}{\numberline {1.5}Neural Net from Scratch}{13}{subsection.1.5}%
\contentsline {subsection}{\numberline {1.6}Quick Start to PyTorch}{17}{subsection.1.6}%
\contentsline {subsubsection}{\numberline {1.6.1}Datasets and Features/Label Transformations}{17}{subsubsection.1.6.1}%
\contentsline {subsubsection}{\numberline {1.6.2}Building a Neural Net}{19}{subsubsection.1.6.2}%
\contentsline {subsubsection}{\numberline {1.6.3}Automatic Differentiation}{21}{subsubsection.1.6.3}%
\contentsline {subsubsection}{\numberline {1.6.4}Optimizing Model Parameters}{21}{subsubsection.1.6.4}%
\contentsline {section}{\numberline {2}Training Stability}{23}{section.2}%
\contentsline {subsection}{\numberline {2.1}Weight Initialization}{23}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Optimizers}{23}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Vanishing Gradient Problem}{23}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}Activation Functions}{23}{subsubsection.2.3.1}%
\contentsline {subsubsection}{\numberline {2.3.2}Residual Connections}{24}{subsubsection.2.3.2}%
\contentsline {subsection}{\numberline {2.4}Exploding Gradient Problem}{25}{subsection.2.4}%
\contentsline {subsubsection}{\numberline {2.4.1}Normalization Layers}{25}{subsubsection.2.4.1}%
\contentsline {subsubsection}{\numberline {2.4.2}Max Norm Regularization}{26}{subsubsection.2.4.2}%
\contentsline {section}{\numberline {3}Regularization}{26}{section.3}%
\contentsline {subsection}{\numberline {3.1}Early Stopping}{26}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}L1 and L2 Regularization}{26}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Dropout}{26}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Data Augmentation}{28}{subsection.3.4}%
\contentsline {subsection}{\numberline {3.5}Network Pruning}{28}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}Summary}{28}{subsection.3.6}%
\contentsline {section}{\numberline {4}Convolutional Neural Networks}{29}{section.4}%
\contentsline {subsection}{\numberline {4.1}Kernels}{29}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Convolutional Layers}{32}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Pooling Layers}{34}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Backpropagation}{34}{subsection.4.4}%
\contentsline {subsection}{\numberline {4.5}Implementation from Scratch}{34}{subsection.4.5}%
\contentsline {subsection}{\numberline {4.6}Total Architecture with PyTorch}{34}{subsection.4.6}%
\contentsline {subsection}{\numberline {4.7}Object Detection}{35}{subsection.4.7}%
\contentsline {subsubsection}{\numberline {4.7.1}Region-Based CNN}{36}{subsubsection.4.7.1}%
\contentsline {subsubsection}{\numberline {4.7.2}Fast RCNN}{37}{subsubsection.4.7.2}%
\contentsline {subsubsection}{\numberline {4.7.3}Faster RCNN}{37}{subsubsection.4.7.3}%
\contentsline {section}{\numberline {5}Generative Models 1}{37}{section.5}%
\contentsline {subsection}{\numberline {5.1}Naive Bayes and LDA}{37}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Graphical Models}{37}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Linear Factor Models and Factor Analysis}{37}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Principal Component Analysis}{37}{subsection.5.4}%
\contentsline {section}{\numberline {6}Generative Models 2}{37}{section.6}%
\contentsline {subsection}{\numberline {6.1}Restricted Boltzmann Machines}{37}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Deep Belief Networks}{37}{subsection.6.2}%
\contentsline {section}{\numberline {7}Generative Models 3}{37}{section.7}%
\contentsline {subsection}{\numberline {7.1}Autoencoders}{37}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Variational Autoencoders}{37}{subsection.7.2}%
\contentsline {subsection}{\numberline {7.3}Importance Weighted Autoencoders}{37}{subsection.7.3}%
\contentsline {subsection}{\numberline {7.4}Conditional VAEs}{37}{subsection.7.4}%
\contentsline {section}{\numberline {8}Generative Models 4}{37}{section.8}%
\contentsline {subsection}{\numberline {8.1}Generative Adversarial Networks}{37}{subsection.8.1}%
\contentsline {section}{\numberline {9}Recurrent Neural Networks}{37}{section.9}%
\contentsline {subsection}{\numberline {9.1}Unidirectional RNNs}{38}{subsection.9.1}%
\contentsline {subsubsection}{\numberline {9.1.1}Loss Functions}{39}{subsubsection.9.1.1}%
\contentsline {subsubsection}{\numberline {9.1.2}Backpropagation Through Time}{40}{subsubsection.9.1.2}%
\contentsline {subsubsection}{\numberline {9.1.3}Stacked Unidirectional RNNs}{41}{subsubsection.9.1.3}%
\contentsline {subsection}{\numberline {9.2}Bidirectional RNNs}{42}{subsection.9.2}%
\contentsline {subsubsection}{\numberline {9.2.1}PyTorch Implementation}{42}{subsubsection.9.2.1}%
\contentsline {subsection}{\numberline {9.3}Long Short Term Memory (LSTMs)}{42}{subsection.9.3}%
\contentsline {subsubsection}{\numberline {9.3.1}Multilayer LSTMs}{45}{subsubsection.9.3.1}%
\contentsline {subsection}{\numberline {9.4}Gated Recurrent Units}{46}{subsection.9.4}%
\contentsline {section}{\numberline {10}Encoder-Decoder Models}{46}{section.10}%
\contentsline {subsection}{\numberline {10.1}Sequence to Sequence}{47}{subsection.10.1}%
\contentsline {subsubsection}{\numberline {10.1.1}Decoding Schemes}{49}{subsubsection.10.1.1}%
\contentsline {subsection}{\numberline {10.2}Autoencoders}{51}{subsection.10.2}%
\contentsline {subsection}{\numberline {10.3}Image Captioning}{51}{subsection.10.3}%
\contentsline {section}{\numberline {11}Attention Models}{52}{section.11}%
\contentsline {subsection}{\numberline {11.1}Seq2Seq with Attention}{52}{subsection.11.1}%
\contentsline {subsection}{\numberline {11.2}Self-Attention}{54}{subsection.11.2}%
\contentsline {section}{\numberline {12}Transformers}{54}{section.12}%
\contentsline {section}{\numberline {13}Generative Models}{54}{section.13}%
\contentsline {subsection}{\numberline {13.1}Variational Autoencoders}{54}{subsection.13.1}%
\contentsline {subsection}{\numberline {13.2}Generative Adversarial Networks (GANs)}{54}{subsection.13.2}%
\contentsline {section}{\numberline {14}Deep Reinforcement Learning}{54}{section.14}%

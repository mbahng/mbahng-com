\babel@toc {english}{}\relax 
\contentsline {section}{\numberline {1}Multi-Layered Perceptrons}{4}{section.1}%
\contentsline {subsection}{\numberline {1.1}Generalized Linear Models}{4}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Architecture}{5}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Universal Approximation Theorem}{8}{subsection.1.3}%
\contentsline {subsection}{\numberline {1.4}Forward and Back Propagation}{9}{subsection.1.4}%
\contentsline {subsubsection}{\numberline {1.4.1}Summary}{14}{subsubsection.1.4.1}%
\contentsline {subsection}{\numberline {1.5}Neural Net from Scratch}{14}{subsection.1.5}%
\contentsline {subsection}{\numberline {1.6}Quick Start to PyTorch}{18}{subsection.1.6}%
\contentsline {subsubsection}{\numberline {1.6.1}Datasets and Features/Label Transformations}{18}{subsubsection.1.6.1}%
\contentsline {subsubsection}{\numberline {1.6.2}Building a Neural Net}{20}{subsubsection.1.6.2}%
\contentsline {subsubsection}{\numberline {1.6.3}Automatic Differentiation}{22}{subsubsection.1.6.3}%
\contentsline {subsubsection}{\numberline {1.6.4}Optimizing Model Parameters}{22}{subsubsection.1.6.4}%
\contentsline {section}{\numberline {2}Training Stability}{24}{section.2}%
\contentsline {subsection}{\numberline {2.1}Weight Initialization}{24}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Optimizers}{24}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Vanishing Gradient Problem}{24}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}Activation Functions}{24}{subsubsection.2.3.1}%
\contentsline {subsubsection}{\numberline {2.3.2}Residual Connections}{25}{subsubsection.2.3.2}%
\contentsline {subsection}{\numberline {2.4}Exploding Gradient Problem}{26}{subsection.2.4}%
\contentsline {subsubsection}{\numberline {2.4.1}Normalization Layers}{26}{subsubsection.2.4.1}%
\contentsline {subsubsection}{\numberline {2.4.2}Max Norm Regularization}{27}{subsubsection.2.4.2}%
\contentsline {section}{\numberline {3}Regularization}{27}{section.3}%
\contentsline {subsection}{\numberline {3.1}Early Stopping}{27}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}L1 and L2 Regularization}{27}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Dropout}{27}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Data Augmentation}{29}{subsection.3.4}%
\contentsline {subsection}{\numberline {3.5}Network Pruning}{29}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}Summary}{29}{subsection.3.6}%
\contentsline {section}{\numberline {4}Convolutional Neural Networks}{30}{section.4}%
\contentsline {subsection}{\numberline {4.1}Kernels}{30}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Architecture}{33}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Convolutional Layers}{34}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Pooling Layers}{35}{subsection.4.4}%
\contentsline {subsection}{\numberline {4.5}Backpropagation}{35}{subsection.4.5}%
\contentsline {subsection}{\numberline {4.6}Total Architecture with PyTorch}{35}{subsection.4.6}%
\contentsline {subsection}{\numberline {4.7}Object Detection}{36}{subsection.4.7}%
\contentsline {subsubsection}{\numberline {4.7.1}Region-Based CNN}{37}{subsubsection.4.7.1}%
\contentsline {subsubsection}{\numberline {4.7.2}Fast RCNN}{39}{subsubsection.4.7.2}%
\contentsline {subsubsection}{\numberline {4.7.3}Faster RCNN}{40}{subsubsection.4.7.3}%
\contentsline {subsubsection}{\numberline {4.7.4}Measuring Performance}{42}{subsubsection.4.7.4}%
\contentsline {section}{\numberline {5}Linear Factor Models}{42}{section.5}%
\contentsline {subsection}{\numberline {5.1}Factor Analysis and Probabilistic PCA}{43}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Independent Component Analysis}{44}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Slow Feature Analysis}{45}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Sparse Coding}{46}{subsection.5.4}%
\contentsline {section}{\numberline {6}Autoencoders}{47}{section.6}%
\contentsline {section}{\numberline {7}Boltzmann Machines}{49}{section.7}%
\contentsline {subsection}{\numberline {7.1}Graphical Models}{49}{subsection.7.1}%
\contentsline {subsubsection}{\numberline {7.1.1}Directed Graphical Models}{49}{subsubsection.7.1.1}%
\contentsline {subsubsection}{\numberline {7.1.2}Undirected Graphical Models}{53}{subsubsection.7.1.2}%
\contentsline {subsection}{\numberline {7.2}Boltzmann Machines}{55}{subsection.7.2}%
\contentsline {subsubsection}{\numberline {7.2.1}Restricted Boltzmann Machines}{57}{subsubsection.7.2.1}%
\contentsline {subsubsection}{\numberline {7.2.2}Gaussian Bernoulli RBMs}{61}{subsubsection.7.2.2}%
\contentsline {section}{\numberline {8}Variational Autoencoders}{61}{section.8}%
\contentsline {subsection}{\numberline {8.1}Deep Latent Variable Models}{62}{subsection.8.1}%
\contentsline {subsubsection}{\numberline {8.1.1}Reparameterization Trick}{64}{subsubsection.8.1.1}%
\contentsline {subsection}{\numberline {8.2}Variational Autoencoders}{64}{subsection.8.2}%
\contentsline {subsection}{\numberline {8.3}Conditional VAEs}{65}{subsection.8.3}%
\contentsline {subsection}{\numberline {8.4}Importance Weighted Autoencoders}{65}{subsection.8.4}%
\contentsline {section}{\numberline {9}Generative Adversarial Networks}{65}{section.9}%
\contentsline {section}{\numberline {10}Recurrent Neural Networks}{65}{section.10}%
\contentsline {subsection}{\numberline {10.1}Tmp}{65}{subsection.10.1}%
\contentsline {subsection}{\numberline {10.2}Perm}{65}{subsection.10.2}%
\contentsline {subsection}{\numberline {10.3}Unidirectional RNNs}{66}{subsection.10.3}%
\contentsline {subsubsection}{\numberline {10.3.1}Loss Functions}{67}{subsubsection.10.3.1}%
\contentsline {subsubsection}{\numberline {10.3.2}Backpropagation Through Time}{68}{subsubsection.10.3.2}%
\contentsline {subsubsection}{\numberline {10.3.3}Stacked Unidirectional RNNs}{69}{subsubsection.10.3.3}%
\contentsline {subsection}{\numberline {10.4}Bidirectional RNNs}{70}{subsection.10.4}%
\contentsline {subsubsection}{\numberline {10.4.1}PyTorch Implementation}{70}{subsubsection.10.4.1}%
\contentsline {subsection}{\numberline {10.5}Long Short Term Memory (LSTMs)}{70}{subsection.10.5}%
\contentsline {subsubsection}{\numberline {10.5.1}Multilayer LSTMs}{73}{subsubsection.10.5.1}%
\contentsline {subsection}{\numberline {10.6}Gated Recurrent Units}{74}{subsection.10.6}%
\contentsline {section}{\numberline {11}Encoder-Decoder Models}{74}{section.11}%
\contentsline {subsection}{\numberline {11.1}Sequence to Sequence}{75}{subsection.11.1}%
\contentsline {subsubsection}{\numberline {11.1.1}Decoding Schemes}{77}{subsubsection.11.1.1}%
\contentsline {subsection}{\numberline {11.2}Autoencoders}{79}{subsection.11.2}%
\contentsline {subsection}{\numberline {11.3}Image Captioning}{79}{subsection.11.3}%
\contentsline {section}{\numberline {12}Attention Models}{80}{section.12}%
\contentsline {subsection}{\numberline {12.1}Seq2Seq with Attention}{80}{subsection.12.1}%
\contentsline {subsection}{\numberline {12.2}Self-Attention}{82}{subsection.12.2}%
\contentsline {section}{\numberline {13}Transformers}{82}{section.13}%
\contentsline {section}{\numberline {14}Generative Models}{82}{section.14}%
\contentsline {subsection}{\numberline {14.1}Variational Autoencoders}{82}{subsection.14.1}%
\contentsline {subsection}{\numberline {14.2}Generative Adversarial Networks (GANs)}{82}{subsection.14.2}%
\contentsline {section}{\numberline {15}Deep Reinforcement Learning}{82}{section.15}%

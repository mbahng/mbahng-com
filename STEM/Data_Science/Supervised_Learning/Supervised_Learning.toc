\babel@toc {english}{}\relax 
\contentsline {section}{\numberline {1}Overview}{3}{section.1}%
\contentsline {subsection}{\numberline {1.1}Types of Models}{4}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Loss Functions}{5}{subsection.1.2}%
\contentsline {subsubsection}{\numberline {1.2.1}Maximum Likelihood Estimation}{6}{subsubsection.1.2.1}%
\contentsline {subsubsection}{\numberline {1.2.2}Optimization}{7}{subsubsection.1.2.2}%
\contentsline {subsubsection}{\numberline {1.2.3}Generalization Error and Statistical Learning Theory}{7}{subsubsection.1.2.3}%
\contentsline {subsubsection}{\numberline {1.2.4}Bias Variance Noise Decomposition of MSE Loss}{8}{subsubsection.1.2.4}%
\contentsline {subsection}{\numberline {1.3}Model Selection}{9}{subsection.1.3}%
\contentsline {subsubsection}{\numberline {1.3.1}Model Complexity}{10}{subsubsection.1.3.1}%
\contentsline {subsubsection}{\numberline {1.3.2}Train Test Split and Cross Validation}{11}{subsubsection.1.3.2}%
\contentsline {subsubsection}{\numberline {1.3.3}Regularization}{12}{subsubsection.1.3.3}%
\contentsline {subsubsection}{\numberline {1.3.4}Ensemble Learning}{14}{subsubsection.1.3.4}%
\contentsline {subsection}{\numberline {1.4}Preprocessing Data}{14}{subsection.1.4}%
\contentsline {subsubsection}{\numberline {1.4.1}Feature Extraction}{14}{subsubsection.1.4.1}%
\contentsline {subsubsection}{\numberline {1.4.2}Standardizing Data}{18}{subsubsection.1.4.2}%
\contentsline {subsection}{\numberline {1.5}Information Theory}{19}{subsection.1.5}%
\contentsline {subsubsection}{\numberline {1.5.1}Kullback Leibler Divergence}{21}{subsubsection.1.5.1}%
\contentsline {subsubsection}{\numberline {1.5.2}Mutual Information}{21}{subsubsection.1.5.2}%
\contentsline {section}{\numberline {2}Linear Regression}{22}{section.2}%
\contentsline {subsection}{\numberline {2.1}Construction}{22}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Least Squares}{23}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Likelihood Estimation}{24}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Simple Linear Regression}{25}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Significance Tests}{26}{subsection.2.5}%
\contentsline {subsubsection}{\numberline {2.5.1}T Test}{26}{subsubsection.2.5.1}%
\contentsline {subsubsection}{\numberline {2.5.2}F Test}{28}{subsubsection.2.5.2}%
\contentsline {section}{\numberline {3}Perceptron}{28}{section.3}%
\contentsline {section}{\numberline {4}Logistic Regression}{30}{section.4}%
\contentsline {subsection}{\numberline {4.1}Likelihood Estimation}{31}{subsection.4.1}%
\contentsline {section}{\numberline {5}Softmax Regression}{31}{section.5}%
\contentsline {subsection}{\numberline {5.1}Likelihood Estimation}{33}{subsection.5.1}%
\contentsline {section}{\numberline {6}Generalized Linear Models}{34}{section.6}%
\contentsline {subsection}{\numberline {6.1}Exponential Family}{37}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Canonical Exponential Family}{38}{subsubsection.6.1.1}%
\contentsline {subsection}{\numberline {6.2}Link Functions}{40}{subsection.6.2}%
\contentsline {subsubsection}{\numberline {6.2.1}Canonical Link Functions}{41}{subsubsection.6.2.1}%
\contentsline {subsection}{\numberline {6.3}Likelihood Optimization}{42}{subsection.6.3}%
\contentsline {section}{\numberline {7}Discriminant Analysis}{43}{section.7}%
\contentsline {subsubsection}{\numberline {7.0.1}Fisher Discriminant Analysis}{43}{subsubsection.7.0.1}%
\contentsline {subsubsection}{\numberline {7.0.2}Gaussian Discriminant Analysis (Generative Model)}{43}{subsubsection.7.0.2}%
\contentsline {section}{\numberline {8}K Nearest Neighbors}{44}{section.8}%
\contentsline {section}{\numberline {9}Decision Trees}{46}{section.9}%
\contentsline {subsection}{\numberline {9.1}Splitting Criteria}{47}{subsection.9.1}%
\contentsline {subsubsection}{\numberline {9.1.1}Misclassification Error}{47}{subsubsection.9.1.1}%
\contentsline {subsubsection}{\numberline {9.1.2}Information Gain}{47}{subsubsection.9.1.2}%
\contentsline {subsubsection}{\numberline {9.1.3}Gini Index}{49}{subsubsection.9.1.3}%
\contentsline {subsection}{\numberline {9.2}Regularization}{50}{subsection.9.2}%
\contentsline {subsection}{\numberline {9.3}Splitting on Continuous Values}{51}{subsection.9.3}%
\contentsline {subsection}{\numberline {9.4}Random Forests}{51}{subsection.9.4}%
\contentsline {subsection}{\numberline {9.5}Boosting}{51}{subsection.9.5}%
\contentsline {section}{\numberline {10}Kernel Methods}{51}{section.10}%
\contentsline {section}{\numberline {11}Support Vector Machines}{52}{section.11}%
\contentsline {subsubsection}{\numberline {11.0.1}Functional and Geometric Margins}{54}{subsubsection.11.0.1}%
\contentsline {subsection}{\numberline {11.1}Lagrange Duality}{54}{subsection.11.1}%
\contentsline {subsection}{\numberline {11.2}Nonseparable Case}{55}{subsection.11.2}%
\contentsline {section}{\numberline {12}Naive Bayes}{55}{section.12}%
\contentsline {section}{\numberline {13}Introduction}{55}{section.13}%
\contentsline {subsection}{\numberline {13.1}Bayesian Probability}{55}{subsection.13.1}%
\contentsline {subsection}{\numberline {13.2}Density Estimation}{56}{subsection.13.2}%
\contentsline {subsubsection}{\numberline {13.2.1}Frequentist Approach}{56}{subsubsection.13.2.1}%
\contentsline {subsubsection}{\numberline {13.2.2}Bayesian Approach}{57}{subsubsection.13.2.2}%
\contentsline {subsection}{\numberline {13.3}Regression with Regularization}{57}{subsection.13.3}%
\contentsline {subsubsection}{\numberline {13.3.1}Frequentist's Maximum Likelihood Approach}{57}{subsubsection.13.3.1}%
\contentsline {subsubsection}{\numberline {13.3.2}Bayesian Approach}{58}{subsubsection.13.3.2}%

\section{Rings} 

  We have extensively talked about groups, and now we look at an algebraic structure called a ring that has two operations. As we introduce rings, we will use the integers as the primary structure to demonstrate our theorems, along with the ring of continuous functions and the ring of matrices. 

  \begin{definition}[Ring]
    A \textbf{ring} is a set $(R, +, \times)$ equipped with two operations, called addition and multiplication. It has properties: 
    \begin{enumerate}
      \item $R$ is an abelian group with respect to $+$, where we denote the additive identity as $0$ and the additive inverse of $x$ as $-x$. 
      \item $R$ is a monoid with respect to $\times$, where we denote the multiplicative identity as $1$, also known as the \textbf{unity}. 
      \item $\times$ is both left and right distributive with respect to addition $+$
      \begin{align}
        a \times (b + c) & = a\times b + a\times c \\ 
        (a + b) \times c & = a\times c + b\times c 
      \end{align}
      for all $a, b, c \in \mathbb{R}$. 
    \end{enumerate} 
    If $\times$ is commutative, $R$ is called a \textbf{commutative ring}. 
  \end{definition}

  In fact, in some cases associativity (in multiplication) or the existence of the multiplicative identity is not even assumed, though we will do it here.\footnote{If a multiplicative identity is not assumed, then this is called an \textit{rng}, or a \textit{rung}.} It turns out that the existence of a multiplicative inverse, also called a \textit{unity}, forces addition to be abelian. Try computing the product $(1 + 1)(a + b)$ in two different ways. 
  \begin{align}
    (1 + 1)(a + b) & = 1(a + b) + 1(a + b) = a + b + a + b \\
    (1 + 1)(a + b) & = (1 + 1)a + (1 + 1)b = a + a + b + b
  \end{align}
  and so from the group properties, we necessarily have $b + a = a + b$. 

  \begin{figure}[H]
    \centering 
    \begin{tikzpicture}[
      node distance=2cm,
      box/.style={
          text width=5cm,
          align=center
      }
      ]
      % Nodes for ring types
      \node[box] (rings) at (0,0) {Rings};
      \node[box] (comm) at (-2,-1) {Commutative Rings};
      \node[box] (domains) at (2,-1) {Domains};
      \node[box] (int) at (-2,-2) {Integral Domains};
      \node[box] (ufd) at (-2,-3) {UFDs}; % Added UFD between ID and PID
      \node[box] (divring) at (2,-5) {Division Rings};
      \node[box] (pid) at (-2,-4) {PIDs}; % Moved PID down
      \node[box] (euc) at (-2,-5) {Euclidean Domains}; % Moved ED down
      \node[box] (fields) at (0,-6) {Fields}; % Moved Fields down
      
      % Left path arrows
      \draw[->] (rings) -- (comm);
      \draw[->] (comm) -- (int);
      \draw[->] (int) -- (ufd); % New arrow to UFD
      \draw[->] (ufd) -- (pid); % New arrow from UFD to PID
      \draw[->] (pid) -- (euc);
      \draw[->] (euc) -- (fields);
      \draw[->] (divring) -- (fields);
      
      % Right path arrows
      \draw[->] (rings) -- (domains);
      \draw[->] (domains) -- (int);
      \draw[->] (domains) -- (divring);
    \end{tikzpicture}
    \caption{Basic hierarchy of rings with UFDs included.} 
    \label{fig:ring_hierarchy}
  \end{figure}

  Since a ring is a group with respect to addition, we know from \ref{thm:unique_add_inverse} that additive inverses are unique. However, we can say a little more with rings because of the distributive property. 

  \begin{lemma}[Additive Inverses] 
    Let $R$ be a ring. Then, for all $a, b \in R$, 
    \begin{enumerate}
      \item $0a = a0 = 0$. 
      \item $(-a)b = a(-b) = -(ab)$. 
      \item $(-a)(-b) = ab$. 
      \item The identity $1$ is unique and $-a = (-1)a$. 
    \end{enumerate}
  \end{lemma}
  \begin{proof}
    We can see that 
    \begin{align}
      -1 + 1 = 0 & \implies (-1 + 1) \times a = 0 \times a \\
    \end{align}
    and therefore by definition $-1 \times a$ must be the additive inverse. 
  \end{proof} 

  We will provide some examples of rings, though we have not properly defined some of them yet. We have only properly defined the power set ring and the integer ring in set theory. As for the rest, I hope the reader is familiar enough with these materials to at least recognize that they are rings. 

  \begin{example}[Power Set]
    Given a set $X$, $(2^X, \bigtriangleup, \cap)$ is a commutative associative ring with respect to the operations of symmetric difference $M \bigtriangleup N \coloneqq (M \setminus N) \cup (N \setminus M)$ and intersection. The additive identity is $\emptyset$ and the multiplicative identity is $X$. We can clearly see that both operations are commutative and $\cap$ is associative. 
    \begin{align*}
      M \bigtriangleup N & = (M \setminus N) \cup (N \setminus M) \equiv N \bigtriangleup M \\
      M \cap N & = N \cap M \\
      M \cap N \cap P & = (M \cap N) \cap P = M \cap (N \cap P)
    \end{align*}
  \end{example}

  \begin{example}[Number Systems]
    $(\mathbb{Z}, +, \times)$, $(\mathbb{Q}, +, \times)$, $(\mathbb{R}, +, \times)$, $(\mathbb{C}, +, \times)$ are all commutative rings, with additive and multiplicative identities $0$ and $1$. 
  \end{example}

  \begin{example}[Matrix Rings]
    The set of matrices $\mathbb{R}^{n \times n}$\footnote{really over any field and even more generally a ring $R$} forms a noncommutative ring under matrix addition $+$ and multiplication $\times$. It has the additive and multiplicative identities $0$ and $I_{n}$. This forms a non-commutative ring for $n > 1$, even when $R$ is commutative.
  \end{example}

  \begin{example}[Polynomials]
    The set of all polynomials over the reals are a ring. 
  \end{example}

  \begin{example}[Continuous Functions]
    The set of all continuous functions $f: \mathbb{R} \rightarrow \mathbb{R}$ is a ring under point-wise addition and multiplication. 
  \end{example}

  Next, just like how we did for groups, we can talk about subrings. 

  \begin{definition}[Subring]
    Given ring $(R, +, \times)$ a \textbf{subring} $(S, +, \times)$ is a ring such that $S \subset R$. $S$ is called a \textbf{proper subring} if $S \subsetneq R$. 
  \end{definition}

  \begin{example}[Quadratic Field]
    Let $D \in \mathbb{Q}$ be a square-free rational number (as in $D$ cannot be expressed as the perfect square of another rational). Now let us consider the set 
    \begin{equation}
      \mathbb{Q} (\sqrt{D}) \coloneqq \{a + b \sqrt{D} \mid a, b \in \mathbb{Q} \}
    \end{equation}
    equipped with component-wise addition and multiplication where $\sqrt{D}^2 = D$ and the rational commute with $\sqrt{D}$. This is indeed a commutative subring of $\mathbb{R}$. 
  \end{example}

  \begin{example}[Gaussian Integers]
    The \textbf{Gaussian integers} is the set 
    \begin{equation}
      \mathbb{Z}[i] \coloneqq \{a + bi \mid a, b \in \mathbb{Z} \} \subset \mathbb{C}
    \end{equation}
    equipped with component-wise addition and multiplication where $i^2 = 1$ and reals commute with $i$. This is indeed a commutative subring of $\mathbb{C}$. 
  \end{example}

  \begin{theorem}[Intersections of Subrings is a Subring]
    If $S_1, S_2$ are subrings of $R$, then $S_1 \cap S_2$ is a subring. 
  \end{theorem}

  Finally, we will mention a product ring. 

  \begin{definition}[Direct Product of Rings]
    Given rings $(R, +_R, \times_R)$ and $(S, +_S, \times_S)$, the direct product of the rings is the set $R \times S$ with the operations 
    \begin{enumerate}
      \item $(r_1, s_1) + (r_2, s_2) \coloneqq (r_1 +_R r_2, s_1 +_S s_2)$. 
      \item $(r_1, s_1) \times (r_2, s_2) \coloneqq (r_1 \times_R r_2, s_1 \times_S s_2)$. 
    \end{enumerate}
  \end{definition}
  \begin{proof}
    The proof is standard. 
  \end{proof}

\subsection{Ring Homomorphisms}

  So far, we have talked about many properties of rings but have not thoroughly gone over their classification. This is what we will do in this section, just like how we have classified groups. It turns out that classifying rings is significantly harder to do so, so we will talk about some low-order finite rings and provide some examples of isomorphisms between more complex rings. 

  \begin{definition}[Ring Homomorphism, Isomorphism]
    A \textbf{ring homomorphism} $f: R \rightarrow S$ is a function that satisfies for all $a, b \in R$
    \begin{enumerate}
      \item $f(a + b) = f(a) + f(b)$
      \item $f(ab) = f(a) f(b)$ 
      \item $f(1_R) = 1_S$\footnote{The reason we need this third is that while $f$ is a group homomorphism with respect to $+$, it automatically follows that $f(0) = 0$. However $f$ is only a monoid homomorphism w.r.t. $\times$, and so we need this extra constraint. }
    \end{enumerate}
    for all $a, b \in R$.\footnote{Note that the first is equivalent to it being a group homomorphism between $(R, +)$ and $(S, +)$. The second property may look like it is a group homomorphism between $(R, \times)$ and $(S, \times)$, but remember that neither are groups and it just states that closure distributes. Combined with the fact that the multiplicative identity matches, $f$ is really a homomorphism of \textit{monoids}. } Furthermore, 
    \begin{enumerate}
      \item A \textbf{ring isomorphism} is a bijective ring homomorphism, and we call rings $R$ and $S$ isomorphic, denoted $R \simeq S$ if there exists an isomorphism between them. 
      \item A \textbf{ring endomorphism} is a ring homomorphism onto itself. 
      \item A \textbf{ring automorphism} is an isomorphism from a ring to itself. 
    \end{enumerate}
  \end{definition} 

  \begin{example}[Homomorphisms of Rings]
    We provide some simple examples of ring homomorphisms. 
    \begin{enumerate}
      \item The identity map $\iota : R \to R$ is a ring automorphism. 
      \item If $R \subset S$ as rings, then the canonical injection map $\iota: R \to S$ is a ring homomorphism. 
      \item Complex conjugation $z \in \mathbb{C} \mapsto \bar{z} \in \mathbb{C}$ is a ring automorphism. 
      \item Differentiation is a ring automorphism over the polynomial ring $\mathbb{R}[x]$. 
    \end{enumerate}
  \end{example} 

  \begin{definition}[Kernel]
    The \textbf{kernel} of a ring homomorphism $f: R \rightarrow S$ is the preimage of $0 \in S$.\footnote{Note that this is the additive identity, not the multiplicative identity. We must specify which identity, unlike a group which has just one identity.}
  \end{definition}

  \begin{lemma}[Images and Kernels of Ring Homomorphisms]
    If $f: R \rightarrow S$ is a ring homomorphism, then 
    \begin{enumerate}
      \item $\im{f}$ is a subring of $S$. 
      \item $f$ is injective iff $\ker{f} = \{0\}$. 
    \end{enumerate}
  \end{lemma}
  \begin{proof}
    For the first claim, let $x, y, z \in \im{f}$. Then $x = f(a), y = f(b), z = f(c)$ for some $a, b \in R$. 
    \begin{enumerate}
      \item \textit{Closed under Addition}. $x + y = f(a) + f(b) = f(a + b) \in \im{f}$. 
      \item \textit{Associative under Addition}. $(x + y) + z = f(a + b) + f(c) = f((a + b) + c) = f(a + (b + c)) = f(a) + f(b + c) = x + (y + z)$
      \item \textit{Additive Identity}. $f(0) = 0$
      \item \textit{Additive Inverses}. We claim that $x^{-1} = f(a)^{-1} = f(a^{-1})$. Indeed, we have $f(a) f(a^{-1}) = f(a a^{-1}) = f(1) = 1$. 
      \item \textit{Closed under Multiplication}. $xy = f(a) f(b) = f(ab) \in \im{f}$. 
      \item \textit{Multiplicative Identity}. $f(1) = 1$. 
    \end{enumerate}
    For the second claim, we prove bidirectionally. 
    \begin{enumerate}
      \item $(\rightarrow)$. Let $\ker{f} \neq \{0\}$ and call its nonzero element $k$. Then, $f(a + k) = f(a) + f(k) = f(a) + 0 = f(a)$, and so $f(a) = f(a + k)$, which means $f$ is not injective. 
      \item $(\leftarrow)$. Assume that $f$ is not injective. Then there exists $a, b \in R$ s.t. $f(a) = f(b)$. This means that $0 = f(a) - f(b) = f(a - b)$, and so $a - b \in \ker{f}$. 
    \end{enumerate}
  \end{proof}

  Note that $\ker{f}$ is \textit{not} a subring, and we can quickly verify this by noticing that the identity element does not necessarily have to be in the kernel. However, we will see later that this is a specific instance of a more general structure called an \textit{ideal}. 

  \begin{theorem}[Compositions of Ring Homomorphisms]
    Compositions of ring homomorphisms are ring homomorphisms. 
  \end{theorem} 
  \begin{proof}
    Let $R \xrightarrow{f} S \xrightarrow{g} T$ be two ring homomorphisms. We can see that 
    \begin{enumerate}
      \item $(g \circ f)(a + b) = g( f(a) + f(b)) = g(f(a)) + g(f(b))$. 
      \item $g(f(ab)) = g(f(a) f(b)) = g(f(a)) + g(f(b))$ 
      \item $g(f(1_R)) = g(1_S) = 1_T$
    \end{enumerate}
  \end{proof}

  Now let's focus a bit more on ring isomorphisms. The following should be intuitive. 

  \begin{lemma}[Inverse of Ring Isomorphism is an Isomorphism]
    If $f: R \to S$ is a ring isomorphism, then $f^{-1}$ is a ring isomorphism. 
  \end{lemma} 
  \begin{proof}
    Since $f$ is a bijection, $f^{-1}$ is well defined and is a bijection. Now let $x, y \in S$, which implies that $x = f(a), y = f(b)$ for a unique $a, b \in R$. Now we see that $f^{-1}$ satisfies the 3 properties of a ring homomorphism. 
    \begin{enumerate}
      \item $f^{-1} (x + y) = f^{-1} (f(a) + f(b)) = f^{-1}(f(a + b)) = a + b = f^{-1}(a) + f^{-1} (b)$. 
      \item $f^{-1} (x y) = f^{-1} (f(a) f(b)) = f^{-1}(f(a b)) = a b = f^{-1}(a) f^{-1} (b)$. 
      \item $f^{-1}(1_S) = 1_R$. 
    \end{enumerate}
    Therefore, as a bijective ring homomorphism $f^{-1}$ is also a ring isomorphism. 
  \end{proof}

\subsection{Characteristics}

  Note that given a ring $R$, we can pay attention to the subring $\langle 1 \rangle$. This must either be isomorphic to $\mathbb{Z}$ or $\mathbb{Z}_n$, so we can think of it being embedded in $R$. 
  
  \begin{theorem}[Integer Ring Exists in Any Ring]
    For every ring $R$, there exists a unique ring homomorphism $f: \mathbb{Z} \to R$. 
  \end{theorem}
  \begin{proof}
    We know that $f(1_{\mathbb{Z}}) = 1_R$, and so for $n > 0$, 
    \begin{align}
      f(n_{\mathbb{Z}}) & = f(1_{\mathbb{Z}} + \ldots + 1_{\mathbb{Z}}) \\
                        & = f(1_{\mathbb{Z}}) + \ldots + f(1_{\mathbb{Z}}) \\
                        & = 1_R + \ldots + 1_R \\
                        & = n_R
    \end{align} 
    Similarly, we have 
    \begin{align}
      f(-n_{\mathbb{Z}}) & = f(-1_{\mathbb{Z}} - \ldots - 1_{\mathbb{Z}}) \\
                         & = f(1_{\mathbb{Z}}) - \ldots - f(1_{\mathbb{Z}}) \\
                         & = -1_R - \ldots - 1_R \\
                         & = -n_R
    \end{align} 
    Since $\mathbb{Z}$ is a PID, $\ker{f}$---which is an ideal---must be principal, and so $\ker{f} = \langle m \rangle$ for some $m \in \mathbb{Z}$. 
  \end{proof} 

  Therefore, this motivates the following attribute of a ring, i.e. the smallest $\langle m \rangle$ that embeds (an injective homomorphism) into the ring. 

  \begin{definition}[Characteristic Number]
    The \textbf{characteristic} of ring $R$, denoted $\Char(R)$, is defined equivalently. 
    \begin{enumerate}
      \item It is the smallest number of times one must successively add the multiplicative identity $1$ to get the additive identity $0$. 
      \begin{equation}
        1 + 1 + ... + 1 = 0 
      \end{equation}
      If no such number $n$ exists, then $\Char(R) = 0$. 

    \item It is equal to $m$, where $\ker{f} = \langle m \rangle$ for the homomorphism defined above.\footnote{Note that $m$ always exists since $\mathbb{Z}$ is a PID.}
    \end{enumerate}
  \end{definition}

  Often, it is not obvious whether two given rings $R$ and $S$ are isomorphic. The characteristic number is preserved across ring isomorphisms and therefore is a good sanity check. 

  \begin{theorem}[Preservation of Characteristic Number in a Ring Homomorphism]
    $R \simeq S \implies \Char(R) = \Char(S)$. 
  \end{theorem}
  \begin{proof}

  \end{proof}

  However, the converse is not true! If so, we would have completely classified all rings just based on their characteristic number, and the study of rings would end pretty soon. 

  \begin{example}[Same Characteristic does not Imply Isomorphic]
    There exists no isomorphism from $\mathbb{Z}$ to $\mathbb{R}$. 
  \end{example}

  \begin{theorem}[Wilson's Theorem]
    Let $p \in \mathbb{N}$ be prime. Then 
    \begin{equation}
      (p-1)! \equiv -1 \pmod{p}
    \end{equation}
  \end{theorem}
  
  The following corollary isn't really worth stating in my opinion, but it has a popular name that might get mentioned a few times. 

  \begin{corollary}[Freshman's Dream]
    Given a ring $R$ of characteristic $p$, 
    \begin{equation}
      (a + b)^p = a^p + b^p
    \end{equation}
  \end{corollary}
  \begin{proof}
    We have 
    \begin{equation}
      (a + b)^p = \sum_{k = 0}^p \binom{p}{k} a^{p-k} b^{k}
    \end{equation}
    It is clear that 
    \begin{equation}
      \binom{p}{k} = \frac{p (p-1) ... (p - k+1)}{k!}
    \end{equation}
    is divisible by $p$ for all $k \neq 0, p$, so all the middle terms must cancel out to $0$. 
  \end{proof}

\subsection{Divisors and Reducibility} 

  Note that we do not assume that there exists multiplicative inverses in a ring. However, there may be some elements for which multiplicative inverses do exist, i.e. $a, b \in R$ where $ab = 1$. 

  \begin{definition}[Unit]
    A \textbf{unit} of a ring $R$ is an element $u \in R$ that has a multiplicative inverse in $R$. That is, there exists a $v \in R$ s.t. $uv = vu = 1$. 
  \end{definition}

  \begin{example}[Units and Non-Units]
    A ring $R$ may have either none (except for $0$ and $1$), some, or all of its elements as units. 
    \begin{enumerate}
      \item $\mathbb{Z}$ has no non-unity element that is a unit. For example, given $z \in \mathbb{Z}$, there is no element of the form $1/z$.  
      \item In $\mathbb{Q}$, every nonzero element is a unit. Given any element of form $\frac{p}{q} \in \mathbb{Q}$, the element $\frac{q}{p}$ is the multiplicative inverse. 
      \item In $\mathbb{Z}_8$, the units are $1, 3, 5, 7$ as $1 \cdot 1 = 3 \cdot 3 = 5 \cdot 5 = 7 \cdot 7 = 1$. However, $0, 2, 4, 6$ are not units since you can look in $\mod{2}$. 
    \end{enumerate}
  \end{example}

  Another property that we would desire is some sort of decomposition of ring elements as other ring elements. More specifically, the existence of elements $a, b$ such that $ab = 0$ will be of particular interest to us. 

  \begin{definition}[Left, Right Divisor]
    Let $a, b, r \in R$ a ring. 
    \begin{enumerate}
      \item If $ab = r$, then $a$ is said to be a \textbf{left divisor} of $r$ and $b$ a \textbf{right divisor} of $r$. 

      \item $a$ is said to be a left divisor of $r$ if it is a left divisor and a right divisor of $r$: $ax = ya = r$, but $x$ does not necessarily equal $y$. 

      \item If $ab = 0$, then $a$ and $b$ are said to be a \textbf{left zero divisor} and \textbf{right zero divisor}, respectively. 
    \end{enumerate}
    If $R$ is commutative, then we just call $a$ a \textbf{divisor} of $r$ or a \textbf{zero divisor}.\footnote{$a$ is a right divisor of $b \iff \exists x (xa = b) \iff \exists x (ax = b) \iff a$ is a left divisor. } 
  \end{definition}

  \begin{definition}[Reducibility of Elements]
    Let $R$ be a commutative ring and $r \in R$ be nonzero and not a unit. 
    \begin{enumerate}
      \item Then $r$ is \textbf{irreducible} in $R$ if whenever $r = ab$ with $a, b \in R$, at least one of $a, b$ is a unit in $R$. 
      \item Otherwise, $r$ is said to be \textbf{reducible}, and $a, b$ are said to be \textbf{factors}
    \end{enumerate}
  \end{definition}
  
  Note that reducibility is slightly different than the existence of divisors of an element. $r$ may have divisors, but they could also be units. Therefore, irreducibility is weaker than having no divisors. This should not be mixed up with prime/composite elements either, which we have not defined 

  \begin{lemma}[Units and Zero Divisors are Mutually Exclusive]
    An element $a \in R$ can never be both a unit and a zero divisor. 
  \end{lemma}
  \begin{proof}
    Let $a \in R$ be a unit. Then $1 = ab$ for some $b \in R$. Now if $a$ was a zero divisor, then $ra = 0$ for some $r \in R$. However, we have $r(ab) = r1 = r \neq 0 = 0b = (ra)b$, which contradicts associativity. 
  \end{proof}

  Let's go through some examples to see that we can have widely differing behavior in terms of divisors. 

  \begin{example}[Left Divisor But Not Right Divisor in Matrix Ring]
    Let us define the ring
    \begin{equation}
      R = \begin{pmatrix} \mathbb{Z} & \mathbb{Z}_2 \\ 0 & \mathbb{Z} \end{pmatrix} = \bigg\{ \begin{pmatrix} x & y \\ & z \end{pmatrix} \; \bigg| \; x, z \in \mathbb{Z}, y \in \mathbb{Z}_2 \bigg\} 
    \end{equation}
    This should be checked that it is a ring. Let 
    \begin{equation}
      a = \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}, \; b = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}
    \end{equation}
    Then, we can see that $ab = 0$ but $ba \neq 0$. That is, $b$ is a right zero divisor of $a$, but $b$ is not a left zero divisor. 
  \end{example}

  Note that $0$ is divisible by every element since $0a = 0$ for all $a \in R$. Furthermore, if $p$ was a unit, then it can always be multiplied by $p^{-1}$ and then by any $a \in R$ to get the factorization $a = (a p^{-1}) p$. So $p$ as a unit would divide \textit{every} element in $R$. 

  \begin{example}[Prime and Composite Elements]
    An element in a ring $R$ may either be prime, composite, or neither. 
    \begin{enumerate}
      \item In $\mathbb{Z}$, $2$ is prime but $6 = 2 \cdot 3$. 
      \item In $\mathbb{Q}$, there are no such things are prime or composite elements since every nonzero element is a unit. 
      \item In $\mathbb{Z}_5$, every nonzero element is a unit since $2 \cdot 3 = 4 \cdot 4 = 1$, so calling the elements prime or composite does not make sense. 
      \item In $\mathbb{Z}_6$, $2, 4$ are not units, so they must be either prime or composite. It turns out that $2$ is prime and $4 = 2 \cdot 2$ is composite. 
    \end{enumerate}
  \end{example}

  Therefore, in a general ring there is too little structure to determine much about the divisibility of elements. The following lemma is all we have. 

  \begin{lemma}[Divisibility of Linear Combinations of Rings Elements]
    Let $R$ be a commutative ring and $a, b, d \in R$. If $d \mid a$ and $d \mid b$, then $d \mid (ma + nb)$ for any $m, n \in R$. 
  \end{lemma} 

  One may also intuit that when $a \mid b$, $a$ must be ``less than'' $b$. First, in a ring without an order or a norm, this statement doesn't really make sense, and you can indeed have two distinct elements that are divisors of each other! 

  \begin{example}[Two Distinct Elements are Divisors of Each Other]
    In $\mathbb{Z}_{12}$, we have 
    \begin{enumerate}
      \item $2 \mid 10$ since $10 = 2 \cdot 5$, and $10 \mid 2$ since $2 = 10 \cdot 5$. 
      \item $3 \mid 9$ since $9 = 3 \cdot 3$ and $3 \mid 9$ since $3 = 9 \cdot 7$. 
    \end{enumerate}
  \end{example}

  Therefore, this motivates the following definition. 

  \begin{definition}[Associate Elements]
    Elements $a$ and $b$ are \textbf{associated}, denoted $a \sim b$ if either of the following equivalent conditions holds
    \begin{enumerate}
      \item $a \mid b$ and $b \mid a$. 
      \item $a = u b$, for some unit $u \in R$. 
    \end{enumerate}
    This forms an equivalence relation. 
  \end{definition} 
  \begin{proof}
    We first prove the equivalence. 
    \begin{enumerate}
      \item Assume that $a \mid b$ and $b \mid a$. Then $a \mid b \implies b = ra$ for some $r \in R$. Furthermore, $b \mid a \implies a = qb$ for some $q \in R$. Therefore, we have $b = ra = (rq)b$, and so $rq = 1$, which means $r, q$ must be units. 
      \item Assume that $a = ub$ for some unit $u \in R$. Then, $b \mid a$. Now, we can multiply by $u^{-1}$ to get $u^{-1} a = b \implies a \mid b$. 
    \end{enumerate}
    To prove that this is an equivalence relation, we prove the following properties. 
    \begin{enumerate}
      \item \textit{Reflexive}. $a \sim a$ since $a = 1a$. 
      \item \textit{Symmetric}. If $a \sim b$, then $a \mid b$ and $b \mid a$, implying that $b \sim a$. 
      \item \textit{Transitive}. If $a \sim b, b \sim c$, then there exists units $u, v \in R$ s.t. $a = ub, b = vc$, and so $a = (uv)c$, where $uv$ is a unit with $(uv)^{-1} = v^{-1} u^{-1}$. 
    \end{enumerate}
  \end{proof}

  \begin{example}[Associate Elements in a Commutative Ring]
    We present some examples of associate elements. 
    \begin{enumerate}
      \item In $\mathbb{Z}$, $\pm 6$ are associate elements since $6 = -1 \cdot 6$, where $-1$ is a unit. 
      \item In $\mathbb{Z}[i]$, $1 + i$, $1 - i$ are associate elements since $1 + i = i (1 - i)$, where $i$ is a unit since $i \cdot -i = 1$. 
      \item As above, in $\mathbb{Z}_{12}$ the elements $2, 10$ are associate elements since $2 = 5 \cdot 10$, where $5$ is a unit since $5 \cdot 5 = 1$. 
    \end{enumerate}
  \end{example}

  Remember that for commutative rings, distinguishing left and right divisors are meaningless, and so we can talk about just \textit{divisors}. Almost all rings that we will deal with are commutative, so let's try to find some properties of commutative rings.  

  \begin{definition}[Greatest Common Divisor]
    Let $R$ be a commutative ring and let $a, b \in R$ with $b \neq 0$. The \textbf{greatest common divisor} of elements $a$ and $b$---denoted $\gcd(a, b)$---is an element $d \in R$ satisfying: 
    \begin{enumerate}
      \item $d \mid a$ and $d \mid b$ 
      \item if $k \mid a$ and $k \mid b$, then $k \mid d$. 
    \end{enumerate}
    If $\mathrm{gcd}(a, b) = 1$, then $a$ and $b$ are said to be \textbf{relatively prime}. 
  \end{definition} 

  Note that in an arbitrary commutative ring, the gcd of two elements always exists since we can at least identify $1$, but there may not be a \textit{unique} gcd. 

\subsection{Ideals}

  Now assuming that $R$ and $S$ are commutative rings, let's consider a special sort of subset of a commutative ring. Consider the kernel of the ring homomorphism. We can see that if $a, b \in \ker(f)$, then $f(a + b) = f(a) + f(b) = 0 + 0 = 0$, and so $\ker(f)$ is closed under addition. Furthermore, $a \in \ker(f)$ and \textit{any} $b \in R$ gives $f(ab) = f(a) f(b) = 0 f(b) = 0$, and so multiplying any element in the kernel by an arbitrary element in the rings keeps it in the kernel. We would like to generalize these properties into an \textit{ideal}. 

  \begin{definition}[Ideals]
    For a commutative ring $(R,+, \times)$, a \textbf{two-sided ideal}---or \textbf{ideal}---is a subset $I \subset R$ satisfying 
    \begin{enumerate}
      \item $a, b \in I \implies a + b \in I$. 
      \item $a \in I, r \in R \implies ra = ar \in I$.\footnote{Note that this property and closure under addition actually implies that it is an abelian subgroup under addition, since we can see that $-1 \in R$ and $a \in I$ implies $-1 \cdot a = -a \in I$.}
    \end{enumerate}
    If $R$ is not necessarily commutative, then we $ra \neq ar$ in general, so we may distinguish between left and right ideals. 
  \end{definition}

  Therefore, we can see that it is an abelian group under $+$ and closed under $\times$. However, it is not guaranteed to have a multiplicative identity, which is why we can interpret $I$ as a ring without a multiplicative identity, also known as a \textit{rung}. Ideals are analogous to normal subgroups, which were used to induce a congruence relation on a group to get its quotient. Ideals play a similar role. 

  \begin{example}[Matrix with Last Row of Zeros]
    Let $R$ be the set of all $n \times n$ matrices. Then 
    \begin{enumerate}
      \item The set of all $n \times n$ matrices whose last row is zero forms a right ideal, but not a left ideal.
      \item The set of all $n\times n$ matrices whose last column is zero is a left ideal, but not a right ideal. 
    \end{enumerate}
  \end{example}

  \begin{example}[Multiples of Elements Are an Ideal]
    We give 2 ideals: 
    \begin{enumerate}
      \item The set of even integers $2 \mathbb{Z}$ is an ideal in the ring $\mathbb{Z}$, since the sum of any even integers is even and the product of any even integer with an integer is an even integer. However, the odd integers do not form an ideal. 
      \item The set of all polynomials with real coefficients which are divisible by the polynomial $x^2 + 1$ is an ideal in the ring of all polynomials. 
    \end{enumerate}
  \end{example}

  Let's talk about a few more properties of ideals, namely their construction and behavior under set theoretic operations. 

  \begin{theorem}[Sum and Intersection of Ideals are Ideals] 
    \label{thm:sum_int_ideals}
    Given two ideals $I, J \subset R$, 
    \begin{enumerate}
      \item $I \cap J$ is an ideal. 
      \item $I + J \coloneqq \{i + j \mid i \in I, j \in J\}$ is an ideal. 
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    Listed. 
    \begin{enumerate}
      \item $I \cap J$ is an ideal. Given $a, b \in I \cap J$, then $a, b \in I \implies a + b \in I$, and $a, b \in J \implies a + b \in J$. So $a + b \in I \cap J$. Furthermore, for every $r \in R$, $a \in I \implies r a \in I$ and $a \in J \implies r a \in J$, so $a \in I \cap J \implies ra \in I \cap J$. 

      \item $I + J$ is an ideal. Given $x, y \in I + J$, then $x = a_x + b_x$ and $y = a_y + b_y$ for $a_x, a_y \in I, b_x, b_y \in J$. So 
      \begin{equation}
        x + y = (a_x + b_x) + (a_y + b_y) = (a_x + a_y) + (b_x + b_y)
      \end{equation}
      where $a_x + a_y \in I, b_x + b_y \in J$ by definition of an ideal, and so $x + y \in I + J$. Noe let $x = a_x + b_x \in I + J$. Then given $r \in R$,
      \begin{equation}
        rx = r(a_x + b_x) = r a_x + r b_x
      \end{equation}
      where $r a_x \in I$ and $r b_x \in J$ since $I, J$ are ideals. Therefore $rx \in I + J$.  
    \end{enumerate}
  \end{proof}
  
  \begin{theorem}[Preimage of Ideals are Ideals]
    If $f: R \to S$ is a ring homomorphism of commutative rings $J \subset S$ is an ideal, then $f^{-1} (J)$ is an ideal of $R$. 
  \end{theorem}
  \begin{proof}
    We prove the two properties of an ideal. 
    \begin{enumerate}
      \item Consider $a, b \in f^{-1} (J) \subset R$. Then $f(a + b) = f(a) + f(b) \in J \implies a + b \in f^{-1}(J)$. 
      \item Consider $r \in R$ and $a \in I f^{-1}(J)$. Then, $f(ra) = f(r) f(a)$ where $f(r) \in S$ and $f(a) \in J$. So $f(r) f(a) = f(ra) \in J \implies ra \in f^{-1}(J)$. 
    \end{enumerate}
  \end{proof}

  \begin{example}[Image of Ideal is Not Necessarily an Ideal]
    It is not true in general that for an ideal $I \subset R$ and a ring homomorphism $f: R \to S$, the image $f(I)$ is an ideal of $S$. 
  \end{example}

  Given the two examples above, let's formalize the idea of an ideal consisting of all multiples of a specific element $a$. This sounds pretty familiar to \textit{generators} of groups. 

  \begin{definition}[Generators of Ideals]
    Given a commutative ring $R$, the \textbf{ideal generated by $a \in R$} is denoted 
    \begin{equation}
      \langle a \rangle \coloneqq \{r a \mid r \in R\}
    \end{equation}
    and more generally, we may have multiple generating elements. 
    \begin{equation}
      \langle a_1, \ldots, a_n \rangle \coloneqq \{ r_1 a_1 + \ldots r_n a_n \mid r_1, \ldots, r_n \in R \}
    \end{equation}
  \end{definition}

  A good---yet not completely accurate---intuition to have about ideals is that they are the set of multiples of a certain element. This technically isn't true in general, but if this intuition is true, then we call this a \textit{principal ideal}. 

  \begin{definition}[Principal Ideals]
    A \textbf{principal ideal} is an ideal generated by a single element: $I = \langle a \rangle$. 
  \end{definition}

  \begin{example}[Some Principal Ideals]
    Let's take a look at some examples and non-examples of principal ideals. 
    \begin{enumerate}
      \item In any ring $R$, the sets $\{0\} = \langle 0 \rangle$ and $R$ are principal ideals. 
      \item The set of all even integers $2\mathbb{Z} = \{\ldots, -4, -2, 0, 2, 4, \ldots\}$ is a principal ideal generated by $2 \in \mathbb{Z}$. 
      \item The set of all imaginary multiples $i\mathbb{Z} = \{ai \mid a \in \mathbb{Z} \}$ is a principal ideal $\langle i \rangle \subset \mathbb{Z}[i]$. 
    \end{enumerate}
  \end{example}

  What is nice about principal ideals it that they ``encode'' the divisors. 

  \begin{theorem}[Principal Ideals and Divisors]
    Given a commutative ring $R$ and $a, b \in R$, the following are equivalent. 
    \begin{enumerate}
      \item $b \mid a$. 
      \item $a \in \langle b \rangle$. 
      \item $\langle a \rangle \subset \langle b \rangle$. 
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    
  \end{proof}

  This allows us to define the GCD with ideals. 

  \begin{corollary}[GCD as a Minimal Ideal]
    Let $R$ be a commutative ring, $a, b \in R$, and $I = \langle a, b \rangle$. Then $d$ is the greatest common divisor if 
    \begin{enumerate}
      \item $I$ is contained in the principal ideal $\langle d \rangle$. 
      \item If $\langle d^\prime \rangle$ is any principal ideal containing $I$, then $\langle d \rangle \subseteq \langle d^\prime \rangle$. 
    \end{enumerate}
  \end{corollary}
  \begin{proof}
    
  \end{proof}

  That is, a greatest common divisor of $a, b$ is a generator for the smallest principal ideal containing $a$ and $b$. However, there are cases in which the gcd is not unique, and hence there are multiple elements $d, d^\prime$ that generate such a minimal ideal! This can happen in two ways: either $\langle d \rangle = \langle d^\prime \rangle$, or both principal ideals $\langle d \rangle, \langle d^\prime \rangle$ contain $a$ and $b$ but are not contained in each other. 

  \begin{example}[Two Distinct Elements can Generate the Same Ideal]
    Continuing on our example from before, let's verify that the associate elements indeed generate the same ideal. 
    \begin{enumerate}
      \item For $\pm 6 \in \mathbb{Z}$, we indeed have 
        \begin{align}
          \langle 6 \rangle & = \{ \ldots, -12, -6, 0, 6, 12, \ldots \} \\
          \langle -6 \rangle & = \{ \ldots, 12, 6, 0, -6, -12, \ldots \} 
        \end{align}

      \item For $1 + i, 1 - i \in \mathbb{Z}[i]$, every element in $\langle 1 + i \rangle$ is of the form $r (1 + i)$ for some $r \in \mathbb{Z}[i]$. Therefore, 
        \begin{equation}
          r(1 + i) = ri (-i)(1 + i) = ri (1 - i) \in \langle 1 - i \rangle
        \end{equation}
        for some $ri \in \mathbb{Z}[i]$, implying that $\langle 1 + i \rangle \subset \langle 1 - i \rangle$. The reverse inclusion is the same logic. 

      \item Given $2, 10 \in \mathbb{Z}_{12}$, let us write out their ideals. 
        \begin{align}
          \langle 2 \rangle & = \{0, 2, 4, 6, 8, 10\} \\ 
          \langle 10 \rangle & = \{0, 10, 20 = 8, 18 = 6, 16 = 4, 14 = 2\}
        \end{align}
    \end{enumerate}
  \end{example} 

  This gives us a hint as to what these elements are. 

  \begin{theorem}[Elements that Generate Same Ideal are Associated]
    Given commutative ring $R$ and $a, b \in R$, $a$ and $b$ are associate elements if and only if $\langle a \rangle = \langle b \rangle$. 
  \end{theorem}
  \begin{proof}
    We prove bidirectionally. 
    \begin{enumerate}
      \item $(\rightarrow)$. Let $a, b \in R$ be associate elements. Then there exists a unit $u \in R$ s.t. $a = ub$. Therefore $ \langle a \rangle \subset \langle b \rangle$. On the other hand, $b = u^{-1} a$, and so $\langle b \rangle \subset \langle a \rangle$. 
      \item $(\leftarrow)$. Let $\langle a \rangle = \langle b \rangle$. Then this implies that $a \mid b$ and $b \mid a$, and so they are associate elements. 
    \end{enumerate}
  \end{proof}

  Now that we have learned ideals, we can define prime ideals and prime elements. 
  
  \begin{definition}[Prime Ideal]
    An ideal $P$ of a commutative ring $R$ is \textbf{prime} if it has the following two properties. 
    \begin{enumerate}
      \item If $a, b \in R$ where $ab \in P$, then either $a \in P$ or $b \in P$. 
      \item $P \subsetneq R$. 
    \end{enumerate}
  \end{definition}

  \begin{definition}[Prime Elements]
    Let $R$ be a commutative ring and $p \in R$ be nonzero and not a unit. $p$ is \textbf{prime} if either of the equivalent conditions is true. 
    \begin{enumerate}
      \item The ideal $\langle p \rangle$ is a prime ideal. 
      \item Whenever $p \mid ab$ for any $a, b \in R$, then either $p \mid a$ or $p \mid b$. 
    \end{enumerate}
  \end{definition}

  The final property of ideals is whether it ``almost'' fills up the whole ring in that it is maximal. 

  \begin{definition}[Maximal Ideal]
    Let $R$ be a commutative ring and $I \subset R$ an ideal. $I$ is \textbf{maximal} if there exists no ideal $J$ s.t. $I \subsetneq J \subsetneq R$. 
  \end{definition}

\subsection{Quotient Rings}

  What is nice about ideals is that they induce not just an equivalence relation---but a congruence relation---on a ring, which is a generalization of working in the integers modulo $n$. 

  \begin{theorem}[Equivalence Relation Induced by an Ideal]
    Given a commutative ring $R$ and an ideal $I \subset R$, we say that two elements $a, b \in R$ are \textbf{congruent} $\pmod{I}$, written $a \equiv b \pmod{I}$ iff $a - b \in I$. We claim two things: 
    \begin{enumerate}
      \item $\equiv$ is an equivalence relation. 
      \item $\equiv$ is a congruence relation. Given that $a \equiv a^\prime \pmod{I}$ and $b \equiv b^\prime \pmod{I}$, 
      \begin{equation}
        a + b \equiv a^\prime + b^\prime \pmod{I}, \qquad ab \equiv a^\prime b^\prime \pmod{I}
      \end{equation}
    \end{enumerate}
    Occasionally, if the ideal $I$ is clear from context, we will write $a \equiv b$. 
  \end{theorem}
  \begin{proof}
    We first prove that $\equiv$ is indeed an equivalence relation. 
    \begin{enumerate}
      \item \textit{Reflexive}. $a \equiv a \pmod{I}$ is trivial since $a - a = 0 \in I$. 
      \item \textit{Symmetric}. If $a \equiv b$, then $a - b \in I \implies -(a - b) = -a + b = b - a \in I \implies b \equiv a$. 
      \item \textit{Transitive}. If $a \equiv b$ and $b \equiv c$, then $a - b \in I$ and $b - c \in I$. Since $I$ is an additive group and so it is closed under addition, so $(a - b) + (b - c) = a - c \in I \implies a \equiv c$. 
    \end{enumerate}
    Note that so far, we have only used the group property of ideals to prove that is is an equivalence class. Now for congruence of multiplication, we need the ring properties. 
    \begin{enumerate}
      \item $a \equiv a^\prime, b \equiv b^\prime \implies (a - a^\prime), (b - b^\prime) \in I$. By adding them together and distributivity, we have 
      \begin{equation}
        a - a^\prime + b - b^\prime = (a + b) - (a^\prime + b^\prime) \in I \implies a + b \equiv a^\prime + b^\prime \pmod{I}
      \end{equation}

      \item We see that $a \in R, (b - b^\prime) \in I \implies a(b - b^\prime) \in I$. Similarly, $b^\prime \in R, (a - a^\prime) \in I \implies (a - a^\prime) b^\prime \in I$. Now adding the two, we have 
      \begin{equation}
        a (b - b^\prime) + (a - a^\prime) b^\prime = ab - ab^\prime + ab^\prime - a^\prime b^\prime = ab - a^\prime b^\prime \in I \implies ab = a^\prime b^\prime \pmod{I}
      \end{equation}
    \end{enumerate}
  \end{proof} 

  This quotient space maintains a lot of nice properties of the algebraic operations, and so we can form a new ring structure with this quotient space.  

  \begin{definition}[Quotient Rings, Rings of Residue Class]
    The quotient space $R/I$ induced by the mapping $a \mapsto [a]$ is indeed a commutative ring, called the \textbf{quotient ring}, with addition and multiplication defined 
    \begin{equation}
      [a] + [b] \coloneqq [a + b], \qquad [ab] \coloneqq [a] \, [b]
    \end{equation}
  \end{definition}
  \begin{proof}
    Note that the properties of the operation in $\frac{M}{R}$ inherits all the properties of the addition operation on $M$ that are expressed in the form of identities and inverses, along with the existence of the zero identity. 
    \begin{align*}
      0 \in M & \implies [0] \text{ is the additive identity in } \frac{M}{R} \\
      a + (-a) = 0 & \implies [a] + [-a] = [0] \\
      1 \in M & \implies [1] \text{ is the multiplicative identity in } \frac{M}{R}
    \end{align*}
  \end{proof} 

  \begin{theorem}[Quotient Maps are Homomorphisms]
    The map $p: R \to R/I$ is a ring homomorphism. 
  \end{theorem}
  \begin{proof}
    This is true by definition since we have made $\equiv$ a congruence relation. 
  \end{proof}

  \begin{example}[Quotient Rings of Integers]
    The quotient set $\mathbb{Z}/\langle n \rangle$ by the relation of congruence modulo $n$ is denoted $\mathbb{Z}_{n}$. 
    \begin{equation}
      \mathbb{Z}_{n} = \{ [0]_{n}, [1]_{n}, \ldots, [n-1]_{n} \}
    \end{equation}
    Note that the quotient ring $(\mathbb{Z}/\langle n \rangle, +, \times)$ is precisely the cyclic quotient group $\mathbb{Z}_n = \mathbb{Z}/6\mathbb{Z}$ when considering only addition. We list some quotient rings of the integers. 
    \begin{enumerate}
      \item In $\mathbb{Z}_{5} = \mathbb{Z}/\langle 5 \rangle$, the elements $[2]$ and $[3]$ are multiplicative inverses of each other since $[2] [3] = [6] = [1]$, and $[4]$ is its own inverse since $[4] [4] = [16] = [1]$. The addition and multiplication tables for $\mathbb{Z}_5$ is shown below. 
      \item Consider the ideal $I = \langle 2 \rangle \subset \mathbb{Z}_6$. We have $0 \equiv 2 \equiv 4 \pmod{I}$ and $1 \equiv 3 \equiv 5 \pmod{I}$, and so the quotient ring $\mathbb{Z}_6 / I$ consists of the two equivalence classes $[0]$ and $[1]$. 
    \end{enumerate}
  \end{example}

  \begin{example}[Quotient Rings of Polynomials]
    We list some quotient rings of polynomials. 
    \begin{enumerate}
      \item Consider $\mathbb{Q}[x] / \langle x^2 - 2 \rangle$. We can see that any polynomial $f \in \mathbb{Q}[x]$ is equivalent $\pmod{I}$ to a linear polynomial, since $x^2 \equiv 2$. Alternatively we can apply the division algorithm to replace $f(x)$ by its remainder upon division by $x^2 - 2$, and thus in the quotient ring, $[x]$ plays the role of $\sqrt{2}$, which may indicate that $\mathbb{Q}[x] / \langle x^2 - 2 \rangle = \mathbb{Q}[\sqrt{2}]$. 
      \item Consider $\mathbb{Z}_2 [x]/ \langle x^2 + x + 1 \rangle$. As in the previous example, any polynomial in $\mathbb{Z}_2[x]$ is equivalent to a linear polynomial since $x^2 \equiv x + 1 \pmod{I}$. Therefore the elements of the quotient ring are $[0], [1], [x], [x+1]$ with the addition and multiplication tables. 

      \begin{figure}[H]
        \centering
        \begin{subfigure}[b]{0.48\textwidth}
          \centering
          \begin{tabular}{c|cccc}
            $+$ & $0$ & $1$ & $x$ & $x + 1$ \\
            \hline
            $0$ & $0$ & $1$ & $x$ & $x + 1$ \\
            $1$ & $1$ & $0$ & $x + 1$ & $x$ \\
            $x$ & $x$ & $x + 1$ & $0$ & $1$ \\
            $x + 1$ & $x + 1$ & $x$ & $1$ & $0$ \\
          \end{tabular}
          \caption{}
        \end{subfigure}
        \hfill 
        \begin{subfigure}[b]{0.48\textwidth}
          \centering
          \begin{tabular}{c|cccc}
            $\cdot$ & $0$ & $1$ & $x$ & $x + 1$ \\
            \hline
            $0$ & $0$ & $0$ & $0$ & $0$ \\
            $1$ & $0$ & $1$ & $x$ & $x + 1$ \\
            $x$ & $0$ & $x$ & $x + 1$ & $1$ \\
            $x + 1$ & $0$ & $x + 1$ & $1$ & $x$ \\
          \end{tabular}
          \caption{}
        \end{subfigure}
        \label{fig:boolean-algebra-tables}
      \end{figure}
    \end{enumerate}
  \end{example}

  Note that just like how quotient topologies do not preserve topological properties, as shown \hyperref[pst-quotient_trivial]{here} and \hyperref[pst-quotient_hausdorff]{here}, quotient rings inherit some---but not all---ring properties. It obviously inherits commutativity since the quotient space is constructed with a congruence relation. However, the characteristic is changed. 

  Just like in group theory, we have a method of constructing isomorphisms between cleverly chosen rings $S$ and a quotient ring $R/I$. This seems to be a common pattern here when considering groups, rings, and topological spaces... This will be investigated more in category theory. 

  \begin{theorem}[First Isomorphism Theorem for Rings]
    Let $R$ and $S$ be commutative rings, and suppose $f: R \rightarrow S$ be a surjective ring homomorphism. Then this induces a ring isomorphism
    \begin{equation}
      R /\ker{f} \simeq S
    \end{equation} 
    satisfying $\phi = \bar{\phi} \circ \pi$. 

    \begin{figure}[H]
      \centering 
      \begin{tikzcd}
        R \arrow[r, "\phi"] \arrow[d, "\pi"] & S \\
        R/\ker(\phi) \arrow[ru, "\bar{\phi}"] &  
      \end{tikzcd}
      \caption{The theorem states that the following diagram commutes. } 
      \label{fig:fund_ring_homo_theorem}
    \end{figure}
  \end{theorem}
  \begin{proof}
    
  \end{proof} 

  A direct application of this is the Chinese remainder theorem. 

  \begin{corollary}[Chinese Remainder Theorem]
    Given a commutative ring $R$, let $I, J \subset R$ be ideals such that $I + J = R$. Then, 
    \begin{equation}
      \pi: R \to \frac{R}{I} \times \frac{R}{J}, \qquad r \mapsto ([r]_I, [r]_J)
    \end{equation}
    with component-wise quotient mappings is a surjective ring homomorphism with $\ker{\pi} = I \cap J$. By the fundamental ring homomorphism theorem, it immediately follows that 
    \begin{equation}
      \frac{R}{I \cap J} \simeq \frac{R}{I} \times \frac{R}{J}
    \end{equation}
  \end{corollary}
  \begin{proof}
    Since $I + J = R$, there exists $i \in I$ and $j \in j$ s.t. $i + j = 1$. Let $\bar{a} = a + I \in R/I$ and $\bar{b} = b + J \in R/J$ be any elements. Then 
    \begin{equation}
      \pi(aj + bi) = ([aj + bi]_I, [a_j + bi]_J) = ([aj]_I, [bi]_J) \in \frac{R}{I} \times \frac{R}{J}
    \end{equation} 
    But we have 
    \begin{enumerate}
      \item $a(j + i) = a \in R \implies aj = a(j + i) \in R/I$. Therefore $[aj]_I = [a]_I$ 
      \item $b(j + i) = b \in R \implies bi = bj + bi \in R/J$. Therefore $[b]_J = [bi]_J$. 
    \end{enumerate}
    Therefore, we have $\pi(aj + bi) = ([a]_I, [b]_J)$, which proves surjectivity. 
  \end{proof} 

  \begin{example}
    We claim that $\mathbb{Z}_{10} \simeq \mathbb{Z}_5 \times \mathbb{Z}_2$ as rings. In fact, the whole isomorphism is defined with the mappings $f(1, 1) = 1$. 
  \end{example}

  \begin{example}[Chinese Remainder Theorem on Integers]
    Suppose that we are solving the system of linear conguence equations 
    \begin{equation}
      x \equiv b_1 \pmod{m_1}, \qquad x \equiv b_2 \pmod{m_2}
    \end{equation}
    where $m_1, m_2$ are coprime. The Chinese remainder theorem says that there exists a solution $x$ where any two solutions $x_1, x_2$ are congruent modulo $N$. We can think of each equation as modeling $x$ as living in an ideal specified by the isomorphism 
    \begin{equation}
      \phi: \frac{\mathbb{Z}}{N\mathbb{Z}} \to \frac{\mathbb{Z}}{m_1 \mathbb{Z}} \times \frac{\mathbb{Z}}{m_2 \mathbb{Z}}, \qquad x \pmod{N} \xrightarrow{\phi} (x \pmod{m_1}, x \pmod{m_2})
    \end{equation}
    Therefore, for doing a sequence of arithmetic operations in $\mathbb{Z}/N\mathbb{Z}$, we can do in each component ring and then get the result by applying the isomorphism backwards. This isomorphism becomes 
    \begin{equation}
      x \equiv a_2 b_1 m_2 + a_1 b_2 m_1 \pmod{m_1 m_2}
    \end{equation}
    where $1 = a_1 m_1 + a_2 m_2$. Alternatively, we can start off with the congruences, and begin by using Bezout's identity on $m_1, m_2$, and then multiplying by the $b_1, b_2$. 
    \begin{align}
      1 & = a_1 n + a_2 m_2 \\
      b_1 & = a_1 b_1 m_1 + a_2 b_1 m_2 \\ 
      b_2 & = a_1 b_2 m_1 + a_2 b_2 m_2 
    \end{align}
    Then we can cleverly set 
    \begin{equation}
      x = a_2 b_1 m_2 + a_1 b_2 m_1
    \end{equation}
    which now satisfies $x \equiv a_2 b_1 m_2 \pmod{m_1}$ and $x \equiv a_1 b_2 m_1 \pmod{m_2}$. 
  \end{example} 

\subsection{Division Rings}

  \begin{definition}[Division Ring]
    A \textbf{division ring}, also called a \textbf{skew field}, is an associative ring where every nonzero element is invertible with respect to $\times$.\footnote{Division rings differ from fields in that multiplication is not required to be commutative. }
  \end{definition}

  Let's establish the hierarchy. 

  \begin{lemma}[Division Rings are Domains]
    Every division ring $R$ is automatically a domain. 
  \end{lemma}
  \begin{proof}
    Every nonzero element is a unit and hence cannot be a zero-divisor. 
  \end{proof}

  \begin{example}[Invertible Matrices]
    The classic example is the ring of invertible matrices over the reals $\GL(\mathbb{R}^n)$, which is not necessarily commutative, but is a ring in which ``division'' can be done by right and left multiplication of a matrix inverse. 
    \begin{equation}
      A A^{-1} = A^{-1} A = I
    \end{equation}
    This implies that every element in the division ring commutes with the identity, but again commutativity does not necessarily hold for arbitrary elements $A, B$. 
  \end{example} 

  \begin{example}[Hamiltonian Quaternions]
    The real Hamiltonian quaternions 
    \begin{equation}
      \mathbb{H} \coloneqq \{a + bi + cj + dk \mid a, b, c, d \in \mathbb{R} \} 
    \end{equation}
    where addition is defined component-wise and multiplication defined by expanding 
    \begin{equation}
      i^2 = j^2 = k^2 = 1, \quad ij = -ji = k, \quad jk = -kj = k, \quad ki = -ik = j 
    \end{equation}
    where the real coefficients commute with $i, j, k$. This can be proven tediously to be a division ring, along with the rational Hamiltonian quaternions. 
  \end{example}


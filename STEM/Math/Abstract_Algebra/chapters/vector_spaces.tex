\section{Vector Space Structures}

  \begin{definition}[Vector Space]
     A \textbf{vector space over a field $F$} consists of an abelian group $(V, +)$ and an operation called \textbf{scalar multiplication} 
     \begin{equation}
       \cdot: F \times V \rightarrow V
     \end{equation}
    such that for all $x, y\in V$ and $\lambda, \mu \in F$, we have 
    \begin{enumerate}
      \item $\lambda \cdot (x + y) = \lambda \cdot x + \lambda \cdot y$
      \item $(\lambda + \mu) \cdot x = \lambda \cdot x + \mu \cdot x$ 
      \item $(\lambda \mu) \cdot x = \lambda \cdot (\mu \cdot x )$, which equals $(\mu \lambda) \cdot x = \mu \cdot (\lambda \cdot x)$ since $F$ is commutative 
      \item $1 \cdot x = x$ , where $1$ is the unity of $F$
    \end{enumerate}
  \end{definition}

  \begin{definition}
    A \textbf{left R-module} $M$ consists of an abelian group $(M, +)$ and an operation called \textbf{scalar multiplication}
    \begin{equation}
      \cdot: R \times M \longrightarrow M
    \end{equation}
    such that for all $\lambda, \mu \in R$ and $x, y \in M$, we have 
    \begin{enumerate}
      \item $\lambda \cdot (x + y) = \lambda \cdot x + \lambda \cdot y$
      \item $(\lambda + \mu) \cdot x = \lambda \cdot x + \mu \cdot x$ 
      \item $(\lambda \mu) \cdot x = \lambda \cdot (\mu \cdot x )$, not necessarily equaling $(\mu \lambda) \cdot x = \mu \cdot (\lambda \cdot x)$
      \item $1 \cdot x = x$ , where $1$ is the unity of $R$
    \end{enumerate}
    Note that a left $R$-module is a vector space if and only if $R$ is a field.
  \end{definition}

  \begin{definition}
    A \textbf{right $R$-module} $M$ is defined analogously to a left $R$-module, except that the scalar multiplication operation is defined
    \begin{equation}
      \cdot: M \times R \longrightarrow M
    \end{equation}
  \end{definition}

  \begin{definition}
    Let $A$ be a vector space over a field $F$ equipped with an additional binary operation 
    \begin{equation}
      \times: A \times A \longrightarrow A
    \end{equation}
    $A$ is an \textbf{algebra over $F$} if the following identities hold for all $x, y, z \in A$ and all $\lambda, \mu \in F$. 
    \begin{enumerate}
      \item Right distributivity. $(x + y) \times z = x \times z + y \times z$ 
      \item Left distributivity. $z \times (x + y) = z \times x + z \times y$
      \item Compatibility with scalars. $(\lambda \cdot x ) \times (\mu \cdot y) = (\lambda \mu) \cdot (x \times y)$ 
    \end{enumerate}
  \end{definition}

  Note that vector multiplication of an algebra does not need to be commutative. 

  \begin{example}
    The set of all $n \times n$ matrices with matrix multiplication is a noncommutative, associative algebra. Similarly, the set of all linear endomorphisms of a vector space $V$ with composition is a noncommutative, associative algebra. 
  \end{example}

  \begin{example}
    $\mathbb{R}^3$ equipped with the cross product is an algebra, where the cross product is \textbf{anticommutative}, that is $x \times y = - y \times x$. $\times$ is also nonassociative, but rather satisfies an alternative identity called the \textbf{Jacobi Identity}. 
  \end{example}

  \begin{example}
    The set of all polynomials defined on an interval $[a,b]$ is an infinite-dimensional subalgebra of the set of all functions $f: \mathbb{R} \longrightarrow \mathbb{R}$ defined on $[a,b]$.
  \end{example}

  \begin{definition}
    Similar to division rings, a \textbf{division algebra} is an algebra where the operation of "division" defined as such: Given any $a \in A$, nonzero $b \in A$, there exists solutions to the equation
    \begin{equation}
      A = bx
    \end{equation}
    that are unique. If we wish, we can distinguish left and right division to be the solutions of $A = b x$ and $A = x b$. 
  \end{definition}

  \begin{definition}
    Here are examples of division algebras.
    \begin{enumerate}
      \item $\mathbb{R}$ is a $1$-dimensional algebra over itself. 
      \item $\mathbb{C}$ is a $2$-dimensional algebra over $\mathbb{R}$. 
      \item There exists no $3$-dimensional algebra. 
      \item Quaternions forms a $4$-dimensional algebra over $\mathbb{R}$. 
    \end{enumerate}
  \end{definition}

\subsection{Modules}

  Vector space but over a ring. 

\subsection{Algebras}

  Vector space with bilinear product.  

\subsection{Tensor Algebras}

  Remember that an algebra is (loosely) a vector space $V$ with a multiplication operation
  \begin{equation}
    \times: V \times V \longrightarrow V
  \end{equation}

  \begin{definition}
    The \textbf{tensor algebra} of vector space $V$ over field $\mathbb{F}$ is 
    \begin{align*}
      T(V) \equiv \bigoplus_{n = 0}^{\infty} V^{\otimes n} & = V^{\otimes 0} \oplus V^{\otimes 1} \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus ... \\
      & = \mathbb{F} \oplus V \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus V^{\otimes 4} \oplus ...
    \end{align*}
    with elements being infinite-tuples
    \begin{equation}
      (a, B^\mu, C^{\nu \gamma}, D^{\alpha \beta \epsilon}, ...)
    \end{equation}
    The addition operation is defined component-wise, and the multiplication operation is the tensor product 
    \begin{equation}
      \otimes: T(V) \times T(V) \longrightarrow T(V)
    \end{equation}
    and the identity element is
    \begin{equation}
      I = (1, 0, 0, ...)
    \end{equation}
    Linearity can be easily shown. 
  \end{definition}

  The tensor algebra is often used to "add" differently ranked tensors together. But in order to do this rigorously, we must define the canonical injections
  \begin{equation}
    i_j: V^{\otimes j} \longrightarrow T(V), \; i_j (T^{\kappa_1, ..., \kappa j}) = (0, ...,0, T^{\kappa_1, ..., \kappa j}, 0, ..., 0) 
  \end{equation}
  shown in the diagram
  \[\begin{tikzcd}
      & & T(V) & & \\
      \mathbb{F} \arrow{urr}{i_0} & V \arrow{ur}{i_1} & V^{\otimes 2} \arrow{u}{i_2} & V^{\otimes 3} \arrow{ul}{i_3} & ... \arrow{ull}
  \end{tikzcd}\]
  Therefore, with these $i_j$'s, we can implicitly define the addition of arbitrary tensors $A \in V^{\otimes n}$ and $B \in V^{\otimes m}$ as 
  \begin{equation}
    A + B \equiv i_n (A) + i_m (B) \in T(V)
  \end{equation}
  along with multiplication of tensors as
  \begin{equation}
    A \otimes B \equiv i_n(A) \otimes i_m(B) \equiv i_{n+m} (A \otimes B)
  \end{equation}
  We can also redefine the tensor product operation between two spaces to be an operation within $T(V)$ itself. 
  \begin{equation}
    i_i(V^{\otimes i}) \otimes i_j( V^{\otimes j}) = i_{i+j} (V^{\otimes (i+j)})
  \end{equation}
  We can now proceed to define Exterior and Symmetric algebras as quotient algebras. 

  \begin{definition}
    The \textbf{exterior algebra} $\Lambda(V)$ of a vector space $V$ over field $\mathbb{F}$ is the quotient algebra of the tensor algebra $T(V)$
    \begin{equation}
      \Lambda(V) \equiv \frac{T(V)}{I}
    \end{equation}
    where $I$ is the two-sided ideal generated by all elements of the form $x \otimes x$ for $x \in V$ (i.e. all tensors that can be expressed as the tensor product of a vector in V by itself). 

    The \textbf{exterior product} $\wedge$ of two elements of $\Lambda(V)$ is the product induced by the tensor product $\otimes$ of $T(V)$. That is, if 
    \begin{equation}
      \pi: T(V) \longrightarrow \Lambda(V)
    \end{equation}
    is the canonical projection/surjection and $a, b \in \Lambda(V)$ ,then there are $\alpha, \beta \in T(V)$ such that $a = \pi(\alpha), b = \pi(\beta)$, and 
    \begin{equation}
      a \wedge b = \pi(\alpha \otimes \beta)
    \end{equation}
    We can define this quotient space with the equivalence class
    \begin{equation}
      x \otimes y = - y \otimes x \pmod{I}
    \end{equation}
  \end{definition}

  \begin{definition}
    The \textbf{symmetric algebra} Sym$(V)$ of a vector space $V$ over a field $\mathbb{F}$ is the quotient algebra of the tensor algebra $T(V)$ 
    \begin{equation}
      \Lambda(V) \equiv \frac{T(V)}{J}
    \end{equation}
    where $J$ is the two-sided ideal generated by all elements in the form 
    \begin{equation}
      v \otimes w - w \otimes v
    \end{equation}
    (i.e. commutators of all possible pairs of vectors). 
  \end{definition}


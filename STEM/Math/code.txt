\documentclass[a4paper, 12pt]{report}

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage[english]{babel}
\usepackage[noheader]{packages/sleek}
\usepackage{packages/sleek-title}
\usepackage{packages/sleek-theorems}
\usepackage{packages/sleek-listings}
\usepackage{tikz-cd}
\usepackage{extarrows} 
\usepackage{esvect}
\usepackage{esint}
\usepackage{pgfplots}
\usepackage{centernot}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}
\usepackage{dcolumn}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
]{doclicense}
\newcolumntype{2}{D{.}{}{2.0}}

\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\Div}{div}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\SL}{SL}
\DeclareMathOperator{\GA}{GA}
\DeclareMathOperator{\std}{std}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Corr}{Corr}
\DeclareMathOperator{\Int}{Int}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Lie}{Lie}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Alt}{Alt}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\aff}{aff}
\DeclareMathOperator{\arccot}{arccot}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{example}
\newtheorem{example}{Example}[section]
\theoremstyle{conjecture}
\newtheorem{conjecture}{Conjecture}[section]

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{./resources/pdf/logo.pdf}
\institute{Duke University}
\faculty{Department of Mathematics}
\title{Mathematics}
\subtitle{Personal Notes}
\author{Muchang Bahng}

%%%%%%%%%%%%%%%%
% Bibliography %
%%%%%%%%%%%%%%%%

%%%%%%%%%%
% Others %
%%%%%%%%%%

\lstdefinestyle{latex}{
    language=TeX,
    style=default,
    %%%%%
    commentstyle=\ForestGreen,
    keywordstyle=\TrueBlue,
    stringstyle=\VeronicaPurple,
    emphstyle=\TrueBlue,
    %%%%%
    emph={LaTeX, usepackage, textit, textbf, textsc}
}

\FrameTBStyle{latex}

\def\tbs{\textbackslash}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
\maketitle
\vspace*{\fill}
\vfill
This version was compiled on \today. 

Email any inquiries or comments to muchang.bahng@duke.edu. 

Copyright $\copyright$  2021 Muchang Bahng
\doclicenseThis
https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en
\romantableofcontents

\chapter{Introduction}
This book is a series of notes from math courses that I have taken at Duke in the 2019-2020 school year, along with courses that I have independently studied. As the reader will see in the table of contents, this book covers a variety of topics in mainly undergraduate and occasionally graduate level mathematics. The Duke course material that this book covers is: Math 216/218/221: Linear Algebra, Math 403: Adv. Linear Algebra, Math 212/222: (Adv.) Vector Calculus, Math 230/340: Adv. Introduction to Probability, Math 353/356: Differential Equations, Math 501: Abstract Algebra, Math 411: Topology, Math 531: Real Analysis, Math 611: Algebraic Topology, Math 620: Smooth Manifolds. Occasionally, it does touch upon other more advanced topics, such as representation theory and category theory. By no means do I guarantee that this book will be comprehensive for all of these courses. Additionally, I have ordered the chapters in such a way that prerequisite information for future chapters is initially covered, but the content in these courses are so interdependent that it made it difficult to do so completely. 

This is book is not too rigorous nor too non-rigorous on its introduction to the topics mentioned. Unlike most textbooks, this book does not focus on a specific field of math; it provides an introduction to a wide variety of fields. This book is mainly aimed for people who would like to have a non-rigorous introduction to the courses covered and to students who have taken these courses and would like to review them briefly. I believe that this book serves as an excellent glossary that comprehensively covers the important, fundamental ideas in the courses. Furthermore, I have tried to place an emphasis on the geometric interpretations behind many of the concepts explained in this book. 

Finally, I would like to state that this book is a work in progress, and I welcome any constructive criticisms that readers may have for this book. Any questions and inquiries can be emailed to: muchang.bahng@duke.edu. I would like to thank the professors, peers, and textbooks that have helped me understand the material in this book. I would also like to extend my gratitude to those that may help me in the future. 

\subsubsection{Axiom of Choice}
The only axiom that will be explicitly stated here will be the \textit{axiom of choice} or often called \textit{AC}. Informally, it is an axiom of set theory equivalent to the statement that a Cartesian product of a collection of nonempty sets is nonempty. We can interpret it as saying that given any collection of urns, each containing at least one object, it is possible to make a selection of at least one object from each urn, even if there are an infinite number of urns. Formally, it states the following: 
\begin{center}
    \textit{For every indexed family $(S_i)_{i \in I}$ of nonempty sets, there exists an indexed family $(x_i)_{i \in I}$ of elements such that $x_i \in S_i$ for every $i \in I$.}
\end{center}

In many cases, such a selection can be made without invoking the axiom of choice. One such case would be if the number of sets is finite. Another would be if a selection rule is available; that is, there is some distinguishing property that holds for exactly one element in each set. One useful example are sets picked from the natural numbers. From such sets, one may always select the smallest number, e.g. given the sets $\{\{4, 5, 6\}, \{10, 12\}, \{1, 400, 617\}\}$, the set containing each smallest element is $\{4, 10, 1\}$. 

In the previous example, "select the smallest number" is a \textit{choice function}. Even if infinitely many sets were collected from the natural numbers, it will always be possible to choose the smallest element from each set to produce a set. That is, the choice function provides the set of chosen elements. However, no choice function is known for the collection all nonempty subsets of the real numbers. In this case, the axiom of choice must be invoked. 

\begin{definition}
A \textit{choice function} is a function $f$, defined on a collection $X$ of nonempty sets, such that for every set $A$ in $X$, $f(A)$ is an element of $A$. 
\end{definition}

With this concept, the axiom can be stated. 

\textbf{Axiom} For any set $X$ of nonempty sets, the exists a choice function $f$ defined on $X$. 

Thus, the negation of the axiom of choice states that there exists a collection of nonempty sets that has no choice function. The axiom of choice is also equivalent to the following statement. 
\begin{center}
    \textit{Given any family of nonempty sets, their Cartesian product is a nonempty set.}
\end{center}
Another equivalent axiom only considers collections $X$ that are essentially powersets of other sets. 
\begin{center}
    \textit{For any set $A$, the power set of $A$ (with the empty set removed) has a choice function.}
\end{center}


\chapter{Linear Algebra}
A multiple-year course in linear algebra at the advanced undergraduate and graduate level. The notes for this section can be a bit too abstract for someone learning linear algebra for the first time, so I suggest learning about groups, rings, and fields first. 

\section{Vector Spaces and Dual Spaces}
\begin{definition}
A \textit{vector space} $V$ over a field $\mathbb{F}$ (usually $\mathbb{R}$ or $\mathbb{C}$) is a set of vectors that is algebraically closed under the operations: 
\begin{enumerate}
    \item $+: V \times V \longrightarrow V$
    \item $\times: \mathbb{F} \times V \longrightarrow V$
\end{enumerate}
It is also an additive abelian group, with additional axioms. That is, given $\lambda, \mu \in \mathbb{F}$ and $v, u \in V$, 
\begin{enumerate}
    \item $(\lambda + \mu) v = \lambda v + \mu v$
    \item $\lambda (v + u) = \lambda v + \lambda u$
    \item $(\lambda \mu) v = \lambda (\mu v) = \mu (\lambda v)$ 
\end{enumerate}
\end{definition} 

\begin{definition}
A \textit{vector} is an element of a vector space. 
\end{definition}

\begin{proposition}
There are no zero divisors of vector space $V$. That is, 
\[\lambda v = 0 \implies \lambda = 0 \text{ or } v = 0\]
\end{proposition}
\begin{proof}
$\lambda v = 0 \implies \lambda v + \lambda v = 0 + \lambda v \implies 2\lambda v = \lambda v \implies (2\lambda - \lambda ) v = 0$. But $\lambda \neq 0$, so $v$ must equal $0$. This leads to a contradiction. 
\end{proof}

We now introduce some classic interpretations of vectors. 

\begin{example}
$n$-tuples of elements of a field $\mathbb{F}$, that is, in the form
\[(a_1, a_2, ..., a_n)\]
are elements of a vector field, with vector addition and scalar multiplication defined component-wise. 
\end{example}

\begin{example}
The set of all arrows in space, with addition defined by the parallelogram rule and scalar multiplication defined as the stretching/compressing of the arrow from the origin, forms the vector space of arrows. 
\end{example}

We define some more vector spaces that are often used. 

\begin{example}
The set of all polynomials of degree strictly less than $n$ with coefficients in $\mathbb{F}$ defines a vector space over $\mathbb{F}$. 
\end{example}

\begin{definition}
A subset $Y$ of a linear space $X$ is called a \textit{subspace} if sums and scalar multiples of elements of $Y$ belong to $Y$. Note that $\{ 0 \}, X$ are subspaces of $X$. 
\end{definition}

\begin{definition}
Given vector spaces $U, V$ over the same field $\mathbb{F}$, a mapping $f: V \longrightarrow U$ that has properties 
\[ f(v_1 + v_2) = f(v_1) + f(v_2), \; \; f(c v) = c f(v), (c \in \mathbb{F})\]
is called a \textit{homomorphism}. The set of all homomorphisms from $V$ to $U$ is denoted Hom$(V, U)$. If $f$ is bijective, then $f$ is called an \textit{isomorphism}, and $U$ is said to be \textit{isomorphic} to $V$, denoted $U \simeq V$. Elements of Hom$(U,U)$, denoted End$(U)$, are called \textit{endomorphisms} of $U$, and an endomorphism of $U$ that is also an isomorphism is called an \textit{automorphism}. The set of all automorphisms of $U$ is denoted Aut$(U)$. 
\end{definition}

\subsection{Basis and Dimension}
\begin{definition}
A \textit{linear combination} of $j$ vectors $v_1, v_2, ..., v_j$ of a linear space is a vector of the form 
\begin{equation}
    c_1 v_1 + c_2 v_2 + c_3 v_3 + ... + c_j v_j, c_1, ..., c_j \in \mathbb{F}
\end{equation}
\end{definition}

\begin{definition}
The \textit{span} of a collection of vectors $v_1, v_2, ..., v_j \in V$ is the set
\[\Span \{ v_1, v_2, ..., v_j \} \equiv \{ c_1 v_1 + c_2 v_2 + c_3 v_3 + ... + c_j v_j\; | \; c_1, ..., c_j \in \mathbb{F}\} \]
That is, $\Span \{v_1, v_2, ..., v_j\}$ is the smallest subspace of $V$ that contains all $v_1, ..., v_j$. 
\end{definition}

It clearly follows that $v_1, ..., v_n$ span the whole space $V$ if every vector in $V$ can be expressed as a linear combination of the $v_i$'s. 

\begin{definition}
Vectors $v_1, ..., v_j$ are \textit{linearly independent} if 
\[ c_1 v_1 + c_2 v_2 + c_3 v_3 + ... + c_j v_j = 0 \implies c_1, ..., c_j = 0\]
They are \textit{linearly dependent} if there exists nonzero $c_1, ..., c_j$ such that the equality holds true, which is equivalent to saying that there is at least one vector $v_i, 1 \leq i \leq j,$ such that it can be represented as a linear combination of all the other vectors. 
\end{definition}

\begin{definition}
A set of linearly independent vectors $v_1, ..., v_n$ that span vector space $V$ is called a \textit{basis} of $V$. These vectors $v_i$ are called \textit{basis vectors}. Note that this basis is not unique; it is actually highly un-unique. 
\end{definition}

\begin{definition}
The basis $e_i$ of $\mathbb{F}^n$ are the vectors with every element equal to $0$ except for the $i$th element, which is equal to $1$. 
\end{definition}

\begin{proposition}
Every possible basis of a vector space $V$ has the same number of vectors.
\end{proposition}

\begin{proposition}
Any maximal linearly independent subset $\{ e_1, e_2, ..., e_k\}$ of a set $S$ is a basis of $\Span S$. 
\end{proposition}

\begin{definition}
The number of vectors in a basis of vector space $V$ is called the \textit{dimension} of $V$, denoted $\dim{V}$. 
\end{definition}

\begin{theorem}
Every $n$-dimensional vector space $V$ over $\mathbb{F}$ is isomorphic to $\mathbb{F}^n$, the set of $n$-tuples of elements in $\mathbb{F}$. 
\end{theorem}

\begin{corollary}
Vector spaces of the same field are isomorphic if and only if their dimensions are the same. 
\end{corollary}

\begin{example}
The field of complex numbers $\mathbb{C}$, regarded as a vector space over $\mathbb{R}$, has dimension $2$. The algebra of quaternions $\mathbb{H}$ has dimension $4$. 
\end{example}

\begin{definition}
A $(n - 1)$-dimensional subspace of an $n$-dimensional space is called a \textit{hyperplane}. 
\end{definition}

\begin{definition}
The sum of subspaces $U_1, U_2, ..., U_n \subset V$, denoted
\[U_1 + U_2 + U_3 + ... + U_n\]
is called the \textit{sum} of the subspaces $U_1, ..., U_n$. It is the set of all vectors that can be expressed as the sum of vectors in each of its respective space. That is, 
\[ \sum_{i=1}^n U_i \equiv \Big\{ \sum_{i = 1}^n u_i \;|\; u_i \in U_i\Big\}\]

\end{definition}

\begin{definition}[Direct Sum of Spaces]
Given subspaces $V_1, V_2, ..., V_n \subset V$ where the intersection between two $V_i$'s are pairwise disjoint, the \textit{direct sum} of the subspaces is the set of vectors that can be expressed uniquely as the sum of vectors in each of its respective spaces. That is, 
\[\bigoplus_{i=1}^n V_i \equiv \Big\{ \sum_{i=1}^n v_i \; | \; v_i \in V_i\Big\}\]
$V_1 \oplus V_2 \oplus ... \oplus V_n$ is also a vector space. 
\end{definition}

The crucial difference between the sum and the direct sum is that the direct sum requires the subspaces to be disjoint except for at the origin, which allows the expression of each vector in $V_1 \oplus ... \oplus V_n$ to be unique. It is also worth noting that the Cartesian product of vector spaces is merely just the set of tuples of vectors that are in each respective space and is \textit{not} a vector space (since addition and multiplication is not defined on that new set). If we define the operations component-wise, then 
\[ \prod_{i=1}^n V_i = \sum_{i=1}^n V_i\]

Note that we can also define the direct sum of spaces $U$ and $V$ by their basis. That is, given that the basis for $U$ is $\{e_i\}_{i=1}^n$ and the basis for $V$ is $\{f_j\}_{j=1}^n$, the basis for $U \oplus V$ is
\[\{(e_1, 0), (e_2, 0), ..., (e_n, 0), (0, f_1), ..., (0, f_m)\} \]

\begin{proposition}
\[\dim{\bigoplus_{i=1}^n V_i} = \sum_{i=1}^n \dim{V_i}\]
\end{proposition}
\begin{proof}
This follows from the basis construction of the direct sum of $V_i$'s. 
\end{proof}

\begin{definition}[Congruence Relations on Vector Spaces]
Given vector space $X$ and subspace $Y$ we say that two vectors $x_1$ and $x_2$ are \textit{congruent modulo $Y$}, denoted 
\[ x_1 \equiv x_2 \pmod{Y}\]
if $x_2 - x_1 \in Y$. This congruence is a \textit{relation}, meaning that it is symmetric, reflective, and transitive (elaborated in the abstract algebra chapter). The \textit{congruence classes} $\{ y\}$ is the set of all vectors that are congruent modulo $Y$ to $y$. 
\end{definition}

\begin{definition}[Quotient Vector Space]
The \textit{quotient space} modulo $Y$, denoted $ X / Y$, is the set of all congruence classes modulo $Y$. We can define addition and scalar multiplication on this set as such 
\[ \{ x\} + \{ y\} = \{ x + y\}\]
\end{definition}

\begin{proposition}
Given vector space $X$, $Y$ a subspace of $X$. Then, 
\[ X \simeq Y \oplus \frac{X}{Y}\]
\end{proposition}

Vector spaces over one field can be interpreted as a vector space over another field. This is most common when interpreting complex vector spaces as real ones. For example, given a complex vector space $Z$ with basis $\{z_1, z_2, ..., z_n\}$, every vector can be expressed as
\[z = \sum_{j=1}^n c_j z_j, \; c_j \in \mathbb{C}\]
We can set $c_j = a_j + b_j i$ uniquely, with $a, b \in \mathbb{R}$, and rewrite
\[z = \sum_{j=1}^n a_j z_j + b_j (i z_j)\]
$\implies \{ z_j\} \cup \{ i z_j\}$ forms a basis of $Z$ as a \textit{real vector space}. 

\subsection{Dual Spaces}
\begin{definition}
A \textit{linear map} is a homomorphism between vector spaces. That is, a linear map $f: X \longrightarrow Y$ has the properties 
\begin{align*}
    & \forall u, v \in X \; f(u + v) = f(u) + f(v) \\
    & \forall u \in X, c \in \mathbb{F} \; f(c u) = c f(u) 
\end{align*}
\end{definition}

\begin{definition}[Dual Space]
Given a vector space $V$ over $\mathbb{F}$, the \textit{dual vector space} $V^*$ is the set of all linear maps that, given a vector in $V$, outputs a scalar in $\mathbb{F}$. That is, 
\[ V^* \equiv \{ l \text{ linear} \; | \; l: V \longrightarrow \mathbb{F}\}\]
or equivalently, 
\[V^* \equiv \text{Hom}(V, \mathbb{F})\]
The addition and scalar multiplication of $V^*$ is defined pointwise. That is, given $l, m \in V^*$, 
\[(l + m) (x) = l(x) + m(x), \; (c l)(x) = c l(x)\]
\end{definition}

\begin{theorem}
\[ \dim{V} = n \implies \dim{V^*} = n\]
\end{theorem}

While we initially view elements of $V$ as "things" and elements of $V^*$ as linear functions, this thought is actually erroneous. Given $l \in V^*$, we see that 
\[l: V \longrightarrow \mathbb{F}\]
But since both $V$ and $V^*$ are vector spaces, we can also see that given $x \in V$, $x$ is also a linear function 
\[x: V^* \longrightarrow \mathbb{F}, \text{ where } x(l) \equiv l(x)\]
But this means that $x$ is an element of $V^{**}$ the dual of $V$! This statement is elaborated with the following theorem. 

\begin{theorem}[Canonical Isomorphisms of Double Duals]
$V^{**}$ is \textit{naturally, or canonically, isomorphic} to vector space $V$. However, $V$ is not naturally isomorphic to $V^*$. 
\end{theorem}

\begin{proof}
What we mean by natural is that we do not need to select a basis in either vector space to define the isomorphism. We fix a vector $l \in V^*$, and given $x \in V, \phi \in V^{**}$, we define
\[ \phi(l) \equiv l(x) \]
This defines a one-to-one correspondence between $V$ and $V^{**}$. On the contrary, there is no way to define an isomorphism between $V$ and $V^*$ without further structure on $V$. 
\end{proof}

It is important to be aware of this \textit{duality} between elements $x \in V$ and $l \in V^*$, and thus we should interpret $x \in V$ as a linear function of $V^*$ and $l \in V^*$ as a linear function of $V$.

\begin{definition}
Given a basis $\{ e_1, e_2, ..., e_n\}$ of $V$, the \textit{dual basis} $\{f_1, f_2, ..., f_n\}$ of $V^*$ has vectors satisfying 
\[ f_j (e_i) = \delta_{i j} = 
\begin{cases}
0 & i \neq j \\
1 & i = j
\end{cases}\]
where $\delta_{i j}$ is called the \textit{Kronecker delta function}. 
\end{definition}

\begin{definition}[Annihilator]
Let $Y$ be a subspace of $X$. Then the set of functions in $X^*$ that vanish on $Y$, that is, satisfy
\[l(y) = 0 \text{ for all } y \in Y\]
is called the \textit{annihilator} of $Y$, denoted $Y^0$. If $Y = X$, then it is easy to see that $Y^0$ is trivial. 
\end{definition}

\begin{theorem} Given subspace $Y$ of $X$ 
\[ Y^0 \simeq (X / Y)^*\]
\end{theorem}

\begin{proof}
The isomorphism is defined as such. Given $l \in Y^0$, we define $L \in (Y/X)^*$ as 
\[L\{x\} \equiv l(x)\]
\end{proof}

\begin{corollary}
\[\dim Y^0 + \dim Y = \dim X\]
\end{corollary}

\begin{corollary}
\[Y^{0 0} = Y\]
\end{corollary}

\begin{theorem}
Let $l$ be an interval on $\mathbb{R}$ containing $t_1, t_2, ..., t_n$ $n$ distinct points. Then, given any polynomial $p$ with degree $< n$, there exist $n$ real numbers $c_1, c_2, ..., c_n$ such that
\[ \int_l p(t) d t = c_1 p(t_1) + c_2 p(t_2) + ... + c_n p(t_n)\]
called the \textit{quadrature formula} suffices. That is, the integral of any polynomial over $l$ can be expressed as a linear combination of the polynomials evaluated at $n$ distinct points in $l$. 
\end{theorem}

\begin{proof}
The space of all polynomials with degree $< n$ is an $n$-dimensional vector space, denote it $V$. We define the basis of the dual space $V^*$ as 
\[\phi_i (p) \equiv p(t_i), \; i = 1, 2, ..., n\]
with addition and scalar multiplication defined
\begin{align*}
    & (\phi + \gamma) (p) \equiv \phi(p) + \gamma(p) \\
    & (c \phi) (p) \equiv c \phi (p) 
\end{align*}
We can see that the $\phi$'s are indeed linear since, given $p, q \in \mathbb{R}[t]$
\begin{align*}
    & \phi_i (p + q) = (p + q) (t_i) = p(t_i) + q(t_i) = \phi_i (p) + \phi_i (q) \\
    & \phi_i (c p) = (c p) (t_i) = c p(t_i) = c \phi_i (p)
\end{align*}
We claim that all the $phi_i$'s are linearly independent. Assume that \[\sum_{i=1}^n c_i \phi_i (p) = \sum_{i=1}^n c_i p(t_i) = 0\]
Since the $\phi$'s must be linearly independent for every polynomial $p$, set it equal to
\[q_k (t) \equiv \prod_{j \neq k} (t - t_j), \; k = 1, 2, ..., n\]
$p = q_k$ must imply that all $\phi_i (p) = 0$ for all $i \neq k$, which implies that $c_k = 0$ in the linear combination. Repeating this for $k = 1, 2, ..., n$ results in all $c_i = 0$, implying that the $\phi_i$'s form a basis of $V^*$. Clearly, the function of definite integration over $l$ is a linear mapping from $V \longrightarrow \mathbb{R}$, meaning that it is in $V^*$. Therefore, it can be expressed as a linear combination of $\phi_i$'s. 
\end{proof}

\section{Linear Maps}
Remember that a linear transformation is just a homomorphism between vector spaces. That is, given linear transformation $T: U \longrightarrow V$, 
\[T \in \text{Hom}(U,V)\]
We can visualize all linear transformations as "transforming" the axes as shown below. 
\begin{center}
    \includegraphics[scale=0.25]{Linear_Map.PNG}
\end{center}

\begin{definition}[Image]
The \textit{image or range} of $T: U \longrightarrow V$ is the image of $U$ under $T$, denoted Im$T$. 
\[\im{T} \equiv \{ T(u) \; | \; u \in U\} \subset V\]
The \textit{kernel or nullspace} of $T$ is the subset of $U$ that is mapped onto $0$, denoted ker$T$. 
\[\text{ker}\,T \equiv \{ u \in U \; | \; T(u) = 0\} \]
\end{definition}

\begin{example}
Let $U_1$ be a subspace of $U$ and given the quotient map
\[ \pi: U \longrightarrow U / U_1\]
Then, 
\[\text{ker}\,\pi = U_1, \; \im{\pi} = U / U_1\]
Note that a quotient map is always surjective. 
\end{example}

\begin{theorem}[Rank Nullity Theorem]
Let $T: U \longrightarrow V$ be linear. Then, 
\[ \dim \ker T + \dim \im T = \dim U\]
This theorem is quite intuitive, if we visualize the map. We just have to realize that given a linear transformation mapping from a $n$-dimensional $V$ to a $m$-dimensional $U$, every vector in $V$ will either get mapped to $0 \in U$ or will get mapped to a nonzero vector in $U$. 
\begin{center}
    \includegraphics[scale=0.4]{Rank_Nullity.PNG}
\end{center}
\end{theorem}

\begin{proposition}
Hom$(U, V)$ is the vector space of linear mappings, with addition and scalar multiplication defined
\begin{align*}
    & (S + T) (x) \equiv S(x) + T(x) \\
    & (c T) (x) \equiv c T(x)
\end{align*}
\end{proposition}

\begin{definition}
The \textit{composition} of linear functions, denoted with $\circ$, is defined
\[ (S \circ T) (x) \equiv S\big( T(x)\big) \]
Given $T \in $ Hom$(U, V)$ and $S \in $ Hom$(V, W)$, then $S \circ T \in $ Hom$(U, W)$. For simplicity, we also denote the composition as 
\[ S \circ T \equiv S T\]
\end{definition}

\begin{proposition}
Composition is (right and left) distributive with respect to the addition of linear maps. That is, 
\begin{align*}
    & (R + S) \circ T = R \circ T + S \circ T \\
    & T \circ (R + S) = T \circ R + T \circ S 
\end{align*}
\end{proposition}

\begin{definition}
An \textit{algebra} $A$ is a vector space with the additional operation of vector multiplication. That is, $A$ is closed under 
\[\circ: A \times A \longrightarrow A\] 
An algebra is \textit{associative} if multiplication is associative. That is, given $R, S, T \in A$
\[ R \circ (S \circ T) = (R \circ S) \circ T \]
Note that multiplication is not necessarily commutative. 
\end{definition}

\begin{proposition}
End$(V)$ is an associative, noncommutative algebra. 
\end{proposition}

\begin{example}
A rotation around any axis or a flip across any hyperplane is an element of End$(\mathbb{R}^n)$. 
\end{example}

\begin{definition}
A \textit{projection mapping} is a linear mapping $P$ where 
\[ P = P^2\]
\end{definition}

\begin{example}
Let $P$ be an orthogonal projection mapping onto a subspace $Y$ of $X$. $\im P = Y$, and $\ker P = Y^\perp$ or the span of vectors in $X$ that are "orthogonal" to $Y$. Note that we haven't actually endowed a structure onto $X$ to even define orthogonality yet, so this definition is purely visual and not mathematically rigorous. 
\end{example}

\begin{example}
Reflections, projections, shears, and rotations are all linear maps. Differentiation and integration are also examples of linear mappings. 
\end{example}

\begin{remark}
Linear maps over vector spaces over different fields are generally not well defined since the definition of homomorphisms do not cover the fields in which vector spaces are associated with. 
\end{remark}

\begin{theorem}
Given $A: V \longrightarrow U$ a linear mapping between vector spaces and $b \in U$, all solutions to the equation $Ax = b$ is in $a + \ker A$, that is, of the form 
\[ x = a + y, \; y \in \ker A\]
where $x = a$ is one solution. 
\end{theorem}

\begin{corollary}
A linear map $A$ is injective if and only if $\ker A = 0$.
\end{corollary}

\begin{definition}
The \textit{rank} of a linear map $A$ is the dimension of its image. 
\end{definition}

\subsection{Factorization of Linear Maps}
\begin{definition}
Let $\varphi: U \longrightarrow V$ be a linear mapping and let $U_1 \subset U, V_1 \subset V$ be subspaces. Such that \[\varphi u \in V \text{ for all } u \in U\]
Then, the linear mapping 
\[\varphi_1: U_1 \longrightarrow V_1, \; \varphi_1 u = \varphi_u, u \in U_1\]
is called the \textit{restriction} of $\varphi$ to $U_1, V_1$. It suffices the identity
\[\varphi \circ i_U = i_V \circ \varphi_1\]
where $i_U: U_1 \longrightarrow U, i_V: V_1 \longrightarrow V$ are canonical injections. Equivalently, we say that the diagram below is \textit{commutative}. 
\[
  \begin{tikzcd}
    U \arrow{r}{\varphi} & V \\
    U_1 \arrow{u}{i_U} \arrow{r}{\varphi_1} & V_1 \arrow{u}{i_V}
  \end{tikzcd}
\]
We can also define 
\[\varphi_1 \equiv i_v^{-1} \varphi i_U\]
\end{definition}

The construction of the restriction is an enormously helpful tool for many proofs and very useful for factoring linear mappings. 

\begin{definition}
Given $\varphi: U \longrightarrow V$ with quotient maps 
\[\pi_U: U \longrightarrow U / U_1, \; \pi_V: V \longrightarrow V / V_1 \]
the \textit{induced mapping of the quotient spaces} is the unique mapping $\bar{\varphi}: U/U_1 \longrightarrow V / V_1$ such that 
\[\bar{\varphi} \circ \pi_U = \pi_V \circ \varphi\]
or equivalently, the following diagram commutes. 
\[\begin{tikzcd}
    U \arrow{r}{\varphi} \arrow{d}{\pi_U} & V \arrow{d}{\pi_V}\\
    U / U_1 \arrow{r}{\bar{\varphi}} & F / F_1
\end{tikzcd}\]
\end{definition} 

\begin{theorem}
Every linear mapping can be written as the composition of a surjective mapping followed by an injective mapping. That is, every $A$ can be factored into 
\[A = A_{inj} \circ A_{surj}\]
\end{theorem}
\begin{proof}
We can induce a quotient mapping to construct a factoring of a linear mapping. We can define the unique mapping 
\[\bar{\varphi}: U / \ker{U} \longrightarrow F\]
such that, $\varphi = \bar{\varphi} \circ \pi_U$, or that 
\[\begin{tikzcd}
     U \arrow{r}{\varphi} \arrow{d}{\pi_U} & V \\
     U / \ker{\varphi} \arrow{ru}{\bar{\varphi}}
\end{tikzcd} \]
commutes. Clearly, $\bar{\varphi}$ is injective since if it were not, $\bar{\varphi} \pi_U x = 0 \implies \varphi x = 0 \implies x \in \ker{\varphi} \implies \pi_U x = 0$. This also means that the restriction of $\bar{\varphi}$ to $U / \ker{\varphi}$
\[\bar{\bar{\varphi}}: U / \ker{\varphi} \longrightarrow \im{\varphi}\]
is a linear isomorphism. Thus, for any $\varphi$, it can be written as $\bar{\varphi} \circ \pi_U$, with $\bar{\varphi}$ injective and $\pi_U$ surjective. 
\end{proof}

\begin{proposition}
Given $E_1, E_2$ subspaces of $E$. Then, 
\[\frac{E_1}{E_1 \cap E_2} \simeq \frac{E_1 + E_2}{E_2}\]
In fact, they are naturally isomorphic. 
\end{proposition}
\begin{proof}
$E_1 + E_2$ can be decomposed to $E_1^\prime \oplus (E_1 \cap E_2) \oplus E_2^\prime$, where $E_1^\prime$ consists of the subspace of vectors $x$ that can only be expressed as $x = x_1, x_1 \in E_1$ and $E_2^\prime$ are vectors that can only be expressed as $x = x_2, x_2 \in E_2$. Define the projection mapping
\[\text{proj}: E_1 + E_2 \longrightarrow E_1^\prime\]
Since $E_1 = E_1^\prime \oplus (E_1 \cap E_2)$, we can define the natural isomorphism 
\[\kappa: E_1^\prime \longrightarrow \frac{E_1}{E_1 \cap E_2}, \; \kappa{x} = \{x\}\]
We now define the mapping $\varphi: E_1^\prime \longrightarrow (E_1 + E_2) / E_2$ such that
\[\pi = \varphi \text{proj}\]
given by the diagram 
\[\begin{tikzcd} 
    E_1 + E_2 \arrow{d}{proj} \arrow{r}{\pi} & \frac{E_1 + E_2}{E_2} \\
    E_1^\prime \arrow{ru}{\varphi} \arrow{r}{\kappa} & \frac{E_1}{E_1 \cap E_2}
\end{tikzcd}\]
Such a $\varphi$ exists because proj is surjective and can thus be inverted. We now claim that $\varphi$ is an isomorphism. $\ker{\text{proj}} = \ker{\pi} = E_2 \implies \kappa$ is injective. Given $x = x_1 + y + x_2 \in E_1 + E_2$ such that $x_1 \in E_1^\prime, y \in E_1 \cap E_2, x_2 \in E_2^\prime$, 
\[\pi(x) = \pi(x_1 + y + x_2) = \pi(x_1) = \varphi \text{proj} (x_1) = \varphi (x_1)\]
meaning that for every vector $v \in (E_1 + E_2) / E_2$, it can be expressed as $v = \pi (x) = \varphi (x_1)$, meaning that there exists a $x_1 \in E_1^\prime$ mapping to $v$ under $\varphi \iff \varphi$ is surjective. So, $\varphi$ is an isomorphism $\implies \varphi \kappa^{-1}$ is an isomorphism.  
\end{proof}

\begin{corollary}
In the special case when $E_1 \oplus E_2 = E$, then the proposition states that 
\[E_1 \simeq \frac{E}{E_2}\]
\end{corollary}

Let $f_1, f_2, ..., f_n$ be any $n$ linear functionals of $U$. Define the subspace $F \subset E$ as 
\[ F \equiv \bigcap_{i=1}^n \ker{f_i}\]
and define linear map 
\[\phi: U \longrightarrow \mathbb{F}^n, \;\phi(x) \equiv (f_1(x), f_2(x), ..., f_n(x))\]
$\implies \ker{\phi} = F$. So, $\phi: U \longrightarrow \mathbb{F}^n$ defines the isomorphism 
\[\bar{\phi}: U / F \longrightarrow \im{\phi}\]

\begin{proposition}
Given linear mappings $\phi: E \longrightarrow F$, $\psi: E \longrightarrow G$ such that
\[\ker{\phi} \subseteq \ker{\psi}\]
Then there exists a map $\kappa$ such that 
\[ \psi = \kappa \phi\]
or equivalently, such that the diagram below commutes. 
\[\begin{tikzcd} 
    E \arrow{r}{\phi} \arrow{d}{\psi} & F \arrow{dl}{\kappa} \\
    G 
\end{tikzcd}\]
\end{proposition}

Now, we introduce the concept of exact sequences which is useful in the factoring of linear maps. Note that exact sequences are used in group theory to factor transformation groups. 

\begin{definition}
A sequence of linear mappings 
\[F \xrightarrow{\varphi} E \xrightarrow{\psi} G\]
is \textit{exact at E} if
\[ \im{\varphi} = \ker{\psi}\]
\end{definition}

Notice that if we have an exact sequence 
\[0 \xrightarrow{\varphi} E \xrightarrow{\psi} G\]
then, $0 = \im{\varphi} = \ker{\psi} \implies \psi$ is injective. If we have exact sequence 
\[F \xrightarrow{\varphi} E \xrightarrow{\psi} 0\]
then, $\im{\varphi} = \ker{\psi} = E \implies \varphi$ is surjective. 

\begin{definition}
A \textit{short exact sequence} is a sequence of the form
\[0 \xrightarrow{} F \xrightarrow{\varphi} E \xrightarrow{\psi} G \xrightarrow{} 0\]
such that it is exact at $F, E$, and $G$. It is clear that the first and last maps are the zero maps. With this definition, we can easily prove that

i) $\varphi$ is injective

ii) $\psi$ is surjective

iii) $E / \im{F} \simeq G$
\end{definition}

\begin{example}
The sequence 
\[0 \xrightarrow{} E_1 \xrightarrow{i} E \xrightarrow{\pi} E / E_1 \xrightarrow{} 0\]
is exact, where $i$ denotes the canonical injection and $\pi$ the canonical projection. This example is the only example of an exact sequence between vector spaces up to isomorphism. 
\end{example}

\begin{definition}
A commutative diagram of the form
\[\begin{tikzcd}
    0 \arrow{r} & F_1 \arrow{d}{\alpha} \arrow{r}{\varphi_1} & E_1 \arrow{d}{\beta} \arrow{r}{\psi_1} & G_1 \arrow{d}{\gamma} \arrow{r} & 0 \\
    0 \arrow{r} & F_2 \arrow{r}{\varphi_2} & E_2 \arrow{r}{\psi_2} & G_2 \arrow{r} & 0 
\end{tikzcd}\]
where both horizontal sequences are short exact sequences and $\alpha, \beta, \gamma$ are homomorphisms between linear spaces is a \textit{homomorphism of exact sequences}. If $\alpha, \beta, \gamma$ are linear isomorphisms, then this is an \textit{isomorphism of exact sequences}. 
\end{definition}

\begin{proposition}
A short exact sequence of vector spaces
\[0 \xrightarrow{} F \xrightarrow{\varphi} E \xrightarrow{\psi} G \xrightarrow{} 0\]
is split if it essentially presents $E$ as the direct sum of groups $F$ and $G$. That is, there exists an isomorphism of exact sequences.
\[\begin{tikzcd}
    0 \arrow{r} & F \arrow{d}{\alpha} \arrow{r}{\varphi_1} & E \arrow{d}{\beta} \arrow{r}{\psi_1} & G \arrow{d}{\gamma} \arrow{r} & 0 \\
    0 \arrow{r} & F \arrow{r}{\varphi_2} & F \oplus G \arrow{r}{\psi_2} & G \arrow{r} & 0 
\end{tikzcd}\]
or equivalently, there exists an isomorphism between $E$ and $F \oplus G$. 
\end{proposition}

\begin{definition}
Given a short exact sequence
\[0 \xrightarrow{} F \xrightarrow{\varphi} E \xrightarrow{\psi} G \xrightarrow{} 0\]
if there exists a map $\kappa: G \longrightarrow E$, such that $ \psi \circ \kappa = I$, then the sequence is said to be a \textit{split short exact sequence}, written
\[0 \xrightarrow{} F \xrightarrow{\varphi} E \xleftrightarrow{\psi, \kappa} G \xrightarrow{} 0\]
\end{definition}

\begin{proposition}
Every short exact sequence can be split. 
\end{proposition}
\begin{proof}
It will be proved later that $\psi$ is surjective $\implies$ $\psi$ is left invertible. 
\end{proof}

\begin{definition}
Given $\varphi: E \longrightarrow E$, a subspace $E_1 \subset E$ is called \textit{stable} 
\[x \in E_1 \implies \varphi x \in E_1\]
That is, the restriction of $\varphi$ to $E_1$, denoted
\[\varphi: E_1 \longrightarrow E_1\]
is well-defined. Clearly, $\im{\varphi}$ and $\ker{\varphi}$ is stable, and the induced map 
\[\bar{\varphi}: E / E_1 \longrightarrow E / E_1\]
is a linear endomorphism of $E / E_1$. 
\end{definition}

We end this subsection by defining the induced linear map from the direct sum of spaces. 
\begin{definition}
Given linear maps $A_i \in$ End$(V_i)$ for $i = 1, 2, ..., n$, the induced linear map
\[\bigoplus_{i =1}^n A_i: \bigoplus_{i=1}^n V_i \longrightarrow \bigoplus_{i=1}^n V_i\]
is defined
\[(\bigoplus_{i=1}^n A_i)(\bigoplus_{i=1}^n x_i) \equiv \bigoplus_{i=1}^n A_i x_i\]
\end{definition}

\subsection{Invertibility and Transpose}
We now introduce the concepts of left and right invertibility of linear mappings. 

\begin{theorem}
A linear mapping $T: U \longrightarrow V$, with $\dim{U} = n, \dim{V} = m$, is \textit{left-invertible}. That is, there exists linear $S$ such that 
\[S T = I\]
if and only if $T$ is injective $\iff$ rank$(T) = n$. Linear $T$ is \textit{right-invertible}, that is, there exists linear $S$ such that 
\[T S = I\]
if and only if $T$ is surjective $\iff$ rank$(T) = m$. 
\end{theorem}
\begin{proof}
We will only prove the case for left-invertibility. Right invertibility follows analogously. \\
$(\leftarrow)$ $T$ is injective $\implies$ rank$(T) = \dim{U} = \dim{\im{T}}$. Let $(\im{T})^\prime$ exist such that 
\[\im{T} \oplus (\im{T})^\prime = V\]
We define the isomorphism 
\[\Tilde{T}: V \longrightarrow \im{T}\]
and then define $S$. Given that $v = w + w^\prime \in V$, with $w \in \im{T}, w^\prime \in (\im{T})^\prime$, 
\[S : V \longrightarrow U, \; S(v) \equiv \Tilde{T}^{-1} (v)\]
$\implies S T (u) = \Tilde{T}^{-1} T (u) = u \iff S T = I$. \\
$(\rightarrow)$ We prove the contrapositive. $T$ is not injective $\implies \dim{\ker{T}} > 0 \implies $ there exists 2 linearly independent vectors $x, y \in U$ such that
\[T x = T y\]
Assume that a left inverse $S$ exists. Then 
\[x = S T x = S T y = y \implies x = y\]
leading to a contradiction $\implies$ the left-inverse does not exist. 
\end{proof}

\begin{definition}
The inverse of a linear map $A$, denoted $A^{-1}$ is a unique linear map satisfying 
\[ A A^{-1} = A^{-1} A = I\]
where $I$ is the identity map. 
\end{definition}

\begin{corollary}
A linear map is invertible if and only if it is an isomorphism. 
\end{corollary}

We finally end this section by defining the transpose of a linear mapping. 

\begin{definition}
Given a linear mapping $A: U \longrightarrow V$, let there exist a certain $\varphi \in V^*$. Then, there exists a corresponding $l \in U^*$ such that 
\[ l \equiv \varphi A \]
This mapping $A^T: V^* \longrightarrow U^*$ that assigns every $\varphi$ to a corresponding $l$ is called the \textit{transpose} of $A$. Note that the transpose is canonically formed when defining any linear map. We do not need any additional structure on $U$ or $V$ to define $A^T$.
\[
  \begin{tikzcd}
    U \arrow{r}{A} \arrow[swap]{dr}{l = \varphi A} & V \arrow{d}{\varphi} \\
    & \mathbb{F}
  \end{tikzcd}
\]
\end{definition}

It is worth mentioning that $A^T$ maps every element in the annihilator $V^0$ to an element in $U^0$, but not necessarily the other way around. 

\begin{theorem}
\[ (\im A)^0 = \ker A^T \text{ or equivalently, } \im A = (\ker A^T)^0\]
\end{theorem}

\section{Metrics, Norms, and Inner Products} 
Given a vector space $V$, we can induce different structures on it to allow us to conduct different measurements on it. For example, the endowment of the basis structure on $V$ allows us to represent vector as an $n$-tuple of scalars. Some structures may induce other structures, such as the inner product inducing a norm or a metric inducing a norm. We will begin by defining these structures. It must be further noted that in order to induce such structures on $V$, its base field $\mathbb{F}$ must be ordered. We will treat $\mathbb{F} = \mathbb{C}$ for the following definitions. 

\begin{definition}
A \textit{metric} on a vector space $V$ over field $\mathbb{C}$ is a mapping
\[d: V \times V \longrightarrow \mathbb{R} \]
satisfying three properties 
\begin{enumerate}
    \item $d(x, y) = d(y, x)$
    \item $d(x, y) \geq 0$, with $d(x,y) = 0 \iff x=y$
    \item $d(x, y) + d(y,z) \geq d(x,z)$
\end{enumerate}
A metric allows us to define some notion of distance in $V$. A vector space $V$ with a metric is called a \textit{metric space}, denoted $(V, d)$. 
\end{definition}

\begin{definition}
A \textit{norm} on a vector space $V$ over field $\mathbb{C}$ is a mapping 
\[\rho: V \longrightarrow \mathbb{R}\]
satisfying three properties 
\begin{enumerate}
    \item $\rho (x) \geq 0$, with $\rho(x) = 0 \iff x = 0$
    \item For $a \in \mathbb{C}$, $\rho (a x) = |a| \rho(x)$ 
    \item $\rho(x + y) \leq \rho(x) + \rho(y)$ 
\end{enumerate}
A norm allows us to define some notion of a magnitude or length on each vector in $V$. A vector space $V$ with a norm is called a \textit{normed space}, denoted $(V, \rho)$. 
\end{definition}

\begin{example}[Absolute Value]
The absolute value function $|\cdot|: \mathbb{C} \longrightarrow \mathbb{R}_+$ is an example of a norm on the 1 dimensional space $\mathbb{C}$. 
\end{example}

\begin{example}[Euclidean Norm, $L_2$-Norm]
The Euclidean norm of a vector $x \equiv (x_1, x_2, ..., x_n)^T \in \mathbb{R}^n$ is defined
\[ ||x||_2 \equiv \bigg( \sum_{i=1}^n x_i^2 \bigg)^{\frac{1}{2}}\]
This is the most commonly used norm in $\mathbb{R}^n$. 
\end{example}

\begin{example}[Taxicab Norm, Manhattan Norm]
The Taxicab norm of $x \equiv (x_1, x_2, ..., x_n)^T \in \mathbb{R}^n$ is defined
\[ ||x||_1 \equiv \sum_{i=1}^n |x_i|\]
\end{example}

\begin{example}[Infinity Norm, $L_\infty$-Norm]
The Infinity norm of vector $x \equiv (x_1, x_2, ..., x_n)^T \in \mathbb{R}^n$ is defined
\[ ||x||_\infty \equiv \max{\{|x_1|, |x_2|, ..., |x_n|\}}\]
\end{example}

\begin{example}[p-norm, $L_p$-Norm]
Let $p\geq 1$ be a real number. The p-norm of a vector $x \equiv (x_1, x_2, ..., x_n)^T \in \mathbb{R}^n$ is defined
\[ ||x||_p \equiv \bigg( \sum_{i=1}^n x_i^p \bigg)^{\frac{1}{p}}\]
For $0<p<1$, this function could be of some use, but it is not considered a norm since it violates the triangle inequality. When $p = 1$ and $p =2$, the norm is the Taxicab norm and Euclidean norm, respectively, and 
\[ \lim_{p \rightarrow \infty} ||\cdot||_p = ||\cdot||_\infty\]
\end{example}

\begin{definition}
A \textit{seminorm}, or a pseudo-norm, has the same properties except that $\rho(x) = 0$ does not necessarily imply that $x = 0$. That is, nonzero vectors can have norms of $0$. 
\end{definition}

\begin{proposition}
Every norm induces a metric in the following way
\[ d(x, y) \equiv \rho(x-y)\]
However, a metric does not necessarily induce a norm because the definition
\[\rho(x) \equiv d(x, 0)\]
is not guaranteed to have all properties of the norm. 
\end{proposition}

\begin{definition}
An \textit{inner product} on a vector space $V$ over field $\mathbb{C}$ is a mapping 
\[(\cdot, \cdot): V \times V \longrightarrow \mathbb{R}\]
satisfying three properties 
\begin{enumerate}
    \item First Argument Linearity: $(\lambda x + \mu y, z) = \lambda (x, z) + \mu (y, z)$
    \item Conjugate symmetry: $(x, y) = \bar{(y, x)}$
    \item $(x, y) \geq 0$, with $(x, y) = 0 \iff x = y$
\end{enumerate}
An inner product allows us to define some notion of an angle between two vectors in $V$. A vector space $V$ with an inner product is called an \textit{inner product space}. Note that when the field is $\mathbb{C}$, the inner product is \textit{sesqui-linear}, that is, linear with respect to the first argument and \textit{skew linear} with respect to the second. When $\mathbb{R}$, it is bilinear. 
\end{definition}

\begin{remark}
The inner product of a vector space $V$ over $\mathbb{R}$ is an element of $V^* \otimes V^*$. This concept of the metric tensor occurs when studying Riemannian manifolds in general relativity. 
\end{remark}

\begin{definition}
An inner product induces a norm in the following way
\[||x|| \equiv \sqrt{(x,x)} \]
\end{definition}

\begin{theorem}[Schwarz Inequality]
For all $x, y \in V$, 
\[ |(x, y)| \leq ||x|| ||y||\]
\end{theorem}

\begin{example}[Dot Product]
Given vectors $x, y \in \mathbb{R}^n$, 
\[ x \cdot y \equiv  \begin{pmatrix}
x_1\\x_2\\\vdots\\x_n
\end{pmatrix} \cdot \begin{pmatrix}
y_1\\y_2\\\vdots\\y_n
\end{pmatrix} \equiv \sum_{i=1}^n x_i y_i\]
\end{example}

\begin{example}[Integral Product]
Let $C^0[a, b]$ be the space of all continuous real-valued functions defined over the interval $[a,b] \subset \mathbb{R}$. Given $f, g \in C^0[a,b]$, 
\[(f, g) \equiv \int_a^b f(x)g(x) d x\]
is an inner product on $C^0[a, b]$. 
\end{example}

\begin{theorem}[Pythagorean Theorem]
\[ ||x||^2 + ||y||^2 = ||x+y||^2\]
\end{theorem}

\begin{theorem}
\[||x|| = \max_{||y||=1} (x, y)\]
\end{theorem}

\begin{definition}
Two vectors $x, y$ of an inner product space are said to be \textit{orthogonal} if 
\[(x, y) = 0\]
\end{definition}

Note that the definition of orthogonality is dependent on the definition of the inner product. If the inner product is defined differently, then orthogonality will be defined differently. In the case when the inner product is defined to be the dot product, orthogonality is defined to be the "normal" perpendicularity between vectors. We can further define subspaces to be orthogonal. 

\begin{definition}
Two subspaces $Y, Z$ of inner product space $Z$ are said to be orthogonal to each other if 
\[(y, z) = 0 \text{   for every } y \in Y, z \in Z\]
\end{definition}

\begin{definition}
Given a subspace $Y$ of inner product space $X$, the \textit{orthogonal complement} of $Y$, denoted $Y^\perp$, is defined
\[ \{ x \in X \; | \; (x, y) = 0 \;\;\; \forall y \in Y\}\]
which is the set of all vectors in $X$ orthogonal to every vector in $Y$. Clearly, $Y \oplus Y^\perp = X$. 
\end{definition}

The concept of orthogonality also allows us to define orthogonal projections onto a vector or subspace. 

\begin{definition}
Let $x \in X$ and let $Y$ be a subspace of $X$. Then $x$ can be decomposed into the form $x = y + z, \; y \in Y, z \in Y^\perp$. The \textit{orthogonal projection} of $x$ onto $Y$ is then defined as 
\[\text{proj}_Y (x) = y\]
Orthogonal projections are linear transformations. 
\end{definition}

\begin{proposition}
Given that $x \in \mathbb{R}^n$ is projected onto a 1-dimensional subspace $Y$. The orthogonal projection of $x$ onto $Y$ can be computed with the formula 
\[\text{proj}_Y (x) = \frac{x \cdot y}{||y||^2} y\]
where $y$ is an arbitrary vector in $Y$ and $\cdot$ is the dot product in $\mathbb{R}^n$. Furthermore, for a $k$-dimensional subspace $Y$, we can calculate the projection by first adding up the projections of $x$ onto a set of basis vectors of $Y$ and then adding them up. That is, given basis $r_1, r_2, ..., r_k$ of $Y$,
\begin{equation*}
    \text{proj}_Y (x) = \sum_{i=1}^k \text{proj}_{r_i} (x) = \sum_{i=1}^k \frac{x \cdot r_i}{||r_i||^2} r_i 
\end{equation*}
\end{proposition}

\begin{theorem}
Every inner product space has a basis consisting of vectors that are pairwise orthogonal, called an \textit{orthogonal basis}. Furthermore, each vector in the orthogonal basis can be scaled to have magnitude 1, forming an \textit{orthonormal basis}.  
\end{theorem}

\begin{proof}
The algorithm used to construct an orthonormal basis is called \textit{Grahm-Schmidt}. We start off with any basis, not necessarily orthonormal, of $X$, denoted $\{x_1, x_2, ..., x_n\}$. We first assign 
\[x_1 = l_1\]
Then we take $x_2$ and find the orthogonal component (with respect to $l_1$) with the equation
\[l_2 = x_2 - \text{proj}_{l_1} (x_2)\]
This creates an orthogonal basis for span$\{x_1, x_2\}$. Then we take $x_3$ and find the orthogonal component (with respect to span$\{l_1, l_2\}$. 
\[l_3 = x_3 - \text{proj}_{l_1} (x_3) - \text{proj}_{l_2} (x_3)\]
This creates an orthogonal basis for span$\{x_1, x_2, x_3\}$. We repeat this process until we complete the basis of $X$, using the general equation
\[l_k = x_k - \sum_{i=1}^{k-1} \text{proj}_{l_k} (x_k) = x_k - \sum_{i=1}^{k-1} \frac{x_k \cdot l_k}{||l_k||^2} l_k, \; k = 1, 2, ..., n\]
Finally, we take these orthogonal vectors and normalize them to magnitude 1. Note that this algorithm does not produce a unique orthonormal basis. Rather, it is highly un-unique. 
\end{proof}

Given that we have an orthonormal basis $\{r_i\}_{i=1}^k$ of subspace $Y$ in $\mathbb{R}^n$, we can more simply define 
\[ \text{proj}_Y (x) = \sum_{i=1}^k (x \cdot r_i) r_i \]

\begin{theorem}
The inner product endowed on $V$ induces a natural isomorphism between $V$ and $V^*$. 
\end{theorem}
\begin{proof}
We fix $y \in V$ and simply define the isomorphism to be. 
\[ l(y) \equiv (x, y)\]
which defines a bijection between $x \in V$ and $l \in V^*$. 
\end{proof}

Note that given vector spaces $U, V$, the set of all linear mappings $A: U \longrightarrow V$ also forms a vector space. More specifically, it is a rank (1,1) tensor product space. This means that we can define similar Euclidean structures on them. The norm of a matrix is worth mentioning. 



Note that the structures and concepts of metrics, norms, inner products, distances, magnitudes, orthogonality, and basis are not intrinsic properties of the vector space. So, we will not assume the existence of these structures unless otherwise stated or explicitly implied. 

\section{Matrices}
\subsection{Representations of Linear Maps}
We now describe the construction of the matrix realization of a linear map from $V \longrightarrow U$. In order to do this, we \textit{must} define a basis for each $V$ and $U$. If $V = U$, then we usually define the same basis for both the domain and codomain. 

Let the basis for $U$ be $\{ u_1, u_2, ..., u_n\}$ and the basis of $V$ be $\{v_1, v_2, ..., v_m\}$. In fact, the assignment of this specific basis is a linear map in of itself. That is, 
\begin{align*}
    i: U \longrightarrow \mathbb{F}^n, \; i(u_\alpha) = e_\alpha  \\
    j: V \longrightarrow \mathbb{F}^m, \; j(v_\beta) = e_\beta 
\end{align*}
However, we do not usually include this transformation in the notation. We just denote $i(u)$ as $u$ and $j(v)$ as $v$. Every vector $u \in U$ can then be represented as a linear combination
\[u = \sum_{j=1}^n c_j u_j\]
By linearity of the mapping $A: U \longrightarrow V$, 
\[ A u = A \bigg( \sum_{j=1}^n c_j u_j \bigg) = \sum_{j=1}^n c_j A u_j \]
This means that $A$ can be completely, uniquely determined by defining how it maps the $n$ basis vectors $u_j \in U$, that is, by defining the values 
\[ A u_1, A u_2, ..., A u_{n-1}, A u_n\]
Each $A u_j$ will be an element of $V$, which means that $A u_j$ can be decomposed into the linear combination of $v_i$'s. That is, 
\[ A u_j = \sum_{i=1}^m a_{i j} v_i, \; j = 1, 2, ..., n \]
We are done. Given the basis of the domain and codomain, the elements $a_{i j}$ are precisely the entries of the $m \times n$ matrix $(1 \leq i \leq m, 1 \leq j \leq n)$. 
\[ v = A u \iff 
\begin{pmatrix}
 b_1 \\ b_2 \\ \vdots \\ b_m
\end{pmatrix}
= \begin{pmatrix}
 a_{1 1} & a_{1 2} & \ldots & a_{1 n} \\
 a_{2 1} & a_{2 2} & \ldots & a_{2 n} \\
 \vdots & \vdots & \ddots & \vdots \\
 a_{m 1} & a_{m 2} & \ldots & a_{m n} 
\end{pmatrix} \begin{pmatrix}
 c_1 \\ c_2 \\ c_3 \\ \vdots \\ c_n
\end{pmatrix}\]

It is important to note that the matrix is \textit{not} $A$ in of itself. In the most rigorous sense, the matrix $A$ is really just equal to the composition of mappings $ j^{-1} A i$, but for simplicity it is just written as $A$. It is just one representation of a linear map given the two bases of the domain and codomain. Furthermore, as soon as one writes down a matrix to represent a linear map, they are automatically assuming some choice of basis given by $i$ and $j$. 

\begin{definition}
The \textit{algebra} of $n \times n$ matrices over field $\mathbb{F}$, denoted Mat$(n, \mathbb{F})$, is defined with regular matrix addition and multiplication. 
\end{definition}

Furthermore, we can define the mapping between linear operators $T: \mathbb{F}^n \longrightarrow \mathbb{F}^m$ and $m \times n$ matrices (given that there is a basis for both $\mathbb{F}^n, \mathbb{F}^m$. 

\begin{definition}
The linear mapping between the algebras 
\[\rho: \text{Hom}(\mathbb{F}^n, \mathbb{F}^m) \longrightarrow \text{Mat}(m \times n, \mathbb{F})\]
is a multiplicative group homomorphism. This mapping that assigns abstract group elements of linear mappings to matrices is called a \textit{representation}. 
\end{definition}

\begin{proposition}
Mat$(n, \mathbb{F}) \simeq $ End$(\mathbb{F}^n)$ 
\end{proposition}
\begin{proof}
A matrix is completely determined by the basis mapping $i$. By definition, a linear mapping over $\mathbb{F}$ is a basis mapping if and only if it is an element of End$(\mathbb{F}^n)$. 
\end{proof}

Note that the composition operation in the algebra of linear operators is realized as the operation of matrix multiplication. These are two distinct operations that are related only through the basis mappings $i$ and $j$. 

\begin{example}
Let $\alpha: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ be the linear transformation of the counterclockwise rotation by $\theta$ and $\beta: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ be the counterclockwise rotation of $\phi$. Then the matrix representation of $\alpha \circ \beta$ is 
\begin{align*}
    & \begin{pmatrix}
\cos{\theta} & - \sin{\theta} \\
\sin{\theta} & \cos{\theta}
\end{pmatrix} \begin{pmatrix}
\cos{\phi} & - \sin{\phi} \\
\sin{\phi} & \cos{\phi} 
\end{pmatrix} \\
 & = \begin{pmatrix}
\cos{\theta} \cos{\phi} - \sin{\theta} \sin{\phi} & - \sin{\phi} \cos{\theta} - \cos{\phi} \sin{\theta} \\
\sin{\theta} \cos{\phi} + \cos{\theta} \sin{\phi} & - \sin{\theta} \sin{\phi} + \cos{\theta} \cos{\phi}
\end{pmatrix}
\end{align*}
But the counterclockwise rotation by $\theta$ and then $\phi$ is really just a counterclockwise rotation by $\theta + \phi$, which has the matrix representation
\[\begin{pmatrix}
\cos{(\theta + \phi)} & - \sin{(\theta + \phi)} \\
\sin{(\theta + \phi)} & \cos{(\theta + \phi)}
\end{pmatrix}\]
Since both matrices must be equivalent, this produces the trigonometric identities for angle addition.
\begin{align*}
    \sin{(\theta + \phi)} = \sin{\theta} \cos{\phi} + \cos{\theta} \sin{\phi} \\
    \cos{(\theta + \phi)} = \cos{\theta} \cos{\phi} - \sin{\theta} \sin{\phi}
\end{align*}
\end{example}

\begin{proposition}
Given mappings $A_i \in$ End$(V_i)$ for $i = 1, 2, ..., n$, the matrix representation of the induced linear mapping $A_1 \oplus A_2 \oplus ... \oplus A_n$ is the block matrix 
\[\begin{pmatrix}
A_1 & & & \\
& A_2 & & \\
& & \ddots & \\
& & & A_n
\end{pmatrix}: \bigoplus_{i=1}^n V_i \longrightarrow \bigoplus_{i=1}^n V_i\]
\end{proposition}

\subsection{Change of Basis}
\begin{definition}
A linear transformation $A$ that maps every vector from $U$ to a vector in $V$ is called an \textit{active transformation}. However, a \textit{passive transformation}, or a \textit{change of basis transformation}, linearly transforms the set of basis vectors to another set of basis vectors within the same space. That is, a passive transformation takes the components of a vector $v$ with respect to basis $\{e_1, e_2, ..., e_n\}$ and merely represents $v$ with respect to another set of basis $\{f_1, f_2, ..., f_n\}$. 
\end{definition}

It is obvious that a passive transformation in $V$ is an element of End$(V)$. But note that an element of End$(V)$ could be interpreted \textit{both} as a passive and active transformation. Usually, the context will make it clear whether we are interpreting a transformation as passive or active. We now provide the construction of the change of basis. 
\\

Suppose ${e_1, e_2, ..., e_n}$ is a basis for vector space $V$ and ${f_1, f_2, ..., f_n}$ is another basis for $V$. So, every basis vector $f_i$ can be presented as a linear combination of the old basis vectors. 
\[f_j = \sum_{i =1}^{n} s_{i j} e_i \quad \text{for all i, j}\]
A general vector $x \in V$ will transform as such
\begin{equation} \label{eq1}
\begin{split}
x & = \sum_{j} y_j f_j \quad \text{for} \ y_{1}, y_{2}, ... \in \mathbb{F} \\
 & = \sum_{i,j} y_j s_{i j} e_i \\
 & = \sum_{i} \Big( \sum_{j} s_{i j} y_j \Big) e_i \\
 & = \sum_{i} x_i e_i \implies x_i = \sum_{j} s_{i j} y_j
\end{split}
\end{equation}
Similarly to the process of how we constructed matrix representations of linear operators, this process makes it clear that $s_{i j}$ are the entries of the $n \times n$ matrix representation of the passive mapping $S$. The final line of the equation above can be expressed, in terms of matrices, as 
\[\begin{pmatrix}x_1\\x_2\\...\\...\\x_n\end{pmatrix} = 
\begin{pmatrix} \\ \\ & & & S & & &  \\\\\\\end{pmatrix} \begin{pmatrix}
y_1\\y_2\\...\\...\\y_n\end{pmatrix} \]
This is a change of basis, since both the coefficients $x_i$ and $y_i$ represent the same vector $x$ in $V$, but through a different basis determined by $S$. Note that $S$ must be an invertible matrix since we are mapping bases to bases. So, given that $x = S y$, if $Ax = b$ is a matrix equation, then
\[A x = b \implies A S y = S b^\prime \implies S^{-1} A S y = b^\prime\]
where $b^\prime$ is the set of new coefficients for the vector with respect to the basis induced by $S$. 
This leads to the concept of matrix similarities. We once again note that whenever we create a matrix as an $m \times n$ entry of numbers, we are intuitively fixing a basis (not necessarily orthonormal, even) for the vectors that the matrix is transforming on. For example, the matrix $A$ in $y' = Ax'$ transforms the vector $x'$ with respect to the basis which $x'$ is in, i.e. the basis ${e_1', e_2', ..., e_n'}$. This transformation is not the same if it were to act on the vector $x$, which is determined by the basis ${e_1, e_2, ..., e_n}$. Therefore, we must also "change" the matrix A acting on $x'$ in order to account for the change in basis from $x'$ to $x$. This change is 
\[A \rightarrow B = S A S^{-1}\]
where matrix $A$ represents the transformation with respect to basis formed by the column vectors of $S$, and $B$ represents the same transformation with respect to the basis formed by the column vectors of $S^{-1}$. 

\begin{definition}
Two matrices $A$ and $B$ are \textit{similar} if and only if there exists an invertible matrix $S$ such that $B = S A S^{-1}$. A and B both represent the same transformation $T$ but merely in different bases. Matrix similarity is a relation that partitions the $n^2$-dimensional matrix algebra Mat$(n, \mathbb{R})$ into similarity classes. 
\end{definition}

\subsection{Solving Systems of Equations}
\begin{definition}
Fix a field $\mathbb{F}$. A \textit{linear equation} with variables $x_1, x_2, ..., x_n$ is in the form 
\begin{equation}
    a_1 x_1 + a_2 x_2 + a_3 x_3 + ... + a_n x_n = b
\end{equation}
where the \textit{coefficients} $a_i$ and the \textit{free term} $b$ belong to $\mathbb{F}$. If $b = 0$, then $(3)$ is called a \textit{homogeneous equation} and if $b \neq 0$, then it is called a \textit{inhomogeneous equation}. 
\end{definition}

A system of $m$ linear equations with $n$ variables has the following general form 
\begin{align*}
    &a_{1 1} x_1 + a_{1 2} x_2 + ... + a_{1 n} x_n = b_1 \\
    &a_{2 1} x_1 + a_{2 2} x_2 + ... + a_{2 n} x_n = b_2 \\
    &..............................................=....\\
    &a_{m 1} x_1 + a_{m 2} x_2 + ... + a_{m n} x_n = b_m
\end{align*}
By matrix multiplication, this system is equal to the matrix equation $A x = b$.
\[\begin{pmatrix}
 a_{1 1} & a_{1 2} & \ldots & a_{1 n} \\
 a_{2 1} & a_{2 2} & \ldots & a_{2 n} \\
 \vdots & \vdots & \ddots & \vdots \\
 a_{m 1} & a_{m 2} & \ldots & a_{m n} 
\end{pmatrix} \begin{pmatrix}
 x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix}
b_1 \\ b_2 \\ \vdots \\ b_m
\end{pmatrix}\]
That is, given a linear transformation $A: \mathbb{F}^n \longrightarrow \mathbb{F}^m$ and a vector $b \in \mathbb{F}^m$, we must find the preimage of $b$ under $A$. Clearly, $x$ is a solution of this matrix equation if and only if it is a solution of the system of equations. 

We can interpret this matrix equation in two ways. First, we introduce the \textit{hyperplane interpertation}. The solution to each linear equation of $n$ variables represents an affine hyperplane in $\mathbb{F}^n$. Therefore, the solutions to the system of $m$ linear equations is simply the intersection of the $m$ affine hyperplanes of dimension $n-1$ within $\mathbb{R}^n$. That is, $x$ is a solution of $A x = b$ if and only if  
\[ x \in \bigcap_{i = 1}^m \Big\{ (x_1, x_2, ..., x_n) \; | \; \sum_{j = 1}^n a_{i j} x_j = b_i \Big\} \]
The \textit{column space interpretation} presents $A x = b$ in this equivalent form. 
\[ x_1 \begin{pmatrix}
a_{1 1} \\ a_{2 1} \\ \vdots \\ a_{m 1}
\end{pmatrix} + x_2 \begin{pmatrix}
a_{1 2} \\ a_{2 2} \\ \vdots \\ a_{m 2}
\end{pmatrix} + \ldots + x_n \begin{pmatrix}
a_{1 n} \\ a_{2 n} \\ \vdots \\ a_{m n}
\end{pmatrix} = \begin{pmatrix}
b_1 \\ b_2 \\ \vdots \\ b_m
\end{pmatrix}\]
That is, the solutions $x_1, x_2, ..., x_n$ are precisely the coefficients of the linear combination of the column vectors of $A$ that add up to vector $b$. Equivalently, it is the realization of vector $b$ with respect to the coordinate system of the column vectors of $A$. Note that the column space need not be a basis of $\mathbb{F}^m$. It does not need to be linearly independent nor does it need to span $\mathbb{F}^n$. 

\begin{definition}
The matrix $A$ under the system is called the \textit{coefficient matrix} and the matrix 
\[\Tilde{A} \equiv \begin{pmatrix}
| & | & ... & | & | \\
a_1 & a_2 & ... & a_n & b \\
| & | & ... & | & | 
\end{pmatrix} \equiv \begin{pmatrix}
a_{1 1} & a_{1 2} & \ldots& a_{1 n} & b_1\\
 a_{2 1} & a_{2 2} & \ldots & a_{2 n} & b_2\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
 a_{m 1} & a_{m 2} & \ldots & a_{m n} & b_m
\end{pmatrix}\]
is called the \textit{extended matrix}. 
\end{definition}

\begin{definition}
A system of equations is called \textit{compatible} if it has at least one solution and \textit{incompatible} otherwise. 
\end{definition}

\begin{definition}
An \textit{elementary transformation} of a system of linear equation is one of the following three types of transformations
\begin{enumerate}
    \item adding an equation multiplied by a number to another \textit{later} equation
    \item interchanging two equations
    \item multiplying an equation by a nonzero number
\end{enumerate}
\end{definition}

\begin{definition}
An \textit{elementary row transformation} of a matrix is one of the following three types of transformations
\begin{enumerate}
    \item adding a row multiplied by a number to another \textit{later} row
    \item interchanging two rows
    \item multiplying a row by a nonzero number
\end{enumerate}
\end{definition}

Clearly, these two definitions are equivalent since every elementary transformation of a system has a corresponding row transformation in its extended matrix. Given the $i$th row of a matrix, a "later" row means the $j$th row, where $j > i$. Defining property (i) to add to a later row does not actually restrict where we can add rows to, since property (ii) allows us to add any scalar multiple of any row to any other row. We define it this way for future convenience in defining the $L U P$ Decomposition. 

\begin{definition}
The elementary transformations on a $m \times n$ matrix $A$ is equivalent to left matrix multiplication by the following $m \times m$ matrices. Due to the following difficulty in presenting these matrices in a general form, we present them in the specific $4 \times 4$ case and hope that the reader can extrapolate this process to general matrices. \\ \\
i) Adding row $i$ multiplied by scalar $\alpha$ to row $j$ (where $j > i$) is denoted $E^1_{\alpha \times i + j}$. The matrix is the identity matrix with $\alpha$ in the $(j, i)$ position. 
\[E^1_{2 \times 1 + 2} = \begin{pmatrix}
1&0&0&0 \\ 2&1&0&0 \\ 0&0&1&0 \\ 0&0&0&1
\end{pmatrix}, \;\; E^1_{-3 \times 2 + 4} = \begin{pmatrix}
1&0&0&0 \\ 0&1&0&0 \\ 0&0&1&0 \\ 0&-3&0&1
\end{pmatrix}\]
ii) Interchanging the $i$th and $j$th row is denoted by matrix $E^2_{i j}$. Note that these are permutation matrices, or more speficially, transpositions. 
\[ E^2_{2 3} = \begin{pmatrix}
1&0&0&0 \\ 0&0&1&0 \\ 0&1&0&0 \\ 0&0&0&1
\end{pmatrix}, \; \; E^2_{2 4} = \begin{pmatrix}
1&0&0&0 \\ 0&0&0&1 \\ 0&0&1&0 \\ 0&1&0&0
\end{pmatrix}\]
iii) Multiplying the $i$th row by a scalar $\alpha$ is denoted by matrix $E^3_{\alpha \times i}$. 
\[ E^3_{3 \times 3} = \begin{pmatrix}
1&0&0&0 \\ 0&1&0&0 \\ 0&0&3&0 \\ 0&0&0&1
\end{pmatrix}, \;\; E^3_{7 \times 1} = \begin{pmatrix}
7&0&0&0 \\ 0&1&0&0 \\ 0&0&1&0 \\ 0&0&0&1
\end{pmatrix}\]
\end{definition}

\begin{proposition}
Each elementary matrix is invertible and their inverses are also elementary matrices. More specifically, 
\begin{enumerate}
    \item $(E^1_{\alpha \times i + j})^{-1} = E^1_{-\alpha \times i + j}$ (same matrix but $\alpha$ changed to -$\alpha$)
    \item $(E^2_{i j})^{-1} = E^2_{i j}$ (same matrix) 
    \item $(E^3_{\alpha \times i})^{-1} = E^{3}_{(1/\alpha) \times i}$ (same matrix but $\alpha$ changed to $1 / \alpha$)
\end{enumerate}
\end{proposition}

\begin{remark}
Elementary column operations of are equivalent to right multiplication of matrices. 
\end{remark}

\begin{definition}
The \textit{pivot} of a row $(a_1, a_2, ..., a_n)$ is its first nonzero element. If this element is $a_k$, then $k$ is the \textit{index} of the pivot. 
\end{definition}

\begin{definition}
A matrix is in \textit{Echelon form}, or \textit{row Echelon form}, if 
\begin{enumerate}
    \item the indices of the pivots of its nonzero rows form a strictly increasing sequence, like steps
    \item zero rows, if they exist, are at the bottom
\end{enumerate}
Thus, a matrix in Echelon form is in form
\[\begin{pmatrix}
a_{1 j_1} & * & \ldots & \ldots & * \\
0 & a_{2 j_2} & * & \ldots & * \\
0& 0& \ddots & \ldots & * \\
0& 0& 0& a_{r j_r} & \vdots \\
0 & 0 & \ldots & 0 & 0
\end{pmatrix}\]
where $*$'s represent arbitrary numbers, $a_{i j_i}$'s are nonzero (with indices $j_i$, and the entries to the left of below them are $0$. Property $(i)$ also states that $j_1 < j_2 < ... < j_r$. Let us denote the Echelon form of matrix $A$ as ref$(A)$. 
\end{definition}

\begin{theorem}
Every matrix can be reduced to step form by elementary row transformations. 
\end{theorem}

\begin{proof}
The relevant algorithm used will not be shown here, but we will mention that this procedure is called \textit{Gauss Elimination}, or \textit{row reduction}. 
\end{proof}

The computational efficiency of Gauss Elimination is well known. Solving a system of $n$ equations with $n$ variables with this algorithm requires approximately $2 n^3 / 3$ operations, meaning that it has arithmetic complexity of $O(n^3)$. However, for matrices of large order, multiple problems can occur. 

The algorithm generally does not have memory problems if the field is finite or if the coefficients are floating-point numbers. However, if the coefficients are integers or rational numbers, the intermediate entries of the algorithm can grow exponentially large, so bit complexity is exponential. However, there is a variant of Gaussian elimination, called the Bareiss algorithm, that avoids this problem, but has bit complexity of $O(n^5)$. Another problem is numerical instability, caused by the possibility of dividing by numbers very close to $0$. Any such number would have its existing error amplified. Gaussian elimination algorithm is generally known to be stable for positive-definite matrices. 

Under the column space interpretation, Gaussian Elimination is really just an algorithm that performs a change of basis in steps. Each elementary operation simultaneously changes all of the vectors of the column space in such a way that eventually, this set of vectors will be "nice-looking" with a lot of zero entries. Under the hyperplane interpretation, it is a bit harder to visualize, but it is sufficient to say that each elementary operation either "stretches/compresses" (iii) a hyperplane or it "rotates" (i) the hyperplane around the axis where the solution exists. Either way, the intersection between the hyperplane and the set of solutions do not change. 

\begin{definition}
A system of linear equations is said to be in \textit{step form} if its extended matrix is in Echelon form. 
\end{definition}

\begin{definition}
A matrix is in \textit{reduced row echelon form}, denoted rref$(A)$, if
\begin{enumerate}
    \item it is in row echelon form
    \item the pivots are all equal to 1
    \item each column containing a pivot has zeros in all other entries
\end{enumerate}
\end{definition}

\begin{theorem}
Every matrix can be reduced to reduced row echelon form by elementary row operations. 
\end{theorem}

\begin{proof}
We will briefly describe the method to do this. We first reduce matrix $A$ to step form. Then, we perform the algorithm known as \textit{back substitution}, where we start with the bottom row and use elementary operations to cancel out terms in upper rows. 
\end{proof}

\begin{definition}
A system of linear equations is said to be \textit{solved} if its extended matrix is in reduced row echelon form. 
\end{definition}

\begin{definition}
A matrix is called \textit{lower triangular} if $a_{i j} = 0$ for $i < j$. It is called \textit{upper triangular} if $a_{i j} = 0$ for $i > j$. A square matrix is \textit{diagonal} if $a_{i j} = 0$ for $i \neq j$. 
\end{definition}

\begin{proposition}
Elementary operations on either a system of linear equations or its extended matrix does not change its solutions. 
\end{proposition}

\begin{proof}
It is easy to see this is true when performing the computations with the three transformations. We can prove this more abstractly, however. 
\\
\\
Given the system $A x = b$ with $x \in \mathbb{F}^n, b \in \mathbb{F}^m$. We see that $A \in $ Mat$(m \times n, \mathbb{F}) \implies \Tilde{A} \in$ Mat$(m \times (n+1), \mathbb{F})$. Each elementary row transformation on $\Tilde{A}$, denote it $E$, is a bijective mapping. Let us define the mapping 
\[\text{sol}: \text{Mat}\big( m \times (n+1), \mathbb{F} \big) \longrightarrow 2^{\mathbb{F}^n}, \; \text{sol} \begin{pmatrix}
A & b
\end{pmatrix} \equiv \{ x\in \mathbb{F}^n \; | \; A x = b\} \]
where $2^{\mathbb{F}^n}$ is the set of all subsets of $\mathbb{F}^n$. By matrix multiplication, we see that 
\[ E \begin{pmatrix}
A & b
\end{pmatrix} = \begin{pmatrix}
E A & E b
\end{pmatrix}\]
Since $E$ is bijective, it is invertible. So, 
\begin{align*} 
\text{sol} \big( E \begin{pmatrix}
A & b \end{pmatrix} \big) & = \text{sol} \begin{pmatrix}
E A & E b \end{pmatrix} \\ 
& = \{ x \; | \; E A x = E b\} \\ 
& = \{ x \; | \; A x = b\} \\ 
& = \text{sol} \begin{pmatrix} A & b \end{pmatrix}
\end{align*}
\end{proof}

Note the importance of this proposition. This result is the foundation behind the applications of Jordan Elimination.

\begin{definition}
A linear system can have either have no possible solutions (\textit{overdetermined}), one unique solution, or multiple solutions (\textit{underdetermined}) (infinite solutions if char$\, \mathbb{F}$ = 0). We can say with probability 1 that given a random $m \times n$ matrix $A$ with random $m$-dimensional vector $b$, the system $A x = b$ has
\begin{enumerate}
    \item 0 solutions if $m > n$, since there are more equations than variables
    \item 1 solution if $m = n$ with the same number of equations and variables
    \item Infinite solutions if $m < n$ since there are more variables than equations
\end{enumerate}
\end{definition}

\begin{definition}
The variables corresponding to the indices of the pivots are called the \textit{pivot variables}. The rest of the variables are called \textit{free variables}
\end{definition}

Because of proposition 3.3, we can determine whether a system has 0, 1, or multiple solutions by looking at the extended matrix's Echelon form. The case for 0 solutions is easy. 

\begin{theorem}
The system $A x = b$ has 0 solutions if and only if ref$(\Tilde{A})$ contains a row in the form 
\[ \begin{pmatrix}
0 & 0 & ... & 0 & c
\end{pmatrix}, \; c \neq 0\]
\end{theorem}

\begin{proof}
The existence of this row is equivalent to the linear equation
\[ 0 x_1 + 0 x_2 + ... + 0 x_n = c, \; c \neq 0\]
which is absurd and cannot have any solution. Under the hyperplane interpretation, we can visualize all the hyperplanes failing to have a common point. 
\end{proof}

\begin{corollary}
Given $m \times n$ matrix $A$, if $m > n$ and the row vectors of $A$ are all linearly independent, then the system $A x = b$ has 0 solutions. 
\end{corollary}

\begin{theorem}
The system $A x = b$ has 1 solution if and only if ref$(A)$ is diagonal. 
\end{theorem}

\begin{proof}
ref$(A)$ being diagonal implies that there exists at least one solution and also implies the absence of any free variables. 
\end{proof}

\begin{theorem}
The system $A x = b$ has multiple solutions if and only if ref$(A)$ has free variables. 
\end{theorem}
\begin{proof}
Clear. 
\end{proof}

\begin{definition}
The number of pivots in ref$(A)$ is called the \textit{rank} of $A$, denoted rk$(A)$. 
\end{definition}

\begin{proposition}
Let $A$ be a $m \times n$ matrix. Then rk$(A) \leq$ min$\{m ,n\}$. 
\end{proposition}
\begin{proof}
By definition, the number of pivots cannot exceed the number of variables nor can it exceed the number of equations. 
\end{proof}

\begin{definition}
A $n \times n$ matrix $A$ is called \textit{nonsingular} if and only if rk$(A) = n$. It is \textit{singular} if and only if rk$(A) < n$. Clearly, rk$(A) \not> n$. 
\end{definition}

\subsection{Four Fundamental Spaces}
We will begin to bring over the general concepts of linear transformations and state them within the realm of matrices. We will start with the concept of dual vectors. 

It is customary to interpret vectors in the abstract sense as a column of $n$ numbers. Given that vectors are column vectors, it is sometimes useful (but not entirely comprehensive) to interpret covectors as row vectors. That is, given a vector $v$ and covector $l$, $l$ linearly maps $v$ to a field element by left matrix multiplication. 
\[ l(v) = \begin{pmatrix} l_1 & l_2 & ... & l_n \end{pmatrix} \begin{pmatrix}
v_1 \\ v_2 \\ ... \\ v_n
\end{pmatrix} = \sum_{i = 1}^{n} l_i v_i\]

\begin{definition}
The \textit{transpose} of matrix $A$, denoted $A^T$, is the matrix with entries $(a^T)_{i j} = a_{i j}$. That is, it is $A$, "flipped over." 
\end{definition}

We illustrate why this definition of a transpose is equivalent to the abstract definition to the transpose of a linear map. Given a linear map $A: U \longrightarrow V$ with $\dim U = n, \dim V = m$, we can fix a basis on both $U$ and $V$ to define its matrix $A$. The abstract definition states that 
\[ A^T: V^* \longrightarrow U^*, \; l \equiv \varphi A\]
Treating $l$ and $\varphi$ as row vectors, we can see that the $m \times n$ matrix $A$ maps the $1 \times m$ covector $\varphi$ to the $1 \times n$ covector $l$. Note that this linear mapping is realized through \textit{right multiplication} of $A$ on $\varphi$. It is customary to present linear maps as \textit{left} multiplication, so by "flipping" (i.e. taking the matrix transpose) of all the elements in the equation, we get 
\[ l^T \equiv A^T \varphi^T \]
which presents the mapping in the more usual way of left matrix multiplication. Note that $l^T$ and $\varphi^T$ are still covectors. Just because they are now represented as column vectors, it does not mean that they are not covectors, which is why we shouldn't be too dependent on the row vector interpretation of dual vectors mentioned above.  

Continuing the previous point, note that the way we represent vectors and linear transformation has all been arbitrarily chosen. There is nothing innate about the way we express these transformation as matrix multiplication. This last example especially shows us that the entire definition of the matrix transpose (rooting from the abstract definition) is dependent on our \textit{initial choice} to represent linear mappings as \textit{left} matrix multiplication and to represent all vectors as column vectors. 

\begin{theorem}[Properties of the Transpose]
Given that $A, B: U \longrightarrow V$ is linear, $c$ a constant
\begin{enumerate}
    \item $(A^T)^T = A$. 
    \item $(A+B)^T = A^T + B^T, \; (c A)^T = c A^T$. 
    \item $(A B)^T = B^T A^T$. 
    \item If $A$ is invertible, $(A^{-1})^T = (A^T)^{-1}$ and $A$ invertible $\implies A^T$ invertible. 
    \item $x \cdot y = x^T y$. Furthermore, 
\[Ax \cdot y = (A x)^T y = x^T A^T y = x \cdot A^T y\]
\end{enumerate}
\end{theorem}

\begin{definition}
Matrix $A$ is a \textit{symmetric matrix} if $A = A^T$. $A$ is \textit{skew-symmetric}, or \textit{anti-symmetric}, if $A^T = - A$. 
\end{definition}

Now we are ready to describe the four fundamental spaces of a matrix $A$: the column space, row space, nullspace, and left nullspace. All four of these spaces are subspaces, but we will not check them here. 

\begin{definition}
The \textit{column space} of matrix $A$, denoted $C(A)$, is the span of its column vectors. That is, 
\[C(A) = \text{span}\{ a_1, a_2, ..., a_n\}\]
We will denote the column vectors with lowercase $a_i$'s.
\end{definition}

\begin{definition}
The \textit{row space} of matrix $A$, denoted $R(A)$, is the span of its row vectors. That is, 
\[R(A) = \text{span}\{ A_1, A_2, ..., A_m\}\]
We will denote the row vectors with uppercase $A_i$'s. 
\end{definition}

\begin{definition}
The kernel of linear transformation is called the \textit{nullspace} of its associated matrix, denoted Null$(A)$. 
\end{definition}

\begin{definition}
The \textit{left nullspace} of matrix $A$ is the nullspace of $A^T$. It is denoted Null$(A^T)$. 
\end{definition}

\begin{proposition}
By the column space interpretation, it is clear that
\[C(A) = \im \, A\]
\end{proposition}

We state the matrix analogue of Theorem 2.5. 
\begin{theorem}
A vector is a solution to the system of equation $A x = b$ if and only if it is of the form 
\[ a + \text{Null}\; (A)\]
where $a$ is one solution. 
\end{theorem}

\begin{theorem}
Let $A: \mathbb{F}^n \longrightarrow \mathbb{F}^m$ be a $m \times n$ matrix with rank $k$. Assuming that $\mathbb{F}^n$ and $\mathbb{F}^m$ are inner product spaces,  
\begin{align}
    Null(A) = R(A)^\perp &\iff Null(A)^\perp = R(A) \\
    Null(A^T) = C(A)^\perp &\iff Null(A^T)^\perp = C(A)
\end{align}
That is, Null$(A)$ and $R(A)$ are orthogonal complements in $\mathbb{F}^n$, with $\dim R(A) = k$ and $\dim\,$Null$(A) = n - k$. Null$(A^T)$ and $C(A)$ are orthogonal complements in $\mathbb{F}^m$, with $\dim C(A) = k$ and $\dim \,$Null$(A^T) = m - k$. 
\end{theorem}

\begin{corollary}
The solution to the homogeneous system $A x = 0$ is precisely Null$(A)$. 
\end{corollary}

\begin{definition}
The homogeneous system $A x = 0$ always has a \textit{trivial solution} $x = 0$. 
\end{definition}

\begin{example}
Given a system of linear equations 
\begin{align*}
    x + 3 y - 2z = 5 \\
    3 x + 5 y + 6 z = 7 \\
    2 x + 4 y + 3 z = 8
\end{align*}
We put it into extended matrix form $A$ and perform Gauss Elimination to get rref$(A)$. 
\[\begin{pmatrix}
1 & 3&-2&5 \\ 3&5&6&7\\ 2&4&3&8
\end{pmatrix} \rightarrow \begin{pmatrix}
1&3&-2&5\\ 0&1&-3&2 \\ 0&0&1&2 \end{pmatrix} \rightarrow \begin{pmatrix}
1&0&0&-15 \\ 0&1&0&8 \\ 0&0&1&2
\end{pmatrix}\]
So, rref$(A)$ has the solution $(-15, 8, 2)$ and it is unique because there are no free variables. 
\end{example}

This leads to the following theorem. 

\begin{theorem}
The set of $n$ linear equations with $n$ variables can be expressed in the form of $A x = b$, where $A$ is an $n \times n$ matrix. 
\[ A x = b \text{ has a unique solution} \iff A \text{ is nonsingular} \iff \text{rk}\,(A) = n\]
\end{theorem}
\begin{proof}
$A$ is nonsingular is equivalent to saying that rref$(A) = I_n$, where $I_n$ is the $n \times n$ identity matrix. This clearly means that rref$(\Tilde{A})$ will always reveal unique solutions. 
\end{proof}

\begin{theorem}
$n \times n$ matrix $A$ is invertible if and only if it is nonsingular. 
\end{theorem}
\begin{proof}
$A$ is nonsingular $\iff A x = b$ will always have a unique solution $\iff$ $A$ is an isomorphism from $\mathbb{F}^n$ to itself $\iff$ by definition, $A$ is invertible. 
\end{proof}

The realization of an endomorphism of $\mathbb{F}^n$ in matrix form is a $n \times n$ matrix. The realization of an automorphism of $\mathbb{F}^n$ in matrix form is an $n \times n$ nonsingular matrix. This set is actually a multiplicative, nonabelian group denoted GL$_n(\mathbb{F})$ and is one example of a Lie Group. 

\begin{proposition}
There are $k$ free variables in $A$ if and only if $\dim\,$Null$(A) = k$. 
\end{proposition}
\begin{proof}
We do not give a rigorous proof but we outline one. Each free variable corresponds to a free vector in the row echelon form of $A$ that are all linearly independent. Since the span of these free vectors is equal to Null$(A)$, the $k$ vectors form a basis of $A$ $\implies$ by definition, $\dim\,$Null$(A) = k$.
\end{proof}

\begin{theorem}
\[\text{rk}(A) = \dim \, \im \,A = \dim C(A)\]
\end{theorem}

\begin{proof}
Let $A$ be a $m \times n$ matrix over $\mathbb{F}$. Then, let rk$(A) = k$, which implies that there are $n-k$ free variables $\implies \dim \,$ Null$(A) = n - k$. By rank nullity, 
\[\dim \im{A} = n - \dim \text{Null}(A) = n - (n -k) = k = \text{rk} A \]
\end{proof}

This theorem establishes the consistency in definition between the rank of an abstract mapping mentioned in chapter 2 and the rank of its matrix representation. We can in fact establish strong claims on top of this. 

\begin{theorem} 
\[\dim C(A) = \dim R(A)\]
\end{theorem}

\begin{proof}
Let $A$ be a $m \times n$ matrix of rank $r$. There are $r$ pivots and a pivot in each nonzero row of ref$(A)$, so $\dim R(A) = r$. The previous theorem says $r = \dim C(A)$. 
\end{proof}

\begin{corollary}
\[C(A) \simeq R(A)\]
\end{corollary}

\begin{proof}
While this is a direct result of the dimensions of the two subspaces being equal, it is worthwhile to mention this alternative proof. We will prove that the linear mapping $A$ is the isomorphism itself. Let rk$(A) = r$ and let $\{ v_1, v_2, ..., v_r\}$ be a basis for $R(A)$. Then, the set $\{ A v_1, A v_2, ..., A v_r\}$ are $r$ vectors in $C(A)$. They are linearly independent because 
\begin{align*}
    \sum_{i = 1}^r c_i A v_i = A \sum_{i=1}^r c_i v_i = 0 & \implies \sum_{i=1}^r c_i v_i \in \text{Null}(A) \text{, but } \sum_{i=1}^r c_i v_i \in R(A) \\
    & \implies \sum_{i=1}^r \in \text{Null}(A) \cap R(A) = \{0\}
\end{align*} 
Since $\dim C(A) = r$, $\{A v_i\}$ must form a basis of $C(A)$. Therefore, $A$ is a bijection between vector spaces and is thus an isomorphism. 
\end{proof}

\begin{corollary}
\[\text{rk}(A) = \text{rk}(A^T)\]
\end{corollary}

\begin{proposition}
The product of square lower triangular matrices is a lower triangular matrix. The product of square upper triangular matrices is an upper triangular matrix. 
\end{proposition}

\subsection{LU Decomposition}
\begin{theorem}
If a $m \times n$ matrix $A$ can be reduced to row echelon form using only elementary row operations $E^1$, it can be decomposed into the product of a lower triangular $m \times m$ matrix $L$ with diagonal entries equal to $1$ and an upper triangular $m \times n$ matrix $U$. 
\[A = L U\]
This is called \textit{LU decomposition}, or \textit{LU factorization}. 
\end{theorem}

\begin{proof}
We reduce $A$ to its echelon form ref$(A)$ by successively multiplying elementary matrices $E^{\gamma_i}$ representing elementary operation (i). After a finite amount of steps $r$, we will reduce it to ref$(A)$.
\[ \text{ref}(A) = E^{\gamma_r} E^{\gamma_{r-1}} ... E^{\gamma_2} E^{\gamma_1} A = \bigg(\prod_{i = 0}^{r-1} E^{\gamma_{r-i}}\bigg) A\]
Since each $E^{\gamma_i}$ is invertible, we multiply the product of the inverses of the elementary matrices of operation (i), which are also elementary matrices of operation (i). 
\[ (E^{\gamma_1})^{-1} (E^{\gamma_2})^{-1} ... (E^{\gamma_r})^{-1} ref(A) = \bigg( \prod_{j = 1}^r (E^{\gamma_j})^{-1} \bigg) \bigg( \prod_{i=1}^{r-1} E^{\gamma_{r-i}} \bigg) A = A \]
Since each $(E^{\gamma_j})^{-1}$ is an elementary row operation, it is lower diagonal, and by proposition 3.16, their product is also lower triangular. It is easy to prove that if the diagonal entries are furthermore equal to 1, then the product has diagonal entries equal to 1. Finally, it is clear that every matrix in row echelon form is upper triangular, and we are done. 
\[ A = \bigg( \prod_{j = 1}^r (E^{\gamma_j})^{-1} \bigg) \text{ref}(A) = L U\]
\end{proof}

\begin{remark}
Note that the existence of the LU decomposition for a general $m \times n$ matrix is not guaranteed. It will not exist if we must switch rows in matrix $A$ in order to reduce it to its echelon form. It does not matter whether we need to use elementary operation (ii) or not. Only the necessity of elementary operation (iii) to reduce the matrix determines the existence of the LU decomposition. The decomposition is also unique. 
\end{remark}

Finding the LU decomposition of a matrix is useful for solving systems of linear equations. Given a system in the form of $A x = b$, if we know the LU decomposition of $A$, we can rewrite the system as 
\[ L U x = b\]
Setting $y = U x$, we can easily solve the system $L y = b$ using forward substitution and then we can solve the system $U x = y$ using back substitution. Therefore, knowing this decomposition beforehand greatly aids in computing the solutions to the linear system. But computing $L$ and $U$ in order to solve this system takes as much effort as solving the system using Gauss Elimination in the first place. 

It is imperative to mention a similar decomposition for $n \times n$ matrices, known as \textit{LUP decomposition}. 

\begin{definition}
An $n \times n$ permutation matrix is a matrix of $0$s and $1$s with exactly one $1$ in each row and column. The set of all $n \times n$ permutation matrices form a multiplicative matrix group of order $n!$. We can also view this group as the matrix representation of the symmetric group $S_n$. 
\end{definition}

\begin{example}
The set of all $2 \times 2$ permutation matrices is 
\[S_2 = \bigg\{  \begin{pmatrix}1 & 0 \\0 & 1 \end{pmatrix}, \begin{pmatrix}1 & 0 \\0 & 1 \end{pmatrix} \bigg\}\]
and the set of all $3 \times 3$ permutation matrices is
\[S_3 = \Bigg\{I_3, 
\begin{pmatrix}1 & 0 & 0 \\0 & 0 & 1 \\0 & 1 & 0 \end{pmatrix},
\begin{pmatrix}0 & 1 & 0 \\1 & 0 & 0 \\0 & 0 & 1 \end{pmatrix}, 
\begin{pmatrix}0 & 1 & 0 \\0 & 0 & 1 \\1 & 0 & 0 \end{pmatrix}, 
\begin{pmatrix}0 & 0 & 1 \\0 & 1 & 0 \\1 & 0 & 0 \end{pmatrix}, 
\begin{pmatrix}0 & 0 & 1 \\1 & 0 & 0 \\0 & 1 & 0 \end{pmatrix} \Bigg\} \]
\end{example}

\begin{theorem}
Every $n \times n$ matrix $A$ can be decomposed into the form $A = P L U$, where $L$ is lower triangular, $U$ is upper triangular, and $P$ is a permutation matrix. 
\end{theorem}

\begin{proof}
We can modify the Gauss Elimination algorithm to do all the row interchanges in the beginning. The permutation matrices form a group, so the product of all the initial row changes is a permutation matrix. Call it $P^\prime$. The previous theorem states that we can do LU decomposition on $P^\prime A$. 
\[ P^\prime A = LU \implies A = P^{\prime -1} L U = P L U\]
Since $P^{\prime -1}$ is also in the symmetric group of permutations, we can denote it as $P$. 
\end{proof}

\begin{corollary}
Every $n \times n$ matrix $A$ can be decomposed into the form $L U P$. That is, in the form
\[ A = L U P = 
\begin{pmatrix}
1 & 0 & 0 & \ldots & 0\\
* & 1 & 0 & \ldots & 0\\
* & * & 1 & \ldots & \vdots\\
\vdots & \vdots & \vdots & \ddots & 0\\
* & * & ... & * & 1 
\end{pmatrix}
\begin{pmatrix}
u_{11} & * & * & \ldots & *\\
0 & u_{22} & * & \ldots & *\\
0 & 0 & u_{33} & \ldots & \vdots\\
\vdots & \vdots & \vdots & \ddots & * \\
0 & 0 & \ldots & 0 & u_{n n} 
\end{pmatrix}
\begin{pmatrix}
\\
\\
 & & & P & & & \\
\\
 & 
\end{pmatrix}\]
\end{corollary}

\begin{proof}
We decompose $A^T = P_0 L_0 U_0$, where $P_0$ is a permutation matrix, $L_0$ lower triangular, $U_0$ upper triangular. This implies that 
\[ A = A^{T T} = U_0^T L_0^T P_0^T = L U P\]
since $U_0^T$ is lower triangular and $L_0^T$ is upper triangular. Note that $L$ is unique, but $U$ is not unique, so this decomposition is not unique. 
\end{proof}

This decomposition can also be used to solve matrix equations
\[ A X = B\] 
Since this equation can be expressed in the form
\[ A \begin{pmatrix}
| & & | \\ x_1 & ... & x_n \\ | & & | 
\end{pmatrix} = \begin{pmatrix}
| & & | \\ A x_1 & ... & A x_n \\ | & & | 
\end{pmatrix} = \begin{pmatrix}
| & & | \\ b_1 & ... & b_n \\ | & & | 
\end{pmatrix}\]
solving this matrix is equivalent to solving the system of systems of linear equations 
\[ Ax_1 = b_1, Ax_2 = b_2, ..., Ax_n = b_n\]
i.e. by solving one column at a time. This method can also be used to solve 
\[A X = I\]
to find $X = A^{-1}$. Equivalently, we can left multiply elementary matrices to reduce $A$ to rref$(A)$. 
\[ E^{\gamma_r} E^{\gamma_{r-1}} ... E^{\gamma_2} E^{\gamma_1} A X = \text{rref}(A) X = E^{\gamma_r} E^{\gamma_{r-1}} ... E^{\gamma_2} E^{\gamma_1} I = \prod_{i = 0}^{r-1} E^{\gamma_{r-i}}\]
If rref$(A)= I$, then 
\[A^{-1} = \prod_{i = 0}^{r-1} E^{\gamma_{r-i}}\]
and if rref$(A) \neq I$, then $A^{-1}$ does not exist. This is in fact precisely the method of finding the inverse where we do Gauss Elimination on the extended matrix
\[\begin{pmatrix}
& &| & & \\ & A &| & I & \\ & &| & & 
\end{pmatrix} \longrightarrow \begin{pmatrix}
& &| & & \\ & I &| & A^{-1} & \\ & &| & & 
\end{pmatrix}\]

\subsection{Strassen Algorithm}
When computing the product two $n \times n$ matrices $A$ and $B$ to another $n \times n$ matrix $C$, since each entry of $C$ is the product of a row of $A$ with a column of $B$, and since $C$ has $n^2$ entries, we need $n^3$ scalar multiplications to compute (as well as $n^3 - n^2$ additions). In order words, the computing efficiency of the algorithm is at $O(n^3)$. However, there are faster algorithms than this. This is algorithm is known as the \textit{Strassen Algorithm} (however, there do exist faster algorithms). 

\begin{theorem}[Strassen Algorithm]
Let $A, B$ be $2 \times 2$ matrices such that $AB = C$. That is, component-wise,
\[\begin{pmatrix}
a_{11} & a_{12} \\ a_{21} & a_{22}
\end{pmatrix} \begin{pmatrix}
b_{11} & b_{12} \\ b_{21} & b_{22}
\end{pmatrix}
 = \begin{pmatrix}
  c_{11} & c_{12} \\ c_{21} & c_{22}
 \end{pmatrix}\]
where for $i, j = 1, 2$, 
\[c_{ij} = a_{i1} b_{1j} + a_{i2} + b_{2j}\]
Then, let us define 
\begin{align*}
    P_1 &= (a_{11} + a_{22}) (b_{11} + b_{22}) \\
    P_2 &= (a_{21} + a_{22}) b_{11} \\
    P_3 &= a_{11} (b_{12} - b_{22}) \\
    P_4 &= a_{22} (b_{21} - b_{11} \\
    P_5 &= (a_{11} + a_{12}) b_{22} \\
    P_6 &= (a_{21} - a_{11}) (b_{11} + b_{12}) \\
    P_7 &= (a_{12} - a_{22}) (b_{21} + b_{22}) 
\end{align*}
Then, the theorem states that we the entries of $C$ are 
\begin{align*}
    c_{11} &= P_1 + P_4 - P_5 + P_7 \\
    c_{12} &= P_3 + P_5 \\
    c_{21} &= P_2 + P_4 \\
    c_{22} &= P_1 + P_3 - P_2 + P_6
\end{align*}
\end{theorem}

This algorithm for multiplying $2\times 2$ matrices requires $7$ scalar multiplications, while regular multiplication requires $8$. Using block multiplication, we can use this algorithm to calculate any matrix of order $2^k$. That is, to calculate $2^k \times 2^k$ matrices, we have to perform seven multiplications of blocks of size $2^{k-1} \times 2^{k-1}$, and doing this recursively, it reduces it down to 
\[7^k = 2^{k \log_2{7}} = n^{\log_2{7}}\]
where $n$ is the order of the matrices being multiplied. 

Additionally, the number of scalar additions or subtractions needed is bounded by 
\[6 \times 7^k = 6 \times 2^{k \log_2{7}} = 6 n^{\log_2{7}}\]
Since $\log_2{7} \approx 2.807 < 3$, this algorithm does indeed have more computational efficiency. Note that matrices whose order is not a power of $2$ can be turned into one by adjoining a suitable number of $1$s on the diagonal. 

\begin{remark}[Conjecture]
For any positive number $\varepsilon$, there is an algorithm that computes the product of two $n \times n$ matrices with computational efficiency of $O(n^{2 + \varepsilon})$. 
\end{remark}

\section{Determinants and Trace}
The definition of the determinant is given first and then shown that it has the corresponding properties. We will work backward and construct the determinant from its properties. 

\begin{definition}
The determinant of a $n \times n$ matrix $A$, with column vectors $a_1, a_2, ..., a_n$, is a function
\[\det: \text{Mat}(n, \mathbb{F}) \longrightarrow \mathbb{F}\]
with the following three properties
\begin{enumerate}
    \item The determinant of the identity matrix is 1. 
\[\det{(I)} \equiv \det{(e_1, e_2, ..., e_n)} = 1\]
    \item Interchanging two columns $a_i$ and $a_j$ of $A$ once changes the sign of $\det{A}$. 
\[\det{(a_1, ..., a_i, ..., a_j, ..., a_n)} = -\det{(a_1, ..., a_j, ..., a_i, ..., a_n)}\]
    \item It is a multilinear function of the $n$ column vectors. 
\[\det{(a_1, ..., \lambda a_i + \mu a_i^\prime, ... a_n)} = \lambda \det{(a_1, ..., a_i, ... a_n)} + \mu \det{(a_1, ..., a_i^\prime, ... a_n)} \]
\end{enumerate}
\end{definition}

An important way to visualize determinants is by using the linear map visualization introduced before. That is, the determinant is the area of the transformed shaded unit square. 
\begin{center}
    \includegraphics[scale=0.25]{Determinant.PNG}
\end{center}

\begin{proposition}
The column vectors of $A$ are linearly dependent if and only if $\det{A} = 0$. 
\end{proposition}
\begin{proof}
By linearity, it is sufficient to prove that if two column vectors $a_i$ and $a_j$ of a matrix $A$ are equal, then $\det{A} = 0$. This can be easily seen by property (ii) of determinants. 
\end{proof}

\begin{theorem}
\[ \det{\bigg(\prod_i A_i \bigg)} = \prod_i \det{A_i}\]
\end{theorem}

\begin{theorem}
A matrix is invertible if and only if its determinant is nonzero. 
\end{theorem}
\begin{proof}
A matrix is invertible $\iff$ it is nonsingular $\iff$ its columns are linearly independent $\iff$ its determinant is nonzero, by the previous proposition. 
\end{proof}

\begin{corollary}
Given $n \times n$ matrix $A$,
\[\det{(A^{-1})} = \frac{1}{\det{A}}\]
\end{corollary}

\begin{theorem}
The determinants of similar matrices are equal. 
\end{theorem}
\begin{proof}
Let $A$ and $B$ be similar matrices. Then, there exists an $S$ such that $A = S^{-1} B S$ and 
\[ \det{(A)} = \det{(S^{-1} B S} = \det{(S^{-1})} \det{(B)} \det{(S)} = \det{B}\]
\end{proof}

This theorem implies that the determinant is an intrinsic property of a linear transformation, so it is invariant under a change of basis. That is, choosing different matrix representations of a linear transformation does not change the determinant.  

\begin{corollary}
\[\det{(A)} = \det{(A^T)}\]
\end{corollary}
\begin{proof}
$A$ is similar to $A^T$, which will be proven in chapter 6. 
\end{proof}

\begin{proposition}
The properties of the determinant combined with the previous corollary implies that 
\begin{enumerate}
    \item Adding a scalar multiple of a row/column to another row/column doesn't affect the determinant. 
    \item Interchanging two rows/columns switches the sign of the determinant. 
    \item Multiplying a row/column by $\alpha$ multiplies the determinant by $\alpha$. 
\end{enumerate}
\end{proposition}

\begin{theorem}
Let $A$ be an $n \times n$ matrix whose first column is $e_1$
\[A = \begin{pmatrix}
1&*&*&* \\
0 &&& \\
\ldots& & A_{11}& \\
0&&&
\end{pmatrix}\]
where $A_{11}$ is the $(n-1) \times (n-1)$ submatrix of $A$ with entries $a_{i j}, \; i, j > 1$. Given this, 
\[\det{A} = \det{A_{11}}\]
\end{theorem}
\begin{proof}
Using column reduction, we can see that 
\[ \det{A} = \det{\begin{pmatrix}
1&0&0&0 \\
0 &&& \\
\ldots& & A_{11}& \\
0&&&
\end{pmatrix}}\]
it is clear that the right hand side is equal to $\det{A_{11}}$ since it behaves exactly like $\det{A_{11}}$ with respect to the three properties. 
\end{proof}

\begin{corollary}
Let $A$ be an upper or a lower triangular matrix. Then the determinant of $A$ is the product of its diagonal entries. That is,  
\[ \det{A} = \prod_{i} a_{i i}\]
\end{corollary}
\begin{proof}
We apply the previous theorem recursively to satisfy when $A$ is upper triangular. Since $\det{(A)} = \det{(A^T)}$, this fact can be applied to lower triangular matrices too. 
\end{proof}

It is once again verified that the three elementary row (and column) operations affect the determinant in the way stated in Proposition 5.5. To elaborate, since $E_1, E_2$, and $E_3$ are all lower triangular, we can compute their determinants easily
\begin{align*}
    \det{E^1_{\alpha \times i + j}} = 1 \\
    \det{E^2_{i j}} = -1 \\
    \det{E^3_{\alpha \times i}} = \alpha
\end{align*}
and multiplying matrix $A$ by elementary matrices $E^1, E^2$, and $E^3$ multiplies the determinant by $1, -1$, and $\alpha$, respectively. 
\\

We can describe the determinant visually. Given a linear mapping $A: V \longrightarrow V$, we can fix any basis $\{e_1, e_2, ..., e_n\}$ on $V$. Note that these basis vectors do not need to be orthogonal, nor are they restricted to any magnitude. The set of vectors 
\[\Big\{ \sum_{i=1}^n c_i e_i \; | \; 0 \leq c_i \leq 1, i = 1, 2, ..., n\Big\}\]
forms an $n$-dimensional parallelepiped in $V$. Let the volume of this parallelepiped be $U$. Let $W$ be the volume of the parallelepiped 
\[\Big\{ \sum_{i=1}^n c_i A e_i \; | \; 0<c_i<1, i = 1, 2, ..., n\Big\}\]
which is formed by the transformed basis vectors $\{Ae_1, Ae_2, ..., Ae_n\}$. We can view this latter shape as the image of the first parallelepiped under transformation $A$. Then, 
\[ \det{A} = W / V \]
That is, the ratio of the transformed parallelepiped to the original parallelepiped is the determinant. This is consistent with the properties of the determinant. For example, if $A$ is not isomorphic, then the parallelepiped will get "squished" into a lower-dimensional parallelepiped with volume $0$. The fact that we use a ratio between the original and transformed parallelepiped allows this value to be invariant under the basis that we use. 

Computationally, finding the LUP decomposition of a matrix $A$ is the best known algorithm to compute the determinant of a general $n \times n$ matrix. That is, 
\[ \det{A} = \det{L} \det{U} \det{P} = \pm \det{U} = \pm \prod_i u_{i i}\]
since $\det{L} = 1$ and $\det{P} = \pm 1$. 

There are other methods to compute the determinant. First, we state the simple but useful formula.

\begin{proposition}
\[\det{\begin{pmatrix}
a&b\\c&d 
\end{pmatrix}} = a d - b c\] 
\end{proposition}

\begin{definition}
Given an $n \times n$ matrix $A$, the $(i j)$th minor of $A$, denoted $A_{i j}$, is the determinant of the $(n-1) \times (n-1)$ matrix formed by removing the $i$th row and $j$ th column from $A$. 
\end{definition}

\begin{theorem}[Laplace Expansion]
Let $A$ be an $n \times n$ matrix and $j$ any index between $1$ and $n$. Then
\[\det{A} = \sum_i (-1)^{i + j} a_{i j} A_{i j}\]
that is, the alternating sums of the $ij$th minors multiplied by the $ij$th entries in the $j$th column of $A$. This can be done by choosing an arbitrary $i$th row, which leads to the alternative formula 
\[\det{A} = \sum_j (-1)^{i + j} a_{i j} A_{i j} \]
\end{theorem}

\begin{theorem}[Cramer's Rule]
Given a system of linear equations in the form $A x = b$ where $A$ is an $n \times n$ matrix, the solutions of this system can be expressed with the formulas 
\[ x_i = \frac{ \det{A_i}}{\det{A}}\]
where $\det{A_i}$ is the matrix formed by replacing $a_i$, the $i$th column of $A$, by the column vector $b$. 
\end{theorem}

Albeit very computationally heavy, determinants can also be used to calculate the inverse of a matrix. 

\begin{theorem}
The inverse matrix $A^{-1}$ of an invertible matrix $A$ has the form 
\[(A^{-1})_{i j} = (-1)^{i+j} \frac{\det{A_{i j}}}{\det{A}}\]
\end{theorem}

\begin{definition}
The trace of a square matrix $A$, denoted $\Tr{A}$, is the sum of its diagonal entries. 
\[\Tr(A) = \sum_{i} a_{ii}\]
\end{definition}

\begin{proposition}
\[\Tr(\lambda A + \alpha B) = \lambda \Tr(A) + \alpha \Tr(B)\]
\end{proposition}
\begin{proof}
Obvious if we look at the entries of $A$ and $B$ and see that it is bilinear.
\end{proof}

\begin{theorem}[Cyclic Property of the Trace]
\[\Tr{\bigg(\prod_{i=1}^n A_i\bigg)} = \Tr{\bigg(A_n \prod_{i=1}^{n-1} A_i\bigg)}\]
\end{theorem}
\begin{proof}
We first prove when $m=2$. Given that the subscripts $i j$ denote that $(i,j)$th element of a matrix, observe that
\begin{align*}
    (AB)_{ij} = \sum_{k} A_{ik} B_{kj} & \implies (AB)_{ii} = \sum_{K} A_{ik} B_{ki} \\
    & \implies \Tr(AB) = \sum_{i} \sum_{k} A_{ik} B_{ki} \\
    & \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;= \sum_{k} \sum_{i} B_{ki} B_{ik} = Tr(BA)
\end{align*}
Similarly, for $m=3$
\begin{align*}
    (ABC)_{ij} = \sum_{k,l} A_{ik} B_{kl} C_{lj} & \implies \Tr(ABC) = \sum_{i,k,l} A_{ik} B_{kl} C_{li} \\ 
    & \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;= \sum_{i,k,l} C_{li} A_{ik} B_{kl} = \Tr(CAB)
\end{align*}
And so we can generalize for $m$. 
\end{proof}

\begin{corollary}
The trace is invariant under a change of basis. That is, the trace is an intrinsic property of a linear transformation since it does not change depending on how it is represented. 
\end{corollary}
\begin{proof}
Given that $A$ is similar to $B$. 
\[\Tr(B) = \Tr(S A S^{-1}) = \Tr(S^{-1} S A) = \Tr(A) \]
\end{proof}

\begin{theorem}
Let $A$ be a $n \times n$ skew-symmetric matrix over $\mathbb{C}$ (or any field of characteristic $\neq 2$). If $n$ is odd, 
\[\det{A} = 0 \]
\end{theorem}
\begin{proof}
\[\det{A} = \det{A^T} = \det{-A} = (-1)^n \det{A} \implies \det{A} = 0 \]
\end{proof}

We can actually conclude something even futher about antisymmetric matrices. 

\begin{theorem}
The determinant of an antisymmetric matrix $A$ of even order is the square of a homogeneous polynomial of degree $n/2$ in the entries of $A$. That is, 
\[\det{A} = P^2\]
The polynomial $P$ is called the \textit{Pfaffian}. 
\end{theorem}

\begin{definition}
A \textit{Vandermonde matrix} is a square matrix whose columns form a geometric progression. That is, let $a_1, a_2, ..., a_n$ be $n$ scalars. Then, $V(a_1, a_2, ..., a_n)$ is the $n \times n$ matrix
\[\begin{pmatrix}
1&1&\ldots&1&1 \\
a_1&a_2&\ldots&a_{n-1}&a_n\\
\vdots&\vdots&\ddots&\vdots&\vdots\\
a_1^{n-2}&a_2^{n-2}&\ldots&a_{n-1}^{n-2}&a_n^{n-2}\\
a_1^{n-1}&a_2^{n-1}&\ldots&a_{n-1}^{n-1}&a_n^{n-1}
\end{pmatrix}\]
\end{definition}

\begin{theorem}
The determinant of a Vandermonde matrix is
\[\det{V(a_1, a_2, ..., a_n)} = \prod_{j>i} (a_j - a_i)\]
\end{theorem}

A symmetry in the multivariable expression of a determinant can also reveal a symmetry in the matrix.

\begin{example}[2019 Putnam A1]
The symmetric polynomial 
\[ f(x, y, z) = x^3 + y^3 + z^3 - 3 x y z\]
can be expressed as the determinant of the $3 \times 3$ matrix
\[\det{\begin{pmatrix}
x&y&z\\
z&x&y\\
y&z&x
\end{pmatrix}}\]
\end{example}

\subsection{Matrices in Block Form}
\begin{theorem}
Given $2 \times 2$ block matrices
\[X = \begin{pmatrix}
A_1&B_1\\C_1&D_1
\end{pmatrix}, \; \; Y = \begin{pmatrix}
A_2&B_2\\C_2&D_2
\end{pmatrix}\]
We can compute $X Y$ similarly to regular matrix multiplication, treating the blocks as entries. 
\[ X Y = \begin{pmatrix}
A_1&B_1\\C_1&D_1
\end{pmatrix} \begin{pmatrix}
A_2&B_2\\C_2&D_2
\end{pmatrix} = \begin{pmatrix}
A_1 A_2 + B_1 C_2 & A_1 B_2 + B_1 D_2 \\
C_1 A_2 + D_1 C_2 & C_1 B_2 + D_1 D_2 
\end{pmatrix}\]
Furthermore, this process can be done in general for any $m \times n$ block matrix $X$ and $n \times p$ block matrix $Y$. 
\end{theorem}

\begin{theorem}
Given that $I_N, A, B$ are $n \times n$ matrices, define the $(2n) \times (2n)$ matrix 
\[X = \begin{pmatrix}
I & 0 \\ A & B
\end{pmatrix}\]
Then 
\[\det{X} = \det{B}\]
\end{theorem}
\begin{proof}
We can perform Gauss elimination to reduce $X$ without affecting the determinant.
\[\det{\begin{pmatrix}
I&0\\A&B
\end{pmatrix}} = \det{
\begin{pmatrix}
I&0\\
0&B
\end{pmatrix}} = \det{B}\]
since it satisfies the correct properties for $\det{B}$. 
\end{proof}

\begin{corollary}
\[\det{\begin{pmatrix}
A&0\\C&D
\end{pmatrix}} = \det{A} \det{D}\]
\end{corollary}

\begin{proof}
\[ \det{\begin{pmatrix}
A&0\\C&D 
\end{pmatrix}} = \det{\begin{pmatrix}
A&0\\C&I
\end{pmatrix} \begin{pmatrix}
I&0\\0&D
\end{pmatrix}} = \det{\begin{pmatrix}
A&0\\C&I
\end{pmatrix}} \det{\begin{pmatrix}
I&0\\0&D
\end{pmatrix}}\]
\end{proof}

However, 
\[\det{\begin{pmatrix}
A&B\\C&D
\end{pmatrix}} \neq \det{A} \det{D} - \det{B} \det{C}\]

Rather, we introduce the following theorem

\begin{theorem}
\begin{align}
    \det{\begin{pmatrix} A&B\\C&D \end{pmatrix}}  & = \det{(A)} \det{(D - C A^{-1} B)} \\
    & = \det{(D)} \det{(A - B D^{-1} C)}
\end{align}
\end{theorem}
\begin{proof}
\[\begin{pmatrix} A&B\\C&D\end{pmatrix} = \begin{pmatrix}
A&0\\C&I\end{pmatrix} \begin{pmatrix}
I& A^{-1} B \\ 0 & D - C A^{-1} B
\end{pmatrix}\]
by similarity, equation $(6)$ is equal to equation $(7)$. 
\end{proof}

\begin{definition}
A \textit{block diagonal matrix} is a square matrix in block form such that the diagonal blocks are square matrices and all off-diagonal blocks are zero matrices. 
\[A = \begin{pmatrix}
A_1&0&\ldots&0\\
0&A_2&\ldots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\ldots&A_k
\end{pmatrix}\]
\end{definition}

\begin{theorem}
Given a matrix $A$ in block diagonal form, with diagonal blocks $A_1, A_2, ..., A_k$,
\[\det{A} = \prod_{i=1}^k A_i, \; \; \Tr{A} = \sum_{i=1}^k \Tr{A_i}\]
Furthermore, $A$ is invertible if and only if all the $A_i$'s are invertible, and 
\[A^{-1} = \begin{pmatrix}
A_1&0&\ldots&0\\
0&A_2&\ldots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\ldots&A_k
\end{pmatrix} = \begin{pmatrix}
A_1^{-1}&0&\ldots&0\\
0&A_2^{-1}&\ldots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\ldots&A_k^{-1}
\end{pmatrix}\]
\end{theorem}
\begin{proof}
The results are obvious when performing block multiplication or Gauss Elimination. 
\end{proof}

\subsection{Dodgson Condensation}
We already know that the LUP decomposition is an algorithm used to compute the determinant of a general $n \times n$ matrix. We will introduce another, called \textit{Dodgson condensation}. The algorithm can be described in the following steps.

\begin{enumerate}
    \item Let $A$ be a given $n \times n$ matrix. Arrange $A$ so that no zeros occur in its interior (this can be done by any combination of elementary row or column operations that would not change the determinant). 
    \item Create an $(n-1) \times (n-1)$ matrix $B$ consisting of the determinants of every $2 \times 2$ submatrix of $A$. Explicitly, 
    \[B = \det{\begin{pmatrix}
    a_{i,j} & a_{i,j+1} \\ a_{i+1,j} & a_{i+1,j+1}
    \end{pmatrix}}\]
    \item With this $(n-1) \times (n-1)$ matrix $B$, perform step $2$ to obtain an $(n-2) \times (n-2)$ matrix $C$. Divide each term in $C$ by the corresponding term in the interior of $A$. 
    \[C_{i,j} = \det{\begin{pmatrix}
    b_{i,j} & b_{i,j+1} \\ b_{i+1,j} & b_{i+1,j+1}
    \end{pmatrix}} \bigg/ a_{i+1,j+1}\]
    \item Let $A = B$ and $B=C$. Repeat step $3$ as necessary until the $1 \times 1$ matrix is found, which is the determinant. 
\end{enumerate}

The reason that we do not want $0$s in $A$ is because then in doing step $3$ we may divide by $0$. 

\begin{example}
Let us find
\[\det{\begin{pmatrix}
-2&-1&-1&-4\\-1&-2&-1&-6\\-1&-1&2&4\\2&1&-3&-8
\end{pmatrix}}\]
All of the interior elements are nonzero, so there is no need to rearrange the matrix. We calculate
\[\begin{pmatrix}
-2&-1&-1&-4\\-1&-2&-1&-6\\-1&-1&2&4\\2&1&-3&-8
\end{pmatrix} \rightarrow \begin{pmatrix}
3&-1&2\\-1&-5&8\\1&1&-4
\end{pmatrix} \rightarrow \begin{pmatrix}
-16&2\\4&12
\end{pmatrix}\]
With this $2 \times 2$ matrix, we must divide each term by the interior of the original $A$. 
\[\begin{pmatrix}
-16/-2 & 2/-1\\4/-1 & 12/2
\end{pmatrix} = \begin{pmatrix}
8&-2\\-4&6
\end{pmatrix}\]
Calculating this determinant gives $40$, and dividing by the interior of the $3 \times 3$ matrix $(-5)$ gives $\det{A} = 40/-5 = -8$. 
\end{example}

\subsection{Matrix Calculus}
There is nothing special about matrix calculus on its own, since matrices are themselves vectors; they can be sufficiently analyzed using vector calculus. Regardless, we will emphasize a few points. Let
\[A: \mathbb{R} \longrightarrow \text{Mat}(m \times n, \mathbb{R})\]
be a matrix valued differential function. That is, the $m \times n$ component functions of $A$ is differentiable. Then, just like in calculus, we introduce differentiation rules.
\begin{align*}
    & \frac{d}{d x} \big( A(t) + B(t)\big) = \frac{d}{d t} A(t) + \frac{d}{d t} B(t) \\
    & \frac{d}{d x} \big( c A(t)\big) = c \frac{d}{d t} A(t)
\end{align*}
The scalar multiplication can actually be extended. By linearity (of matrix multiplication), we can say that if $A$ is independent of $t$, then 
\[\frac{d}{d x} A B (x) = A \frac{d}{d x} B(x)\]
The linearity of the derivative allows us to state more rules. Given that $v: \mathbb{R}^n \longrightarrow \mathbb{R}$ is a scalar valued function and $l \in (\mathbb{R}^n)^*$, then  
\[\frac{d}{d x} l \big( v(x) \big) = l \bigg( \frac{d}{d x} v(x) \bigg)\]
This result can be extended to when $v$ is replaced by matrix valued function $A$ and $l$ is replaced by $\phi: \text{Mat}(m \times n, \mathbb{R}) \longrightarrow \mathbb{R}$. 
\[\frac{d}{d x} \phi \big( A(x) \big) = \phi \bigg( \frac{d}{d x} A(x) \bigg)\]
Since the trace is a linear operator, we have the following theorem. 

\begin{theorem}
Given a linear function $A: \mathbb{R} \longrightarrow \text{Mat}(n, \mathbb{R})$ with paramater $x$, 
\[\frac{d}{d x} \Tr{A} = \Tr \bigg( \frac{d}{d x} A \bigg)\]
Note that $A$ in here really means $A(x)$.
\end{theorem}

The product rule of matrix calculus is similar.
\[\frac{d}{d x} A B = \bigg(\frac{d}{d x} A\bigg) \cdot B + A \cdot \bigg(\frac{d}{d x} B \bigg)\]
It is also noting that the derivative of the inner product of two vector valued functions $v, w: \mathbb{R} \longrightarrow \mathbb{R}^n$ is 
\[\frac{d}{d x} \big( v(x), w(x) \big) = \Big( \frac{d}{d x} v(x), w(x) \Big) + \Big( v(x), \frac{d}{d x} w(x) \Big)\]

\begin{definition}
A matrix valued function $A$ is \textit{invertible at a point $x \in \mathbb{R}$} if there exists a function, denoted $A^{-1}$ such that
\[A(x) A^{-1} (x) = A^{-1}(x) A(x) = I\]
where $I$ is the identity matrix. If there exists such $A^{-1}$ for all values $x \in \mathbb{R}$, then $A$ is said to be \textit{invertible}. 
\end{definition}

\begin{theorem}
Let $A$ be a matrix valued function, differentiable and invertible. Then, the function $A^{-1}$ is also differentiable and 
\[\frac{d}{d x} A^{-1} = - A^{-1} \bigg( \frac{d}{d x} A \bigg) A^{-1}\]
\end{theorem}
\begin{proof}
We derive this using the product rule. 
\begin{align*}
    0 = \frac{d}{d x} I & = \frac{d}{d x} \big( A(x) A^{-1} (x) \big) \\
    & = A(x) \bigg(\frac{d}{d x} A^{-1} (x) \bigg) + \bigg( \frac{d}{d x} A(x) \bigg) A^{-1} (x) \\
    \implies \frac{d}{d x} A^{-1} (x) & = - A^{-1} (x) \bigg( \frac{d}{d x} A(x) \bigg) A^{-1}(x)
\end{align*}
\end{proof}
Note that the chain rule is a rule of differentiaion that applies for scalar valued functions. That is, given $f: V \longrightarrow \mathbb{R}$ and $g: \mathbb{R} \longrightarrow V$ ($V$ vector space), 
\[\frac{d}{d x} f \circ g (x) = f^\prime \big( g(x) \big) \cdot \frac{d}{d x} g(x)\]
The $\cdot$ operation in the right hand side is the operation of multiplication in the field $\mathbb{R}$. But given $f: \text{Mat}(n, \mathbb{R}) \longrightarrow \mathbb{R}$ and $A \mathbb{R} \longrightarrow \text{Mat}(n, \mathbb{R})$, multiplication within the algebra of matrices are inherently different than component-wise operations, so the chain rule does not apply (it would apply if matrix multiplication was defined component-wise). 

\begin{example}
Let $f(A) \equiv A^2$, and let $A$ be a matrix valued function. Then, 
\begin{align*}
    \frac{d}{d x} f \circ A(x) = \frac{d}{d x} \big( A(t) \big)^2 & = \bigg( \frac{d}{d x} A(x) \bigg) \cdot A(x) + A(x) \cdot \bigg( \frac{d}{d x} A(x) \bigg) \\
    & \neq 2 A(x) \cdot \frac{d}{d x} A(x)
\end{align*}
since matrix multiplication is in general not commutative. 
\end{example}

\begin{proposition}
\[\frac{d}{d x} A^k = A^\prime A^{k-1} + A A^\prime A^{k-2} + ... + A^{k-2} A^\prime A + A^{k-1} A^\prime\]
\end{proposition}
\begin{proof}
We inductively apply the product rule
\[\frac{d}{d x} A^k = A^\prime A^{k-1} + A \frac{d}{d x} A^{k-1}\]
\end{proof}

\begin{corollary}
Given any polynomial $p$ with $A$ a differentiable, square matrix valued function, if $A$ and $A^\prime$ commute, then 
\[\frac{d}{d x} p(A) = p^\prime (A) A^\prime\]
\end{corollary}
\begin{proof}
We can completely define differentiation over the vector space of polynomials with the formula
\[\frac{d}{d x} A^k = k A^{k-1} A^\prime \; \forall k \in \mathbb{N}\]
\end{proof}

\begin{corollary}
Given polynomial $p$ with $A$ a differentiable, square matrix valued function, 
\[\frac{d}{d x} \Tr{p(A)} = \Tr{\big( p^\prime(A) \cdot A^\prime \big)}\]
\end{corollary}
\begin{proof}
Use the cyclic trace property.
\end{proof}

\begin{definition}
The \textit{exponential map} is defined
\[\text{exp}: \text{Mat}(n, \mathbb{C}) \longrightarrow \text{Mat}(n, \mathbb{C})\]
where 
\[e^A = I + A + \frac{1}{2!} A^2 + \frac{1}{3!} A^3 + ... = \sum_{k=0}^\infty \frac{1}{k!} A^k\]
where $A^0 \equiv I$. This can clearly be extended to when $A$ is a square, matrix valued function. 
\end{definition}

This final theorem establishes the connection between the determinant and trace. 

\begin{theorem}
Given a differentiable square matrix valued function $A$ such that $A$ is invertible for a certain $x \in \mathbb{R}$, then 
\[\frac{d}{d x} \log{\det{A}} = \Tr \bigg( A^{-1} \frac{d}{d x} A \bigg)\]
Where the log mapping is the inverse of the exponential mapping of matrices. 
\end{theorem}

\begin{definition}
The \textit{commutator} in the algebra of $n \times n$ matrices is defined as 
\[[A, B] = A B - B A\]
\end{definition}

\begin{theorem}
If $A$ and $B$ are commuting square matrices, then 
\[e^{A + B} = e^A \, e^B\]
In general, the solution $C$ to the equation
\[e^{A} \, e^B = e^C\]
is given by the \textit{Baker-Campbell-Hausdorff formula}, defined
\[C = A + B + \frac{1}{2}[A,B] + \frac{1}{12} [A,[A,B]] - \frac{1}{12} [B,[A,B]] + ...\]
consisting of terms involving higher commutators of $A$ and $B$. The full series is much too complicated to write, so we ask the reader to be satisfied with what is shown. 
\end{theorem}

\begin{corollary}
\[\Tr{\log{e^A \, e^B}} = \Tr{A} + \Tr{B}\]
\end{corollary}

\section{Spectral Theory} 
\subsection{Spectral Theory of General Mappings}
\begin{definition}
Let $A: V \longrightarrow V$ be a linear transformation over $\mathbb{F}$. If there exists a vector $v \in V$ such that
\[ A v = \lambda v, \; \lambda \in \mathbb{F}\]
then $a$ is called an \textit{eigenvalue} of $A$, and $v$ is an \textit{eigenvector} of $A$. Clearly, if a basis is realized for $V$ and $A$ is represented as a matrix, $v$ would have a basis representation. However, the value of $\lambda$ is invariant. The set of all eigenvalues 
\[\lambda(A) \equiv \{ \lambda_1, \lambda_2, ..., \lambda_k\}\]
is called the \textit{spectrum} of $A$. 
\end{definition}

\begin{remark}
For a given eigenvalue $\lambda$ and its corresponding eigenvector $v$, it is clear that by linearity, every vector in $\Span v$ is an eigenvector, too. 
\end{remark}

Now that we have defined eigenvalues and eigenvectors, we first provide a visual description of these terms. Given a linear transformation $A: V \longrightarrow V$, we can visualize a certain basis of $V$ such that all the linear transformation $A$ does on that basis is merely extend or contract the basis vectors.

\begin{definition}
Given a $n \times n$ matrix $A$, the \textit{characteristic polynomial} of $A$, denoted $p_A (t)$, is defined
\[ p_A (t) \equiv \det{(A - t I)}\]
The mapping $A \mapsto p_A (t)$ can be thought of as a mapping from Mat$(n, \mathbb{F}) \longrightarrow \mathbb{F}[t]$, where Mat$(n, \mathbb{F})$ is the algebra of $n \times n$ matrices over field $\mathbb{F}$, and $\mathbb{F}[t]$ is the polynomial algebra over $\mathbb{F}$. $p_A (t)$ is invariant under matrix similarity. 
\end{definition}

The motivation for defining such a polynomial is that it allows us to compute the eigenvalues of $A$. 
\begin{definition}
The \textit{characteristic equation} of $A$ is defined by equating $p_A (t) = 0$. 
\end{definition}

\begin{proposition}
The solutions of the characteristic equation of $A$ (i.e. the roots of $p_A (t)$) is precisely the spectrum of $A$. 
\end{proposition}

\begin{proof} $(\rightarrow)$ Let there be a $t = \lambda$ such that $p_A (\lambda) = 0 \iff \det{(A - \lambda I)} = 0$ which is equivalent to saying that ker$(A - \lambda I)$ is nontrivial. There must exist a $v \in $ ker$(A - \lambda I)$, meaning that $(A - \lambda I) v = 0 \iff A v = \lambda v$. By definition, $\lambda$ is an eigenvalue of $A$. \\
$(\leftarrow)$ This reasoning can be extended in the opposite direction. 
\end{proof}

\begin{theorem}
Eigenvectors of a linear transformation $A$ corresponding to different eigenvalues are linearly independent, but not necessarily orthogonal. It follows that if the characteristic polynomial of a $n \times n$ matrix $A$ has $n$ distinct roots, then $A$ has $n$ linearly independent eigenvectors. 
\end{theorem}

\begin{proof}
Simple, by contradiction.
\end{proof}

\begin{example}
It is clear that the Fibonacci sequence can be produced with matrix multiplication as such 
\[ \begin{pmatrix}
a_{n+1} \\ a_n
\end{pmatrix} = A^n \begin{pmatrix}
a_1 \\ a_0
\end{pmatrix} = \begin{pmatrix}
1&1\\1&0
\end{pmatrix}^n \begin{pmatrix}
1\\1
\end{pmatrix}\]
Given that 
\[\lambda_1 = \frac{1+\sqrt{5}}{2}, \; \lambda_2 = \frac{1 - \sqrt{5}}{2}\]
we can diagonalize $A$ into the form 
\[A = \begin{pmatrix}
\frac{1}{\lambda_1 - \lambda_2} & \frac{\lambda_2}{\lambda_2 - \lambda_1} \\
\frac{1}{\lambda_2 - \lambda_1} & \frac{\lambda_1}{\lambda_1 - \lambda_2}
\end{pmatrix} \begin{pmatrix}
\lambda_1 & 0 \\ 0 & \lambda_2 
\end{pmatrix} \begin{pmatrix}
\lambda_1 & \lambda_2 \\
1 & 1
\end{pmatrix} \implies A^n = S^{-1} \begin{pmatrix}
\lambda_1^n & 0 \\ 0 & \lambda_2^n 
\end{pmatrix} S\]
which implies that after evaluating, we get 
\[ a_n = \frac{1}{\sqrt{5}} \bigg( \Big(\frac{1+\sqrt{5}}{2}\Big)^n - \Big(\frac{1-\sqrt{5}}{2}\Big)^n \bigg)\]
This is a surprising result since it also says that the expression above is always an integer for all natural number $n$. 
\end{example}
\begin{definition}
Given a subspace $U_1 \subset U$ and linear transformation $T: U \longrightarrow U$. We say that $U_1$ is \textit{invariant} under $T$ if 
\[u \in U_1 \implies T u \in U_1\]
\end{definition}

\begin{theorem} 
Let $a_1, a_2, ..., a_n$ be the eigenvalues of $A$. Then 
\[\sum_i a_i = \Tr{A}, \;\;\; \prod_i a_i = \det{A}\]
\end{theorem}

\begin{proof}
The mapping $A \mapsto \det{(A - x I)}$ is a mapping from the set of $n \times n$ matrices to the polynomial algebra $\mathbb{F}[x]$. Direct application of the Viete's formulas in $\mathbb{F}[x]$ produces the statement and this result can be extended to the rest of the formulas. 
\end{proof}

\begin{theorem}[Spectral Mapping Theorem]
Let $q$ be any polynomial, $A$ a square matrix with an eigenvalue $a$. Then: 

i) $q(a)$ is an eigenvalue of $q(A)$. 

ii) Every eigenvalue $q(A)$ is of the form $q(a)$, where $a$ is an eigenvalue of $A$. 
\end{theorem}
\begin{proof} 
i) Let $h$ be an eigenvector of A with corresponding eigenvalue $a$. 
\begin{align*}
    Ah = ah & \implies A^{2} h = Aah = aAh = a^{2} h \\
 & \implies A^{n} h = a^{n} h   \\
 & \implies q(A)h = q(a)h \\
 & \implies q(a) \text{ is an eigenvalue of }q(A)
\end{align*}
ii) Let $p$ be the eigenvalue of $q(A) \iff \det{\big(q(A) - p I\big)} = 0$. We expand: 
$$ q(s) - p = c\prod \big(s-r_{i}\big), r_{i} \in \mathbb{C} $$ 
Replacing the variable $s$ with $A$, we have
$$ q(A) - pI = c \prod \big(A-r_{i}I\big) $$
Since $\det{\big( q(A) - pI\big)} = 0$, at least one $r_{i}$, say $r_{k}$ exists such that $\det{\big( A - r_{k} I \big)} = 0 \iff r_{k}$ is an eigenvalue of $A$. Since $q(r_{j})-p = 0$, $p = q(r_{j})$ is an eigenvalue of $q(A)$. 
\end{proof}

The following theorem is an equivalent version of the spectral mapping theorem.
\begin{theorem}
Let $A$ be a $n \times n$ matrix and let $f$ be a polynomial. If the chracteristic polynomial of $A$ has factorization 
\[p_A (t) = \prod_{i = 1}^n (t - \lambda_i)\]
then the characteristic polynomial of the matrix $f(A)$ is given by 
\[p_{f(a)} (t) = \prod_{i = 1}^n (t - f(\lambda_i))\]
\end{theorem}

We can actually create a bound on the spectrum of a square matrix. 

\begin{theorem}[Gershgorin Circle Theorem]
Let $A \in $ Mat$(n, \mathbb{C})$ with entries $a_{i j}$. Let $R_i = \sum_{i \neq j} |a_{i j}|$ be the sum of the absolute values of the non-diagonal entries of the $i$th row, and let $D_(a_{i i}, R_i) \subset \mathbb{C}$ be a closed disk with radius $R_i$ centered at $a_{i i}$ in the complex plane, called a \textit{Gershgorin Disk}. Then every eigenvalue of $A$ lies within the union of all $n$ Gershgorin Disks. That is, 
\[ \lambda_j (A) \in \bigcup_{i= 1}^{n} D_(a_{i i}, R_i) \subset \mathbb{C}, \text{ for all } j\]
\end{theorem}

\begin{proof}
Let $\lambda$ be an eigenvalue of $A$ with its eigenvector $v = (v_j)$. Scale $v$ by multiplying it by $ \pm 1 / \max{\{|v_j|\}_j}$ to get a vector $x$ with its maximal entry $x_i = 1$ and $|x_j| \leq 1, \; j \neq i$. Then, 
\[A x = \lambda x \implies \sum_{j} a_{i j} x_j = \lambda x_i = \lambda \implies \sum_{j \neq i} a_{i j} x_j + a_{i i} = \lambda\]
Applying the triangle inequality, 
\[| \lambda - a_{i i} | = \bigg| \sum_{j \neq i} a_{i j} x_j\bigg| \leq \sum_{j \neq i} |a_{i j}| |x_j| \leq \sum_{j \neq i} |a_{i j}| = R_i\]
\end{proof}

\begin{corollary}
The eigenvalues of $A$ must also lie within the Gershgorin discs $C_j$ corresponding to the columns of $A$. 
\end{corollary}

\begin{proof}
This is a direct result from the fact that $A$ is similar to $A^T$. Alternatively, we can apply the same process in the proof above to $A^T$.
\end{proof} 

If one observes that the off-diagonal entries of $A$ are small in absolute value, it can be concluded that the diagonal entries are "close" to the true eigenvalues of $A$. $A$ is diagonal if and only if the Gershgorin disks are points. 

\begin{theorem}[Cayley Hamilton]
Every matrix $A$ satisfies its own characteristic equation. That is, 
\[ p_{A}(A) = 0\]\
\end{theorem} 

\subsection{Eigendecompositions and Jordan Normal Form}

However, the entire concept of matrices are not fully grasped with just eigenvectors. If it were, then linear algebra would be a much simpler matter. To extend our toolkit, we must introduce generalized eigenvectors. From here, we will assume that our field is over $\mathbb{C}$. We use the fact that the field is over $\mathbb{C}$ because it allows us to claim that the characteristic polynomial in $\mathbb{C}[t]$ can be factored into linear components, by the fundamental theorem of algebra. 

\begin{definition}
A genuine eigenvector of $A$ satisfies $(A-aI)h = 0$. A \textit{generalized eigenvector} $f$ satisfies $(A-a I)^{d} f = 0$ for some $d \geq 1$. 
\end{definition}

To provide a visual intuition of how generalized eigenvectors transform under $A$, observe that 
\begin{align}
    (A - aI) h = 0 \text{ and } (A - aI)^2 f = 0 & \implies (A - aI)^f = h \\
    & \implies A f = a f + h, \; Ah = ah \\
    & \implies A^2 f = a A f + A h = a^2 f + 2 a h \\
    & \implies A^N f = A^N f + N a^{N-1} h 
\end{align}
This implies that the generalized eigenvector is first scaled by a factor of $a$, similar to a genuine eigenvector, but then a factor of the genuine eigenvector is then added to the scaled generalized one. Note that in higher dimensions of $N$, a greater multiple of $h$ must be added after scaling $f$. 

This means that given an eigenvalue $\lambda$, there is always at least one genuine eigenvalue associated with $\lambda$. Furthermore, there may be additional generalized eigenvectors also corresponding to $\lambda$. This leads to the following definition

\begin{definition}
The subspace formed by the span of the generalized (and genuine) eigenvectors of $\lambda$ form what is called the \textit{eigenspace associated with $\lambda$}, denoted $E(\lambda)$. 
\end{definition}

We can measure the characteristics of the eigenspaces with the following definitions. 

\begin{definition}
The \textit{algebraic multiplicity} of an eigenvalue $\lambda$ is the dimension of its eigenspace. It is precisely
\[\dim{E(\lambda)}\]  
In order to compute the algebraic multiplicity of $\lambda_i$ in $A$, we find the maximal value of $d_i$ such that $(t-\lambda)^{d_i}$ divides $p_A (t)$. With this, we can define 
\[E(\lambda) = \ker{(A - \lambda_i I)^{d_i}}\]
\end{definition} 

\begin{theorem}
Given $A: V \longrightarrow V$ with eigenspaces $E(\lambda_1), E(\lambda_2), ..., E(\lambda_k)$, 
\[E(\lambda_1) \oplus E(\lambda_2) \oplus ... \oplus E(\lambda_k) = V\]
That is, every vector $v \in V$ can be uniquely expressed as the sum 
\[ v = h_1 + h_2 + ... + h_k, \; h_i \in E(\lambda_i)\]
this is called the \textit{eigenbasis of $V$}. 
\end{theorem}
\begin{proof}
The definition of algebraic multiplicity implies that each eigenspace is disjoint except at $0$ and that their dimensions sum to $\dim{V}$. 
\end{proof}

\begin{definition}
The \textit{geometric multiplicity} of an eigenvalue $\lambda$ of a linear transformation $A$ is the dimension of the span of genuine eigenvectors in its eigenspace. It is precisely 
\[\dim{\ker{(A - \lambda I)}}\]
Note that since the span of genuine eigenvectors is a subspace of $E(\lambda)$, the geometric multiplicity is always less than or equal to the algebraic multiplicity. 
\end{definition}

Now we are ready to introduce the eigendecomposition of a linear mapping $A$.

\begin{theorem}
Given a linear mapping $A$ with its eigenvalues $\lambda_1, \lambda_2, ..., \lambda_k$ and associated eigenspaces $E(\lambda_1), E(\lambda_2), ..., E(\lambda_k)$, $A$ maps each eigenspace to itself. That is, 
\[A\big( E(\lambda_i) \big) \subset E(\lambda_i), \; i = 1, 2, ..., k\]
\end{theorem}

\begin{corollary}[Jordan Normal Form]
Every linear mapping $A: V \longrightarrow V$ can be decomposed into the sum of the linear mappings of each eigenspace $E(\lambda_i)$. That is, it can be expressed in the form 
\[A: \prod_i E(\lambda_i) \longrightarrow \prod_i E(\lambda_i)\]
which we can define, given $h_i \in E(\lambda_i)$, 
\[A(v) = A\bigg(\sum_i h_i \bigg) = \sum_i A(h_i), \; A(h_i) \in E(\lambda_i) \]
\end{corollary}

The process of eigendecomposition for a linear mapping $A$ is really just a clever change of basis for the $n \times n$ matrix representation of $A$ over $\mathbb{C}$, where the new basis is now the set of genuine and generalized eigenvectors. The new matrix formed by performing the change of basis on matrix $A$ is called the \textit{Jordan Normal Form}, or \textit{Jordan Canonical Form}, of $A$. We will now describe the construction of the JNF of an arbitrary $n \times n$ matrix. 

It is actually simple. Let the eigenvalues of the matrix $A$ be $\lambda_1, \lambda_2, ..., \lambda_k$, with its associated eigenspaces $E(\lambda_i)$. Let the algebraic multiplicity of eigenspace $E(\lambda_i)$ be $alg_i$. Then, every $n \times n$ matrix over $\mathbb{C}$ has the block form 
\[ J = \begin{pmatrix}
A_1&0&0&0\\
0&A_2&0&0\\
0&0&...&0\\
0&0&0&A_k
\end{pmatrix}\]
where each block $A_i$ represents the transformation in $E(\lambda_i)$. This means that each $A_i$ must be an $alg_i \times alg_i$ submatrix. The definition of the generalized eigenvectors shown in equation $(11)$ shows that each block must be of form 
\[A_i = \begin{pmatrix}
\lambda_i & 1 & 0 & ... & 0\\
0 &\lambda_i & 1 &...&0 \\
0&0&\lambda_i&...&0\\
...&...&...&...&1\\
0&0&...&0&\lambda_i
\end{pmatrix}\]
With $\lambda_i$'s in the main diagonal and $1$'s in the superdiagonal of $A_i$. The first column of $A$ refers to the transformation of the genuine eigenvector, while the other columns refers to the transformation of the generalized eigenvectors, where $\lambda_i$ refers to the scaling of the $d$th generalized eigenvector and the $1$ refers to the adding of the $(d-1)$th generalized eigenvector to the scaled $d$th vector. If there are no generalized eigenvectors in an eigenspace $E(\lambda_i)$, then $A_i$ is a $1 \times 1$ matrix $( \lambda_i )$. Observe that this form is consistent with our previous theorems, especially the fact that $A$ maps distinct eigenspaces to themselves. 

Finally, the change of basis is represented through the matrix multiplication. 
\[J = P^{-1} A P, \; P = \begin{pmatrix}
|&|&|&| \\ 
f_1&f_2&...&f_n \\
|&|&|&|
\end{pmatrix} \]
where $f_i$ is the genuine/generalized eigenvectors corresponding to the transformation represented in the $i$th column of $J$. The Jordan Normal Form of a matrix is unique up to the permutations of its diagonal blocks. 

Notice that the Jordan Normal Form must be an $n \times n$ matrices over $\mathbb{C}$, not $\mathbb{R}$. However, given a matrix $A$ over $\mathbb{R}$, we can construct a similar block diagonal form over $\mathbb{R}$. Since $A$ is real $\implies p_A (t) \in \mathbb{R}[t]$, $\mu \in \mathbb{C}$ is a root of $p_A$ implies that $\bar{\mu}$ is also a root. This means that in the case where $\mu = a \pm b i$ is a pair of complex eigenvectors with eigenvectors $z$ and $\bar{z}$. The associated $2 \times 2$ Jordan block will be of form
\[\begin{pmatrix}
a&-b\\ b&a
\end{pmatrix}\]
with the associated column vectors in $P$ being
\[v_1 = \frac{z + \bar{z}}{2}, \; v_2 = \frac{i (z - \bar{z})}{2}\]
Notice that $z \in \mathbb{C}^n$ is a complex eigenvector belonging to complex eigenvalue $\mu$, and we make the best "approximations" of $z, \bar{z}$ and $\mu, \bar{\mu}$ with the new real vectors $v_1$ and $v_2$. Note that the Jordan block states that
\[A(v_1) = a v_1 + b v_2, \; A(v_2) = -b v_1 + a v_2\]
which is true since 
\begin{align*}
    A(v_1) = A\Big( \frac{z + \bar{z}}{2} \Big) & = \frac{1}{2} \big( A(z) + A(\bar{z}) \big) \\
    & = \frac{1}{2}\big( (a+bi)z + (a-bi) \bar{z} \big) \\
    & = \frac{1}{2} \big( (a)(z + \bar{z}) + (bi) (z - \bar{z})\big) \\
    & = a \frac{z + \bar{z}}{2} + b \frac{i(z-\bar{z}}{2} = a v_1 + b v_2 \\
\end{align*}
and 
\begin{align*}
    A(v_2) = A \Big( \frac{i(z-\bar{z})}{2} \Big) & = \frac{i}{2} \big( A(z) - A(\bar{z}) \big) \\
    & = \frac{i}{2} \big( (a+bi) z - (a-bi) \bar{z}\big) \\
    & = \frac{i}{2} \big( (a) (z - \bar{z}) + (bi)(z+\bar{z})\big) \\
    & = a \frac{i(z-\bar{z})}{2} - b \frac{z + \bar{z}}{2} = a v_2 - b v_1
\end{align*}
It suffices to only modify this case for $2 \times 2$ blocks because all complex eigenvalues of real matrices must come in conjugate pairs (but this is not necessarily true for complex matrices, which have characteristic polynomials in $\mathbb{C}[t]$). 

\begin{corollary}
The following $2 \times 2$ Jordan block of the form shown below can be turned into the complex Jordan block and vice versa. 
\[\begin{pmatrix}
\cos{\theta} & -\sin{\theta} \\
\sin{\theta} & \cos{\theta} 
\end{pmatrix} \xleftrightarrow{} \begin{pmatrix}
e^{i \theta} & 0 \\
0 & e^{- i \theta}
\end{pmatrix}\]
\end{corollary}

However, there could be bigger Jordan blocks of generalized eigenspaces corresponding to conjugate pairs. Observe the following JNF, with columns (from left to right) corresponding to the transformations $h_1$ (genuine), $k_1$ (generalized), $h_2$ (genuine), and $k_2$ generalized). 
\[\begin{pmatrix}
e^{i \theta} & 1 & & \\
& e^{i \theta} & & \\
& & e^{-i \theta} & 1 \\
& & & e^{i- \theta}
\end{pmatrix}\]
Using the corollary shown above, we can modify the eigenvalues and eigenvectors into real values and construct the simplest "real form" (assuming $i \neq 0, \pi$) of the matrix 
\[\begin{pmatrix}
\cos{\theta} & - \sin{\theta} & 1 & 0 \\
\sin{\theta} & \cos{\theta} & 0 & 1 \\
0 & 0 & \cos{\theta} & - \sin{\theta} \\
0 & 0 & \sin{\theta} & \cos{\theta}
\end{pmatrix}\]
where the columns (from left left to right) now correspond to transformation of real eigenvectors
\[\frac{h_1 + h_2}{2}, \frac{i(h_1 - h_2)}{2}, \frac{k_1 + k_2}{2}, \frac{i(k_1 - k_2)}{2}\]
Therefore, we can state that the linear transformation represented by the two matrices in their respective bases are equivalent. 

\begin{example}
The linear operator that rotates around a vector $v$ by an angle $\theta$ has an eigendecomposition of the span of $v$ as shown (with eigenvalue $1$) and the 2-dimensional plane (having two complex eigenvalues). 
\begin{center}
    \includegraphics[scale=0.25]{Rotation_Map_Eigendecomposition.PNG}
\end{center}
\end{example}

\begin{definition}
A matrix is \textit{diagonalizable} if we can perform a change of basis on it to create a diagonal matrix. 
\end{definition}

\begin{theorem}
A matrix is diagonalizable if and only if its algebraic multiplicities is equal to its geometric multiplicities. That is, if the matrix only has genuine eigenvectors. This is also equivalent to saying that all of $A$'s eigenspaces have dimension $1$. 
\end{theorem}

It is clear that since eigendecompositions are intrinsic to linear mappings, the JNF of similar matrices are the same. That is, the eigenvalues and the dimensions of the eigenspaces are invariant under a change of basis. 

\begin{proposition}
Two matrices are similar if and only if their eigendecompositions are the same. That is, if they have the same eigenvalues and the dimensions of the corresponding eigenspaces are the same. 
\end{proposition}

\begin{proof}
$(\rightarrow)$ $A \sim B \implies A = S^{-1} B S = S^{-1} P^{-1} J P S = (PS)^{-1} J (PS) \implies$ JNF of $A$ and $B$ are the same.  \\
$(\leftarrow)$ $A$ and $B$ have same JNF $\implies A = P^{-1} J P, B = Q^{-1} J Q \implies J = Q B Q^{-1} \implies A = P^{-1} Q B Q^{-1} P = (Q^{-1} P)^{-1} B (Q^{-1} P) \implies A \sim B$. 
\end{proof}

\begin{theorem}
$A \sim A^T$. 
\end{theorem}
\begin{proof}
By the proposition above, it is sufficient to prove that $A$ and $A^T$ have the same eigendecomposition. Since $(A - \lambda I)^T = A^T - \lambda I$, $\det{(A - \lambda I)} = 0 \iff \det{(A - \lambda I)^T} = \det{(A^T - \lambda I)} \implies $ $A$ and $A^T$ have the same eigenvalues. Similarly, $\big( (A - \lambda I)^d \big)^T = (A^T - \lambda I)^d \implies$ the eigenspaces of $A$ and $A^T$ have the same dimension. 
\end{proof}

\section{Further Properties of Linear Mappings}
\subsection{Adjoint Operators}
\begin{definition}
Let $A: U \longrightarrow V$ be a linear mapping between inner product spaces, with the inner product in $U$ and $V$ denoted $(\cdot,\cdot)_U$ and $(\cdot,\cdot)_V$, respectively. We can fix any $v \in V$ and define the linear function $l \in U^*$
\begin{equation}
    l(\cdot) = \big(A(\cdot), v\big)_V
\end{equation}
Since $U$ is naturally isomorphic to $U^*$, we can define
\begin{equation}
    l(\cdot) \equiv (\cdot, u^\prime)
\end{equation} 
to get 
\begin{equation}
    \big(\cdot, u^\prime \big)_U \equiv \big(A(\cdot), v \big)_V
\end{equation}
By combining $(8)$, which defines an isomorphism between $U^*$ and $V$, and $(9)$, the natural isomorphism between $U$ and $U^*$, equation $(10)$ takes the composition of these to define an isomorphism from $V$ to $U$. This isomorphism is called the \textit{adjoint} of $A$. 
\[A^\dagger: V \longrightarrow U, \;  \big(\; \cdot \;, A^\dagger v \big)_U = \big( A(\cdot), v \,\big)_V \]
By definition, given any $v \in V$, $A^\dagger v$ is defined so that the equality
\[(u, A^\dagger v) = (A u, v)\]
holds for all values of $u \in U$. 
\end{definition}

It is important to note that the adjoint is not the same as the transpose since the transpose is a mapping between the dual spaces. Furthermore, the transpose is canonically defined upon defining the linear transformation $A: U \longrightarrow V$, while defining the adjoint requires the additional structure of an isomorphism from $U$ to $U^*$ and from $V$ to $V^*$. There are two ways to define these isomorphisms. \\

First, we can define dot products on both $U$ and $V$ and define the natural isomorphism 
\begin{align*}
    &i: U \longrightarrow U^*, \; i(u) \equiv (u, \cdot) \in U^*\\
    &j: V \longrightarrow V^*, \; j(v) \equiv (v, \cdot) \in V^*
\end{align*}
This canonically creates the mapping 
\[i^{-1} A^T j: V \longrightarrow U\]
which we define as the adjoint $A^\dagger$. This method using natural isomorphisms is precisely how we have defined the adjoint above. \\

There is a second way, however. We can fix \textit{orthonomal} bases on $U$ and $V$ and then assign them their respective dual spaces (satisfying the Kronecker delta function). Let the basis of $U$ be $\{u_1, ..., u_n\}$, $U^*$ be $\{u_1^\prime, ..., u_n^\prime\}$, $V$ be $\{v_1, ..., v_m\}$, and $V^*$ be $\{v_1^\prime, ..., v_m^\prime\}$. Now we can define the isomorphisms 
\begin{align*}
    & i^\prime: U \longrightarrow U^*, \; i^\prime (u) \equiv c_1 u_1^\prime + ... + c_n u_n^\prime \\
    & j^\prime: V \longrightarrow V^*, \; j^\prime (v) \equiv k_1 v_1^\prime + ... + k_m v_m^\prime
\end{align*}
and then define the adjoint as 
\[A^\dagger \equiv i^{\prime -1} A^T j^\prime\]
Let us compare these two definitions. Given a vector $u = a_1 u_1 + ... + a_n u_n, \Tilde{u} = b_1 u_1 + ... b_n u_n \in U$, 
\begin{align*}
    &i(u)(\Tilde{u}) \equiv (u, \Tilde{u}) = \Big(\sum_{\alpha = 1}^n a_\alpha u_\alpha, \sum_{\beta = 1}^n b_\beta u_\beta \Big) = \sum_{\alpha, \beta} a_\alpha b_\beta \delta^\alpha_\beta = \sum_{\gamma=1}^n a_\gamma b_\gamma \\
    &i^\prime(u)(\Tilde{u}) \equiv \Big(\sum_{i=1}^n a_i u_i^\prime \Big) \Big( \sum_{j=1}^n b_j u_j \Big) = \sum_{i, j} a_i b_j u_i^\prime (u_j) = \sum_{i, j} a_i b_j \delta^i_j = \sum_{k=1}^n a_k b_k
\end{align*}
Similarly for vector $v = g_1 v_1 + ... g_n v_n, \Tilde{v} = h_1 v_1 + ... + h_n v_n \in V$, 
\begin{align*}
    &i(v)(\Tilde{v}) \equiv (v, \Tilde{v}) = \Big(\sum_{\alpha = 1}^n g_\alpha v_\alpha, \sum_{\beta = 1}^n h_\beta v_\beta \Big) = \sum_{\alpha, \beta} g_\alpha h_\beta \delta^\alpha_\beta = \sum_{\gamma=1}^n g_\gamma h_\gamma \\
    &i^\prime(v)(\Tilde{v}) \equiv \Big(\sum_{i=1}^n g_i u_i^\prime \Big) \Big( \sum_{j=1}^n h_j v_j \Big) = \sum_{i, j} g_i h_j v_i^\prime (v_j) = \sum_{i, j} g_i h_j \delta^i_j = \sum_{k=1}^n g_k h_k
\end{align*}
Therefore, $i = i^\prime$ and $j = j^\prime$, meaning that the two derivations of the adjoint $A = i^{-1} A^T j = i^{-1 \prime} A^T j^\prime$ are exactly the same! We must note that the basis endowed on both $U$ and $V$ must be orthonormal for it to "mimic" the inner product. The derivation of the adjoint in these two equivalent methods may help the reader further understand that the adjoint $A^\dagger$ is really just a composition of fundamental linear functions $j: V \longrightarrow V^*$, $A^T: V^* \longrightarrow U^*$, and $i^{-1}: U^* \longrightarrow U$ that are all canonically created as soon as $A: U \longrightarrow V$ is created, along with the inner product spaces $U$ and $V$. 
\[
  \begin{tikzcd}
    U \arrow{r}{A} \arrow{d}{i} & V \arrow{d}{j}\\
    U^* & V^* \arrow{l}{A^T}
  \end{tikzcd}
\]

However, it is hard to grasp a visual intuition of adjoint operators in general. Note that the properties of the transpose indicate that given $A: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ with the standard orthonormal basis and dot product, the matrix representation of $A^\dagger$ is just $A^T$. If $A$ is a matrix over $\mathbb{C}$, then $A^\dagger$ is $A^H \equiv \bar{A}^T$, the \textit{Hermitian transpose}, or \textit{conjugate transpose}, of $A$. 

\begin{remark}
Note that this definition of the adjoint of linear operators is completely unrelated to the definition of an adjoint of a matrix! 
\end{remark}

We now describe one common application of adjoints. 
\begin{theorem}
Let $A \in$ Mat$(m \times n, \mathbb{R})$ with $m > n$. This means that the system of equations $A x = p$ is an overdetermined system and will have no solutions with probability 1. However, we can find the \textit{best-fit solution} of the system. That is, the vector $x$ that minimizes $||A x -p||^2$ is the solution $z$ of 
\[ A^\dagger A z = A^\dagger p\]
$z$ is therefore, the "closest approximation" of the solution of $A x = p$ that lives in $\mathbb{R}^n$. 
\end{theorem}

The QR decomposition is often used to simplify these linear least squares problems into a more manageable equation. 

\begin{theorem}[QR Decomposition]
Any real $m \times n$ matrix $A$ mapping $\mathbb{R}^n \longrightarrow \mathbb{R}^m$ may be decomposed as
\[A = Q R\] 
where $Q$ is a $m \times n$ matrix with column vectors that are pairwise orthonormal and $R$ is an upper triangular square matrix. $Q$ having pairwise orthonormal columns $\implies Q^T Q = I$, so we can simplify the normal equation
\begin{align*}
    A^T A x = A^T b & \implies (Q R)^T (Q R) x = R^T Q^T Q R x = R^T R x = R^T Q^T b \\
    & \implies R x = Q^T b \\
    & \implies x = R^{-1} Q^T b
\end{align*}
\end{theorem}

\begin{theorem}
Let $P_Y$ be the orthogonal projection onto $Y$. Then, 
\begin{enumerate}
    \item $P_Y = P_Y^2$. 
    \item $P_Y = P_Y^\dagger$. 
\end{enumerate}
\end{theorem}

\begin{theorem}[Properties of the Adjoint] Let $A, B: X \longrightarrow U, \; C: U \longrightarrow V$ be linear mappings. Then, 
\begin{enumerate}
    \item $(A + B)^\dagger = A^\dagger + B^\dagger$
    \item $(C A)^\dagger = A^\dagger C^\dagger$
    \item $(A^{-1})^\dagger = (A^\dagger)^{-1}$ if $A$ is bijective
    \item $(A^\dagger)^\dagger = A$
\end{enumerate}
\end{theorem}

\begin{definition}
Linear mapping $A$ is \textit{self adjoint} if and only if $A = A^\dagger$. If $M$ is any linear mapping, then its self-adjoint part is 
\[M_\delta = \frac{M + M^\dagger}{2}\]
\end{definition}

\begin{theorem}[Spectral Theorem]
A $n$-dimensional self-adjoint map $H$ over $\mathbb{C}$ has real eigenvalues and an orthonormal basis of genuine eigenvectors. That is, its eigendecomposition consists of $n$ pairwise orthogonal eigenspaces. 
\end{theorem}

\begin{corollary}
Given a real self-adjoint matrix $H$, there exists a real invertible matrix $M$ such that $M^\dagger H M = D$, with $D$ diagonal and the column vectors form an orthonormal basis.
\\

So, given self-adjoint $H: X \longrightarrow X$, the whole space can be written as the direct sum of pairwise orthogonal eigenspaces. 
\[X = \bigoplus_{i=1}^n E(\lambda_i)\]
which implies that every $x \in X$ can be written uniquely as 
\[x = x_1 + x_2 + ... + x_n, \; x_i \in E(\lambda_i) \]
\end{corollary}

\begin{definition}
Given that $P_j$ is the orthogonal projection onto the $j$th eigenspace $E(\lambda_j)$, that is
\[P_j (x) = x_j \in E(\lambda_j), \; \text{ ($P_j$ also self adjoint)}\]
the \textit{spectral resolution} of self-adjoint mapping $H$ is the decomposition into the form 
\[H = \sum_j \lambda_j P_j \implies H x = \bigg( \sum_j \lambda_j P_j \bigg) x = \sum_j \lambda_j x_j\]
The resolution of the identity is
\[I = \sum_j P_j\]
\end{definition}

\begin{proposition}
Given the spectral resolution of self-adjoint $H$, 
\[H  = \sum_j \lambda_j P_j \implies H^2 = \sum_j \lambda_j^2 P_j\]
\end{proposition}

Note that the spectral resolution of a self adjoint mapping is precisely the eigendecomposition of the mapping into its 1-dimensional eigenspaces. It is merely a simpler form of the eigendecomposition in the specific case when the linear mapping is self-adjoint. 

\begin{theorem}
Let $H, K$ be self-adjoint mappings such that $H K = K H$. Then $H$ and $K$ have the same spectral resolution, i.e. they have the same eigendecomposition. 
\[H = \sum_j a_j P_j, \; \; K = \sum_j b_j P_j\]
\end{theorem}
\begin{proof}
$ x \in E(a) H x = a x \implies K H x = a K x \implies H K x = a K x \implies K x \in E(a)$. Similarly, we can do this with $K$ to find $x \in E(a) \implies H x \in E(a)$, meaning that $K$ and $H$ have the same eigendecompositions (though their eigenvalues are not necessarily equal). 
\end{proof}

\begin{definition}
Map $A$ is \textit{anti-self adjoint }if $A^\dagger = - A$. Conjugate symmetry implies that
\[ A^\dagger = A \iff (i A)^\dagger = - (i A)\]
So, given an anti-self adjoint map $A$, we can apply the spectral resolution to $iA$. 
\end{definition}

\begin{theorem}
Given anti-self adjoint $A: \mathbb{C}^n \longrightarrow \mathbb{C}^n$, 

i) eigenvalues of $A$ are purely imaginary

ii) we can choose an orthonormal basis of eigenvectors of $A$
\end{theorem}

\begin{proof}
This easily follows from the Spectral Theorem. 
\end{proof}

\begin{definition}
$N: X \longrightarrow X$ is a \textit{normal mapping} if $N^\dagger N = N N^\dagger$. Self-adjoint, anti-self adjoint, and unitary matrices are all normal. Surprisingly, the set of normal matrices are not closed under addition nor multiplication, so they do not form a group. 
\end{definition}

\begin{theorem}
A map $N$ is normal if and only if it has an orthonormal basis of eigenvectors, i.e. it is unitarily diagonalizable. That is, 
\[N = U^\dagger D U \]
\end{theorem}

\begin{proof}
$(\rightarrow)$ Let 
\[H = \frac{1}{2} (N + N^\dagger), \; A = \frac{1}{2} (N - N^\dagger)\]
$N^\dagger N = N N^\dagger \implies A H = H A$, where $H$ is self adjoint, $A$ is anti-self adjoint, and $N = H + A, N^\dagger = H - A$. Since $A H = H A$, they have the same spectral resolution of orthonormal eigenspaces, which also forms the same spectral resolution for $N = H + A$. \\
$(\leftarrow)$ $A = U^\dagger D U \implies A^\dagger A = (U^\dagger D U) (U^\dagger \bar{D} U) = U^\dagger D \bar{D} U = A A^\dagger$. 
\end{proof}

\subsection{Lie Groups and the Exponential Map}
\begin{definition}
Aut$(V)$ of vector space $V$ also forms a group under composition. We denote it GL$(V)$. The group of automorphisms of $\mathbb{R}^n$ and $\mathbb{C}^n$ is denoted GL$(\mathbb{R}^n)$ and GL$(\mathbb{C}^n)$, respectively. The group of all invertible $n \times n$ matrices over $\mathbb{R}$ and $\mathbb{C}$ is denoted GL$_n(\mathbb{R})$ and GL$_n(\mathbb{C})$. GL$_n(\mathbb{R})$ is also denoted GL$(n, \mathbb{R})$, and similarly for GL$(n, \mathbb{C})$. 
\end{definition}

\begin{proposition}
Given that $V$ is a real vector space, 
\[GL(V) \simeq GL(\mathbb{R}^n) \simeq GL_n (\mathbb{R})\]
since GL$_n(\mathbb{R})$ are representations of linear operators. Similarly, if $V$ is a complex vector space, 
\[GL(V) \simeq GL(\mathbb{C}^n) \simeq GL_n (\mathbb{C})\]
\end{proposition}

\begin{definition}
The group of all real $n \times n$ matrices that have determinant $1$ is called the \textit{special linear group}, denoted SL$_n (\mathbb{R})$. It is a subgroup of GL$_n (\mathbb{R})$. The group of all complex $n \times n$ matrices with determinant $1$ is denoted SL$_n (\mathbb{C})$. It is a subgroup of GL$_n(\mathbb{C})$. 
\end{definition}

\begin{definition}
An \textit{isometry} $M$ of metric space $(X, d)$ is a mapping that preserves all distances. That is, for all $x, y \in X$, 
\[d(x, y) = d(M x, M y) \]
The set of all isometries, denoted Isom$(X)$, is a group that is generated by all translations, rotations, and reflections. 
\end{definition}

Since linear maps always preserve the origin, we will focus on origin-preserving isometries, which is a subgroup called the orthogonal group.

\begin{definition}
The \textit{orthogonal group} of a real Euclidean space of dimension $n$, denoted $O(n)$, is the group of all origin-preserving isometries of the space consisting of rotations and reflections. The matrix representation of this group is the set of real $n \times n$ matrices where the column vectors form an orthonormal basis. Note that the determinant of every element of $O(n)$ is $\pm 1$. 
\end{definition}

\begin{definition}
An \textit{orthogonal matrix} is the matrix representation of an element in $O(n)$. It is the real $n \times n$ matrix where all the column vectors are pairwise orthogonal and all have magnitude 1. 
\end{definition}

\begin{proposition}
The rows of an orthogonal matrix are also pairwise orthonormal.
\end{proposition}

\begin{proposition}
Given an orthogonal matrix $M$,
\[M^T = M^{-1}\]
\end{proposition}

\begin{definition}
The \textit{special orthogonal group} of a real Euclidean space of dimension $n$, denoted $SO(n)$, is the group of all isometries that preserve the handedness of the space consisting only of rotations. It is a subgroup of $O(n)$. The matrix representation of this group is the set of real $n \times n$ matrices where the column vectors are pairwise orthonormal and the determinant $=1$. 
\end{definition}

We extend this concept to complex Euclidean spaces. 

\begin{definition}
The \textit{unitary group of degree $n$} is the group of all complex $n \times n$ matrices where the columns are pairwise orthogonal. It is denoted $U(n)$. 
\end{definition}

\begin{example}
$U(1)$ is the set of complex numbers with norm $1$. 
\end{example}

\begin{definition}
The \textit{special unitary group of degree $n$} is the group of all complex $n \times n$ matrices where the columns are pairwise orthogonal and determinant $=1$. It is denoted $SU(n)$. 
\end{definition}

The groups mentioned in this section are examples of \textit{Lie Groups}. Lie groups in general will not be defined in here, since they require knowledge of smooth manifolds and differential geometry. In order to analyze these abstract groups, we use the exponential map $e \in$ End$($ Mat$(n, \mathbb{F})$ to reduce these Lie groups to Lie algebras.

\subsection{Singular Values, Norms of Linear Mappings}
Since the algebra of linear operators is itself a vector space, we can also define structures on it, too. We focus on matrix norms. 

\begin{definition}
Let $A: X \longrightarrow U$ be linear. Then, we define
\[||A|| = \sup_{||x||=1} ||A x||\]
Note that $||A x||$ is measure with respect to the norm of $U$ and $||x||$ the norm of $X$. 
\end{definition}

There is a very nice visualization of this. Given that $\dim{X}=n$, imagine the $n$-dimensional unit ball in $X$ being transformed under $A$. The image of the ball should be an ellipsoid (of dimension $\leq m$) in $U$. 
\begin{center}
    \includegraphics[scale=0.4]{Matrix_Norm_Visualization.png}
\end{center}
The norm of $A$ is the length of the major axis of the ellipsoid. 

\begin{theorem}
\begin{align}
    ||A z|| \leq ||A|| ||z|| \text{ for all } z \in X \\
    ||A|| = \sup_{||x||, ||v|| = 1} (A x, v)
\end{align}
\end{theorem}
\begin{proof}
\begin{align*}
    &||A z|| \leq \sup{||A z||} = \sup{\Big|\Big| A \frac{z}{||z||} \Big|\Big|} = ||A|| ||z|| \\
    &||u|| \equiv \max_{||v||=1} (u, v) \implies ||A x|| \equiv \max_{||v||=1} (Ax, v) \implies ||A|| \equiv \sup_{||x||, ||v|| =1} (A x, v)
\end{align*}
\end{proof}

\begin{theorem}[Properties of Matrix Norm]
Let there exist any $k \in \mathbb{F}$, with any $A, B: X \longrightarrow U$, $C: U \longrightarrow V$. Then, 
\begin{enumerate}
    \item $||k A|| = |k| ||A||$
    \item $||A + B|| \leq ||A|| + ||B||$
    \item $||C A|| \leq ||C|| ||A||$
    \item $||A|| = ||A^\dagger||$
\end{enumerate}
\end{theorem}

\begin{definition}
The \textit{spectral radius} of $A$ is defined
\[r(A) \equiv \max_i |a_i|, \; a_i \text{ are eigenvalues}\]
\end{definition}

\begin{proposition}
A simple lower and upper bound of $||A||$ can be defined
\[ r(A) \leq ||A|| \leq \bigg( \sum_{i, j} a_{i j}^2 \bigg)^\frac{1}{2}\]
\end{proposition}

Matrix norms have extremely useful applications in determining the existence of invereses. 

\begin{theorem}
Let $A$ be invertible and 
\[||A - B|| < \frac{1}{||A^{-1}||}\]
in the sense that $B$ is "close" to $A$. Then $B$ is invertible. 
\end{theorem}
We now proceed to another crucial decomposition, called the singular value decomposition. While the JNF allows us to choose the most convenient choice of basis for a square matrix, the Singular Value Decomposition (SVD) allows us to decompose general $m \times n$ matrices. 

\begin{theorem}[Singular Value Decomposition]
Any linear mapping $M$ from an $n$-dimensional inner product space to a $m$-dimensional inner product space can be decomposed into 
\[ M = U \Sigma V^\dagger = \begin{pmatrix}
|&|&|&|\\
y_1&y_2&...&y_m \\
|&|&|&|
\end{pmatrix}\begin{pmatrix}
\sigma_1&&&&0\\
&...&&&...\\
&&\sigma_p&&0\\
&&&...&...\\
0&...&0&...&0
\end{pmatrix} \begin{pmatrix}
&x_1&\\&x_2&\\&...&\\&x_n&
\end{pmatrix} \]
where $U \in U(m), V \in U(n)$ and $\Sigma$ has diagonal elements with nonnegative real entries. Also, $p = $ rank$(M) \leq \min{\{n,m\}}$. This form is known as the \textit{singular value decomposition}. The columns of $U$, denoted $y_i$, are called the \textit{left singular vectors} and the columns of $V$ (i.e. the rows of $V^\dagger$), denoted $x_i$, are called the \textit{right singular vectors}. The diagonal entries of $\Sigma$ are called the \textit{singular values}. 
\\

The SVD is unique up to the order of singular values, but it is generally constructed so that $\sigma_1 \geq \sigma_2 \geq ... \geq \sigma_p$. 
\end{theorem}

To provide a brief, yet unrigorous, justificiation of why the SVD exists, we look at the linear mapping $M: X \longrightarrow Y$, with $\dim{X} = n, \dim{Y} = m$. If $M$ is injective $(\iff m \geq n)$, given the basis $\{e_i\}$ for $X$, we can complete the linearly independent set $\{Me_i\}_{i=1}^n$ to a basis in $Y$ and represent $M$ as the mapping
\[\Sigma_{inj} = \begin{pmatrix}
&&\\
&I_n&\\
&&\\
0&...&0
\end{pmatrix}\]
If $M$ is surjective $(\iff m \leq n)$, then given basis $\{f_i\}_{i=1}^m$ of $Y$, we can choose a basis $\{e_j\}_{j=1}^n$ of $X$ such that $M(e_i) = f_i (i = 1, 2, ..., m)$, and $M(e_i) = 0$ when $i > m$. This produces the matrix
\[\Sigma_{surj} = \begin{pmatrix}
&&&0\\&I_m&&...\\&&&0\end{pmatrix}\]
We now present the following theorem without proof. 

\begin{theorem}
Any map $M: X \longrightarrow Y$ can be written as a surjective map followed by an injective map. 
\end{theorem}

This theorem implies that any map, when given the right choice of basis, can be written as 
\[ \Sigma_{inj} \Sigma_{surj} = \begin{pmatrix}
&&&...&0\\
&I_p&&...&0\\
&&&...&...\\
...&...&...&...&0\\
0&0&...&0&0
\end{pmatrix} = \begin{pmatrix}
1&&&&0\\
&...&&&...\\
&&1&&0\\
&&&...&...\\
0&...&0&...&0
\end{pmatrix}\]
where rk$(M) = p = $ the number of $1$'s in $\Sigma_{inj} \Sigma_{surj}$. As for choosing the proper set basis for $X$ and $Y$, we can find these passive transformations in the unitary groups $U(n)$ and $U(m)$. 
\\

We now present a geometric description of the singular value decomposition. Think of the unit $n$-ball being rotated and flipped ($V^\dagger$ applied) under the unitary transformation. Then, it is stretched along its othogonal axes to result in an ellipsoid living in an $m$-dimensional space. The factor of stretching and compressing the axes are precisely the singular values. Finally, this ellipsoid is rotated and flipped ($U$ applied) back to its original basis. 

\begin{theorem}
Geometrically, we can see that the largest singular value is the matrix norm, also called the operator norm. 
\[||M|| = \sigma_1\]
\end{theorem}

\begin{theorem}[Properties of Singular Values] Given linear mapping $A$ from a $n$-dimensional inner product space to $m$-dimensional inner product space, 
\begin{enumerate}
    \item $\sigma_i(A) = \sigma_i (A^T) = \sigma_i (A^\dagger) = \sigma_i (\bar{A})$
    \item $\forall \; U \in U(m), V \in U(n), \; \sigma_i (A) = \sigma_i (U A V)$
    \item Relation to eigenvalues
\[\sigma_i^2(A) = \lambda_i (A^\dagger A) = \lambda_i (A A^\dagger)\]
\end{enumerate}
\end{theorem}

We now present the (not the best) process of computing SVD of small matrices by hand. Given matrix $M$, $M = U \Sigma V^\dagger \implies M^\dagger M = V \Sigma^2 V^\dagger$. The eigenvalues of $M^\dagger M$ are $\sigma_i^2$ with corresponding eigenvectors being the columns of $V$, which can all be found by putting $M^\dagger M$ into JNF. We repeat this process for $M M^\dagger = U \Sigma^2 U^\dagger$ to find the eigenvectors that make up the column vectors of $U$. 

\begin{theorem}
Let $A: X \longrightarrow Y$, with $\dim{X} = n, \dim{Y} = m$, and let $k \leq \min{\{m, n\}}$, with $A = U \Sigma V^\dagger$. Then, amongst all rank $k$ $m \times n$ matrices $B$, the matrix $A^{(k)}$ minimizes 
\[||A-B||_2, \; A^{(k)} = U \Sigma^{(k)} V^\dagger\]
and $\Sigma^{(k)}$ is $\Sigma$ with $\sigma_{k+1} = \sigma_{k+2} = ... = 0$. Therefore, to see how "close" $B$ is to $A$, we can compare the singular values of $A$ and $B$, given that they both have the same unitary matrices $U$ and $V$. 
\end{theorem}

The singular value decomposition has many applications in high dimensional data analysis and data compression. For example, in a set of $m$ data points in $\mathbb{R}^n$ that each lie in the rows of matrix $A$, if the singular values of $A$ suddenly drops (e.g. 120, 118, 107, 98, 2, 1, 0.3, ...) then we can determine that the points "almost" lie in a subspace in $\mathbb{R}^n$. Knowing this allows us to compress high dimensional data to $A^{(k)}$, which is a more manageable form. This is especially useful in the data compression of electronic images, where each pixel is treated as a single number to form a matrix. 

It can also be used to define the "pseudo-inverse" of a matrix that may not be invertible. 

\begin{definition}
Given matrix $M = U \Sigma V^\dagger$ in SVD, we define the \textit{pseudo-inverse} $M^+ = V \Sigma^+ U^\dagger$, where $\Sigma^+$ is $\Sigma$ with entries $\sigma_i^{-1}$, or $0$ if $\sigma_i = 0$. For example,
\[ \Sigma = \begin{pmatrix}3&0&0\\0&2&0\\0&0&0\end{pmatrix} \implies \Sigma^+ = \begin{pmatrix}1/3&0&0\\0&1/2&0\\0&0&0\end{pmatrix}\]
$\implies M^+ M = V \Sigma^+ \Sigma V^\dagger$. If $M$ is square and all $\sigma_i \neq 0$, then $M^\dagger M = V V^\dagger \implies M^\dagger M = I \implies  M^+ = M^{-1}$. 
\end{definition}

By computing the SVD of $M$, where $\sigma_p \neq 0, p =$ rk$\,M = $ rk$\,\Sigma$, we can automatically compute the 4 fundamental spaces. 
\[M = U \Sigma V^\dagger = \begin{pmatrix}&&&&|&\\&&&&|&\\&&U&&|&U^\prime\\&&&&|&\\&&&&|&
\end{pmatrix} \begin{pmatrix}
\sigma_1&&&&0\\
&\sigma_2&&&0\\
&&...&&...\\
&&&\sigma_p&0\\
0&0&...&0&0
\end{pmatrix}\begin{pmatrix}
&&&&\\&&&&\\&&V^\dagger&&\\&&&&\\&&&&
\\&&V^{\dagger \prime}&&
\end{pmatrix}\]
\begin{enumerate}
    \item $\im{M} = C(U)$
    \item $\ker{M} = R(V^{\dagger \prime}) = C(V^\prime)$
    \item $\ker{M^\dagger} = C(U^\prime)$
    \item $\im{M^\dagger} = C(V) = R(V^\dagger)$
\end{enumerate}

One of the main differences between the JNF and SVD of a matrix $A$ lies in how they are affected by perturbations in the elements of $A$. For example, take the small change 
\[ A = \begin{pmatrix}
1 & 1\\
0 & 1
\end{pmatrix} \longrightarrow A^\prime  = \begin{pmatrix}
1 & 1 \\
0 & 1.00001
\end{pmatrix}\]
The SVD of $A^\prime$ will "change" continuously for changes in the elements of $A$, but the JNF of $A$ is completely different from the JNF of $A^\prime$. More specifically, the JNF of $A$ is $A$ itself, but the JNF os $A^\prime$ is now diagonalizable, meaning that the 2-dimensional eigenspace $E(1)$ "breaks up" into two 1-dimensional eigenspaces from small perturbations. 

\begin{definition}
The \textit{Frobenius norm} of a $m \times n$ matrix $A$ is defined
\[||A||_F \equiv \sqrt{\Tr{(A^\dagger A)}} = \sqrt{\Tr{\Sigma^2}} = \bigg( \sum_{i, j} a_{i j}^2 \bigg)^{\frac{1}{2}} \]
By Singular Value Decomposition, we can reduce its calculations to
\[ ||A||_F = \sqrt{\sum_i \sigma_i^2}\]
where $\sigma_i$'s are the singular values. Clearly, 
\[||A||_2 \leq ||M||_F\]
In quantum mechanics, the Frobenius norm is also called the \textit{Hilbert Schmidt norm} in the context of infinite dimensional Hilbert spaces. 
\end{definition}

We end by defining two more common decompositions of square matrices. 

\begin{theorem}[Schur Decomposition]
Every $n \times n$ matrix $A$ over $\mathbb{C}$ can be decomposed into
\[A = Q T Q^\dagger\]
where $Q \in U(n)$ and $T$ is upper triangular. 
\end{theorem}
\begin{proof}
This is an obvious result of the Grahm-Schmidt algorithm. 
\end{proof}

\begin{theorem}[Polar Decomposition]
Every complex $n \times n$ matrix $A$ can be factored into the form
\[A = U P\]
where $U \in U(n)$ and $P$ is a positive semidefinite self-adjoint matrix. If $A$ is a real matrix, then $U \in O(n)$. 
\end{theorem}
\begin{proof}
We take the SVD to get 
\[A = W \Sigma V^\dagger\]
and we can assign 
\[U = W V^\dagger, \; P = V \Sigma V^\dagger\]
Since $V, W$ are unitary, this confirms that $P$ is positive definite and self-adjoint along with $U$ being unitary. Thus, the existence of the SVD implies the existence of the polar decomposition. 
\end{proof}

\subsection{Positive Definite Matrices}
\begin{definition}
A self-adjoint linear mapping $H$ from a real or complex Euclidean space onto itself is \textit{positive definite} if 
\[(x, H x) > 0 \text{ for all } x \neq 0\]
$H$ is called \textit{positive semidefinite} if 
\[(x, H x) \geq 0\]
\end{definition}

\begin{theorem}[Polar Decomposition]
Given a Euclidean space $\mathbb{E}^n$ and any linear endomorphism $f$ of $\mathbb{E}^n$, there are two positive definite self-adjoint linear maps $h_1, h_2 \in$ End$(\mathbb{E}^n)$ and $g \in$ O$(n)$ such that
\[f = g \circ h_1 = h_2 \circ g\]
That is, such that $f$ can be decomposed into the following as shown in this commutative diagram. 
\[\begin{tikzcd}
\mathbb{E}^n \arrow{r}{h_2} & \mathbb{E}^n \\
\mathbb{E}^n \arrow{u}{g} \arrow{ur}{f} \arrow{r}{h_1} & \mathbb{E}^n \arrow{u}{g}
\end{tikzcd}\]
\end{theorem}

\begin{theorem}[Properties of Positive Definite Matrices] Here we state basic properties. 
\begin{enumerate}
    \item $I$ is positive definite. 
    \item Positive mappings form a subspace in the space of linear mappings. 
\begin{align*}
    &M, N \text{ positive} \implies M + N \text{ is positive} \\
    &M \text{ positive} \implies a M \text{ is positive for all} a \in \mathbb{F}
\end{align*}
    \item $H$ positive and $Q$ invertible $\implies Q^\dagger H Q$ positive. 
\end{enumerate}
\end{theorem}

\begin{theorem}
$H$ is positive definite if and only if all of its eigenvalues are positive. Furthermore, every positive mapping is invertible.
\end{theorem}

\begin{theorem}
Every positive mapping $M$ has a unique positive square root. That is, there exists a unique positive mapping $N$ such that
\[ N^2 = M \]
We denote $N$ as $\sqrt{M}$. 
\end{theorem}

\begin{definition}
Given that $M, N$ are positive definite mappings. 
\[M > N \iff M - N > 0, \text{ that is, $M$ is positive}\]
\end{definition}

\begin{theorem}
If $M, N$ are positive definite mappings 
\[ M > N \implies M^{-1} < N^{-1}\]
\end{theorem}

\begin{proposition}
In $\mathbb{R}^n$ endowed with the dot product, a $n \times n$ matrix $A$ is positive definite if and only if 
\[(x, A y) = x^T A y > 0 \]
for every $x, y \in \mathbb{R}^n$. $A$ is positive semi-definite if and only if 
\[(x, A y) = x^T A y \geq 0\]
\end{proposition}

The following is a useful fact regarding inner products of $\mathbb{R}^n$. 
\begin{proposition}
The set of all inner products that can be defined on $\mathbb{R}^n$ is bijective to the set of positive-definite symmetric $n \times n$ matrices $A$ (which is itself bijective to the set of all positive-definite mappings). That is, every inner product of $\mathbb{R}^n$ can be defined 
\[(x, y) \equiv x^T A y\]a
Note that when $A = I_n$, the inner product is the regular dot product.
\end{proposition}

\subsection{Stochastic Matrices, Markov Chains}
\begin{definition}
A real $n \times n$ matrix $P$ is \textit{entrywise positive} if all entries are positive real numbers. We similarly define entrywise positive vectors having components as positive real numbers. With this notion of positiveness. We can define
\[A > B \iff A - B > 0 \iff (A-B)_{i j} > 0 \; \forall i, j\]
\end{definition}

\begin{remark}
Note that this definition of positive matrices is \textit{not} the same as positive-definite matrices! 
\end{remark}

\begin{theorem}[Perron's Theorem]
Every entrywise positive matrix $P$ has a real \textit{dominant eigenvalue}, denoted $\lambda(P) \in \mathbb{R}$ satisfying
\begin{enumerate}
    \item $\lambda(P) > 0$, and the associated eigenvector $h >0$
    \item $\lambda(P)$ is a simple eigenvalue
    \item every other eigenvalue $\kappa$ satisfies: $|\kappa| < \lambda(P)$
    \item there is no other eigenvector $\geq 0$, i.e. all other eigenvectors have at least 1 negative entry.
\end{enumerate}
\end{theorem}

\begin{definition}
A \textit{stochastic matrix} is a matrix $A$ where the elements of each column $a_i$ sum up to $1$. $A$ is \textit{doubly stochastic} if $A$ and $A^T$ are stochastic. 
\end{definition}

\begin{theorem}
Let $S > 0$ be a positive stochastic matrix. Then, $\lambda(S) = 1$. Furthermore, given any nonnegative vector $x \geq 0$, 
\[\lim_{N \rightarrow \infty} S^N x = c h\]
where $h$ is the dominant eigenvector and $c$ is some positive constant. 
\end{theorem}

A common application of this theorem likes in probability and statistics. Since nonnegative stochastic matrices can be used to represent discrete-time Markov Chains, with the dominant eigenvector representing the stationary distribution $\pi$. 

Another application lies within defining Google's Page Rank Algorithm. Upon representing a page as a node, if there is one link that directs the user from page $A$ to page $B$, we can represent this as an oriented path from node $A$ to node $B$. Given that we have $n$ nodes, we can construct a $n \times n$ matrix $A$ where 
\[a_{i j} \equiv  \frac{\text{number of paths from node $i$ to node $j$}}{\text{number of nonzero entries in $j$th column}}\]

For example, the adjacency matrix of the directed graph of five nodes 
\begin{center}
    \includegraphics[scale=0.22]{Markov_Chain_Example.PNG}
\end{center}
is
\[\begin{pmatrix}0&0&0&\frac{1}{3}&0\\
\frac{1}{2}&0&\frac{1}{2}&\frac{1}{3}&0\\
\frac{1}{2}&0&0&0&\frac{1}{2}\\
0&0&\frac{1}{2}&0&\frac{1}{2}\\
0&1&0&\frac{1}{3}&0\end{pmatrix}\]
However, the theorem above requires the matrix to be strictly positive, which is often not true for Markov chains in general. This theorem does not hold true in the following example, 
\[A = \begin{pmatrix}
0&0&0&\frac{1}{3} \\
\frac{1}{2}&0&0&\frac{1}{3} \\
0&0&0&\frac{1}{3} \\
\frac{1}{2}&0&0&0
\end{pmatrix} \implies A^{1000} 
    \begin{pmatrix}
\frac{1}{4} \\ \frac{1}{4} \\ \frac{1}{4} \\ \frac{1}{4}
\end{pmatrix} = 
    \begin{pmatrix}
0 \\ 9/20 \\ 11/20 \\ 0
\end{pmatrix}, \; A^{1001} 
    \begin{pmatrix}
\frac{1}{4} \\ \frac{1}{4} \\\frac{1}{4} \\ \frac{1}{4}
\end{pmatrix} = 
    \begin{pmatrix}
0 \\ 11/20 \\ 9/20 \\ 0
\end{pmatrix}
\]
That is, $A^N v$ oscillates between these two values. Furthermore, given three notes $A, B, C$ as such
\begin{center}
    \includegraphics[scale=0.25]{Degeneratre_Markov_Chain.PNG} 
\end{center}
the entries of the adjacency matrix is not well-defined. 
\[ \begin{pmatrix} 0&0&? \\0&0&? \\1&1&?\end{pmatrix}\]
Google CEO Larry Page actually developed a solution by implementing what he called a \textit{dampening factor}. Given stochastic matrix $B_{i j} = \frac{1}{N}$, he redefined the chain to be 
\[M = \alpha A + (1-\alpha) B, \; 0< \alpha < 1\]
It is clear that $M$ is now a strictly positive stochastic matrix. The $\alpha$ is the dampening factor, and its optimal value is known to be about $0.67$. The value of the alpha determines how much of the data is "washed away." When $\alpha = 0$, none of the data is lost, and when $\alpha = 1$, all of the data is lost. 

Due to the limitations of Perron's theorem, we can extend it with the following.

\begin{theorem}[Frobenius Extension to Perron]
Any $n \times n$ matrix $F \geq 0$, $F \neq 0$ has eigenvalue $\lambda$ such that
\begin{enumerate}
    \item $\lambda \geq 0$ and $F h = \lambda h$, $h\geq 0$ \item every eigenvalue $\kappa$ satisfies: $|\kappa| \leq \lambda$ 
    \item if $|\kappa| = \lambda$, then 
\[\kappa = e^{\frac{2 \pi i k}{m}} \lambda, \; k, m \in \mathbb{Z}_+, \; m \leq n\]
\end{enumerate}
\end{theorem}

\subsection{Duality Theorem}
In this section we will denote vector inequalities as entry-wise inequalities.Recall that elements of a vector space $X$ can be interpreted as column vectors, and elements of the dual of the vector space $X^*$ can be interpreted as row vectors. Therefore, value of $\phi$ at $x$ is denoted
\[\phi (x) = \phi_1 x_1 + \phi_2 x_2 + ... + \phi_n x_n\]
Furthermore, the dual of $X^*$ is $X$ itself, and given that $Y$ is a linear subspace of $X$, the annihilator of $Y^\perp$ is $Y$. 
\[X = X^{**}, \;\; Y = Y^{\perp\perp}\]
Suppose $Y$ is defined as the linear space spanned by the $m$ vectors $y_1, y_2, ..., y_m$ in $X$. That is, $Y$ consists of all vectors $y$ of the form
\[y = \sum_{j=1}^m a_j y_j\]
It is clear by linearity that $\phi$ belongs to $Y^\perp$ if and only if
\[\phi (y_j) = 0, \;\; j = 1, 2, ..., m\]
That is, a vector $y$ can be written as a linear combination of $m$ given vectors $y_j$ if and only if every $\phi$ that annihilates the $m$ vectors a also annihilates $0$. Now, we state a theorem that allows us to check if a vector $y$ can be written as a \textit{nonnegative} linear combinations of the $y_j$s. 

\begin{theorem}
A vector $y$ can be written as a linear combination of given vectors $y_j$ with nonnegative coefficients if and only if every $\zeta \in X^*$ that satisfies 
\[ \zeta (y_j) \geq 0, \;\; j = 1, 2, ..., m\]
also satisfies 
\[\zeta (y) \geq 0\]
\end{theorem}
\begin{proof}
The proof is not the easiest to construct rigorously, but it can be visualized easily. 
\end{proof}

\begin{corollary}
Given a $n \times m$ matrix $Y$, a vector $y$ with $n$ components can be written in the form 
\[y = Y p, \;\; p \geq 0\]
if and only if every row vector $\zeta$ that satisfies 
\[\zeta Y \geq 0\]
also satisfies 
\[\zeta y \geq 0\]
\end{corollary}

\begin{theorem}
Given an $n \times m$ matrix $Y$ and a column vector $y$ with $n$ components, the inequality 
\[y \geq Y p, \;\; p \geq 0\]
is satisfied if and only if every $\zeta$ that satisfies
\[\zeta Y \geq 0, \;\; \zeta \geq 0\]
also satisfies 
\[\zeta y \geq 0\]
\end{theorem}

\begin{theorem}[Duality Theorem]
Let $Y$ be a given $n \times m$ matrix, $y$ a given column vector with $n$ components, and $\gamma$ a given row vector with $m$ components. Let 
\[S = \sup_p \{\gamma p\}\]
for all column vectors $p$ with $m$ components satisfying $y \geq Y p, \; p \geq 0$. A well-defined such $p$ is called \textit{supremum admissible}. Additionally, let 
\[s = \inf_\zeta \{ \zeta y\}\]
for all row vectors $\zeta$ with $n$ components satisfying $\gamma \leq \zeta Y, \; \zeta \geq 0$. A well-defined such $\zeta$ is called \textit{infimum admissible}. Given that admissible vectors $p$ and $\zeta$ exist, then $S$ and $s$ are finite and 
\[S = s\]
\end{theorem}

\subsection{Alternating Sign Matrices}
We now describe a generalization of permutation matrices. While these kinds of matrices haven't been studied deeply, its applications lie in measuring the computational complexity of the Dodgson Condensation method for computing matrix determinants. The set of alternating sign matrices also forms a bijection with combinatorial objects, such as plane partitions, aztec diamonds, ice models, etc. 

\begin{definition}
A matrix with elements $0, -1, 1$ where nonzero entries must alternate in the following pattern: $1, -1, 1, ..., -1, 1$ (i.e. begin and end with $1$) is called an \textit{alternating sign matrix}. This means that every row and column must add up to $1$. 
\end{definition}

\begin{example}
The following are alternating sign matrices. 
\[\begin{pmatrix}
0&1&0&0\\1&-1&0&1\\0&1&0&0\\0&0&1&0
\end{pmatrix}, \begin{pmatrix}
0&1&0\\1&-1&1\\0&1&0
\end{pmatrix}\]
\end{example}

As with permutation matrices, we would like to calculate how many $n \times n$ alternating sign matrices there are for a given $n$. Let the set of all $n \times n$ alternating sign matices be denoted
\[\text{ASM}(n)\]

\begin{proposition}[Alternating Sign Matrix Conjecture (Proved)]
The number of $n \times n$ alternating sign matrices is the following. 
\[\text{card ASM}(n) = \prod_{k=0}^{n-1} \frac{(3k+1)!}{(n+k)!}\]
\end{proposition}

We now define a bijection between ASMs and another type of $n \times n$ matrix. Given $A \in \text{ASM}(n)$, we define $f: \text{ASM}(n) \longrightarrow \text{Mat}(n, \{0,1\})$ such that
\[\big(f(A)\big)_{ij} = \sum_{k=i}^n (a)_{kj}\]
Basically, we leave the bottom row untouched and for each element on upper rows, we sum that element with all of the elements strictly below it. For example, 
\[\begin{pmatrix}
0&1&0&0\\1&-1&0&1\\0&1&0&0\\0&0&1&0
\end{pmatrix} \mapsto \begin{pmatrix}
1&1&1&1\\1&0&1&1\\0&1&1&0\\0&0&1&0
\end{pmatrix}\]

\begin{theorem}
The set of matrices $\im(f) \subset \text{Mat}(n, \{0, 1\})$ is bijective to the set of $n \times n$ 6-vertex (or Ice-type) models, which are used to model crystal lattices for hydrogen bonds. 
\end{theorem}

\section{Numerical Methods in Solving Linear Systems}
In this section, we will concern ourselves with a system of equations with only \textit{one solution}, represented by the matrix equation
\[A x = b\]
where $A$ is an invertible square matrix, $b$ some given vector, and $x$ the vector of unknowns to be determined. 

An algorithm for solving the system takes as inputs the matrix $A$ and vector $b$ and outputs some approximation to the solution $x$. However, with billions of arithmetic operations on top of each other, the errors can accumulate. Algorithms for which this does not happen are said to be \textit{arithmetically stable}. 

The use of finite digit arithmetic places an absolute limitation on the accuracy with which the solution can be determined. To demonstrate this, let us imagine a change $\delta b$ being made in the vector $b$, which causes a corresponding change in $x$, denoted $\delta x$. 
\[A(x + \delta x) = b + \delta b \implies A \delta x = \delta b\]
To compare the changes in $x$ with the changes in $b$, we define the following variable. 
\begin{definition}
The \textit{relative change in x with the relative change in $b$} is the quantity
\[\frac{|\delta x|}{|x|} \bigg/ \frac{|\delta b|}{|b|}\]
where the norm is convenient for the problem (usually a numerical approximation of the Euclidean norm for floating point numbers). We will assume the use of the Euclidean norm from now on. We can rewrite the value as the expression below with the following upper bound, denoted by $\kappa (A)$, called the \textit{condition number}. 
\[\frac{|b|}{|x|} \frac{|\delta x|}{|\delta b|} = \frac{|Ax|}{|x|} \frac{|A^{-1} \delta b|}{|\delta b|} \leq |A||A^{-1}| \equiv \kappa (A)\]
where $|A|$ is the matrix norm of $A$. 
A high value of this relative change would mean that small perturbations in $b$ would cause large changes in $x$.
\end{definition}

Note that $\kappa(A) \geq 1$. Notice also that the higher the condition number $\kappa (A)$, the harder it is to solve the equation $A x = b$, and $\kappa(A) = \infty$ when $A$ is not invertible. For a $k$-digit floating point arithmetic, the relative error in $b$ can be as large as $10^{-k}$, meaning that the relative error in $x$ can be as large as $10^{-k} \kappa (A)$. 

Let $\beta$ be the largest absolute value of the eigenvalues of $A$ and $\alpha$ as the smallest absolute value of the eigenvalues of $A$. Then 
\[\beta \leq |A|, \frac{1}{\alpha} \leq |A^{-1}| \implies \frac{|\beta|}{|\alpha|} \leq \kappa(A)\]


\begin{definition}
An algorithm that generates an exact solution after a finite number of arithmetic steps is called a \textit{direct method} (e.g. Gauss Elimination). An algorithm that generates successive approximations that converge onto the solution is called an \textit{iterative method}. 
\end{definition}

The methods mentioned in this section will be iterative. 
\begin{definition}
Let $\{ x_n\}$ be the sequence of approxmations generated by such an algorithm. The deviation of $x_n$ from the true value $x$ is caelled the \textit{error at the $n$th stage}, denoted by $e_n$. 
\[e_n \equiv x_n - x\]
The amount by which the $n$th approximation fails to satisfy the equation $Ax = b$ is called the $n$th residual, denoted by $r_n$. 
\[r_n \equiv A x_n - b\]
Error and residual are related by the equation. 
\[r_n = A e_n\]
\end{definition}
Note that since we do not know $x$, the error cannot be calculated, but the residuals can be. We further restrict our scope to solving linear systems in which $A$ is real, positive, and self-adjoint. Clearly, we already know that $|A| = \beta$, and since $A$ is positive, we can conclude that 
\[|A^{-1}| = \frac{1}{\alpha}\]
which implies that
\[\kappa(A) = \frac{\beta}{\alpha}\]

\subsection{Method of Steepest Descent}
Assume that $n \times n$ matrix $A$ is self-adjoint.
\begin{theorem}
The solution of $Ax = b$ minimizes the functional 
\[E (y) \equiv \frac{1}{2} (y, A y) - (y, b)\]
where $(\cdot, \cdot)$ is the Euclidean dot product. That is, the solution $x$ is
\[x = \min \big\{ E(y) \big\} = \min \Big\{ \frac{1}{2} (y, Ay) - (y, b) \Big\}\]
\end{theorem}
\begin{proof}
Add to $E(y)$ a constant, that is a term independent of $y$ to define a new function $F$. 
\[F(y) \equiv E(y) + \frac{1}{2} (x, b)\]
Then, by self adjointness of $A$, we can express $F(y)$ as 
\begin{align*}
    F(y) & = \frac{1}{2} (y, Ay) - (y, b) + \frac{1}{2} (x, b) \\
    & = \frac{1}{2} (y, Ay) - \frac{1}{2} (y, Ax) + \frac{1}{2} (Ax, x) - \frac{1}{2} (Ay, x) \\
    & = \frac{1}{2} \big( y, A(y-x)\big) + \frac{1}{2} \big( A(x-y), x\big) \\
    & = \frac{1}{2} \big( y - x, A(y - x)\big) 
\end{align*}
Since $F(x) = 0$ and $F(x) \geq 0$ (since it is an inner product with repsect to $y-x$), $F(y)$, and also $E(y)$, takes a minimum at $y =x$. 
\end{proof}

Now to actually compute the value of $x$, we us the method of steepest descent. Note that $E: \mathbb{R}^m \longrightarrow \mathbb{R}$, so we can utilize ordinary calculus on it. The gradient of $E$ can be computed by the formula 
\[\text{grad}\,E(y) = A y - b\]
So, if our $n$th approximation is $x_n$, then the $(n+1)$st approximation, $x_{n+1}$, is calculated as
\[x_{n+1} = x_n - s (Ax_n - b)\]
where $s$ is the step length in the direction $-$grad$\,E$. By calculating the residual $r_n = A x_n - b$, we can rewrite the above to
\[x_{n+1} = x_n - s r_n\]
Rather than keeping $s$ constant, we can actually determine an optimal value of $s$ at the $n$th step, denoted $s_n$, which minimizes $E(x_{n+1})$. This quadratic minimum problem is easily solved, since
\begin{align*}
    E(x_{n+1}) & = \frac{1}{2} \big(x_n - s r_n, A(x_n - s r_n) \big) - \big( x_n - s r_n, b\big) \\
    & = E(x_n) - s (r_n, r_n) + \frac{1}{2} s^2 (r_n A r_n)
\end{align*}
By taking the derivative and computing the value of $s$ where $E (x_{n+1}) = 0$, we see that the minimum is reached when 
\[s = s_n \equiv \frac{(r_n, r_n)}{(r_n, A r_n)}\]

\begin{theorem}
The sequence of approximations $\{x_n\}$, with $s$ optimized to be $s_n$, converges to the solution of $A x = b$. 
\end{theorem}

The error bound for this algorithm is 
\[||e_n||^2 \leq \frac{2}{\alpha} \bigg( 1-\frac{1}{\kappa(A)} \bigg)^n F(x_0)\]
which shows that the error $e_n$ tends to $0$ in $\mathbb{R}^m$. However, this algorithm has a very slow rate of convergence for large $\kappa(A)$. 

\subsection{Method of Chebyshev Polynomials}
The disadvantage of the method of steepest descent mentioned in the end of the last subsection renders it quite outdated and obsolete. This next method has a much better error bound that can handle large values of $\kappa$ more efficiently. However, we will need a positive lower bound $m$ for the smallest eigenvalue of $A$ and an upper bound $M$ for the largest eigenvalue. That is, 
\[m \leq \alpha, \beta \leq M\]
and all the eigenvalues of $A$ lie in the interval $[m, M]$. It follows that
\[\kappa = \frac{\beta}{\alpha} < \frac{M}{m}\]
We generate the same sequence of approximations $\{x_n\}$ by the same recursion formula
\[x_{n+1} = x_n - s(A x_n - b) \iff x_{n+1} = (I - s_n A) x_n + s_n b\]
Since the solution of $x$ satisfies the formula; that is, since $x = (I - s_n A) x + s_n b$, we subtract this equation from the top to get
\[e_{n+1} = (I - s_n A) e_n\]
Doing this recursively, we can deduce an explicit formula 
\[e_N = P_N (A) e_0 = \prod_{n=1}^N (1 - s_n a)\]
This allows us to estimate the size of $e_N$. 
\[||e_N|| \leq ||P_N (A)|| ||e_0||\]
The norm of a self adjoint matrix $A$ is the largest $|a|$, where $a$ is the eigenvalue, and the spectral mapping theorem states that the eigenvalues $p$ of $P_N (A)$ are of the form $p = P_N (a)$, where $a$ is an eigenvalue of $A$. This means that
\[||A|| \leq \max_{m \leq a \leq M} |a| \implies ||P_N (A)|| \leq \max_{m \leq a \leq M} |P_N (a)|\]
So, we are left with the bound
\[||e_N|| \leq ||e_0|| \max_{m \leq a \leq M} |P_N (a)|\]
To get the best estimate of $e_N$, we have to choose the $s_1, s_2, ..., s_N$ so that the polynomial $P_N$ has a small maximum on the interval $[m, M]$. Note that the polynomial $P_N$ satisfies the normalizing condition 
\[P_N(0) = 1\]
To find such a polynomial, we must first define Chebyshev polynomials. 

\begin{definition}
The \textit{$N$th Chebyshev polynomial} $T_N$ is defined for $-1 \leq u \leq 1$ by
\[T_N (u) = \cos (N \theta), \;\; u = \cos(\theta)\]
\end{definition}

\begin{proposition}
Among all polynomials $P_N$ of degree $N$ that satisfy $P_N (0) = 1$, the one that has the smallest maximum on $[m, M]$ is the \textit{rescaled Chebyshev polynomial} that rescales values from $[-1, 1]$ to the interval $[m, M]$ while preserving the condition that $P_N (0) = 1$. This polynomial is expressed as
\[P_N (a) \equiv T_N \bigg( \frac{M+m-2a}{M-m} \bigg) \bigg/ T_N \bigg(\frac{M+m}{M-m} \bigg)\]
\end{proposition} 
Now, assuming that $M/m \approx \kappa$, 
\[T_N \bigg( \frac{M+m}{M-m} \bigg) = T_N \bigg(\frac{\frac{M}{m} + 1}{\frac{M}{m}-1} \bigg) \approx T_N \bigg(\frac{\kappa + 1}{\kappa - 1} \bigg)\]
Since $|T_N (u)| \leq 1$ for $|u| \leq 1$, this also implies that
\[T_N \bigg( \frac{M + m - 2a}{M-m} \bigg) \leq 1\]
Combining this together, we get
\[||e_N|| \leq ||e_0|| \max_{m \leq a \leq M} |P_N (a)| = ||e_0|| \bigg/ T_N \bigg( \frac{\kappa+1}{\kappa-1} \bigg)\]
It is a fact that higher order Chebyshev polynomials tend to infinity faster once the value reaches out of $[-1, 1]$, meaning that as $N \rightarrow \infty$, $T_N\big( (\kappa+1)/(\kappa-1)\big)$ will also tend to infinity (note that $(\kappa+1)/(\kappa-1)$ is a constant, implying that $e_N$ tends to $0$ as $N$ tends to infinity. The error bound for $e_N$ is given by the following 
\[||e_N|| \leq 2 \bigg( 1 + \frac{2}{\sqrt{\kappa}} \bigg)^{-N} ||e_0|| \approx 2 \bigg( 1 - \frac{2}{\sqrt{\kappa}} \bigg)^{N} ||e_0||\]
Once again, this confirms that $e_N \rightarrow 0$ as $N \rightarrow \infty$. Furthermore, when $\kappa$ is large, the error bound works with $\sqrt{\kappa}$, which is must smaller than $\kappa$ itself. So, $e_N$ converges much faster through this algorithm than through the method of steepest descent. 

\section{Tensors as Multilinear Maps}
There are multiple ways to construct tensor product spaces. Note that all the constructions are equivalent and will lead to the exact same properties of tensors. The first method defines tensors outright as multilinear maps, without the need for a basis. 

\subsection{Tensor Product of Two Spaces}
\begin{definition}
The tensor product of two vector spaces $V$ and $W$ is a vector space, denoted $V \otimes W$, created by the bilinear map 
\[\otimes: V \times W \longrightarrow V \otimes W, \; (x, y) \mapsto x \otimes y\]
That is, 
\[V \otimes W \equiv \{ x \otimes y \; | \; x \in V, y \in W\} \]
where the elements of $V \otimes W$ are called \textit{tensors}. Note that since we have defined the operation $\otimes$ to be bilinear, it satisfies the properties
\begin{enumerate}
    \item $(u_1 + u_2) \otimes v = u_1 \otimes v + u_2 \otimes v$
    \item $v \otimes (u_1 + u_2) = v \otimes u_1 + v \otimes u_2$
    \item $(\lambda u) \otimes v = u \otimes (\lambda v) = \lambda (u \otimes v)$ 
\end{enumerate}
Moreover, each tensor $x \otimes y$ is itself a bilinear operator
\[x \otimes y: V^* \otimes W^* \longrightarrow \mathbb{F}\]
\end{definition}

Using these properties we will deduce further qualities of tensor product spaces. First, given a basis $\{e_i\}$ of $n$-dimensional space $V$ and $\{f_j\}$ of $m$-dimensional space $W$, we can construct a basis 
\[\{e_i \otimes f_j \; | \; 1 \leq i \leq n, 1 \leq j \leq m\}\]
of $V \otimes W$ using only the bilinearity properties of $\otimes$. 

\begin{example}
Let $V^*$ be a 4-dimensional vector space with basis $\{ e^0, e^1, e^2, e^3\}$. Then the basis of $V^* \otimes V^*$ is
\begin{align*} 
\{e^0 \otimes e^0, \; e^0 \otimes e^1, \;e^0 \otimes e^1, \;e^0 \otimes e^1, \\
e^1 \otimes e^0,\; e^1 \otimes e^1,\; e^1 \otimes e^2,\; e^1 \otimes e^3, \\
e^2 \otimes e^0,\; e^2 \otimes e^1,\; e^2 \otimes e^2,\; e^2 \otimes e^3, \\
e^3 \otimes e^0,\; e^3 \otimes e^1,\; e^3 \otimes e^2,\; e^3 \otimes e^3\}
\end{align*}
\end{example}

That is, every tensor can be expressed as a linear combination of these vectors, which implies
\[\dim{V \otimes W} = (\dim{V}) (\dim{W})\]
By equality of dimensionality and bilinearity, it is obvious that
\[V \otimes W \simeq \text{Hom}(V \times W, \mathbb{F})\]
In fact, they are naturally isomorphic. 
\\

Notice that we still haven't actually defined how to "calculate" using the operator $x \otimes y$. It turns out that defining a tensor product is unique up to isomorphism. That is, if $(V \otimes W, \otimes_1)$ and $(V \otimes W, \otimes_2)$ are two tensor product spaces sufficing bilinearity, then $V \otimes_1 W \simeq V \otimes_2 W$. This result is formally stated in the proposition below. 

\begin{proposition}[Universal Property of 2-tensors]
With this constructed basis, we can claim that for every map $\varphi: V \times W \longrightarrow \mathbb{F}$, there exists a unique linear map $\psi: V \otimes W \longrightarrow \mathbb{F}$ such that 
\[\varphi (x, y) = \psi (x \otimes y) \; \forall x \in V, y \in W\]
\end{proposition}
\begin{proof}
Since $\{e_i \otimes f_j\}$ is a basis for $V \otimes W$, we know that every element $z \in V \otimes W$ decomposes uniquely into 
\[z = \sum_{i, j} z_{i j} e_i \otimes f_j, \; z_{i j} \in \mathbb{F}\]
Thus, by linearity it suffices to define these maps for the basis vectors. This linear map is determined as 
\[\psi (e_i \otimes f_j) = \varphi (e_i, f_j)\]
\end{proof}
Denoting the map that is defined by taking all $e_i \otimes f_j \mapsto (e_i, f_j)$ as $S$, we can see that $S$ is clearly an isomorphism defined such that the diagram below commutes. 
\[\begin{tikzcd}
    V \otimes W \arrow{r}{\psi} \arrow{d}{S} & \mathbb{F} \\
    V \times W \arrow{ru}{\varphi}
\end{tikzcd}\]
That is, the unique isomorphism $S$ exists that determines $\psi$ such that 
\[\psi = \varphi \circ S \] 
which means that all definitions of $\otimes$ are equivalent under $S$. Note further that $S$ determines the isomorphism 
\[(V \otimes W)^* \equiv \text{Hom}(V \otimes W, \mathbb{F}) \simeq \text{Hom}(V \times W, \mathbb{F})\]
Therefore, it does not matter how we choose to concretely define the operator $x \otimes y$ for computations. However, it is customary to define it as
\[(x \otimes y) (\alpha, \beta) = \alpha (x) \cdot \beta (y), \; \alpha \in V^*, \beta \in W^*\]
Given $x \otimes y \in V \otimes W$, we can also choose to input elements "partially." That is, if we only input one vector $\alpha \in V^*$ into $x \otimes y$, we get
\[(x \otimes y) (\alpha, \cdot) = \alpha(x) y (\cdot) = \alpha (x) y \in W\]
meaning that the isomorphisms below are all canonical
\[V \otimes W \simeq \text{Hom}(V \times W, \mathbb{F}) \simeq \text{Hom}(V^*, W)\]
This means that
\[V^* \otimes W \simeq \text{Hom}(V, W)\]
That is, an element $\alpha \otimes y \in V^* \otimes W$ is a linear map from $V$ to $W$! We will focus a bit more on elements of $V^* \otimes W$. Given the previous bases $e_i$ and $f_j$ for $V$ and $W$, let $\{\epsilon_i\}$ be the dual basis for $V^*$. Then, the tensor $\alpha \otimes w \in V^* \otimes W$ can be represented as 
\begin{align*}
    \alpha \otimes w & \equiv \bigg(\sum_i \alpha_i \epsilon_i \bigg) \otimes \bigg( \sum_j w_j f_j \bigg) \\
    & = \sum_{i, j} \alpha_i w_j \, \epsilon_i \otimes f_j = \sum_{i, j} A_{i j} \, \epsilon_i \otimes f_j
\end{align*}
In fact, the $A_{i j}$ are precisely the $i j$th components of the matrix representation of linear operator $\alpha \otimes y$ with respect to basis $\{\epsilon_i\}$ and $\{f_j\}$. Indeed,
\begin{align*}
    (\alpha \otimes y)(e_j) & = \bigg( \sum_{i, j} e_i \otimes f_j \bigg) e_j \\
    & = \sum_{i, j} A_{i j} e_i \cdot \delta^j_j = \sum_{i} A_{i j} e_i
\end{align*}
which is consistent with the column space interpretation of matrix multiplication discussed in the beginning of Chapter 4. The realization of this tensor product between a covector and a vector is realized as an \textit{outer product}. 

\begin{definition}
Given vector spaces $U, V$ with defined bases in each of them, the \textit{outer product} of two vectors $u \in U$ and $v \in V$ is defined
\[u \otimes v \equiv u v^T \equiv \begin{pmatrix}
u_1 \\ u_2 \\ ... \\ u_m
\end{pmatrix} \otimes \begin{pmatrix}
v_1 & ... & v_n
\end{pmatrix} = \begin{pmatrix}
u_1 v_1 & ... & u_1 v_n \\
u_2 v_1 & ... & u_2 v_n \\
... & ... & ... \\
u_m v_1 & ... & u_m v_n 
\end{pmatrix}\]
Note that the $\otimes$ symbol in here represents the outer product, not the tensor product. Note that the tensor rank of the outer product of two vectors is $(2,0)$. 
\end{definition}

Abstractly speaking, the outer product of $u \in U$ and $v \in V$ is the element $u \otimes v \in U \otimes V$, which is a rank-(2,0) tensor, not a rank-(1,1) tensor! Just because it "looks" like a matrix, $u \otimes v$ should not be interpreted as a linear map. Such a $m \times n$ matrix could really be the realization of either a (2,0) tensor, (1,1) tensor, or a (0,2) tensor. 

However, if $U$ is an inner product space, then it is possible to define $u \times v$ as a linear map from $U \longrightarrow W$. The structure of the inner product on $U$ allows us to define the canonical isomorphism $\phi$ between $U$ and $U^*$. Then, we can define the canonical injections $i: U \longrightarrow U \otimes V$ and $j: U^* \longrightarrow U^* \otimes V$ to get the commutative diagram 

\[\begin{tikzcd}
    U \otimes V \arrow{r}{\gamma} & U^* \otimes V \\
    U \arrow{u}{i} \arrow{r}{\phi} & U^* \arrow{u}{j}
\end{tikzcd}\]
Given that 
\[\phi(u) \equiv l \text{ such that } (u, x) = l(x) \forall x \in U\]
we can define the mapping $\gamma: j \phi i^{-1}$ such that 
\[\gamma (u \otimes v) \equiv \phi(u) \otimes v \equiv l \otimes v \in U^* \otimes V\]
which is ultimately a linear mapping from $U \longrightarrow V$ since
\[l \otimes v (u_0, \cdot) \equiv l(u_0) v(\cdot)\]
with $l(u_0) \in \mathbb{F}$ and $v(\cdot)$ a vector. This proves the following theorem. 

\begin{proposition}
The matrix rank of the outer product of any 2 vectors is $1$. 
\end{proposition}
\begin{proof}
Trivial.
\end{proof}

We can extrapolate and see that for higher order tensor products, we would get an $n$-dimensional array of scalars. A matrix is a $2$-dimensional array of numbers since it is the tensor product of two vectors. 

\begin{definition}
Given vector spaces $U, V$ with defined bases in each of them, the \textit{Kronecker product} of two vectors $u \in U$ and $v \in V$ is defined
\[u \otimes_{Kron} v \equiv \begin{pmatrix}
u_1 \\ u_2 \\ ... \\ u_m
\end{pmatrix} \otimes \begin{pmatrix}
v_1 & ... & v_n
\end{pmatrix} = \begin{pmatrix}
u_1 v_1 \\ u_1 v_2 \\ ... \\ u_m v_{n-1} \\ u_m v_n 
\end{pmatrix}\]
\end{definition}

Clearly, the outer product and Kronecker product are closely related, and we can interpret the Kronecker product as a form of "vectorization" or "flattening out" of the outer product. 

\subsection{Higher Order Tensor Product Spaces}
Since $U \otimes W$ is a vector space itself, we can multiply it further to create higher order tensor product spaces. 
\[U \otimes W \otimes U \otimes ...\]
Note that by construction, the operation of tensor product on vector spaces is commutative and associative in the sense that 
\[V \otimes W \simeq W \otimes V\]
and 
\[(U \otimes V) \otimes W \simeq U \otimes (V \otimes W) \simeq U \otimes V \otimes W \]
which allows us to write tensor products of any finite number of vector spaces $V_1, V_2, ..., V_n$ without parantheses. By induction, we can keep constructing higher order tensor products as such 
\[V_1 \otimes V_2 \rightarrow (V_1 \otimes V_2) \otimes V_3 \rightarrow \big((V_1 \otimes V_2) \otimes V_3 \big) \otimes V_4 \rightarrow ...\]
to get the tensor product space
\[\bigotimes_{i=1}^{n} V_{i} \equiv V_1 \otimes V_2 \otimes ... \otimes V_n\]
with tensors in the form 
\[ \bigotimes_{i=1}^{n} v_{i} \equiv v_{1} \otimes v_{2} \otimes v_{3} \otimes ... \otimes v_{n}; \; v_{i} \in V_{i}\]
defined as the following multilinear map 
\[ \bigotimes_{i=1}^{n} v_{i}: \prod_{i=1}^{n} V_{i}^{*} \longrightarrow \mathbb{F}, \;\;\; \bigg( \bigotimes_{i=1}^{n} v_{i} \bigg) \big( l_{1}, l_{2}, ..., l_{n} \big) \equiv \prod_{i=1}^{n} v_{i}(l_{i}), \; l_i \in V_i^* \]
This map can then be used to easily see the following statement
\[\bigotimes_{i=1}^n V_i \simeq \text{Hom}\Big( \prod_{i=1}^n V_i^*, \mathbb{F} \Big)\]
Similarly to the section about the tensor product of two spaces, we can "partially" fill in the inputs of a general tensor $v_1 \otimes v_2 \otimes ... \otimes v_n$ to interpret them as multilinear operators that can take in $k$ vectors and output $n-k$ vectors. That is, tensors (written as $\tau$ below) are multilinar maps from a cartesian product of vector spaces to a tensor product of vector spaces. 
\[\tau: V_1 \times ... \times V_n \longrightarrow W_1 \otimes ... \otimes W_m \]
For example, 
\[\text{Hom}\Big( \prod_{i=1}^n V_i^*, \mathbb{F} \Big) \simeq 
\text{Hom}\Big( \prod_{i=2}^n V_i^*, V_1 \Big) \simeq 
\text{Hom}\Big( \prod_{i=3}^n V_i^*, V_1 \otimes V_2 \Big) \simeq ... \]
Furthermore, we can generalize the universal property of two tensors to the following proposition, which is also called the \textit{fundamental principle of tensor algebra}. 

\begin{proposition}[Universal Property]
Given a linear mapping $\varphi: V_1 \times ... \times V_n \longrightarrow \mathbb{F}$, there exists a unique linear map $\psi: V_1 \otimes ... \otimes V_n \longrightarrow \mathbb{F}$. That is, 
\[\text{Hom}\Big( \bigotimes_{i=1}^n V_i, \mathbb{F} \Big) \equiv \bigg( \bigotimes_{i=1}^n V_i \bigg)^* \simeq \text{Hom}\Big(\prod_{i=1}^n V_i, \mathbb{F}\Big)\]
\end{proposition}

\begin{definition}
Given that 
\[ \{ e_{i_{j}}\}_{i_{j}=1}^{k_{j}} \text{ of } V_{j},\; j = 1, 2, ..., n\]
are $n$ sets of bases for each $V_{j}$, 
\[ \{ \bigotimes_{j=1}^{n} e_{i_{j}} \}_{i_{1}, ..., i_{n}} \text{ is a basis of } \bigotimes_{j=1}^{n} V_{j}\]
\end{definition}

\begin{proposition}
Given vector spaces $V_1, V_2, ..., V_n$, 
\[ \dim \bigotimes_{i=1}^{n} V_i = \prod_{i=1}^{n} \dim V_{i}\]
\end{proposition}
\begin{proof}
This follows naturally from the construction of the basis.
\end{proof}

We move on to talk about something quite enlightening: the tensor product of linear operators, which are themselves tensors. 

\begin{definition}
Given linear operators $A \in $ End$(V)$, $B \in $ End$(W)$, we can construct the linear operator 
\[A \otimes B \in \text{End}(V \otimes W)\] 
such that 
\[(A \otimes B) (x \otimes y) \equiv A x \otimes B y \in V \otimes W\]
Notice that since $A, B$ are linear operators, they are tensors. More specifically, $A \equiv \alpha \otimes u$ and $B \equiv \beta \otimes v$, so
\begin{align*}
    (A \otimes B) (x \otimes y) & \equiv A x \otimes B y \\
    & = (\alpha \otimes u) x \otimes (\beta \otimes v) y \\
    & = \alpha (x) \beta (y) \, u \otimes v \\
    & = \big((\alpha \otimes \beta)(x \otimes y)\big) (u \otimes v)(\cdot, \cdot) \\
    & = \big((\alpha \otimes \beta) \otimes (u \otimes v)\big) \big((x \otimes y), (\cdot \otimes \cdot)\big) \\
    & = \big((\alpha \otimes \beta) \otimes (u \otimes v)\big)(x \otimes y) 
\end{align*}
$\implies A \otimes B \equiv \alpha \otimes \beta \otimes u \otimes v$. 
\end{definition}
We will work through an example that gives the matrix representation of the tensor product of linear mappings. For simplicity, let us work with the example when 
\[A = \begin{pmatrix}
a_{11} & a_{12} \\ a_{21} & a_{22}
\end{pmatrix}, \; B = \begin{pmatrix}
b_{11} & b_{12} \\ b_{21} & b_{22}
\end{pmatrix}\]
Given that $U$ has basis $\{u_1, u_2\}$ and $V$ has basis $\{v_1, v_2\}$, $U \otimes V$ will have basis 
\[\{u_1 \otimes v_1, u_1 \otimes v_2, u_2 \otimes v_1, u_2 \otimes v_2\}\]
We then define the induced linear mapping $A\otimes B: U \otimes V \longrightarrow U \otimes V$ by defining it on its basis vectors. Note that the linear mapping $(A \otimes B)(u\otimes v)$ must be an element of $U \otimes V$, implying that it is defined
\[(A \otimes B)(u\otimes v) \equiv Au \otimes Bv\]
This is called the \textit{tensor product} of operators $A$ and $B$.
So, the tensor product of matrices $A$ and $B$ can be calculated
\begin{align*}
    (A \otimes B) (u_1 \otimes v_1) &= (a_{11} u_1 + a_{21} u_2) \otimes (b_{11} v_1 + b_{21} v_2) \\
    & = a_{11} b_{11} (u_1 \otimes v_1) + a_{11} b_{21} (u_1 \otimes v_2) \\
    & + a_{21} b_{11} (u_2 \otimes v_1) + a_{21} b_{21} (u_2 \otimes v_2) \\
    ... & = ... \\
    (A \otimes B) (u_2 \otimes v_2) & = (a_{12} u_1 + a_{22} u_2) \otimes (b_{12} v_1 + b_{22} v_2) \\
    & = a_{12} b_{12} (u_1 \otimes v_1) + a_{12} b_{22} (u_1 \otimes v_2) \\
    & + a_{22} b_{12} (u_2 \otimes v_1) + a_{22} b_{22} (u_2 \otimes v_2) 
\end{align*}
In matrix form, this results in the $4\times 4$ matrix (also in block form)
\[A \otimes B \equiv \begin{pmatrix}
a_{11} b_{11} & a_{11} b_{12} & a_{12} b_{11} & a_{12} b_{12} \\
a_{11} b_{21} & a_{11} b_{22} & a_{12} b_{21} & a_{12} b_{22} \\
a_{21} b_{11} & a_{21} b_{12} & a_{22} b_{11} & a_{22} b_{12} \\
a_{21} b_{21} & a_{21} b_{22} & a_{22} b_{21} & a_{22} b_{22} 
\end{pmatrix} = \begin{pmatrix}
a_{11} B & a_{12} B \\
a_{21} B & a_{22} B 
\end{pmatrix}\]
representing the linear transformation from $U \otimes V$ to itself under the basis $\{u_i \otimes v_j\}$. 
\begin{proposition}
In general,the tensor product of matrices $A \in $ End$(V)$ and $B \in $ End$(W)$ (with basis of $V, W$ defined) is the $(m n) \times (m n)$ matrix
\[A \otimes B \equiv \begin{pmatrix}
a_{11} B & a_{12} B & ... & a_{1n} B \\
a_{21} B & a_{22} B & ... & a_{2n} B \\
... & ... & ... & ... \\
a_{n1} B & a_{n2} B & ... & a_{nn} B 
\end{pmatrix}\]
represented in block form. 
\end{proposition}

\begin{proposition}
\begin{align*}
    & \Tr{A \otimes B} = \Tr{A} \cdot \Tr{B} \\
    & \det{A \otimes B} = (\det{A})^n (\det{B})^m
\end{align*}
\end{proposition}

\begin{proposition}
For finite dimensional space $V$ and $W$, 
\[\text{End}(V \otimes W) = \text{End}(V) \otimes \text{End}(W)\]
\end{proposition}
\subsection{Contractions, Tensor Algebras}
\begin{definition}
Given vector space $V$, a \textit{rank }$(k, l)$-\textit{tensor product space} of $V$, denoted $\mathbb{T}^{k}_{l} V$, is defined
\[ \mathbb{T}^k_l V \equiv \bigg( \bigotimes_{i=1}^{k} V \bigg) \otimes \bigg( \bigotimes_{j=1}^{l} V^{*} \bigg) \equiv V^{\otimes k} \otimes V^{* \otimes l}\]
That is, $\mathbb{T}^{k}_{l}$ is the space of all $(k, l)$-tensors. A \textit{rank }$(k, l)$-\textit{tensor} is an element of a rank $(k, l)$ tensor product space. Note that all tensors are vectors and all tensor product spaces are vector spaces, too. 
\\

The order in which we multiply $V$'s and $V^*$'s matter, but in most cases, and from now, we will work with tensor product spaces strictly in the form 
\[ V^{\otimes k} \otimes V^{* \otimes l} \]
where the $V$'s are multiplied first and $V^*$'s last. So, $\mathbb{T}^{1}_{1} \equiv V \otimes V^*$, but $\mathbb{T}^{1}_{1} \not\equiv V^* \otimes V$. We can do this because the tensor product of spaces are commutative in the sense that we can always find an isomorphism
\[V \otimes W \simeq W \simeq V\]
\end{definition}

\begin{example}
$\mathbb{F}$ is a rank (0,0)-tensor space. $V$ is a rank (1,0)-tensor space, and $V^{*}$ is a rank (0,1)-tensor space. 
\end{example}

We can now think of the tensor product now as a bilinear operator
\[\otimes: \mathbb{T}^p_q V \times \mathbb{T}^r_s V \longrightarrow \mathbb{T}^{p+r}_{q+s} V\]
such that
\[\bigg( \bigotimes_{i=1}^p v_i \otimes \bigotimes_{j=1}^q w_j \bigg) \otimes \bigg( \bigotimes_{i = p+1}^{p+r} v_i \otimes \bigotimes_{j=q+1}^{q+s} w_j \bigg) = \bigotimes_{i=1}^{p+r} v_i \otimes \bigotimes_{j=1}^{q+s} w_j \in \mathbb{T}^{p+r}_{q+s} V\]

\begin{proposition}
\[\mathbb{T}^2_2 V \simeq \text{End}(V) \otimes \text{End}(V)\]
That is, the tensor multiplication $\mathbb{T}^1_1 \times \mathbb{T}^1_1 \longrightarrow \mathbb{T}^2_2$ is precisely the multiplication of the linear operators. 
\end{proposition}
\begin{proof}
Letting $A = u \otimes \alpha, B = v \otimes \beta$ with $u, v \in V$ and $\alpha, \beta \in V^*$, we know that
\[A \otimes B = u \otimes v \otimes \alpha \otimes \beta\]
$\implies \text{End}(V) \otimes \text{End}(V) \simeq V \otimes V \otimes V^* \otimes V^* \simeq \mathbb{T}^2_2 V$. 
\end{proof}

When working with tensors in general, we use the Einstein Summation Notation to write vectors in shorthand form
\[ A^{\mu} e_{\mu} \equiv \sum_{i=1}^{n} A^{i} e_{i}\]
The indices in this context are not important here (but they are significant in physics). For example, the Einstein notation for rank (2,0) tensors is written
\[ T_{\mu \nu} e^{\mu} \otimes e^{\nu} \equiv \sum_{\mu, \nu} T_{\mu \nu} e^{\mu} \otimes e^{\nu}\]
and for an $n$ vectors, 
\begin{align*}
T_{\mu_{1}, ..., \mu_{n}} \bigotimes_{i=1}^{n} e^{\mu_{i}} & \equiv T_{\mu_{1}, ..., \mu_{n}} e^{\mu_{1}} \otimes e^{\mu_{2}} \otimes ... \otimes e^{\mu_{n}} \\
     & \equiv \sum_{\mu_{1}, ..., \mu_{n}} T_{\mu_{1}, ..., \mu_{n}} e^{\mu_{1}} \otimes e^{\mu_{2}} \otimes ... \otimes e^{\mu_{n}} \\
     & \equiv \sum_{\mu_{1}, ..., \mu_{n}} T_{\mu_{1}, ..., \mu_{n}} \bigotimes_{i=1} e^{\mu_{i}}
\end{align*}
Since the coefficients of the shorthand tensor notation implies the tensors themselves, we can simply write
\[ T_{\mu_{1}, ..., \mu_{n}} \equiv T_{\mu_{1}, ..., \mu_{n}} \bigotimes_{i=1}^{n} e^{\mu_{i}} \]
Clearly, this notation is not restricted to the tensor product of contravariant vectors. For example,
\[T_{\mu \;\;\;\;\nu}^{\; \alpha \beta} \; e^{\mu} \otimes e_{\alpha} \otimes e_{\beta} \otimes e^{\nu}  \equiv \sum_{\mu, \alpha, \beta, \nu} T_{\mu \;\;\;\; \nu}^{\; \alpha \beta} \; e^{\mu} \otimes e_{\alpha} \otimes e_{\beta} \otimes e^{\nu}\]
is the form of a general tensor in the tensor space $V^* \otimes V \otimes V \otimes V^*$. Note that the order of the subscripts/superscripts in the coefficients of $T$ matters, but again, we usually work with $\mathbb{T}^p_q$ where vector spaces $V$'s come first and then the dual spaces $V^*$'s come later. 

\begin{example}
Let $e_{\mu} \otimes e^{\nu} \otimes e^{\lambda} \in \mathbb{T}^{1}_{2}$. Then 
\begin{align*}
(e_{\mu} \otimes e^{\nu} \otimes e^{\lambda}) \big( B_{\epsilon} e ^{\epsilon}, A^{\delta} e_{\delta}, C^{\sigma} e_{\sigma} \big) & = e_{\mu} (B_{\epsilon} e^{\epsilon}) \cdot e^{\nu} (A^{\delta} e_{\delta}) \cdot e^{\lambda} (C^\sigma e_{\sigma}) \\
 & = B_{\epsilon} A^{\delta} C^{\sigma} \; \delta_{\mu}^{\epsilon} \, \delta_{\delta}^{\nu} \, \delta_{\sigma}^{\lambda} \\
 & = B_{\mu} A^{\nu} C^{\lambda} \in \mathbb{R} 
 \end{align*}
\end{example}

We now define the contraction of a tensor. 

\begin{definition}
A \textit{contraction} is a linear map
\[C^m_n: \mathbb{T}^p_q \longrightarrow \mathbb{T}^{p-1}_{q-1}, \; 1 \leq m \leq p, 1 \leq n \leq q\]
defined as follows. Let us define the map 
\[\Tilde{C}^m_n: \prod_{p} V \times \prod_q V^* \longrightarrow \mathbb{T}^{p-1}_{q-1} V\]
such that (where the hatted elements are taken out)
\[ (x_1, ..., x_p, \alpha_1, ..., \alpha_q) \mapsto \alpha_n (x_m) \; x_1 \otimes ... \hat{x_m} ... \otimes x_p \otimes \alpha_1 \otimes ... \hat{\alpha_n} ... \otimes \alpha_q\]
This is clearly a multilinear map, so by the universal property, there exists a unique linear map $C^m_n: \mathbb{T}^p_q V \longrightarrow \mathbb{T}^{p-1}_{q-1} V$ such that 
\[ \bigotimes_{i=1}^p x_i \otimes \bigotimes_{j=1}^q \alpha_j \mapsto \alpha_n (x_m) \, \bigotimes_{i \neq m} x_i \otimes \bigotimes_{j \neq n} \alpha_j\]
This mapping $C^m_n$ is called the $m n$th contraction of a tensor in $\mathbb{T}^p_q V$. 
\end{definition}

Note that there are multiple mappings from $\mathbb{T}^p_q \longrightarrow \mathbb{T}^{p-1}_{q-1}$, depending on the choice of $m, n$. This contraction function is also canonical, i.e. we did not have to endow any structures to $V$ to define $C^n_m$. 

We could also contract multiple steps at once with the map $\mathbb{T}^p_q \longrightarrow \mathbb{T}^{p-k}_{q-k}$, but this is really just a composition of single contractions 
\[\mathbb{T}^p_q \longrightarrow \mathbb{T}^{p-1}_{q-1} \longrightarrow \mathbb{T}^{p-2}_{q-2} \longrightarrow ... \longrightarrow \mathbb{T}^{p-k}_{q-k} \]

\begin{definition}
Given a $(0, 2)$-tensor $F_{\alpha \beta}$, we can find its \textit{symmetric component}
\[ F_{ \{ \alpha \beta\}} = \frac{1}{2} \big(F_{\alpha \beta} + F_{\beta \alpha} \big)\]
and its \textit{anti-symmetric component}
\[ F_{ [ \alpha \beta]} = \frac{1}{2} \big(F_{\alpha \beta} - F_{\beta \alpha} \big)\]
such that 
\[ F_{\alpha \beta} = F_{ \{ \alpha \beta \}} + F_{[\alpha \beta]}\]
\end{definition}

In shorthand form, to form a contraction, we can just write the indices that are being contracted as the same letter. 

\begin{example}
When performing a contraction, it is common to make the indices that are being contracted the same. For example, $X^{a b c}_{\;\;\;\;\;\; d} \in V^{\otimes 3} \otimes V^*$ can be contracted, so if we can choose the $a$ and $d$ indices to contract, we get 
\[X^{a b c}_{\;\;\;\;\;\; a} \in V \otimes V\]
\end{example}

\begin{proposition}
The contraction of a linear operator $A = u \otimes \alpha$ is its trace. Notice how that the vector $u$ comes first and the covector $\alpha$ comes second, since we're working in $\mathbb{T}^1_1 V$. 
\end{proposition}
\begin{proof}
Given that $\{e_i\}$ is the basis for $n$-dimensional space $V$ and $\{f_i\}$ is the dual basis of $V^*$.
\begin{align*}
    C^1_1 (x \otimes \alpha) = \alpha (u) 
    = \Big( \sum_{i=1}^n \alpha_i f_i  \Big) \Big( \sum_{j=1}^n x_j e_j \Big)  = \sum_{i, j} \alpha_i x_j \delta^j_i = \sum_{i=1}^n \alpha_i x_i 
\end{align*}
which is clearly the definition of the trace. 
\end{proof}

In addition to contracting a tensor with itself, we can contract a tensor $X$ with another tensor $Y$. 

\begin{example}
$X^{a b c} Y_d \in V^{\otimes 3} \otimes V^*$ 
\end{example}

\begin{proposition}
The contraction of a linear operator $A = u \otimes \alpha$ and a vector $x$ is precisely $A x$, the image of $x$ under the linear operator $A$. 
\[A x = (u \otimes \alpha) x = \alpha (x) u \in V\]
Calculating this after defining coordinates aligns with matrix multiplication of form
\[\begin{pmatrix}
 & A_1 & - \\
- & A_2 & - \\
... & ... & ... \\
- & A_n & - \\
\end{pmatrix} \begin{pmatrix}
... \\ x \\ ... 
\end{pmatrix} = \begin{pmatrix}
 A_1 \cdot x \\ A_2 \cdot x \\ ... \\ A_n \cdot x
\end{pmatrix}\]
\end{proposition}

\begin{proposition}
The contraction of the tensor product of linear operators $A, B$ is just the regular composition $A B$. Note that this contraction contracts the second index of $A$ with the first index of $B$. That is, 
\[C(A \otimes B) = C\big( (u \otimes \alpha) \otimes (v \otimes \beta) \big) = \alpha(v) \, u \otimes \beta \in \mathbb{T}^1_1\]
Clearly, $\alpha(v) \, u \otimes \beta$ is a really another linear map. We can evaluate $A B x$ by performing the contraction on $A B$ first and then contracting it with $x$. 
\[A B x = \alpha (v) (u \otimes \beta) (x) = \alpha (v) \beta(x) u \]
Alternatively, we can evaluate $A B x$ equivalently by performing the contraction on $B x$ first and then $A$ 
\[A B x = \beta (x)\, A v = \alpha(v) \beta(x) u\]
Either way, it results in the same vector $\alpha (v) \beta (x) u$. This is expected because tensor products are associative. 
\end{proposition}

Similarly, we can contract the tensor products of general tensors $T$ and $R$, which is called a \textit{contraction of $T$ with $R$}. 
\\

Furthermore, just like linear mappings or vectors, we can factorize arbitrary tensors in their own way. The field of math dealing with this is called \textit{Tensor Network Theory}, which has multiple applications in computer science, chemistry, and physics. 

\begin{definition}
We can factorize a complex tensor $X$ into a product of tensors that can be contracted to result in $X$. We can think of factoring tensors as analogous to anti-contraction. This process is best illustrated with the following example. Let us factor the tensor into three different tensors: a rank (1,2) tensor $A$, rank (2,2) tensor $B$, and rank (1,2) tensor $C$. 
\[X_{abde}^{\;\;\;\;\;\;\;hg} = A_{ab}^{\;\;\;\;c} \otimes B_{de}^{\;\;\;\;fg} \otimes C_{cf}^{\;\;\;\;h}\]
We can visually represent factorization with the tensor network diagram
\begin{center}
\begin{tikzpicture}
    [scale=.5, auto=center]
    \node (a) at (0,5) {};
    \node (b) at (0,3) {};
    \node (d) at (0,2) {};
    \node (e) at (0,0) {};
    \node (h) at (10,3) {};
    \node (A) at (3,4) {A};
    \node (B) at (3,1) {B};
    \node (C) at (7,3) {C};
    \node (g) at (10,1) {};
    \node (a_1) at (1.4,4.9) {a};
    \node (b_1) at (1.4,3) {b};
    \node (d_1) at (1.4,2) {d};
    \node (e_1) at (1.4,0.14) {e};
    \node (c_1) at (5,3.8) {c};
    \node (f_1) at (4.8,2.4) {f};
    \node (g_1) at (7.5,1.4) {g};
    \node (h_1) at (8.5,3.4) {h};
    \draw[->]
        (a) edge (A) (b) edge (A) (d) edge (B) (e) edge (B) (A) edge (C) (C) edge (h) (B) edge (g) (B) edge (C); 
\end{tikzpicture}
\end{center}
where the "inputs" at each node are covectors and the "outputs" are vectors. Therefore, the entire diagram, which represents the tensor $X$ has a total of 4 inputs (indices $a, b, d, e$) and two outputs (indices $h, g$). We can see from the diagram that the indices $c$ and $f$, which travels "between" the factors are the ones that are being contracted. Therefore, the contraction of $c$ and $f$ contracts the rank (4,6) tensor $A \otimes B \otimes C$ to a rank (2,4) tensor. 
\end{definition}

\begin{definition}
The \textit{tensor algebra} of vector space $V$ over field $\mathbb{F}$ is an associative, noncommutative algebra defined
\begin{align*}
    T(V) \equiv \bigoplus_{n = 0}^{\infty} V^{\otimes n} & = V^{\otimes 0} \oplus V^{\otimes 1} \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus ... \\
    & = \mathbb{F} \oplus V \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus V^{\otimes 4} \oplus ...
\end{align*}
with elements being infinite-tuples
\[ (a, B^\mu, C^{\nu \gamma}, D^{\alpha \beta \epsilon}, ...)\]
The addition operation is defined component-wise, and the multiplication operation is the tensor product 
\[\otimes: T(V) \times T(V) \longrightarrow T(V)\]
and the identity element is
\[I = (1, 0, 0, ...) \]
Linearity is easily proved. 
\end{definition}

The tensor algebra is used to "add" differently ranked tensors together. In order to do this rigorously, we must define the map (which is also an isomorphism)
\[i_j: V^{\otimes j} \longrightarrow T(V), \; i_j (T^{\kappa_1, ..., \kappa j}) = (0, ...,0, T^{\kappa_1, ..., \kappa j}, 0, ..., 0) \]
So, we can implicitly define the addition of arbitrary tensors $A \in V^{\otimes n}$ and $B \in V^{\otimes m}$ as 
\[ A + B \equiv i_n (A) + i_m (B) \in T(V)\]
along with the tensor multiplication of the form
\[ A \otimes B \equiv i_n(A) \otimes i_m(B) \equiv i_{n+m} (A \otimes B)\]
This allows us to alternatively define the tensor product operation as
\[i_i(V^{\otimes i}) \otimes i_j( V^{\otimes j}) \equiv i_{i+j} (V^{\otimes (i+j)})\]

\subsection{Exterior Algebras and Symmetric Algebras}
We can define the symmetric and exterior algebras multiple ways. In here, we will construct their powers separately as quotient spaces and direct sum them to create their respective algebras. But first, we must introduce the Schmidt decomposition, which is the foundation of all the results of this section. 

\begin{theorem}[Schmidt Decomposition]
For any $w \in U \otimes V$, where $U, V$ ($\dim{U} = n, \dim{V} = m$)  are inner product spaces over $\mathbb{F} \in \{ \mathbb{R}, \mathbb{C}\}$, there exists an orthonormal basis $\{u_i\}$ of $U$ and $\{v_j\}$ of $V$ such that 
\[ w = \sum_{i=1}^{\min{\{n, m\}}} \alpha_i u_i \otimes v_i, \; \alpha_i \in \mathbb{F}\]
\end{theorem}
\begin{proof}
Since $U \otimes V \simeq $ Hom$(V^*, U)$, we can interpret $w$ as a matrix $\Tilde{w}$. Using singular value decomposition, there exists unitary matrices $A, B$ and diagonal matrix $\Sigma$ such that
\[\Tilde{w} = A \Sigma B^\dagger\]
$C(A)$ and $R(B^\dagger)$ determine the orthonormal basis of $U \otimes V$, and we can thus see that the minimum number of required $u \otimes v$'s is precisely the number of nonzero singular values, which is the rank of $\Tilde{w}$. 

\end{proof}

\begin{definition}
Let $I$ be a subspace of $V \otimes V$ generated by elements of the form $x \otimes x \in V \otimes V$. That is, given a basis $\{e_i\}$ of $n$-dimensional space $V$, all tensors of the form $x \otimes x \in V \otimes V$ can be written 
\[x \otimes x = \sum_{i=1}^n a_i (e_i \otimes e_i) + \sum_{i \neq j} b_{i j} (e_i \otimes e_j + e_j \otimes e_i)\]
which implies that the components of $e_i \otimes e_j$ and $e_j \otimes e_i$ must be the same for every element in $I$. 
\end{definition}

\begin{example}
Given that $V$ is 2-dimensional, a vector $x \in V$ can be written $x = a e_1 + b e_2$, which implies
\begin{align*}
    x \otimes x & = (a e_1 + b e_2) \otimes (a e_1 + b e_2) \\
    & = a^2 (e_1 \otimes e_1) + a b (e_1 \otimes e_2) + b a (e_2 \otimes e_1) + b^2 (e_2 \otimes e_2) \\
    & = a^2 (e_1 \otimes e_1) + b^2 (e_2 \otimes e_2) + a b (e_1 \otimes e_2 + e_2 \otimes e_1) 
\end{align*}
\end{example}

Since we can group the components $e_i \otimes e_j$ and $e_j \otimes e_i$ together to $e_i \otimes e_j + e_j \otimes e_i$, the basis of $I$ is 
\[\{e_1 \otimes e_1, ..., e_n \otimes e_n, e_1 \otimes e_2 + e_2 \otimes e_1, ..., e_{n-1} \otimes e_n + e_n \otimes e_{n-1}\}\]

\begin{definition}
Now, we can define the \textit{second exterior power of $V$} as
\[\Lambda^2 V \equiv \frac{V \otimes V}{I}\]
and it follows that 
\[\dim{\Lambda^2 V} = n^2 - \dim{I} = \frac{1}{2} n (n-1)\]
We denote the elements of $\Lambda^2 V$ as $x \wedge y$, which really just represents the equivalence class of $x \otimes y$ in the quotient space. It is clear that $x \otimes x \in I \implies x \wedge x = 0$, so
\begin{align*}
    0 = (x + y) \wedge (x + y) & = x \wedge x + x \wedge y + y \wedge x + y \wedge y \\
    & = x \wedge y + y \wedge x \\
    \implies & x \wedge y = - y \wedge x
\end{align*}
That is, the wedge product is antisymmetric. Note also that we can assume distributivity of $\wedge$ since it is just the quotient operation of another operation $\otimes$ that satisfies distributivity. 
\\

We can construct a basis on $\Lambda^2 V$, given by 
\[\{e_i \wedge e_j \; | \; i < j\}\]
Again, we note that $i < j$ since $e_i \wedge e_i = 0$ and $e_i \wedge e_j = - e_j \wedge e_i$. 
\end{definition}

One realization of the space $\Lambda^2 \mathbb{R}^n$ is the set of antisymmetric $n \times n$ matrices. 
\\

We can construct higher order exterior powers, too. For $n = 3$ (and assuming that $\dim{V} \geq 3$), the subspace $I \subset V \otimes V \otimes V$ is the space generated by elements of the forms
\[x \otimes x \otimes y, x \otimes y \otimes x, y \otimes x \otimes x\]
Following a similar construction, the \textit{third exterior power of $V$} is
\[\Lambda^3 V \equiv \frac{V \otimes V \otimes V}{I}\]
with its elements being equivalence classes of the form
\[x \wedge y \wedge z,\; x, y, z \in V\]
such that
\begin{align*}
    x \wedge y \wedge z & = - x \wedge z \wedge y \\
    & = - y \wedge x \wedge z \\
    & = - z \wedge y \wedge x
\end{align*}
The basis of $\Lambda^3 V$ is
\[\{e_i \wedge e_j \wedge e_k \; | \; i < j < k\} \implies \dim{\Lambda^3 V} = \frac{1}{6} n (n-1) (n-2)\]
Generally, if $\sigma$ is a permutation of the ordered list $(1, 2, ..., n)$, and $x_1, x_2, ..., x_n \in V$, then 
\[x_{\sigma(1)} \wedge x_{\sigma(2)} \wedge ... \wedge_{\sigma(n)} = sgn(\sigma) \; x_1 \wedge x_2 \wedge ... \wedge x_n\]
which means that if $x_i = x_j$ for some $1 \leq i \neq j \leq n$, 
\[x_1 \wedge x_2 \wedge ... \wedge x_n = 0\]
By constructing all the exterior powers of $n$-dimensional space $V$, we can construct the algebra 
\begin{align*}
    \Lambda(V) \equiv \bigoplus_{k=0}^n \Lambda^k V \equiv \Lambda^0 V \oplus \Lambda^1 V \oplus \Lambda^2 V \oplus ... \oplus \Lambda^n V 
\end{align*}
Note that $\Lambda^0 V = \mathbb{F}$ and $\Lambda^1 V = V$. Unlike the tensor algebra, the exterior algebra is finite since the exterior powers vanish for finite $n$. In fact, 
\[ \dim{\Lambda^k V} = \begin{cases}
_n C_k & 0 \leq k \leq n \\
0 & n < k
\end{cases}\]
which implies that 
\[\dim{\Lambda(V)} = 2^n \]
\begin{definition}
The $n$th exterior power $\Lambda^n V$ is 1 dimensional, spanned by the singular basis vector 
\[e_1 \wedge e_2 \wedge ... \wedge e_{n-1} \wedge e_n\]
This vector is the \textit{determinant}. Note that this construction of the determinant is consistent with our previous construction of the determinant of a matrix since $e_1 \wedge ... \wedge e_n$ is indeed multilinear and antisymmetric. In its purest sense, 
\[e_1 \wedge ... \wedge e_n: \prod_{i=1}^n V^* \longrightarrow \mathbb{F}\]
is a mapping that is multilinear and antisymmetric. But there is an inconsistency. The matrix determinant takes in \textit{matrices} rather than taking in $n$-tuples of covectors. However, we can interpret the $n$ covectors in $V^* \times ... \times V^*$ as the column (or row) vectors of an $n \times n$ matrix. This completes the realization, and so we can conclude that the matrix determinant is just a realization of the more abstract determinant $e_1 \wedge ... \wedge e_n$. 

Note that any tensor in $\Lambda^n V$ satisfies multilinearity and antisymmetricity, but only the basis vector $e_1 \wedge ... \wedge e_n$ satisfies the normalizing condition
\[\det{I} = 1\]
Since, given that the dual basis of $V^*$ is $\{f_j\}$
\[(e_1 \wedge ... \wedge e_n) (f_1, f_2, ..., f_n) = \prod_{i=1}^n e_i (f_i) = \prod_{i=1}^n \delta_i^i = 1\]
\end{definition}

\begin{example}
Given 3 dimensional vector space $V$ with basis $\{e_1, e_2, e_3\}$, the wedge product of two vectors $a, b \in V$ is 
\begin{align*}
    a \wedge b & = (a_1 e_1 + a_2 e_2 + a_3 e_3) \wedge (b_1 e_1 + b_2 e_2 + b_3 e_3) \\
    & = (a_2 b_3 - a_3 b_2) e_2 \wedge e_3 + (a_3 b_1 - a_1 b_3) e_3 \wedge e_1 + (a_1 b_2 - a_2 b_1) e_1 \wedge e_2 
\end{align*}
which is essentially the formula for the cross product $\times$ in Euclidean space. We can therefore think of the realization of the wedge product in 3 dimensional space $V$ as the cross product. 
\[\wedge: V \times V \longrightarrow \Lambda^2 V\]
Note that $\Lambda^2 V \simeq V$ if $\dim{V} = 3$, so we can construct the more familiar $\times$ operation in $\mathbb{R}^3$. 
\[\times: \mathbb{R}^3 \times \mathbb{R}^3 \longrightarrow \Lambda^2 \mathbb{R}^3 \simeq \mathbb{R}^3\]
which is consistent with $\times$ taking two vectors and outputting a third vector living in $\mathbb{R}^3$ that is orthogonal to the two input vectors. 
\end{example}

\begin{example}
The realization of the wedge product of 3 vectors in 3 dimensional space $V$ is the \textit{triple scalar product}, which we will denote as $\times_3$
\[\wedge: V \times V \times V \longrightarrow \Lambda^3 V\]
Note that since $\Lambda^3 V \simeq V$ when $\dim{V} = 3$, we can write 
\[\times_3: \mathbb{R}^3 \times \mathbb{R}^3 \times \mathbb{R}^3 \longrightarrow \Lambda^3 \mathbb{R}^3 \simeq \mathbb{R}\]
which is consistent with $\times_3$ taking three vectors and outputting the signed volume of their parallelopiped which lies in $\mathbb{R}$. 
\end{example}

Now we introduce the symmetric algebra and its construction. Let $I$ be the subspace of $V \otimes V$ generated by all tensors of the form 
\[u \otimes v - v \otimes u, \; u, v \in V\]
For example, given $a, b \in V$ with basis $\{e_1, e_2\}$, 
\begin{align*}
    a \otimes b - b \otimes a & = (a_1 e_1 + a_2 e_2) \otimes (b_1 e_1 + b_2 e_2) - (b_1 e_1 + b_2 e_2) \otimes (a_1 e_1 + a_2 e_2) \\
    & = (a_1 b_2 - b_2 a_1) e_1 \otimes e_2 + (a_2 b_1 - b_2 a_1) e_2 \otimes e_1 
\end{align*}
is an element of $I$. We can generalize this to see that
\[\{e_i \otimes e_j - e_j \otimes e_i\}, \; i \neq j\]
is the basis for $I$. Now, let us define the \textit{second symmetric power of $V$} as 
\[\Sym^2 V \equiv \frac{V \otimes V}{I}\]
where, given that $\dim{V} = n$, 
\[\dim{\Sym^2 V} = n^2 - \frac{1}{2} n (n-1) = \frac{1}{2} n (n+1)\]
We denote the elements of $\Sym^2 V$ as $x \odot y$, which are really the equivalence classes $\{x \otimes y - y \otimes x\}$. Note that
\begin{align*}
    x \odot y - y \odot x & = \{x \otimes y - y \otimes x\} - \{ y \otimes x - x \otimes y\} \\
    & = \{ x \otimes y - y \otimes x - y \otimes x + x \otimes y\} \\
    & = \{0\} = 0
\end{align*}
$\implies x \odot y = y \odot x$. That is, the $\odot$ operator is symmetric, and $\Sym^2 V$ has basis 
\[ \{e_i \odot e_j\}_{j \geq k}\]
One realization of $\Sym^2 \mathbb{R}^n$ is the set of all symmetric $n \times n$ real matrices. 
\\

We can construct higher symmetric powers satisfying this property that its tensors are invariant under transpositions. 
\[x_1 \odot ... x_i \odot ... x_j \odot ... x_n = x_1 \odot ... x_j \odot ... x_i \odot ... x_n\]
for all $1 \leq i \neq j \leq n$, which implies that it is invariant under any permutation $p \in S_n$ of the $x_i$'s. Additionally, 
\[\dim{\Sym^k V} = {{n+k-1} \choose k }\]

\begin{definition}
The \textit{symmetric algebra} of vector space $V$ is constructed as such 
\[\Sym (V) \equiv \bigoplus_{k=0}^\infty \Sym^k V\]
Note that unlike the exterior algebra, $\Sym(V)$ is infinite dimensional. 
\end{definition}

\begin{example}
The inner product $(\cdot, \cdot)$ on $V$ is an element of $\Sym^2 V$, since it is a bilinear, symmetric operation on $V$. 
\[\odot, (\cdot, \cdot): V \times V \longrightarrow \mathbb{F}\]
\end{example}

There is a simple relationship between $V \otimes V$, $\Lambda^2 V$, and $\Sym^2 V$. 

\begin{theorem}
\[V \otimes V \simeq \Sym^2 V \oplus \Lambda^2 V\]
with isomorphism defined
\[v \otimes w \mapsto \Big( \frac{1}{2} (v \odot w), \frac{1}{2} (v \wedge w) \Big)\]
This is precisely the factoring of a rank (2,0) tensor into its symmetric and antisymmetric parts. 
\end{theorem}
\begin{proof}
Given $v \otimes w \in V \otimes V$, 
\[v \otimes w + w \otimes v \in \Sym^2 V \text{ and } v \otimes w - w \otimes v \in \Lambda^2 V\]
By defining $v \odot w$ and $v \wedge w$ as the expressions above, the isomorphism is satisfied. 
\end{proof}

Therefore, when working in $V \otimes V$, we can interpret 
\begin{align*}
    & v \wedge w = \frac{1}{2} (v \otimes w - w \otimes v) \\
    & v \odot w = \frac{1}{2} (v \otimes w + w \otimes v) 
\end{align*}

However, 
\[V \otimes V \otimes V \not\simeq \Sym^3 V \oplus \Lambda^3 V\]
\textit{Schur functors} are used to fix this discrepancy. 

Note that we have introduced these two algebras by first constructing the quotient spaces $\Lambda^n V$ and $\Sym ^n V$ from the tensor product spaces $T^{\otimes n}$ and then direct summing these powers to construct the algebras. We will introduce another type of construction that directly takes the quotient algebra of $T(V)$ with the two-sided ideal. 

\chapter{Calculus on Euclidean Space}
Coordinate-dependent calculus of vector-valued functions. Note that the entire concept of calculus is dependent on functions that maps elements between metric spaces. To be more rigorous, we really just need a topology to define the following terms shown, but this course will assume that we are working with Euclidean spaces of $\mathbb{R}^n$ with metric topologies. The metric in $\mathbb{R}^n$ will be denoted $||\cdot||$, defined to be the $L2$ metric. 

\section{Differentiation}
\begin{definition}
A sequence $(x_k)$ of vectors in $\mathbb{R}^n$ \textit{converges} to the vector $x$ if 
\[\lim_{k \rightarrow \infty} ||x_k - x|| = 0\]
\end{definition}

Note that this definition of convergence can be defined for any vector in a metric space $(V, ||\cdot||)$. For example, the space of $n \times n$ matrices with the operator norm or the Frobenius norm. Since this specific definition of convergence is limited in the way that the $L2$ norm is dependent on the coordinates of the vector in $\mathbb{R}^n$, the entire concept of coordinate-based vector calculus is also limited. 

The concepts of continuity and derivatives are dependent on how the output of the function changes as we are changing the input. To measure this change in input, we must define a path function. 

\begin{definition}
A \textit{path function} is any function
\[p: \mathbb{R} \longrightarrow \mathbb{R}^n\]
Note that $\im{(p)}$ traces out an oriented path in $\mathbb{R}^n$. Note also that the paramaterization of $p$ may be different even though the image of $p$ may not change. 
\end{definition}

The defining of the path function allows us to construct arbitrary paths traveling through $\mathbb{R}^n$. Now, we can define continuity. 

\begin{definition}
Let $p: \mathbb{R} \longrightarrow \mathbb{R}^n$ be any path function such that $p(t_0) = x_0$, and let $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ be a vector-valued function defined on the open set $U \subset \mathbb{R}^n$. $f$ is \textit{continuous} at $x_0 \in U$ if 
\begin{align}
    \lim_{t \rightarrow t_0} ||(f \circ p)(t) - (f \circ p)(t_0) || = \lim_{t \rightarrow t_0} ||(f \circ p)(t) - f(x_0) || = 0
\end{align}
This is equivalently written as 
\begin{equation}
    \lim_{x \rightarrow x_0} ||f(x) - f(x_0)|| = 0
\end{equation}
It is important to introduce equation $(1)$ since this allows the reader to realize that the limits and the actual value of $f$ at $x_0$ should coincide no matter which path we choose in $\mathbb{R}^n$. While equation $(2)$ is more concise, the expression $x \rightarrow x_0$ does not clearly express the arbitrariness in our choice of path. 
\end{definition}

Note that the metric $||\cdot||$ in $(2)$ is the metric of $\mathbb{R}^m$, not $\mathbb{R}^n$. 

\subsection{Derivatives along Paths, Directional Derivatives}
Differentiability must also be defined using paths since the change of $x \in \mathbb{R}^n$ (an element in the domain of $f$) can be modeled using a specific path function. 

\begin{definition}
Let $p: \mathbb{R} \longrightarrow \mathbb{R}^n$ be a path function such that $p(t_0) = x_0$, and let there exist a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$. We say that $f$ is \textit{differentiable} at $x_0$ if, for every $p$, there exists a value $f_p^\prime (x_0)$ such that 
\[\lim_{h \rightarrow 0} \bigg|\bigg| \frac{(f\circ p)(t_0 + h) - (f \circ p) (t_0)}{h} - f_p^\prime (x_0)\bigg|\bigg| = 0\]
This is equivalent to saying that there exists a well-defined linear mapping $T: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ such that 
\[\lim_{x \rightarrow x_0} \frac{|| f(x) - \big( f(x_0) + T x\big)||}{||x - x_0||} = 0\]
This says that there exists an affine linear approximation $L(x) = f(x_0) + T(x)$ of $f$ in the neighborhood $U$ of $x_0$.
\end{definition}

We now give a visual description of this linear approximation. Let us define the \textit{graph of $f$} as the $m$-dimensional surface
\[G \equiv \{(x_1, x_2, ..., x_n, f_1(x), ..., f_m(x)) \; | \; (x_1, ..., x_n) \in \mathbb{R}^n\} \subset \mathbb{R}^n \oplus \mathbb{R}^m\]
We can interpret $\im{L}$ as the $n$-dimensional affine linear subspace embedded in $\mathbb{R}^n \oplus \mathbb{R}^m$, the extended space where the function is graphed in. That is, 
\[\im{L} \equiv \{(x_1,..., x_n, f_1(x_0) + T_1 (x), ..., f_m(x_0) + T_m (x)) \} \; | \; (x_1, ..., x_n) \in \mathbb{R}^n\}\]
In a way, $\im{L}$ is the affine "tangent space" of $G$ at point $x_0$. We now define the derivative of path functions. 

\begin{definition}
Let $p: \mathbb{R} \longrightarrow \mathbb{R}^n$ be a path function with parameter $t$. Let the coordinate representation of $p$ be defined
\[p \equiv (p_1, p_2, ..., p_n)\]
Then, the derivative of $p$ with respect to $t$ is defined
\[p^\prime (t) = (p_1^\prime, p_2^\prime, ..., p_n^\prime)\]
Visually, this outputs a tangent vector that represents the velocity of the particle traveling through $\im{p} \subset \mathbb{R}^n$ as $t$ travels through $\mathbb{R}$. The magnitude of the vector represents the speed of the particle, while the orientation of the vector represents the particle's direction. 
\end{definition}

The definition of the derivative of the path function now allows us to build on top of it the derivative of a general function. 

\begin{definition}
Given that the derivative of $f$ exists at $x_0$, $f^\prime$ cannot be properly defined unless we specify which path function $p$ (fully on the graph $f$ and passing through $x_0$) the particle is traveling through. Therefore, the derivative of the function $f$ through a path $p$ at $x_0$ is defined
\[f_p^\prime (x_0) \equiv \lim_{h \rightarrow 0} \frac{(f\circ p) (t_0 + h) - (f \circ p) (t_0)}{h}\]
\end{definition}

We can describe the derivative visually, too. $p$ defines a path function that describes a particle traveling through $\mathbb{R}^n$. Now, think of this entire path being mapped onto $\mathbb{R}^m$ through $f$, which will draw another path in $\mathbb{R}^m$. In a way, $f$ has "warped" the velocity of the particle. With this new velocity curve, the tangent vector of curve $f(p(t))$ at the point $t_0$ is the derivative of the $f$ at point $x_0$. (The reader may also realize that we have just described the chain rule, too). 
\begin{center}
    \includegraphics[scale=0.25]{Tangent_Vector_Velocity_Curve.PNG}
\end{center}
We can also visualize how the affine linear approximation is constructed from the tangent vectors of each path. Given the graph $G$ of $f$ in $\mathbb{R}^n \oplus \mathbb{R}^m$, the path function $p$ determines a path on the surface $G$ that passes through $(x_0, f(x_0))$ (we are treating $x_0$ as an $n$-tuple and $f(x_0)$ as an $m$-tuple). This path on $G$ is really just a bigger path function defined as
\[t \mapsto \big( p_1(t), p_2(t), ..., p_n(t), f_1(p(t)), ..., f_m(p(t))\big)\]
or more simply, let $\Tilde{p}$ be the mapping
\[t \mapsto \big( p(t), f(p(t)) \big)\]
Now, for all paths $\Tilde{p}$ on $G$ passing through $(x_0, f(x_0))$, the set of tangent vectors of every possible $\Tilde{p}$ from $x_0$ is precisely the affine linear subspace $\im{L}$. In the $2 + 1 = 3$ dimensional case, we have our familiar tangent plane at point $(x, y, f(x, y))$ on the graph of the function $f$ in $\mathbb{R}^2 \oplus \mathbb{R}$. 
\begin{center}
    \includegraphics[scale=0.2]{Tangent_Plane_to_Graph.PNG}
\end{center}

\subsection{Differential Operators, Total Derivatives}
\subsubsection{Tangent Vectors, Spaces, and Bundles}
\begin{definition}[Tangent Vectors, Spaces at a Point in $\mathbb{R}^n$]
We will construct the geometric tangent space of Euclidean space $\mathbb{R}^n$. Denote the set of all possible path functions $p: \mathbb{R} \longrightarrow \mathbb{R}^n$ that passes through $a \in \mathbb{R}^n$ to be $\mathcal{P}_{a}(\mathbb{R}^n)$. We show some of these path functions in $\mathcal{P}_{a} (\mathbb{R}^n)$ below (note that this is merely a set, so there is no operation defined on these paths, as in the case of the fundamental group of a topological space). 
\begin{center}
    \includegraphics[scale=0.4]{Curves_Through_A_Point.png}
\end{center}
We can define a relation on this set: two path functions $q, r \in \mathcal{P}_{a} (\mathbb{R}^n)$ are equivalent if the tangent vectors of $q$ and $r$ at $a$ (including magnitude) are equal. Note that we have already defined the tangent vector to a path function above, so this move is completely valid. 
\begin{center}
    \includegraphics[scale=0.4]{Curves_in_Same_Equivalence_Class.png}
\end{center}
That is, given $q(t_q) = r (t_r) = a$, 
\[q \sim r \iff q^\prime (t_q) = r^\prime (t_r)\]
which implies that given any smooth function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$, 
\[(f \circ q)^\prime (a) = (f \circ r)^\prime (a)\]
Note that within each equivalence class, there is exactly one straight-line path that goes through $a$ with a given magnitude. This fact is extremely significant because this allows us to simplify the concept of derivatives defined on arbitrary paths to paths that are simpler in general. It isn't too hard to see that every arbitrary path $p$ is equivalent to some line function with constant velocity. That is, given a path $p$ such that $p(t_0) = a$ and 
\[p^\prime (t_0) = v \in \mathbb{R}^n\]
we can construct the unique straight-line path that is equivalent to $p$ under $\sim$ as 
\[l(t) \equiv a + v (t - t_0)\]
and calculate the derivative of $f$ under the path $l$ to find $f^\prime$ under $p$ at $a$. This "simplification" of $\mathcal{P}_{a}(\mathbb{R}^n)$ to the quotient space $\mathcal{P}_{a} (\mathbb{R}^n)/\sim$ of path functions that draw constant-velocity lines allows us to define directional derivatives. Note that paths that have the same image in $\mathbb{R}^n$ could be in different equivalence classes under $\sim$ if their velocities are different at the point $x_0$!

Now, since every path function in $\mathcal{P}_{a} (\mathbb{R}^n)$ can be simplified to a straight line path represented by a vector protruding from $a$, $\mathcal{P}_{a} (\mathbb{R}^n)$ looks a lot like the vector space $\mathbb{R}^n$. 
\begin{center}
    \includegraphics[scale=0.4]{Curves_Modeled_as_Vectors.png}
\end{center}
We can define vector addition, scalar multiplication, etc. to give this set the structure of a vector space. Therefore, this quotient space with this vector space structure is isomorphic to the geometric tangent space of $f$ at point $a$, denoted $T_a \mathbb{R}^n$. 
\[T_a \mathbb{R}^n \simeq \frac{\mathcal{P}_a (\mathbb{R}^n)}{\sim}\]
The vectors in here are called the \textit{tangent vectors of $T_a \mathbb{R}^n$}. So, if we would like to find the directional derivative of $f$ the point $a$ in direction of vector $v$, (given that $l(t) \equiv a + v (t - t_0)$) we can calculate 
\[\frac{d}{dt} f\big(l(t)\big) \bigg|_{t = t_0} = \frac{d}{dt} f(a + v t) \bigg|_{t = 0} = \lim_{t \rightarrow 0} \frac{f(a + v t) - f(a)}{t}\]
Note that while
\[T_a \mathbb{R}^n \simeq T_b \mathbb{R}^n \simeq \mathbb{R}^n\]
for all $a, b \in \mathbb{R}^n$, these tangent spaces are not equivalent to each other. 
\end{definition}

\begin{theorem}
If $f^\prime (t) = 0$ for all $t \in \mathbb{R}^n$ and all paths $p$, then $f$ is a constant function. 
\end{theorem}

\begin{definition}[Tangent Bundles in $\mathbb{R}^n$]
In $\mathbb{R}^n$, the \textit{fiber bundle} of the tangent spaces $T_x \mathbb{R}^n$ for all $x \in \mathbb{R}^n$ is the disjoint union of them, called the \textit{tangent bundle}. 
\[T \mathbb{R}^n \equiv \bigsqcup_{a \in \mathbb{R}^n} T_a \mathbb{R}^n\]
Its has a dimension of $2n$. In this chapter, this notation is used when we must identify a geometric tangent space $T_x \mathbb{R}^n$ but the point $x$ at which the tangent space is constructed is not specified. Therefore, we refer to \textit{all} of the tangent spaces at once. 
\end{definition}

Another concept that will pop up is the vector field of $\mathbb{R}^n$. A vector field of $\mathbb{R}^n$ is actually not a function $V: \mathbb{R}^n \longrightarrow \mathbb{R}^n$. 

\begin{definition}[Vector Field of Tangent Vectors on $\mathbb{R}^n$]
A vector field $V$ on $\mathbb{R}^n$ is a mapping
\[V: \mathbb{R}^n \longrightarrow T \mathbb{R}^n\]
where $V(x) \in T_x \mathbb{R}^n$. We can interpret this visually since every vector is "attached" to a different point in $\mathbb{R}^n$, which represents its own tangent space. 
\end{definition}

\begin{definition}[Differential Operator]
Let us denote the set of all smoothly continuous functions mapping from $\mathbb{R}^n$ to $\mathbb{R}^m$ as $C^1 (\mathbb{R}^n; \mathbb{R}^m)$. We have seen that in order to find the derivative of a function, we need
\begin{enumerate}
    \item a smooth function $f \in C^1 (\mathbb{R}^n; \mathbb{R}^m)$ 
    \item a point $x_0 \in \mathbb{R}^n$, where the derivative will be evaluated
    \item a geometric tangent vector $v \in T_{x_0} \mathbb{R}^n$ that represents the direction in which we are evaluating the derivative 
\end{enumerate}
In the most abstract sense, we can interpret the differentiation operator as a function $d$ that takes in these three inputs and outputs a vector that represents the rate of change of $f$ at $x_0$ in direction $v$. 
\[d: C^1(\mathbb{R}^n; \mathbb{R}^m) \times \mathbb{R}^n \times T \mathbb{R}^n \longrightarrow \mathbb{R}^m\]
where $T \mathbb{R}^n_x$ is the fiber bundle of all geometric tangent spaces at $\mathbb{R}^n$.  
\begin{center}
    \includegraphics[scale=0.2]{Three_Input_Differential_Operator.PNG}
\end{center}
Note that the differential operator, denoted $d$, is
\begin{enumerate}
    \item linear with respect to the function argument
    \[(d_v (f + g)) (p) = d_v f (p) + d_v g(p), \;\; (d_v (c f)) (p) = c  (d_v f) (p)\]
    \item linear with respect to the directional vector argument
    \[(d_{v + w} f) (p) = (d_v f) (p) + (d_w f) (p), \;\; (d_{cv} f) (p) = c (d_v f) (p)\]
    \item not linear with respect to the point argument
\end{enumerate}
In the most abstract sense, $d$ finds the derivative of any function $f$ when the input, starting at point $x$, moves infinitesimally in the direction of vector $v$ within the domain. The output is a vector that represents the direction the corresponding output vector travels from point $f(x)$. 
\begin{center}
    \includegraphics[scale=0.2]{Abstract_Directional_Derivative.PNG}
\end{center}
$df (x)$ is also called the \textit{total derivative or differential} at $x$. 
\end{definition}

\subsubsection{Differential Operator as Iterated Mappings}
Rather than interpreting $d$ as a mapping that takes in three inputs all at once to return a vector in $\mathbb{R}^m$, we can interpret it as a mapping that takes in some arguments and outputs another function that takes in the remaining arguments. We list some common interpretations, but note that usually, the function argument is given or is inputted first: 
\begin{enumerate}
    \item $d$ takes in two inputs $f \in C^1 (\mathbb{R}^n; \mathbb{R}^m)$ and $v \in T_x \mathbb{R}^n$ and outputs the vector field $d_v f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$. This vector field then takes in a point $x \in \mathbb{R}^n$ and outputs the corresponding vector. 
    \begin{center}
        \includegraphics[scale=0.2]{fv_x_Interpretation.PNG}
    \end{center}
    \item $d$ takes in function $f \in C^1 (\mathbb{R}^n; \mathbb{R}^m)$ and outputs a function $d f$. $d f$ then takes in a point $x \in \mathbb{R}^n$ and outputs another function $(d f)(x)$. $(d f)(x)$ finally takes in a vector $v \in T_x \mathbb{R}^n$ (note that this does not have to be a fiber bundle, since $x$ has been determined) and outputs the derivative vector in $\mathbb{R}^m$. 
    \begin{center}
        \includegraphics[scale=0.2]{f_x_v_Interpretation.PNG}
    \end{center}
    \item $d$ takes in function $f \in C^1 (\mathbb{R}^n; \mathbb{R}^m)$ and outputs a function $d f$. $d f$ then takes in a vector $v \in T_x \mathbb{R}^n$ and outputs another function $d_v f$. $d_v f$ finally takes in a point $x \in \mathbb{R}^n$ and outputs the derivative vector in $\mathbb{R}^m$. 
    \begin{center}
        \includegraphics[scale=0.2]{f_v_x_Interpretation.PNG}
    \end{center}
    \item This one is quite different from the previous ones, albeit very powerful. We can define the differential operator on $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ as a function that takes in a vector field $V$ of $\mathbb{R}^n$ and outputs $df(V)$. $df(V): \mathbb{R}^n \longrightarrow \mathbb{R}^m$ is another function that takes in point $x \in \mathbb{R}^n$ and outputs a derivative vector according to the rule: 
    \[df(V) (x) \equiv (d_{V(x)} f)(x)\]
    This can be visualized as such: 
    \begin{center}
        \includegraphics[scale=0.2]{Diff_Operator_with_Vector_Field.PNG}
    \end{center}
    We can use this interpretation to define partial derivatives as 
    \[\frac{\partial f}{\partial v_i} (x) \equiv (d_{e_i} f)(x) \equiv df (V_{e_i}) (x)\]
    where $V_{e_i}$ is the constant vector field that outputs $e_i$. 
    \item $d$ takes in function $f \in C^1 (\mathbb{R}^n ; \mathbb{R}^m)$ and point $x$ and outputs a function $d f(x): T_x \mathbb{R}^n \longrightarrow \mathbb{R}^m$. This interpretation will be used later when we view $d f(x)$ as an element of the cotangent space at $x$.  
\end{enumerate}

\subsubsection{Cotangent Vectors, Spaces, and Bundles}

We will now focus on real valued functions $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, since it is easier to define certain concepts this way without having to worry about abstract generalizations. Also, every function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ can be decomposed into its component functions $f_i: \mathbb{R}^n \longrightarrow \mathbb{R}$ for $i = 1, 2, \ldots, n$ such that
\[f = \begin{pmatrix}
f_1 \\ f_2 \\ \vdots \\ f_m
\end{pmatrix}\]
so we do not lose any data with this simplified interpretation. We will also denote $C^1 (\mathbb{R}^n; \mathbb{R})$ as just $C^1 (\mathbb{R}^n)$. 

\begin{definition}[Cotangent Vectors, Spaces in at a Point in $\mathbb{R}^n$]
The \textit{cotangent space} of $\mathbb{R}^n$ at point $x$ is the dual of the tangent space $T_x \mathbb{R}^n$. It is denoted
\[T_x^* \mathbb{R}^n \equiv (T_x \mathbb{R}^n)^*\]
Its elements are \textit{cotangent vectors}, which are functionals from $T_x \mathbb{R}^n$ to $\mathbb{R}$. Therefore, for every point $a \in \mathbb{R}^n$, there exists a tangent space $T_a \mathbb{R}^n$ and a cotangent space $T_a^* \mathbb{R}^n$. 
\begin{center}
    \includegraphics[scale=0.2]{Tangent_Cotangent_Space_at_Point.PNG}
\end{center}
\end{definition}

\begin{definition}[Derivative at a Point as a Cotangent Vector]
Let us view the total derivative $d$ with interpretation 5. The total derivative of $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ at point $a$ is a linear functional 
\[df (a): T_a \mathbb{R}^n \longrightarrow \mathbb{R}\]
which, by definition, implies that it is a cotangent vector in $T_a^* \mathbb{R}^n$! 
\begin{center}
    \includegraphics[scale=0.25]{Cotangent_Vector_as_Linear_Operator.PNG}
\end{center}
\end{definition}

To generalize this to a field $df$, we must introduce the cotangent bundle. 

\begin{definition}[Cotangent Bundles in $\mathbb{R}^n$]
The fiber bundle of cotangent spaces is called the \textit{cotangent bundle}. 
\[T^* \mathbb{R}^n \equiv \bigsqcup_{a \in \mathbb{R}^n} T_a^* \mathbb{R}^n\]
\end{definition}

\begin{definition}[Covector Field of Total Derivatives on $\mathbb{R}^n$]
The total derivative of $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ can be interpreted as a covector field 
\[df: \mathbb{R}^n \longrightarrow T^* \mathbb{R}^n = \bigsqcup_{a \in \mathbb{R}^n} T_a^* \mathbb{R}^n\]
\end{definition}

To summarize, we have the following analogous ideas: 
\begin{align*}
    \text{Tangent Vectors at a Point}& \iff \text{Cotangent Vectors/Total Derivatives at a Point} \\
    \text{Tangent Spaces at a Point}& \iff \text{Cotangent Spaces at a Point} \\
    \text{Vector Fields} & \iff \text{Covector Fields/Total Derivatives}
\end{align*}

\subsection{Derivatives with Bases}
This abstraction, although useful, doesn't help us actually calculate these derivatives, so let's step away from it for a moment. Fortunately, we are working in $T_a \mathbb{R}^n \simeq \mathbb{R}^n$ which is already endowed with the structure of the standard orthonormal basis $\{e_i\}_{i=1}^n$. Since every vector $v \in T_a \mathbb{R}^n$ can be represented as a linear combination of the basis vectors, 
\[v = v_1 e_1 + v_2 e_2 + \ldots + v_n e_n\]
by linearity we can find $d_v$ for all $v$ if we can find 
\[d_{e_1}, \; d_{e_2}, \; \ldots, d_{e_n}\]

\begin{definition}[Partial Derivatives]
The differential operator $d_v$ that has eaten the basis vector argument $e_i$ of $\mathbb{R}^n$ is called the \textit{partial derivative}, denoted $d_{e_i}$. 
\[d_{e_i} \equiv \frac{d}{d v_i}\]
Note that when referring to partial derivatives, the basis vector $e_i$ is written in $d_{e_i}$ while the coefficient $v_i$ is written in $d / d v_i$. They are both referring to the same thing, since the former refers to the point following along the vector $e_i$ at a rate of $1$ while the latter refers to the coefficient of $e_i$ increasing at a rate of $1$. If $d_{e_i}$ eats function $f$, $d_{e_i} f$ is called the \textit{partial derivative of $f$}. 
\[d_{e_i} f \equiv \frac{\partial f}{\partial v_i}\]
which can be solved using our familiar differentiation techniques from single variable calculus. If $d_v$ eats both $f$ and point $x$, $(d_v f)(x)$ is called the \textit{partial derivative of $f$ at $x$}. 
\[(d_{e_i} f)(x) \equiv \frac{d}{dt} f(x + e_i t) \bigg|_{t=0} \equiv \frac{\partial f}{\partial v_i} (x)\]
\end{definition}

\subsubsection{Matrix Interpretation of Differentiation}
We will derive the Jacobian in full generality for when $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$. 

\begin{definition}[Jacobian Matrix]
Given that $v = v_1 e_1 + \ldots + v_n e_n$,
\begin{align*}
    d_v & = v_1 d_{e_1} + v_2 d_{e_2} + \ldots + v_n d_{e_n} \\
    & = v_1 \frac{\partial}{\partial v_1} + v_2 \frac{\partial}{\partial v_2} + \ldots + v_n \frac{\partial}{\partial v_n} 
\end{align*}
We can rewrite this equation in matrix form. 
\[d_v = \begin{pmatrix}| & \ldots & | \\
d_{e_1} & \ldots & d_{e_n} \\
| & \ldots & | \end{pmatrix} \begin{pmatrix}
v_1 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix}| & \ldots & | \\
\frac{\partial}{\partial v_1} & \ldots & \frac{\partial}{\partial v_n} \\
| & \ldots & | \end{pmatrix} \begin{pmatrix}
v_1 \\ \vdots \\ v_n \end{pmatrix}\]
where $v_1, \ldots, v_n$ are the scalar coefficients of $v$ and the matrix encodes all of the partial derivative operators within itself. If we plug in an arbitrary function $f$ to $d_v$, we would get
\[d_v f = \begin{pmatrix}| & \ldots & | \\
d_{e_1} f& \ldots & d_{e_n} f\\
| & \ldots & | \end{pmatrix} \begin{pmatrix}
v_1 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix}| & \ldots & | \\
\frac{\partial f}{\partial v_1} & \ldots & \frac{\partial f}{\partial v_n} \\
| & \ldots & | \end{pmatrix} \begin{pmatrix}
v_1 \\ \vdots \\ v_n \end{pmatrix}\]
In order to decompose this even further to a matrix form, we can also decompose the function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ into its component functions $f_i: \mathbb{R}^n \longrightarrow \mathbb{R}$ for $i = 1, 2, \ldots, m$. So we would have 
\[f = \begin{pmatrix}
f_1 \\f_2 \\ \vdots \\ f_m
\end{pmatrix} \implies d_{e_i} f = \begin{pmatrix}
d_{e_i} f_1 \\ d_{e_i} f_2 \\ \vdots \\ d_{e_i} f_m
\end{pmatrix}\]
and therefore, we can rewrite the above equation of $d_v f$ into 
\[ d_v f = 
\begin{pmatrix}
\frac{\partial f_1}{\partial v_1} & \frac{\partial f_1}{\partial v_2} & \frac{\partial f_1}{\partial v_3} & \ldots & \frac{\partial f_1}{\partial v_n} \\
\frac{\partial f_2}{\partial v_1} & \frac{\partial f_2}{\partial v_2} & \frac{\partial f_2}{\partial v_3} & \ldots & \frac{\partial f_2}{\partial v_n} \\
\frac{\partial f_3}{\partial v_1} & \frac{\partial f_3}{\partial v_2} & \frac{\partial f_3}{\partial v_3} & \ldots & \frac{\partial f_3}{\partial v_n} \\
\vdots & \vdots & \vdots & \ddots & \vdots\\
\frac{\partial f_m}{\partial v_1} & \frac{\partial f_m}{\partial v_2} & \frac{\partial f_m}{\partial v_3} & \ldots & \frac{\partial f_m}{\partial v_n} \\
\end{pmatrix} \begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_{n-1} \\ v_{n}
\end{pmatrix}\]
where the matrix is called the \textit{Jacobian matrix}. Notice how this matrix equation is consistent with the abstract mapping with three inputs.
\begin{enumerate}
    \item the function $f$ is needed to evaluate all the derivatives as elements of the matrix
    \item the point $x$ is needed to evaluate all $n \times m$ expressions $\partial f_i / \partial v_j$. That is, 
    \[d_v f (x) = \begin{pmatrix}
    \frac{\partial f_1}{\partial v_1} & \ldots & \frac{\partial f_1}{\partial v_n} \\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_m}{\partial v_1} & \ldots & \frac{\partial f_m}{\partial v_n} 
    \end{pmatrix} (x) = \begin{pmatrix}
    \frac{\partial f_1}{\partial v_1} (x)& \ldots & \frac{\partial f_1}{\partial v_n} (x) \\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_m}{\partial v_1} (x) & \ldots & \frac{\partial f_m}{\partial v_n} (x) 
    \end{pmatrix}\]
    \item the directional vector $v$ is needed to evaluate the vector $(v_1\;\ldots\;v_n)^T$. 
\end{enumerate}
This matrix allows us to calculate all directional derivatives at every point in all differentiable functions $f$. The entries of $d_v f$ are the "building blocks" that generate directional derivatives at the point $x$.  
\end{definition}

\begin{theorem}[Chain Rule]
Let $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ and $g: \mathbb{R}^p \longrightarrow \mathbb{R}^n$ be two functions such that $f \circ g: \mathbb{R}^p \longrightarrow \mathbb{R}^m$ is defined. Suppose $g$ is differentiable at $x_0 \in \mathbb{R}^p$ and $f$ is differentiable at $y_0 = g(x_0) \in \mathbb{R}^n$. Then $f \circ g$ is differentiable at $x_0$ and 
\[D (f \circ g) (x_0) = D f (y_0) \cdot D g(x_0)\]
where the right hand side is the matrix product of real $m \times n$ matrix $D f(y_0)$ and $n \times p$ matrix $D g (x_0)$. 
\end{theorem}

Therefore, given the composition of function $f \circ g$, we have two methods of finding the derivative matrix of $f \circ g$ at point $x_0$. First is to explicitly compute $f \circ g$ and find its $m \times p$ derivative matrix $D (f \circ g)$, and plug in $x_0$ to get $D(f\circ g)(x_0)$.

The second way is to use the chain rule to find the individual derivative matrices $D f\big( g(x_0)\big) = D f(y_0)$ and $D g(x_0)$ and multiply them together to get the derivative matrix $D (f \circ g) (x_0)$. 

\begin{theorem}[Product, Quotient Rules]
Given that $f, g: \mathbb{R}^n \longrightarrow \mathbb{R}$ are differentiable at $x_0$. Then given that $h(x) \equiv f(x) g(x)$ for all $x$, 
\[D h(x_0) = g(x_0) D f(x_0) + f(x_0) D g(x_0)\]
Additionally, given that $g$ never vanishes and letting $k(x) \equiv f(x) / g(x)$ for all $x$, 
\[D k(x_0) = \frac{ g(x_0) D f(x_0) - f(x_0) D g(x_0)}{\big( g(x_0)\big)^2}\]
\end{theorem}

\subsection{Del Operators, Gradients}
We have successfully defined the total derivative of function $f$, denoted $df$, as a covector field 
\[df: \mathbb{R}^n \longrightarrow T^* \mathbb{R}^n\]
on $\mathbb{R}^n$, where $df (a) \in T_a \mathbb{R}^n$. We now define the gradient, which is the vector field mapping $\mathbb{R}^n \longrightarrow T \mathbb{R}^n$ on $\mathbb{R}^n$. 

\begin{definition}[Del Operator]
The \textit{del} operator takes in a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ and outputs a vector field. In Cartesian coordinates, it is defined 
\[\nabla \equiv \begin{pmatrix}
\frac{\partial}{\partial x_1} \\ \frac{\partial}{\partial x_2}  \\ \vdots \\ \frac{\partial}{\partial x_n} 
\end{pmatrix}, \;\; \nabla f \equiv \begin{pmatrix}
\frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2}  \\ \vdots \\ \frac{\partial f}{\partial x_n} 
\end{pmatrix}\]
\begin{center}
    \includegraphics[scale=0.3]{del_operator_visual.PNG}
\end{center}
\end{definition}

\begin{definition}[Gradient]
The gradient of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, denoted $\nabla f$ or grad$\,f$, is just the del operator done on $f$. It is a vector field on $\mathbb{R}^n$ 
\[\nabla f: \mathbb{R}^n \longrightarrow T \mathbb{R}^n = \bigsqcup_{a \in \mathbb{R}^n} T_a \mathbb{R}^n \]
satisfying one property. The gradient is the unique vector field whose dot product with any vector $v$ at each point $a$ is the directional derivative of $f$ at $p$ along $v$. That is, $\nabla f$ is the vector field satisfying 
\[\nabla f (a) \cdot v = df_v (a) \text{   for all } a \in \mathbb{R}^n\]
where $\cdot$ is the dot product of $T_a \mathbb{R}^n$.  
\end{definition}

Note that $\nabla f$ is a vector field, while $d f$ is a covector field! However, for visual purposes, we can think of the value of the gradient as a vector in the original space $\mathbb{R}^n$, while the value of the derivative at a point can be thought of as a covector on the original space. 
\begin{align*}
    \nabla f: & \mathbb{R}^n \longrightarrow T \mathbb{R}^n = \bigsqcup_{a \in \mathbb{R}^n} T_a \mathbb{R}^n, \;\; \nabla f(a) \in T_a \mathbb{R}^n \\
    df: & \mathbb{R}^n \longrightarrow T^* \mathbb{R}^n = \bigsqcup_{a \in \mathbb{R}^n} T_a^* \mathbb{R}^n, \;\; df(a) \in T_a^* \mathbb{R}^n 
\end{align*}
The following diagram summarizes the relationship between $d$ and $\nabla$ quite nicely. 
\begin{center}
    \includegraphics[scale=0.28]{d_and_nabla_summary.PNG}
\end{center}

\begin{theorem}[Gradient as Direction of Fastest Increase]
Let $f$ be a real-valued function such that $\nabla f(x) \neq 0$. Then, at the point $x$, $\nabla f(x)$ points in the direction along which $f$ is increasing the fastest. Equivalently, $-\nabla f(x)$ points in the direction along which $f$ is decreasing the fastest. 
\end{theorem}
\begin{proof}
Note that this is a coordinate-independent proof. Let us have a tangent vector $v \in T_x \mathbb{R}^n$; since we are only interested in direction, we can normalize $v$ such that $||v|| = 1$. Evaluating it with the total derivative at $x$ gives us $(d_v f) (x)$. But by definition, 
\[(d_v f) (x) = \nabla f(x) \cdot v\]
which means that 
\begin{align*}
    \sup_{||v|| = 1} \{(d_v f)(x)\} & = \sup_{||v||=1} \{\nabla f(x) \cdot v\} \\
    & = \sup_{||v||=1} \{ ||\nabla f(x)|| ||v|| \cos(\theta)\} \\
    & = \sup \{||\nabla f(x)|| \cos(\theta)\} \\
    & = ||\nabla f(x)|| \text{ when } \theta = 0
\end{align*}
Therefore, $v$ must point in the direction of $\nabla f(x)$. 
\end{proof}

Therefore, we can interpret the gradient evaluated at a point as the tangent vector that points in the direction of fastest increase. We can also interpret the gradient $\nabla f$ itself as the vector field that determines some sort of "flow" in the domain $\mathbb{R}^n$. Therefore, if we drop a point in this field, the point will flow through $\mathbb{R}^n$ through a current determined by $\nabla f$ and will eventually end up at a local maximum. 

\subsubsection{Realization in Terms of Bases}
Since we are working in $\mathbb{R}^n$, we can use the isomorphism $T_a \mathbb{R}^n \simeq \mathbb{R}^n \simeq T_a^* \mathbb{R}^n$ to induce a basis in every tangent space and cotangent space. This allows us to write all vectors as $n$-tuples representing the coefficients of the basis vectors within a linear combination. Our familiar notion of representing vectors as  column ($n$-tuple) vectors and covectors as row vectors will be used. 

\begin{definition}[Realization of the Differential and Del Operator]
The differential operator $d$ that eats function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ and outputs covector field $df$ can be realized as a row vector. The del operator $\nabla$ that eats $f$ and outputs the (gradient) vector field $\nabla f$ is realized as a column vector. 
\[d = \begin{pmatrix}
\frac{\partial}{\partial x_1} & \frac{\partial}{\partial x_2} & \ldots & \frac{\partial}{\partial x_n}
\end{pmatrix}, \;\;\; \nabla = \begin{pmatrix}
\frac{\partial}{\partial x_1} \\ \frac{\partial}{\partial x_2} \\ \vdots \\
\frac{\partial}{\partial x_n} 
\end{pmatrix}\]
\end{definition}

\begin{definition}[Realization of Total Derivative and Gradients]
The realizations of the covector field $d f: \mathbb{R}^n \longrightarrow T^* \mathbb{R}^n$ and the vector field $\nabla f: \mathbb{R}^n \longrightarrow T \mathbb{R}^n$ is 
\[df = \begin{pmatrix}
\frac{\partial f}{\partial x_1} & \frac{\partial f}{\partial x_2} & \ldots & \frac{\partial f}{\partial x_n}
\end{pmatrix}, \;\;\; \nabla f = \begin{pmatrix}
\frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\
\frac{\partial f}{\partial x_n} 
\end{pmatrix}\]
If we feed these mappings the point $a \in \mathbb{R}^n$, this is same as evaluating the vectors as such: 
\[df (a) = \begin{pmatrix}
\frac{\partial f}{\partial x_1} & \ldots & \frac{\partial f}{\partial x_n}
\end{pmatrix} (a) = \begin{pmatrix}
\frac{\partial f}{\partial x_1} (a) & \ldots & \frac{\partial f}{\partial x_n} (a)
\end{pmatrix}, \; \nabla f (a)= \begin{pmatrix}
\frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\
\frac{\partial f}{\partial x_n} 
\end{pmatrix} (a) = \begin{pmatrix}
\frac{\partial f}{\partial x_1} (a)\\ \frac{\partial f}{\partial x_2} (a)\\ \vdots \\
\frac{\partial f}{\partial x_n} (a)
\end{pmatrix}\]
and these resulting vectors $df(a)$ and $\nabla f (a)$ are in their respective cotangent and tangent spaces (not the original domain space $\mathbb{R}^n$!). 
\end{definition}

\subsection{Graphs, Level Surfaces, and Tangent Planes}

\begin{definition}
Let the graph $G$ of $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ be a subset of $\mathbb{R}^n \oplus \mathbb{R}$. Then the \textit{extended level surface of $f$} is the set of points
\[\Tilde{S}_k = \{ (x, k) \in \mathbb{R}^n \oplus \mathbb{R} \; | \; f(x) = k\}\]
We can interpret it as the cross section of the graph $G$ that forms when we intersect $G$ with the affine hyperplane $(0, k) \in \mathbb{R}^n \oplus \mathbb{R}$. The \textit{level surface} of $f$ are the points
\[S_k = \{ x \in \mathbb{R}^n \; | \; f(x) = k\}\]
that exist in $\mathbb{R}^n$, the domain of $f$. Note that there exists a canonical injection between the level surface $S_k$ and extended level surface $\Tilde{S}_k$. That is,
\[\rho: \mathbb{R}^n \longrightarrow \mathbb{R}^n \oplus \mathbb{R}, \; \rho(x) \equiv (x, k) \]
\end{definition}

To define further theorems, we must now introduce the concept of orthogonality between vectors and surfaces, along with tangent planes. 

\begin{definition}
Let there be a surface $S \subset \mathbb{R}^n$ and a vector $v \in \mathbb{R}^n$ protruding from a point $x_0 \in S$. $v$ is \textit{orthogonal}, or \textit{normal}, to $S$ at $x_0$ if for every path function 
\[p: \mathbb{R} \longrightarrow S \subset \mathbb{R}^n\]
such that $x_0 = p(t_0)$, the tangent vector of $p$ at $x_0$ is orthogonal to $v$. That is, 
\[v \cdot p^\prime (t_0) = 0 \text{ for all } p\]
\end{definition}

\begin{definition}
Let there be a surface $S \subset \mathbb{R}^n$ with a normal vector $v(x_0) \neq 0$ at $x_0$. Then, the \textit{tangent plane} of $S$ at $x_0$ is the set of points 
\[\{x \in \mathbb{R}^n \; | \; v(x_0) \cdot (x - x_0) = 0\}\]
\end{definition}
 
\begin{theorem}
Given a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ with a point $x_0 \in S_k \subset \mathbb{R}^n$. Then, the gradient vector at $x_0$ is normal to the surface of $S_k$ at $x_0$. 
\end{theorem}
\begin{corollary}
The tangent plane of level set $S_k$ at $x_0$ is defined
\[\{ x \in \mathbb{R}^n \;|\;\triangledown f(x_0) \cdot (x - x_0) = 0\}\]
\end{corollary}

\subsection{Iterated Partial Derivatives}
\begin{definition}[Iterated Derivatives]
Let us refer to interpretation 1 when thinking about the differential operator. Given a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ and tangent vector $v \in T \mathbb{R}^n$, we have the scalar (since codomain is $\mathbb{R}$) field
\[d_v f: \mathbb{R}^n \longrightarrow \mathbb{R}\]
that outputs the derivative of $f$ in direction $v$ at an arbitrary input point in $\mathbb{R}^n$. But notice that this scalar field is really just another function $g: \mathbb{R}^n \longrightarrow \mathbb{R}$. So interpreting $d_v f$ as a function $g$ (and assuming smoothness), we can choose another vector $w \in T \mathbb{R}^n$ to find its derivative. 
\[d_w (d_v f): \mathbb{R}^n \longrightarrow \mathbb{R}\]
This is called the \textit{2nd derivative of $f$ in direction $v$ and $w$}. Visually, 
\begin{center}
    \includegraphics[scale=0.25]{Iterated_Derivative_Function_Abstract.jpg}
\end{center}
By assuming smoothness when needed, we can extend this to get
\[d_{v_1} \big( d_{v_2} ( d_{v_3} ( \ldots (d_{v_k} f) \ldots ) \big)\]
called the \textit{kth (iterated) derivative}. 
\end{definition}

\subsubsection{Tensor Fields, Tensor Bundles}

\begin{definition}[Iterated Derivatives at a Point as Tensors]
In the 2nd derivative operator $d_w(d_v f)(x)$ shown previously, let us fix the point $x$ and function $f$ and interpret the rest as arguments. We are left with an operator that must take in 2 tangent vectors $v$ and $w$. That is, 
\[d_\cdot (d_\cdot f) (x): T_x \mathbb{R}^n \times T_x \mathbb{R}^n \longrightarrow \mathbb{R}\]
But since $d d f(x) = (d^2 f)(x)$ is bilinear, this means that
\[(d^2 f) (x) \in T_x^* \mathbb{R}^n \otimes T_x^* \mathbb{R}^n = (T_x^* \mathbb{R}^n)^{\otimes 2}\]
Similarly, the $k$th iterated total derivative of $f$ at point $x \in \mathbb{R}^n$ is  
\[(d^k f)(x) \in (T_x^* \mathbb{R}^n)^{\otimes k}, \;\; (d^k f)(x): \prod_k T_x \mathbb{R}^n \longrightarrow \mathbb{R}\]
\end{definition}

\begin{definition}[Iterated Total Derivatives as Tensor Fields]
We can unfix the point $x$ and view $d^k f$ as a mapping receiving point $x$ and vectors $v_1, \ldots, v_k$ as arguments. Then, $d^k f$ becomes a \textit{tensor field of rank $k$}. 
\[d^k f: \mathbb{R}^n \longrightarrow \bigsqcup_{x \in \mathbb{R}^n} (T^*_x \mathbb{R}^n)^{\otimes k}\]
We can just interpret $d^k f$ as a field that assigns to every point $x \in \mathbb{R}^n$ a $k$-tensor. Upon selecting a point $a$, you are given a $k$-tensor living in $(T_a^* \mathbb{R}^n)^{\otimes k}$. Then, you choose the $k$ vectors $v_1, \ldots, v_k$ that define the direction in which you want to take the iterated $k$th derivative, input them into the tensor $d^k f(a)$ and it will output a real number representing the $k$th iterated derivative you are looking for. 

This is a generalization of $df$ being a covector field that assigns to every point $x$ a cotangent vector. After choosing a point $a$, $df$ outputs the cotangent vector $df(a)$ which in turn eats a tangent vector $v$ that you choose and outputs the regular directional derivative of $f$ in direction $v$ at $a$. 
\end{definition}

Recall that the tensor algebra of vector space $T_x \mathbb{R}^n$ is the direct sum of all the tensor product spaces of $T_x \mathbb{R}^n$. That is, 
\[\mathcal{T} (T_x^* \mathbb{R}^n) \equiv \bigoplus_{i=0}^\infty (T_x^* \mathbb{R}^n)^{\otimes i}\]
Therefore, for consistency we can envelop every rank-k tensor space in the tensor algebra
\[d^k f: \mathbb{R}^n \longrightarrow \bigsqcup_{x\in \mathbb{R}^n} \mathcal{T} (T_x^* \mathbb{R}^n) = T \mathcal{T}(T_x^* \mathbb{R}^n)\]


\subsubsection{Iterated Derivatives with Bases}

\begin{definition}[Iterated Partial Derivatives]
An iterated derivative in which all the tangent vectors are basis vectors $e_i$ of $T \mathbb{R}^n$ are called \textit{partial iterated derivatives}. The $k$th partial derivative of $f$ has form 
\[d_{e_{i_1}} \big(\ldots (d_{e_{i_k}} f)\big) = \frac{\partial^k f}{\partial e_{i_1} \ldots \partial e_{i_k}}\]
The \textit{2nd partial derivative} has form 
\[d_{e_i} (d_{e_j} f) \equiv \frac{\partial}{\partial e_i} \frac{\partial f}{\partial e_j} \equiv \frac{\partial^2 f}{\partial e_i \, \partial e_j}, \;\; i, j = 1, 2, \ldots, n\]
\end{definition}


\begin{definition}[Hessian Matrix as a 2-Tensor Field]
The matrix realization of the tensor field 
\[d^2 f: \mathbb{R}^n \longrightarrow \bigsqcup_{a \in \mathbb{R}^n} (T_a^* \mathbb{R}^n)^{\otimes 2}\]
is the $n \times n$ \textit{Hessian matrix} $H$, which is of the form 
\[(H)_{i j} \equiv \frac{\partial^2 f}{\partial x_i \partial x_j}\]
of partials. Note that even though this matrix looks like it takes in a row vector (left multiplication) and a column vector (right multiplication), it actually takes in \textit{two} row vectors, both in $T_a \mathbb{R}^n$. 
\end{definition}

\begin{theorem}
Given function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ with existing 2nd derivatives, for all pairs of $1 \leq i, j \leq n$, 
\[\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}\]
$\implies$ the Hessian matrix of $f$ is symmetric. 
\end{theorem}
\begin{proof}
By abuse of notation, we let us focus on two variables $x, y$ and ignore the rest. Then, the partial derivatives $f_{xy}$ and $f_{yx}$ at a point $(x_0, y_0)$ can be expressed as double limits: 
\[f_{xy} (x_0, y_0) = \lim_{y \rightarrow y_0} \frac{f_x (x_0, y) - f_x (x_0, y_0)}{y - y_0}\]
We can use the two limit definitions of partial derivatives
\[f_x (x_0, y) = \lim_{x \rightarrow x_0} \frac{f(x, y) - f(x_0, y)}{x-x_0}, \;\;\;\;\; f_x (x_0, y_0) = \lim_{x \rightarrow x_0} \frac{f(x, y_0) - f(x_0, y_0)}{x-x_0}\]
to get the two partials 
\begin{align*}
    f_{xy} (x_0, y_0) & = \lim_{y \rightarrow y_0} \frac{ \lim_{x \rightarrow x_0} \frac{f(x, y) - f(x_0, y)}{x-x_0} - \lim_{y \rightarrow y_0} \frac{f(x, y_0) - f(x_0, y_0)}{x-x_0}}{y - y_0} \\
    & =  \lim_{y \rightarrow y_0} \lim_{x \rightarrow x_0} \bigg( \frac{f(x, y) - f(x_0, y) - f(x, y_0) + f(x_0, y_0)}{(x - x_0) (y - y_0)} \bigg) \\
    f_{yx} (x_0, y_0) & = \lim_{x \rightarrow x_0} \frac{ \lim_{y \rightarrow y_0} \frac{f(x, y) - f(x, y_0)}{y-y_0} - \lim_{y \rightarrow y_0} \frac{f(x_0, y) - f(x_0, y_0)}{y-y_0}}{x - x_0} \\
    & = \lim_{x \rightarrow x_0} \lim_{y \rightarrow y_0} \bigg( \frac{f(x, y) - f(x, y_0) - f(x_0, y) + f(x_0, y_0)}{(y-y_0) (x-x_0)} \bigg)
\end{align*}
We can see that therefore $f_{xy} = f_{yx}$ for all $(x_0, y_0)$. 
\end{proof}

\begin{corollary}
Given function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, let 
\[(\alpha_1, \alpha_2, ..., \alpha_k)\]
be any $k$ distinct numbers from $\{1, 2, ..., n\}$, and let 
\[p(\alpha_1, \alpha_2, ..., \alpha_k) \equiv (p(\alpha_1), p(\alpha_2), ..., p(\alpha_n))\]
be any permutation of them. Then
\[\frac{\partial^k f}{\partial x_{\alpha_1}...\partial x_{\alpha_k}} = \frac{\partial^k f}{\partial x_{p(\alpha_1)}...\partial x_{p(\alpha_k)}}\]
for all $p$. 
\end{corollary}

\subsection{Linear, Quadratic, and Taylor Approximations}

\subsubsection{First Order Approximation}
We have defined the total derivative of a function $f$ at a point $x_0$, denoted $df (x_0)$ as the cotangent vector living in the cotangent space $T_{x_0}^* \mathbb{R}^n$. We assume that $f$ is a vector-valued function when we geometrically describe the construction of the total derivative as a linear approximation. 

Most functions $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ are nonlinear and may behave in all kinds of ways; we can control them by setting the condition that they must be smooth. Now, since these smooth functions are differentiable, we can construct a linear function that best "approximates" $f$. 

To do this, we first choose an origin point $x_0 \in \mathbb{R}^n$ and evaluate $f(x_0)$. Denote the approximation function as $P_{x_0}^1$. Given that we want to evaluate $f(x_0 + v)$ for some small vector $v \in T_{x_0} \mathbb{R}^n$, it turns out that as the point moves from $x_0 \rightarrow x_0 + v$, $f(x_0)$ doesn't move linearly towards $f(x_0 + v)$ (marked by the curved line). 
\begin{center}
    \includegraphics[scale=0.25]{Function_Moving_in_Curvy_way.PNG}
\end{center}
So what is the best way to approximate this? In order to choose the "best" linear approximation to these nonlinear motions, we look at two criterion
\begin{enumerate}
    \item the approximation $P_{x_0}^1 (x)$ must be equal to the actual function $f(x)$ at $x_0$.  
    \item It satisfies
    \[\lim_{x \rightarrow x_0} \frac{||f(x) - P_{x_0}^1 (x)||}{||x - x_0||} = 0\]
    This can be interpreted geometrically by viewing $P_{x_0}^1$ as a tangent affine subspace on the graph of $f$ at $x_0$, where the directional derivatives of $f$ and $P_{x_0}^1$ align at $x_0$ for all directional vectors $v \in T_{x_0} \mathbb{R}^n$. 
\end{enumerate}
Conveniently, we can use the total derivative $d f(x_0)$, which is a linear map, and use it to create the affine linear function  $f(x_0 + v) \approx f(x_0) + (d_v f)(x_0)$. 
\begin{center}
    \includegraphics[scale=0.25]{Affine_Linear_Function_Approximation.PNG}
\end{center}
It can be clearly seen that as the vector moves from $x_0 \rightarrow x_0 + v$, the output vector $f(x_0) + d_v f(x_0)$ moves in a straight line, which is consistent with our claim of it being an affine linear transformation. Note that by abuse of language, we call this a linear approximation, when it is in fact not linear and rather an \textit{affine} linear approximation. 

In order to make this approximation a function of $x = x_0 + v$, we change the above formula to
\[f(x) \approx P_{x_0}^1 (x) \equiv f(x_0) + (d_{(x - x_0)} f) (x_0)\]
which satisfies both conditions 1 and 2. 

\begin{definition}[First-Order Approximation of Vector-Valued $f$ at $x_0$ and its Matrix Realization]
The first order affine approximation of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ centered at $x_0$ is 
\[P_{x_0}^1 (x) \equiv f(x_0) + (d_{(x-x_0)} f) (x_0)\]
The matrix realization of this can be expressed with the Jacobian matrix $J f(x_0)$. 
\begin{align*}
    P_{x_0}^1 (x) & \equiv f(x_0) + J f(x_0) (x - x_0) \\
    & = \begin{pmatrix}
    f_1 (x_0) \\ \vdots \\ f_m (x_0) \end{pmatrix} + \begin{pmatrix}
    \frac{\partial f_1}{\partial x_1} (x_0) & \ldots & \frac{\partial f_1}{\partial x_n} (x_0) \\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_m}{\partial x_1} (x_0) & \ldots & \frac{\partial f_m}{\partial x_n} (x_0) 
    \end{pmatrix} \begin{pmatrix}
    x_1 - x_{01} \\ \vdots \\ x_n - x_{0n}
    \end{pmatrix}
\end{align*}
Note that when interpreting $f$ as a vector valued function, the linear term $(df) (x_0)$ is \textit{not} a tensor since it takes
$(df) (x_0): T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m$. 
\end{definition}

We can interpret it as a tensor when considering scalar-valued functions $f$. 

\begin{definition}[First-Order Approximation of Real-Valued $f$ at $x_0$ and its Matrix Realization]
The first order affine approximation of a real-valued function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ centered at $x_0$ is 
\[P_{x_0}^1 \equiv f(x_0) + (d_{(x - x_0)} f) (x_0)\]
Where $(df)(x_0)$ is a $1$-tensor taking in tangent vector $v = x - x_0 \in T_{x_0}\mathbb{R}^n$, and $f(x_0)$ is a $0$-tensor. The matrix realization of this can be expressed with the Jacobian (row vector) matrix $J f(x_0)$. 
\begin{align*}
    P_{x_0}^1 (x) & \equiv f(x_0) + Jf (x_0) (x - x_0) \\
    & = f\begin{pmatrix} x_{01} \\ \vdots \\ x_{0n}
    \end{pmatrix} + \begin{pmatrix}
    \frac{\partial f}{\partial x_1} (x_0) & \ldots & \frac{\partial f}{\partial x_n} (x_0) 
    \end{pmatrix} \begin{pmatrix}
    x_1 - x_{01} \\ \vdots \\ x_n - x_{0n}
    \end{pmatrix}
\end{align*}
Note that the Jacobian row matrix of $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ is the realization of the $1$-tensor. In summation form, the approximation expands to
\[P_{x_0}^1 (x) = f(x_0) + \sum_{i=1}^n \bigg(\frac{\partial f}{\partial x_i} (x_0)  \big(x_i - x_{0i}\big)\bigg)\]
\end{definition}

\subsubsection{Second Order Approximation}
We can improve the linear approximation $P_{x_0}^1$ to a quadratic approximation $P_{x_0}^2$ by utilizing higher order derivatives. Using similar logic, given that we know $f(x_0)$, for some small vector $v$ we can approximate $f(x_0 + v)$ as 
\[f(x_0 + v) \approx f(x_0) + (d_v f) (x_0) + \frac{1}{2!}(d^2_{v, v} f)(x_0)\]
Note that this is a quadratic approximation, and therefore has more "flexibility" than the linear function in approximating $f$. 
\begin{center}
    \includegraphics[scale=0.25]{Affine_Quadratic_Function_Approximation.PNG}
\end{center}
We can make this a function of $x = x_0 + v$ and define it as such. 

\begin{definition}[Second-Order Approximation of Vector-Valued $f$ at $x_0$]
The second order affine approximation of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ centered at $x_0$ is 
\[P_{x_0}^2 (x) \equiv f(x_0) + (d_{(x - x_0)} f) (x_0) + \frac{1}{2!}(d_{(x - x_0, x - x_0)} f) (x_0)\]
Unfortunately, we cannot write the matrix realization of this polynomial, since this would require higher dimensional analogies of matrices. Rather, we can just interpret $f(x_0)$ as a scalar, and the other terms as 
\begin{align*}
    (df)(x_0): & T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m \\
    (d^2 f)(x_0): & T_{x_0} \mathbb{R}^n \times T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m
\end{align*}
which take in tangent vectors $v = x - x_0 \in T_{x_0} \mathbb{R}^n$. 
\end{definition}

We can, however, write down the matrix realization of the second order approximation of a real-valued function $f$.

\begin{definition}[Second-Order Approximation of Real-Valued $f$ at $x_0$]
The second order affine approximation of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ centered at $x_0$ is 
\[P_{x_0}^2 \equiv f(x_0) + (d_{(x - x_0)} f) (x_0) + \frac{1}{2!} (d^2_{(x - x_0, x - x_0)} f) (x_0)\]
where $(d^2 f)(x_0)$ is a 2-tensor (taking in tangent vector $v = x-x_0$), $(d f)(x_0)$ is a 1-tensor, and $f(x_0)$ is a 0-tensor. The matrix realization of this can be expressed with the Jacobian (row vector) matrix $J f(x_0)$ and the $n \times n$ Hessian matrix $H f(x_0)$. 
\begin{align*}
    P_{x_0}^2 (x) & \equiv f(x_0) + Jf(x_0) (x - x_0) + \frac{1}{2!} (x - x_0)^T H f(x_0) (x - x_0) \\
    & = f \begin{pmatrix} x_{01} \\ \vdots \\ x_{0n} \end{pmatrix} + \begin{pmatrix}
    \frac{\partial f}{\partial x_1} (x_0) & \ldots & \frac{\partial f}{\partial x_n} (x_0) \end{pmatrix} \begin{pmatrix}
    x_1 - x_{01} \\ \vdots \\ x_n - x_{0n}
    \end{pmatrix} \\
    & \;\;\;\;\;\;\;\;\;\;\;\; +\frac{1}{2!} \begin{pmatrix}
    x_1 - x_{01} & \ldots & x_n - x_{0n}
    \end{pmatrix} \begin{pmatrix}
    \frac{\partial^2 f}{\partial x_1 \partial x_1} (x_0) & \ldots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
    \vdots & \ddots & \vdots \\
    \frac{\partial^2 f}{\partial x_n \partial x_1} (x_0) & \ldots & \frac{\partial^2 f}{\partial x_n \partial x_n}
    \end{pmatrix} \begin{pmatrix}
    x_1 - x_{01} \\ \vdots \\ x_n - x_{0n}
    \end{pmatrix} 
\end{align*}
In summation form, the multivariate Taylor quadratic expands to
\[P_{x_0}^2 (x) = f(x_0) + \sum_{i=1}^n \bigg(\frac{\partial f}{\partial x_i} (x_0)  \big(x_i - x_{0i}\big)\bigg) + \frac{1}{2!} \sum_{i, j = 1}^n \bigg( \frac{\partial^2 f}{\partial x_i \partial x_j} (x_0) \big(x_i - x_{0i}\big) \big(x_j - x_{0j}\big)\bigg)\]
\end{definition}

Note that the quadratic term is just a $2$-tensor. This is significant because we can notice that every higher order $n$th term (cubic, quartic, etc.) is just a multilinear map that accepts one argument $v$, $n$ times. For example, a quadratic is a $2$-tensor accepting 2 copies of $v \in T_{x_0} \mathbb{R}^n$. 
\begin{center}
    \includegraphics[scale=0.3]{Tensor_As_a_Quadratic.PNG}
\end{center}
Therefore, increasing the vector $v$ by a factor of $2$ would, by linearity of the first argument of $(d^2 f)(x_0)$ increase the output by $2$ and by linearity of the second argument also increase the output by $2$, resulting in a total increase by $4$ times. 

Generalizing this to $(d^k f)(x_0)$, increasing the input vector $v$ by a factor of $\alpha$ would increase the output $(d^k_{(v, \ldots, v)} f)(x_0)$ of the $k$-tensor by $\alpha^k$. 
\begin{center}
    \includegraphics[scale=0.2]{Tensor_as_a_Higher_Order_Term.PNG}
\end{center}

\subsubsection{Higher Order Approximations}
We can extend this approximation to higher order multivariate polynomials. The $k$th order approximation of function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ centered at $x_0$ is 
\[f(x_0 + v) \approx f(x_0) + (d_v f) (x_0) + \frac{1}{2!} (d^2_{v, v} f) (x_0) + \frac{1}{3!}(d^3_{v, v, v} f)(x_0) + \ldots + \frac{1}{k!} (d^k_{v, \ldots , v} f)(x_0)\]
where all the $(d^i f)(x_0)$'s are multilinear mappings (but not tensors, since codomain is not $\mathbb{R}$)
\[(d^i f)(x_0): \prod_i T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m\]
with respect to $v$. Treating this as a function of $x = x_0 + v$, we get the following definition. 

\begin{definition}[Higher-Order Approximation of Vector-Valued $f$ at $x_0$]
The $k$th order affine approximation of function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ centered at $x_0$ is
\[P_{x_0}^k (x) \equiv f(x_0) + (d_{(x - x_0)} f)(x_0) + \frac{1}{2!} (d^2_{(x-x_0, x-x_0)} f)(x_0) + \ldots \frac{1}{k!} (d^k_{(x - x_0, \ldots, x-x_0)} f)(x_0)\]
Again, this expression encompasses high-dimensional terms that cannot be written in matrices, so it is best to interpret each $(d^i f)(x_0)$'s as multilinear mappings
\begin{align*}
    (df)(x_0): & T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m \\
    (d^2f)(x_0): & T_{x_0} \mathbb{R}^n \times T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m \\
    \ldots & \ldots \\
    (d^kf)(x_0): & \prod_k T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m 
\end{align*}
which take in tangent vectors $v = x - x_0 \in T_{x_0} \mathbb{R}^n$.
\end{definition}

We distinguish a separate definition for real valued functions $f$.

\begin{definition}[Higher-Order Approximation of Real-Valued $f$ at $x_0$]
The $k$th order affine approximation of function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ centered at $x_0$ is
\[P_{x_0}^k (x) \equiv f(x_0) + (d_{(x - x_0)} f)(x_0) + \frac{1}{2!} (d^2_{(x-x_0, x-x_0)} f)(x_0) + \ldots \frac{1}{k!} (d^k_{(x - x_0, \ldots, x-x_0)} f)(x_0)\]
where $(d^i f)(x_0)$ is a tensor of rank $i$, and the scalar $f(x_0)$ is a $0$-tensor. 
\begin{align*}
    &(df)(x_0) \in T_{x_0}^* \mathbb{R}^n, & &(df)(x_0): T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m \\
    &(df)(x_0) \in (T_{x_0}^* \mathbb{R}^n)^{\otimes 2}, &&(d^2f)(x_0): T_{x_0} \mathbb{R}^n \times T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m \\
    &\ldots & &\ldots \\
    &(d^k f)(x_0) \in (T_{x_0}^* \mathbb{R}^n)^{\otimes k}, && (d^kf)(x_0): \prod_k T_{x_0} \mathbb{R}^n \longrightarrow \mathbb{R}^m 
\end{align*}
Since tensors of rank greater than $2$ cannot be represented in matrix notation, we must embrace this abstract Taylor polynomial. 
\end{definition}

\begin{example}
The summation representation of the third order approximation of function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ centered at $x_0$ is: 
\begin{align*}
    f(x) & \approx f(x_0) + \sum_{i=1}^n \bigg(\frac{\partial f}{\partial x_i} (x_0) \big(v_i\big) \bigg) + \frac{1}{2!} \sum_{i, j = 1}^n \bigg( \frac{\partial^2 f}{\partial x_i \partial x_j} (x_0) \big(v_i\big) \big(v_j\big)\bigg) \\
    & + \frac{1}{3!} \sum_{i, j, k = 1}^n \bigg( \frac{\partial^3 f}{\partial x_i \partial x_j \partial x_k} (x_0) \big(v_i\big) \big(v_j\big) \big(v_k\big) \bigg)
\end{align*}
where $v = x - x_0$, or in components, $v_i = x_i - x_{0i}$ for $i = 1, 2, \ldots n$. 
\end{example}

\subsection{Local/Global Extrema, Lagrange Multipliers}
Note that while the approximation isn't exact, the $n$th-degree approximation of $f$ "mimics" $f$ in the way that the iterated total derivatives, up to the $n$th order, are the same as the iterated partial derivatives of $f$ at the point $x_0$. This allows us to analyze the behavior of the function $f$ up to the $n$th order at $x_0$ by looking only at the components of its $n$th degree Taylor expansion. 

\subsubsection{Local Extrema}
An application of this is to find the local extrema of $f$ using the second total derivative. In order for the extrema to be properly defined, the codomain of $f$ must be ordered, so we will focus on scalar functions $f: \mathbb{R}^n \longrightarrow \mathbb{R}$. 

\begin{definition}[Local Extrema]
Given a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, a point $x_0 \in \mathbb{R}^n$ is a \textit{local minimum} if there exists a neighborhood $U$ of $x_0$ such that 
\[f(x) \geq f(x_0) \text{ for every } x \in U\]
Similarly, $x_0$ is a \textit{local maximum} if there exists a neighborhood $U$ of $x_0$ such that 
\[f(x) \leq f(x_0) \text{ for every } x \in U\]
\end{definition}

\begin{theorem}[1st Derivative Test]
If $x_0$ is a local extremum of a smooth function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, then $d f(x_0) = 0$, the zero covector in the cotangent space $T_{x_0}^* \mathbb{R}^n$. That is, for every tangent vector $v \in T_{x_0} \mathbb{R}^n$, every directional derivative of $f$ through $x_0$ in direction $v$ is $0$. That is, 
\[x_0 \text{ local extremum} \implies \text{total derivative is 0}\]
However, the converse of this theorem is not true. 
\end{theorem}

In order to determine whether a critical point $x_0$ is a relative maximum, minimum, or neither, we use the second derivative test. 

\begin{theorem}[2nd Derivative Test]
Let $x_0$ be a critical point of smooth function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$. That is, $d f(x_0) = 0$. Then, 
\begin{enumerate}
    \item $x_0$ is a local minimum if $d^2 f(x_0)$ is a positive definite linear map (note that $(d^2 f(x_0)$ is technically a 2-tensor with two inputs, but both inputs by definition must be the same)
    \item $x_0$ is a local maximum if $d^2 f(x_0)$ is a negative definite linear map
    \item $x_0$ is a \textit{saddle point} if $d^2 f(x_0)$ is neither positive definite nor negative definite. 
\end{enumerate}
\end{theorem}

Visually, this makes sense since given a critical point $x_0$, the derivative matrix would be $0$, meaning that the 2nd degree Taylor expansion of $f$ near $x_0$ would be in form
\[f(x) \approx f(x_0) + \frac{1}{2} (d^2_{x-x_0, x-x_0)} f)(x_0)\]
If $H f(x_0)$ is positive definite, then by definition 
\[\frac{1}{2} (d^2_{x-x_0, x-x_0)} f)(x_0) > 0\]
for all $x$ near $x_0$, and so $f$ would increase in every direction within the neighborhood of $x_0$. 
\begin{center}
    \includegraphics[scale=0.25]{Local_Minima_Abstract.PNG}
\end{center}
or when imagining functions of two variables $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$, the neighborhood of $x_0$ looks like a paraboloid.
\begin{center}
    \includegraphics[scale=0.25]{Local_Minimia_Paraboloid.PNG}
\end{center}
The logic follows similarly for negative definite map $(d^2 f)(x_0)$. If $(d^2 f)(x_0)$ is neither positive nor negative definite, then $\frac{1}{2} (d^2_{(x-x_0, x-x_0)} f)(x_0)$ could be positive or negative, depending on which direction vector $v = x - x_0$ we choose for computing the directional derivative. Therefore, $f$ will increase for certain $h$ and decrease for other $h$ and is not an extremum. We call this a saddle point since the graph of functions $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$ in $\mathbb{R}^3$ looks like a saddle within the neighborhood of $x_0$. 
\begin{center}
    \includegraphics[scale=0.4]{Saddle.PNG}
\end{center}

\subsubsection{Global Extrema}

\begin{definition}[Global Extrema]
Given $f: A \subset \mathbb{R}^n \longrightarrow \mathbb{R}$, a point $x_0 \in A$ is said to be an \textit{absolute, or global, maximum} if 
\[f(x_0) \geq f(x) \text{ for all } x \in A\]
and a \textit{global minimum} if 
\[f(x_0) \leq f(x) \text{ for all } x \in A\]
\end{definition}

Unfortunately, determining whether a point $x_0$ is a local extremum requires us to define an open neighborhood $U$ around $x_0$ (such that every point $x \in U$ is greater/smaller than $x_0$). This means that we can only determine local extrema within open sets in $\mathbb{R}^n$. Therefore, we must modify our procedure when looking for extrema on functions defined over closed bounded sets. 

We now describe a method of computing global extrema. 

\begin{theorem}[Computing Global Extrema]
Let $f: D \subset \mathbb{R}^n \longrightarrow \mathbb{R}$ be a function defined on a closed and bounded set $D \equiv U \cup \partial U$, where $U$ is open and $\partial U$ is the boundary of $D$. To find the global extrema on $D$, we find all the stationary points of:
\begin{enumerate}
    \item $f$ defined over open $U$
    \item $f$ defined over $\partial U$, which can be done by composing the path functions $p: \mathbb{R}^{n-1} \longrightarrow \partial U$ and $f: \partial U \longrightarrow \mathbb{R}$ and finding the stationary points of $f \circ p$. 
\end{enumerate}
We take all these stationary points and choose the largest to be the global maximum and the smallest to be the global minimum. 
\end{theorem}

\subsubsection{The Method of Lagrange Multipliers}
In many cases we are required to find the local extrema of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ subject to a system of equality constraints (i.e. subject to the condition that one of more equations have to be satisfied exactly by the chosen values of the variables) of the form: 
\[g_1 (x) = 0, g_c (x) = 0, \ldots, g_c (x) = 0 \]
which can be summarized into the constraint $g: \mathbb{R}^n \longrightarrow \mathbb{R}^c$
\[g = \begin{pmatrix}
g_1 \\ \vdots \\ g_c
\end{pmatrix} \implies g(x) = \begin{pmatrix}
g_1 (x) \\ \vdots \\ g_c (x)
\end{pmatrix} = 0\]
Sometimes, these constraints are written as $g(x) = r$ for some vector $r$, but we can just equivalently set the constraint function as $g(x)-r = 0$. In physics, these types of "well-behaved" constraints are known as \textit{holonomic constraints}. Here is an example of a function $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$ constrained to the unit circle, where $g(x, y) = x^2 + y^2 - 1= 0 $.
\begin{center}
    \includegraphics[scale=0.2]{Function_with_Constraints.PNG}
\end{center}
To solve this constraint problem, we use the method of Lagrange multipliers. The basic idea is to convert a constrained problem into a form such that the derivative test of an unconstrained problem can still be applied. The relationship between the gradient of the function and gradients of the constraints rather naturally leads to a reformulation of the original problem, known as the \textit{Lagrangian function}. That is, in order to find the maximum/minimum of $f$ subjected to the equality constraint $g(x) = 0$, we form the Lagrangian function
\[\mathcal{L}(x, \lambda) \equiv f(x) - \lambda g(x)\]
and find the stationary points of $\mathcal{L}$ considered as a function of $x \in \mathbb{R}^n$ and the Lagrange multiplier $\lambda \in \mathbb{R}$. 

The main advantage to this method is that it allows the optimization to be solved without explicit parameterization in terms of the constraints. 

\begin{theorem}[Lagrange Multipliers Theorem]
Let $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ be a smooth function and let $g(x) = 0$, where $g: \mathbb{R}^n \longrightarrow \mathbb{R}^c$, be a system of smooth constraint equations. 
\[g \equiv \begin{pmatrix}
g_1 \\ \vdots \\ g_c
\end{pmatrix}\]
Let $x^*$ be an optimal solution to the optimization problem of maximizing $f(x)$ subject to the constraint $g(x) = 0$ such that $\rank\big(d g(x^*)\big) = c < n$. Note that $d g(x^*): T_{x^*} \mathbb{R}^n \longrightarrow \mathbb{R}^c$ is the linear differential map of $g$ evaluated at $x^*$, but it can equivalently be interpreted as a map
\[d g(x^*): T_{x^*} \mathbb{R}^n \times (\mathbb{R}^c)^* \longrightarrow \mathbb{R}\]
or as a map
\[d g(x^*): (\mathbb{R}^c)^* \longrightarrow T^*_{x^*} \mathbb{R}^n\]
Then, there exists a unique vector $\lambda^* \in (\mathbb{R}^c)^*$ of Lagrange multipliers $\lambda^*_1, \ldots, \lambda^*_c$ such that the two cotangent vectors of $T^*_{x^*} \mathbb{R}^n$ are equal. 
\[d f(x^*) = d g(x^*) (\lambda^*)\]
Or equivalently, that the two tangent vectors (which are the gradient vector fields $\nabla f$ and $\nabla g (\lambda^*)$ evaluated at $x^*$). 
\[\nabla f(x^*) = \nabla g(x^*)(\lambda^*)\]
Conventionally, we use the latter equation comparing the gradients. 
\end{theorem}

\begin{corollary}[Matrix Realization of the Lagrange Multipliers Theorem]
Let $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ be the objective function and let $g: \mathbb{R}^n \longrightarrow \mathbb{R}^c$ be the constraints function with components $g_i$, both smooth. Let the vector $x^*$ be the optimal solution to the optimization problem of maximizing $f(x)$ subject to the constraint $g(x) = 0$ such that $\rank \big(J g(x^*)\big) = c < n$, where $J g(x^*)$ is the Jacobian matrix of partial derivatives of $g$ evaluated at $x^*$. Then, there exists a unique vector $\lambda^*$ such that 
\[J f (x^*) = \lambda^{*T} J g (x^*)\] 
which in matrix terms is: 
\[\begin{pmatrix}
\frac{\partial f}{\partial x_1} (x^*) & \ldots & \frac{\partial f}{\partial x_c} (x^*) \end{pmatrix} = \begin{pmatrix}
\lambda^*_1 & \ldots & \lambda^*_c \end{pmatrix} \begin{pmatrix}
\frac{\partial g_1}{\partial x_1} (x^*)& \ldots & \frac{\partial g_1}{\partial x_n} (x^*)\\
\vdots & \ddots & \vdots \\
\frac{\partial g_c}{\partial x_1} (x^*)& \ldots & \frac{\partial g_c}{\partial x_n}(x^*)
\end{pmatrix}\]
But conventionally, we express things in terms of vectors, so we just take the transpose of everything to get the gradient form: 
\begin{align*}
    \nabla f (x^*) & = \big( J g(x^*)\big)^T \lambda^* \\
    & = \lambda^*_1 \nabla g_1 (x^*) + \lambda^*_2 \nabla g_2 (x^*) + \ldots + \lambda^*_c \nabla g_c (x^*) \\
    & = \sum_{i=1}^c \lambda^*_i \nabla g_c (x^*) 
\end{align*}
which has a matrix realization of 
\begin{align*}
\begin{pmatrix}
\frac{\partial f}{\partial x_1} (x^*) \\ \vdots\\ \frac{\partial f}{\partial x_n} (x^*) \end{pmatrix} & = \begin{pmatrix}
\frac{\partial g_1}{\partial x_1} (x^*)& \ldots & \frac{\partial g_c}{\partial x_1} (x^*)\\
\vdots & \ddots & \vdots \\
\frac{\partial g_1}{\partial x_n} (x^*)& \ldots & \frac{\partial g_c}{\partial x_n}(x^*)
\end{pmatrix} \begin{pmatrix}
\lambda^*_1 \\ \vdots \\ \lambda^*_c \end{pmatrix} \\
& = \lambda^*_1 \begin{pmatrix}
\frac{\partial g_1}{\partial x_1} (x^*) \\ \vdots \\ \frac{\partial g_1}{\partial x_n}(x^*)
\end{pmatrix} + \lambda^*_2 \begin{pmatrix}
\frac{\partial g_2}{\partial x_1} (x^*) \\ \vdots \\ \frac{\partial g_2}{\partial x_n}(x^*)
\end{pmatrix} + \ldots + \lambda^*_c \begin{pmatrix}
\frac{\partial g_c}{\partial x_1} (x^*) \\ \vdots \\ \frac{\partial g_c}{\partial x_n}(x^*)
\end{pmatrix}
\end{align*}
This equation tells us that at any critical points $x^*$ of $f$ evaluated under the equality constraints, the gradient of $f$ at $x^*$ can be expressed as a linear combination of the gradients of the constraints $\nabla g_i (x^*)$ (at $x^*$), with the Lagrange multipliers acting as coefficients. Therefore, finding the critical points $x^*$ of $f$ constrained with $g$ is equivalent to solving the system of equations 
\begin{align*}
    g(x) & = 0 \\
    \nabla f(x^*) & = \big(J g(x^*)\big)^T \lambda^*
\end{align*}
which can be rewritten as
\begin{align*}
    c \text{ constraint equations} & \begin{cases}
    g_1 (x) & = 0 \\
    \ldots & = 0 \\
    g_c (x) & = 0
    \end{cases} \\
    n \text{ Lagranaian equations} & \begin{cases}
   \frac{\partial f}{\partial x_1} (x^*) & = \lambda^*_1 \frac{\partial g_1}{\partial x_1} (x^*) + \lambda^*_2 \frac{\partial g_2}{\partial x_1} (x^*) + \ldots + \lambda^*_c \frac{\partial g_c}{\partial x_1} (x^*) \\
    \ldots & = \ldots \\
    \frac{\partial f}{\partial x_n} (x^*) & = \lambda^*_1 \frac{\partial g_1}{\partial x_n} (x^*) + \lambda^*_2 \frac{\partial g_2}{\partial x_n} (x^*) + \ldots + \lambda^*_c \frac{\partial g_c}{\partial x_n} (x^*) 
    \end{cases}
\end{align*}
\end{corollary}

Let us introduce a visualization for when where is a single constraint $g: \mathbb{R}^n \longrightarrow \mathbb{R}$. From the properties of the gradient, $\nabla f(x_0)$ is orthogonal to the level set of points satisfying $f(x) = f(x_0)$ at point $x_0$. Note that the constraint function $g$ also maps $\mathbb{R}^n \longrightarrow \mathbb{R}$, and so it has its own level surfaces. We can see that the point where the contour line of $g(x) = 0$ tangentially touches the contours of $f$ is the maximum. Since it intersects it tangentially, the gradient vector at that point $\nabla g(x_0)$ is parallel to $\nabla f(x_0)$. 
\begin{center}
    \includegraphics[scale=0.22]{Lagrange_Multiplier_Single_Constraint.PNG}
\end{center}
We can visualize this for multiple constraints as well, where $\nabla f(x_0)$ (the gradient vector of $f$ at $x^*$) can be expressed as a linear combination of $\nabla g_1 (x_0)$ and $\nabla g_2 (x_0)$ (gradient vectors of the constraint functions at $x^*$). 
\begin{center}
    \includegraphics[scale=0.27]{Lagrange_Multiplier_Multiple_Constraints.PNG}
\end{center}

From the properties of the gradient introduced before, $\triangledown f(x_0)$ is orthogonal to the level set of points satisfying $f(x) = c$ at the point $x_0$. But this level set $f(x) = c$ actually intersects the level set determined by $g(x) = c$ at the point $x_0$ and is indistinguishable from each other at $x_0$. This means that $\triangledown g(x_0)$ is normal the level set of $g(x) = c$ at $x_0 \iff $ it is normal to the level set of $f(x) = c$ at $x_0$. But $\triangledown f(x_0)$ is also normal at that point, so $\triangledown f(x_0)$ must be parallel to $\triangledown g(x_0)$. 

\subsection{k-times Continuously Differentiable Functions}
So far, we have thrown around the words continuous and differentiable a lot, but note that continuity is a topological property, while differentiability is a property of functions mapping between Euclidean spaces. More specifically, for $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$
\begin{enumerate}
    \item $f$ continuous at $x_0$ means that the preimage of every open neighborhood of $f(x_0)$ in $\mathbb{R}^m$ under $f$ is an open neighborhood of $x_0$ in $\mathbb{R}^n$. 
    \item $f$ smooth (i.e. differentiable) at $x_0$ means that there exists a first order approximation $P_{x_0}^1$ centered at $x_0$. In other words, the covector $d f(x_0)$ is well defined for every input tangent vector $v \in T_{x_0} \mathbb{R}^n$. 
\end{enumerate}
We will examine the relationship between these properties. First, it is clear that if a function is differentiable, then its partials exist since they are by definition $d_v f(x_0)$ where $v \in \{e_1, \ldots, e_n\}$. 

\begin{lemma}[Differentiability Implies Existence of Partials]
\[\text{Differentiability } \implies \text{ Existence of Partials}\]
\end{lemma}
We remind the reader that differentiability means that the derivative exists at every point in \textit{every path}. The partials are just one of the few paths out of the infinitely many possibles ones. We can imagine an example by visualizing a surface with a "crinkle" at a point, which may have well-defined partials but upon a certain path, the derivative may not exist at all. By this logic, 
\[\text{Existence of Partials} \centernot\implies \text{Differentiability}\]

\begin{example}

\end{example}

Furthermore, differentiability implies continuity. 

\begin{lemma}[Differentiability Implies Continuity]
\[\text{Differentiability } \implies \text{ Continuity}\]
\end{lemma}

But continuity $\centernot\implies$ differentiability. We show two examples of this case. 

\begin{example}[Simple Continuous but not Differentiable Function]
The function $f: \mathbb{R} \longrightarrow \mathbb{R}, x \mapsto |x|$ is continuous but not differentiable at $x = 0$. 
\end{example}

\begin{example}[Continuous but nowhere Differentiable Function]
The \textit{Weierstrass function} is an example of a function that is continuous everywhere but differentiable nowhere. The function is described as a Fourier series
\[f(x) \equiv \sum_{n=0}^\infty a^n \cos(b^n \pi x)\]
where $0 < a < 1$, $b$ is a positive integer, and 
\[a b > 1 + \frac{3}{2} \pi\]
Like other fractals, this function exhibits self-similarity. 
\begin{center}
    \includegraphics[scale=0.15]{Weierstrass_Function_Fractal.png}
\end{center}
\end{example}

We introduce a powerful theorem that allows us to determine smoothness. 

\begin{theorem}[Differentiability Theorem]
Given function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$, if all of its partials exist and are continuous, then $f$ is differentiable. 
\[\text{Continuous Partials } \implies \text{ Differentiability}\]
\end{theorem}
We can also visualize this theorem. Since the partials are continuous, then the tangent subspace, which is determined by the span of the tangent vectors determined by the partials, also changes continuously. This means that given a $C^1$ function $f$, we can choose \textit{any} directional vector $v \in \mathbb{R}^n$ and the graph of $f_v^\prime$ will be well defined. Following this visual, we can interpret the differentiability theorem as: 
\[ f \in C^k (\mathbb{R}^n) \implies f \text{ can be differentiated k times along any k paths everywhere}\]

This theorem gives rise to a nice classification of functions based on their smoothness. 

\begin{definition}[Differentiability Classes]
Given a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$, if $f$ is continuous, it is said to be of \textit{class $C^0$}. If $f$ has continuous partial derivatives, that is, if
\[d_{e_i} f \equiv \frac{\partial f}{\partial x_i} : \mathbb{R}^n \longrightarrow \mathbb{R}^m \text{ for } i = 1, 2, \ldots, n\]
are continuous, then $f$ is said to be of \textit{class $C^1$}, or \textit{$C^1$ differentiable}. If it additionally has continuous second partial derivatives, that is, if
\[d_{(e_i, e_j)} f \equiv \frac{\partial^2 f}{\partial x_i \partial x_j}: \mathbb{R}^n \longrightarrow \mathbb{R}^m \text{ for } i = 1, 2, \ldots, n\]
are continuous, then $f$ is said to be of \textit{class $C^2$}, or \textit{$C^2$ differentiable}. In general, we say that $f$ is of class $C^k$, or \textit{$C^k$ differentiable}, if its first through $k$th partial derivatives are continuous; that is, if 
\[d_{(e_{i_1}, \ldots, e_{i_k})} f \equiv \frac{\partial^k f}{\partial e_{i_1} \ldots \partial e_{i_k}}: \mathbb{R}^n \longrightarrow \mathbb{R}^m \text{ for } i = 1, 2, \ldots, n\]
are continuous, which implies that $f$ can be differentiated $k$ times (i.e. there exists a $k$th order Taylor approximation of $f$).
\end{definition}

\begin{lemma}[Nested $C^k$ Function Spaces]
The set of all real-valued $C^k$-functions defined over $\mathbb{R}^n$ form an infinite-dimensional vector space, denoted $C^k (\mathbb{R}^n)$. Furthermore, this gives rise to the nested space: 
\[C^0(\mathbb{R}^n) \supset C^1 (\mathbb{R}^n) \supset C^2 (\mathbb{R}^n) \supset ... \supset C^k (\mathbb{R}^n) \supset ... \supset C^\infty (\mathbb{R}^n) \]
\end{lemma}

Note that differentiability does not imply continuous partials! 

\begin{example}[Differentiable but Not Continuously Differentiable Function]
The function 
\[g(x) \equiv \begin{cases}
x^2 \sin\Big(\frac{1}{x}\Big) & x \neq 0 \\
0 & x = 0
\end{cases}\]
is differentiable, with derivative 
\[g^\prime (x) \equiv \begin{cases}
- \cos \Big( \frac{1}{x}\Big) + 2 x \sin\Big(\frac{1}{x}\Big) & x \neq 0 \\
0 & x = 0
\end{cases}\]
But because $\cos(\frac{1}{x})$ oscillates at $x \rightarrow 0$, $g^\prime (x)$ is not continuous at $x = 0$. Therefore $g(x)$ is differentiable but not in $C^1(\mathbb{R})$. 
\end{example}

\begin{theorem}[Nested $C^k$ and $\mathcal{D}^k$ Function Spaces]
Let the space of all $k$-times differentiable functions over $\mathbb{R}^n$ be denoted $\mathcal{D}(\mathbb{R}^n)$. Then, 
\[C^0(\mathbb{R}^n) \supset \mathcal{D}^1 (\mathbb{R}^n) \supset C^1 (\mathbb{R}^n) \supset \mathcal{D}^2 (\mathbb{R}^n) \supset C^2 (\mathbb{R}^n) \ldots \mathcal{D}^k (\mathbb{R}^n) \supset C^k (\mathbb{R}^n) \ldots C^\infty (\mathbb{R}^n) \]
\end{theorem}

Note that mathematicans throw around the word "smooth" a lot. Usually, it means one of three things
\begin{enumerate}
    \item it is of class $C^1$ 
    \item it is of class $C^\infty$
    \item it is of class $C^k$, where $k$ is however high it needs to be to satisfy our assumptions. For example, if I say let us differentiate smooth $f$ two times, then I am assuming that $f \in C^2 (\mathbb{R}^n)$. 
\end{enumerate}
Visualizing $C^k$-functions is easy for low orders. A $C^0$ function produces a graph that isn't "ripped" or "punctured," since this is exactly what a discontinuity would look like. A $C^1$ function requires the surface to be smooth in such a way that there is a well defined affine tangent subspace at every point. This means that there cannot be any sharp "points" or "edges" on the graph since a tangent subspace cannot be well defined. 

\subsection{Inverse Function Theorem}
A special case of the general implicit function theorem is the inverse function theorem. It gives sufficient condition for a function to be invertible in a neighborhood of a point in its domain. 

\begin{theorem}[Inverse Function Theorem for Single-Variable $C^1$ Functions]
If $f: \mathbb{R} \longrightarrow \mathbb{R}$ is a $C^1$ (continuously differentiable) function with a nonzero derivative at point $x_0$, then $f$ is invertible in a neighborhood of $x_0$, the inverse is also $C^1$, and the derivative of the inverse function at $y_0 = f(x_0)$ is the reciprocal of the derivative of $f$ at $x_0$. 
\[\big( f^{-1}\big)^\prime (y_0) = \frac{1}{f^\prime (x_0)}\]
This can be visualized easily by looking at the graph of any $C^1$ function. 
\begin{center}
    \includegraphics[scale=0.25]{Inverse_Function_Theorem_One_Variable.PNG}
\end{center}
In high school mathematics, this theorem is informally presented as the \textit{horizontal line test}. 
\end{theorem}

This can be stated in an alternative form: If $f: \mathbb{R} \longrightarrow \mathbb{R}$ is continuous and injective near $x_0$, and differentiable at $x_0$ such that $f^\prime (x_0) \neq 0$, then $f$ is invertible near $x_0$ with an inverse that's similarly continuous and injective, and where the above formula would apply as well. 

\begin{corollary}[Inverse Function Theorem for Single-Variable $C^k$ Functions]
If $f: \mathbb{R} \longrightarrow \mathbb{R}$ is a $C^k$ functions with a nonzero derivative at point $x_0$, then $f$ is invertible in a neighborhood of $x_0$, the inverse is also $C^k$, and the derivative of the inverse function at $y_0 = f(x_0)$ is the reciprocal of the derivative of $f$ at $x_0$. 
\end{corollary}

\begin{theorem}[Inverse Function Theorem for Multivariable Functions and its Matrix Realization]
Let $f: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ be a $C^1$ function defined on an open neighborhood of $x_0$ in the domain. If the total derivative $d_{x_0} f$ (i.e. the Jacobian matrix $J f(x_0)$) at $x_0$ is invertible, an inverse function of $f$ is defined on some neighborhood of $y_0 = f(x_0)$. Given that we are working with a fixed basis, $f$ can be modeled by the set of $n$ equations 
\begin{align*}
    f_1 (x_1, x_2, \ldots, x_n) &= y_1 \\
    \ldots & = \ldots \\
    f_2 (x_1, x_2, \ldots, x_n) &= y_2
\end{align*}
This theorem says that this system of $n$ equations has a unique solution for $x_1, x_2, \ldots, x_n$ in terms of $y_1, \ldots, y_n$, provided that we restrict $x$ and $y$ to small enough neighborhoods of $x_0$ and $y_0$. 

This inverse function $f^{-1}$ is continuously differentiable, and its derivative $d_{y_0} f^{-1}$ (i.e. the Jacobian matrix $J f^{-1} (y_0)$) at $y_0 = f(x_0)$ is the inverse linear map of $d_{x_0} f$. 
\[d_{y_0} f^{-1} = \big( d_{x_0} f \big)^{-1} \iff J f^{-1} (y_0) = \big( J f (x_0)\big)^{-1}\]
\end{theorem}

\begin{example}
Consider the vector-valued function $f: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ defined by 
\[f(x, y) = \begin{pmatrix}
e^x \cos (y) \\ e^x \sin(y)
\end{pmatrix}\]
The Jacobian matrix is 
\[J f(x, y) = \begin{pmatrix}
e^x \cos(y) & - e^x \sin(y) \\
e^x \sin(y) & e^x \cos(y)
\end{pmatrix} \implies \det J f(x, y) = e^{2x} \cos^2 (y) + e^{2x} \sin^2 (y) = e^{2x}\]
Since the determinant $e^{2x}$ is nonzero everywhere, $J f(x, y)$ is nonsingular. Thus, the theorem guarantees that for every point $x_0 \in \mathbb{R}^2$, there exists a neighborhood about $x_0$ over which $f$ is invertible. However, this does not mean $f$ is invertible over its entire domain: in this case $f$ isn't even injective since it is periodic. 
\end{example}

\subsection{Implicit Function Theorem}
The implicit function theorem is a tool that allows relations between points in $\mathbb{R}^n$ to be converted to functions of several real variables. That is, it states that for sufficiently "nice" points on a surface defined as $f(x) = c$ (where $f:\mathbb{R}^n \longrightarrow \mathbb{R}^m$, we can locally pretend that this surface is a graph of a function. 

That is, let $f: \mathbb{R}^{n+m} \longrightarrow \mathbb{R}^m$ be a $C^1$ function. We can think of $\mathbb{R}^{n+m}$ as the Cartesian product $\mathbb{R}^n \times \mathbb{R}^m$, where a point of this product is written 
\[(x, y) = (x_1, \ldots, x_n, y_1, \ldots, y_m)\]
Starting from the given function $f$, our goal is to construct a function $g: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ whose graph $(x, g(x))$ is precisely the set of all $(x, y)$ such that $f(x, y) = 0$. 



\begin{theorem}[Implicit Function Theorem for 2D, 3D Case]
Let $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$ be a continuously differentiable function and let there be a point $(x_0, y_0) \in \mathbb{R}^2$ such that $f(x_0, y_0) = 0$. If 
\[\frac{\partial f}{\partial y} (x_0, y_0) \neq 0\]
then there is an open neighborhood $U$ around $(x_0, y_0)$ such that we can make $y$ a function of $x$ within $U$ satisfying $f(x, y(x)) = 0$. 

Let $f: \mathbb{R}^3 \longrightarrow \mathbb{R}$ be a continuously differentiable function and let there be a point $(x_0, y_0, z_0) \in \mathbb{R}^3$ such that $f(x_0, y_0, z_0) = 0$. If 
\[\frac{\partial f}{\partial z} (x_0, y_0, z_0) \neq 0\]
then there is an open neighborhood $U$ around $(x_0, y_0, z_0)$ such that we can make $z$ a function of $x$ and $y$ within $U$ satisfying $f(x, y, z(x,y)) = 0$. 
\end{theorem}

\begin{example}
Let $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$ be defined by $f(x, y) = x^2 + y^2 - 1$. The level set at $z = 0$ would be the set of points satisfying 
\[x^2 + y^2 - 1 = 0\]
the unit circle. The derivative of $f$ with respect to $y$ is $0$ at the points $(-1,0)$ and $(1,0)$, meaning that in any neighborhood of these points, we cannot define a function of $y$ with respect to $x$. This is true, indeed, since any such function would fail the vertical line test, which can be seen in the red neighborhood around $(1,0)$. However, the blue neighborhood of the point $(-\sqrt{2}/2, \sqrt{2}/2)$ does indeed define a function of $y$ with respect to $x$ satisfying the vertical line test. 
\begin{center}
\begin{tikzpicture}
    \draw[<->] (-3,0)--(3,0);
    \draw[<->] (0,-3)--(0,3);
    \draw (0,0) circle (2);
    \draw[fill=red] (2,0) circle (0.08);
    \draw[fill=red] (-2,0) circle (0.08);
    \draw[red, thick] (1.732, -1) arc (-30:60:2);
    \draw[dashed, <->] (1.8,-2.5)--(1.8,2.5);
    \draw[fill=blue] (-1.414, 1.414) circle (0.08);
    \draw[blue, thick] (-1, 1.732) arc (120:170:2);
    \draw[dashed,<->] (-1.7,2.5)--(-1.7,-2.5);
\end{tikzpicture}
\end{center}
\end{example}

Note that for the 2D and 3D case, the level surface that we dealt with has a codimension of $1$; that is, the dimension of the manifold generated by the level surface is $n-1$. The special implicit function theorem generalizes cases such as these. 

\begin{definition}[Truncated Jacobian Matrix]
Given a function $f: \mathbb{R}^{n+m} \longrightarrow \mathbb{R}^m$ where the variables are 
\[x_1, \ldots, x_n, y_1, \ldots, y_m\]
the \textit{truncated Jacobian matrix} of $f$ is the $m \times m$ matrix formed by the rightmost $m$ columns of $J  f(x, y)$. That is, the matrix formed by the elements on the right of the vertical line is the truncated Jacobian matrix.
\[J f(x, y) = \left(\begin{array}{ccc|ccc}
   \frac{\partial f_1}{\partial x_1} &\ldots &\frac{\partial f_1}{\partial x_n} & \frac{\partial f_1}{\partial y_1} & \ldots & \frac{\partial f_1}{\partial y_m}\\
   \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
   \frac{\partial f_m}{\partial x_1} &\ldots &\frac{\partial f_m}{\partial x_n} & \frac{\partial f_m}{\partial y_1} & \ldots & \frac{\partial f_m}{\partial y_m}
   \end{array}\right) \mapsto
   \begin{pmatrix}
   \frac{\partial f_1}{\partial y_1} & \ldots & \frac{\partial f_1}{\partial y_m}\\
   \vdots & \ddots & \vdots \\
   \frac{\partial f_m}{\partial y_1} & \ldots & \frac{\partial f_m}{\partial y_m}
   \end{pmatrix} = J f_y \big(x, y)\big)\]
\end{definition}

\begin{theorem}[Special Implicit Function Theorem]
Let $f: \mathbb{R}^{n+1} \longrightarrow \mathbb{R}$ be a continuously differentiable function. We can think of $\mathbb{R}^{n + 1}$ as the Cartesian product $\mathbb{R}^n \times \mathbb{R}$, where an element of this product is $(x, y)$ ($x \in \mathbb{R}^n, y \in \mathbb{R}$). Let us fix a point $(x_0, y_0) = (x_{01}, x_{02}, \ldots, x_{0n}, y_0)$ with $f(x_0, y_0) = 0$. 

If the ($1 \times 1$) \textit{truncated Jacobian matrix} defined with the partial derivatives with respect to the $y$ terms evaluated at $(x_0, y_0)$ 
\[ J f_y (x_0, y_0) \equiv \frac{\partial f}{\partial y} (x_0, y_0)\]
which can also be thought as the matrix truncated
\[J f(x, y) = \left(\begin{array}{ccc|c}
   \frac{\partial f}{\partial x_1} &\ldots &\frac{\partial f}{\partial x_n} & \frac{\partial f}{\partial y}
   \end{array}\right) \mapsto \begin{pmatrix}
   \frac{\partial f}{\partial y}
   \end{pmatrix}\]
is invertible, then there exists an open neighborhood $U \subset \mathbb{R}^n$ containing $x_0$ and a unique $C^1$ function $g: U \longrightarrow \mathbb{R}$ such that $g(x_0) = y_0$, and 
\[f\big( x, g(x)\big) = 0 \text{  for all } x \in U\]
Moreover, the partial derivatives of $g$ in $U$ (represented by its Jacobian matrix) are given by the matrix product
\[J g(x) = - \big( J f_y (x, g(x)) \big)^{-1}  Jf \big(x, g(x)\big)\]
or represented
\[\begin{pmatrix}
\frac{\partial g}{\partial x_1} & \ldots & \frac{\partial g}{\partial x_n} 
\end{pmatrix} = - \begin{pmatrix}
\frac{\partial f}{\partial y} \big(x, g(x)\big)
\end{pmatrix}^{-1} \begin{pmatrix}
\frac{\partial f}{\partial x_1} \big(x, g(x)\big) & \ldots & \frac{\partial f}{\partial x_n} \big(x, g(x)\big)
\end{pmatrix}\]
\end{theorem}

\begin{example}[Circle Example]
Let $n = m = 1$ and 
\[f(x, y) = x^2 + y^2 - 1\]
The matrix of partial derivatives is just a $1 \times 2$ matrix, given by 
\[J f(x_0, y_0) = \begin{pmatrix}
\frac{\partial f}{\partial x} (x_0, y_0) & \frac{\partial f}{\partial y} (x_0, y_0)
\end{pmatrix} = \begin{pmatrix}
2 x_0 & 2 y_0 \end{pmatrix}\]
The truncated Jacobian matrix is just the $1 \times 1$ matrix $(2 y_0)$, which is invertible if and only if $y_0 \neq 0$. By the implicit function theorem we see that we can locally write the circle in the form $y = g(x)$ for all points where $y \neq 0$. For $(\pm 1, 0)$ we cannot (as seen before by the inverse function theorem). But by writing $x$ as a function of $y$ ($x = h(y)$), we can write it at these points. The derivative of this function $g: \mathbb{R} \longrightarrow \mathbb{R}$ can be written using the formula below, where $\frac{\partial f}{\partial y} \big( x, g(x)\big) = 2y_{(x, g(x))} = 2 g(x)$. 
\[\frac{\partial g}{\partial x} = - \big( 2 g(x)\big)^{-1} \big( 2x \big) = - \frac{x}{g(x)}\]
But since the value of $g(x)$ is the $y$ value, we can rewrite this as
\[\frac{dy}{dx} = -\frac{x}{y}\]
and similarly, get the formula for the derivative of $h$ as
\[\frac{dx}{dy} = - \frac{y}{x}\]
\end{example}

\begin{theorem}[General Implicit Function Theorem]
Let $f: \mathbb{R}^{n+m} \longrightarrow \mathbb{R}^m$ be a continuously differentiable function, and let us interpret $\mathbb{R}^{n+m}$ as the Cartesian product $\mathbb{R}^n \times \mathbb{R}^m$, where an element of this product is $(x, y)$ ($x \in \mathbb{R}^n, y \in \mathbb{R}^m$). Let us fix a point $(x_0, y_0) = (x_{01}, \ldots, x_{0n}, y_{01}, \ldots, y_{0m})$, with $f(x_0, y_0) = 0$.

If the $(m \times m)$ truncated Jacobian matrix constructed by truncating the matrix below as such
\[J f = \left(\begin{array}{ccc|ccc}
   \frac{\partial f_1}{\partial x_1} &\ldots &\frac{\partial f_1}{\partial x_n} & \frac{\partial f_1}{\partial y_1} & \ldots & \frac{\partial f_1}{\partial y_m}\\
   \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
   \frac{\partial f_m}{\partial x_1} &\ldots &\frac{\partial f_m}{\partial x_n} & \frac{\partial f_m}{\partial y_1} & \ldots & \frac{\partial f_m}{\partial y_m}
   \end{array}\right) \mapsto
   \begin{pmatrix}
   \frac{\partial f_1}{\partial y_1}& \ldots & \frac{\partial f_1}{\partial y_m}\\
   \vdots & \ddots & \vdots \\
   \frac{\partial f_m}{\partial y_1} & \ldots & \frac{\partial f_m}{\partial y_m}
   \end{pmatrix} (x_0, y_0) = J f_y (x_0, y_0)\]
evaluated at $(x_0, y_0)$ is invertible (i.e. determinant is nonzero), then there exists an open neighborhood $U \subset \mathbb{R}^n$ containing $x_0$ and a unique $C^1$ function $g: U \longrightarrow \mathbb{R}^m$ such that $g(x_0) = y_0$, or in component terms, the smooth functions $k_i$ exist such that
\[y_{0i} = k_i (x_{01}, x_{02}, \ldots, x_{0n}), \;\;\;\;\; i = 1, 2, \ldots, m\]
and 
\[f\big( x, g(x)\big) = 0 \text{ for all } x \in U\]
Moreover, the partial derivatives of $g$ in $U$ (represented by its Jacobian matrix) are given by the matrix product
\[J g(x) = - \big( J f_y (x, g(x))\big)^{-1} J f\big(x, g(x)\big)\]
or equivalently, 
\[\begin{pmatrix}
\frac{\partial g_1}{\partial x_1} & \ldots & \frac{\partial g_1}{\partial x_n} \\
\vdots & \ddots & \vdots \\
\frac{\partial g_m}{\partial x_1} & \ldots & \frac{\partial g_m}{\partial x_n}
\end{pmatrix} = - \begin{pmatrix}
\frac{\partial f_1}{\partial y_1} (x, g(x))& \ldots & \frac{\partial f_1}{\partial y_m} (x, g(x))\\
\vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial y_1} (x, g(x))& \ldots & \frac{\partial f_m}{\partial y_m}(x, g(x))
\end{pmatrix} ^{-1} \begin{pmatrix}
\frac{\partial f_1}{\partial x_1} & \ldots & \frac{\partial f_1}{\partial x_n}\\
\vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial x_1} & \ldots & \frac{\partial f_m}{\partial x_n}
\end{pmatrix}(x, g(x))\]
The derivatives may also be computed by implicit differentiation. 
\end{theorem}



\subsection{Divergence and Curl}
\subsubsection{Tensor Fields}
Note that a scalar field is a set of scalars associated with every point in space. Similarly, a vector field is a set of vectors associated with every point in space. Going further, a tensor field is a set of tensors associated with every point in space. It follows that: 
\begin{enumerate}
    \item A scalar field is a rank $0$ tensor field
    \item A vector field is a rank $1$ tensor field
\end{enumerate}
Therefore, a rank $2$ tensor field would be:
\[F: \mathbb{R}^n \longrightarrow \mathbb{R}^n \otimes \mathbb{R}^n\]
where $F(x_0)$ would be a rank $2$ tensor (or a matrix, given that coordinates are well defined). 

\subsubsection{Coordinate Definition of Divergence}
Colloquially, the divergence is an operator $\Div$ that operates on a vector field and produces a scalar field which provides the quantity of the vector field's source at each point. Technically, the divergence represents the volume density of the outward flux of a vector field from an infinitesimal volume around a given point. 

There is a very nice geometric interpretation for divergence. Imagine that the vector field $F$ represents fluid flow in $\mathbb{R}^n$. Divergence is then the "measure" of the net amount of fluid flowing in and out of an infinitesimally small region, labeled at each point. If the net fluid flow is positive (i.e. more fluid is flowing in than out) at point $x_0$, then $\Div{F}(x_0) > 0$. If the net fluid flow is negative (i.e. more fluid is flowing out than in) at point $x_0$, then $\Div{F}(x_0) < 0$. This measure assigns a number to every point in the space (creating a scalar field). Therefore, each point either acts as a "source" of fluid emanating from it or as a "sink" that sucks in more fluid than it puts out. 
\begin{center}
    \includegraphics[scale=0.25]{Divergence_compared_to_Zero.PNG}
\end{center}

\begin{definition}[Divergence in Coordinates]
In Cartesian coordinates, the \textit{divergence} of a $C^1$ vector field $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ is defined
\[\Div{F} \equiv \nabla \cdot F \equiv 
\begin{pmatrix}
\frac{\partial}{\partial x_1} \\ \vdots \\ \frac{\partial}{\partial x_n} \end{pmatrix} \cdot \begin{pmatrix} F_1 \\ \vdots F_n
\end{pmatrix} = \sum_{i=1}^n \frac{\partial F_i}{\partial x_i}\]
where $\cdot$ is the Euclidean dot product and $\nabla$ is the del operator. 
\end{definition}

\begin{example}
The divergence of the origin in the left graph is clearly negative since the net flow is out of the point, while the divergence of the origin in the right graph is positive since the net fluid flow is in. 
\begin{center}
\pgfplotsset{width=7cm,compat=1.16}
\begin{tikzpicture}[scale=0.8]
\begin{axis}[view={0}{90}, domain=-4:4]
\addplot3 [blue,-stealth,samples=16,
        quiver={
            u={2*x/pow(x^2 + y^2,1/2)},
            v={2*y/pow(x^2 + y^2,1/2)},
            scale arrows=0.2,
        },
    ] { 1};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture}[scale=0.8]
\begin{axis}[view={0}{90}]
\addplot3 [blue,-stealth,samples=16,
        quiver={
            u={-2*x/pow(x^2 + y^2,1/2)},
            v={-2*y/pow(x^2 + y^2,1/2)},
            scale arrows=0.2,
        },
    ] { 1};
\end{axis}
\end{tikzpicture}
\end{center}
\end{example}

\begin{definition}[Divergence of Tensor Fields]
Let $A$ be a $C^1$ second-order tensor field; that is, it assigns a tensor to every point in Euclidean space, defined as 
\[A = \begin{pmatrix}
A_{11} & A_{12} & A_{13} \\ 
A_{21} & A_{22} & A_{23} \\
A_{31} & A_{32} & A_{33}
\end{pmatrix}\]
the divergence in a Cartesian coordinate system is a first-order tensor field and can be defined 
\[\Div A = \begin{pmatrix}
\frac{\partial A_{11}}{\partial x_1} + \frac{\partial A_{12}}{\partial x_2} + \frac{\partial A_{13}}{\partial x_3} \\
\frac{\partial A_{21}}{\partial x_1} + \frac{\partial A_{22}}{\partial x_2} + \frac{\partial A_{23}}{\partial x_3} \\
\frac{\partial A_{31}}{\partial x_1} + \frac{\partial A_{32}}{\partial x_2} + \frac{\partial A_{33}}{\partial x_3}
\end{pmatrix}\]
\end{definition}

\begin{definition}[Divergence in Cylindrical, Spherical Coordinates]
For vector field $F: \mathbb{R}^3 \longrightarrow \mathbb{R}^3$ expressed in cylindrical coordinates as 
\[F = \begin{pmatrix}
F_r \\ F_\theta \\ F_z
\end{pmatrix}\]
the divergence is
\[\Div F = \nabla \cdot F = \frac{1}{r} \frac{\partial}{\partial r} \big(r F_r \big) + \frac{1}{r} \frac{\partial F_\theta}{\partial \theta} + \frac{\partial F_z}{\partial z}\]
Note that the condition of locality is important, since in general a global cylindrical coordinate system would be inconsistent. 

In spherical coordinates $(r, \theta, \phi)$, the divergence is 
\[\Div F = \nabla \cdot F = \frac{1}{r^2} \frac{\partial}{\partial r} \big( r^2 F_r) + \frac{1}{r \, \sin{\theta}} \frac{\partial}{\partial \theta} \big( \sin{\theta} F_\theta\big) + \frac{1}{r\, \sin{\theta}} \frac{\partial F_\phi}{\partial \phi}\]
\end{definition}

\subsubsection{Coordinate Definition of Curl}
Colloquially, the curl is a vector operator that describes the infinitesimal circulation of a vector field in $3$-dimensional Euclidean space, where the curl at each point is represented by a vector whose length and direction denote the magnitude and axis as the maximum circulation. 

That is, if one drops a twig or a ball with its center of mass at a certain point, the curl measures how much it will spin. In physics, the rotation of a rigid body in 3-dimensions can be described by a vector $\omega$ along the axis of rotation. $\omega$ is called the \textit{angular velocity vector}, with $||\omega||$ denoting the angular speed of the body. The curl of this vector field measured at the center of mass of the body is measured as $2 \omega$. That is, the curl outputs \textit{twice} the angular velocity vector of any rigid body. 

Furthermore, if $\curl{F}(x_0) = 0$, then this indicates that there are no "whirlpools" at $x_0$, meaning that any rigid body placed at $x_0$, while it may travel along a path, will not rotate around its own axis. Such a vector field $F$ with this property is called \textit{irrotational}. 

\begin{definition}
The \textit{curl} of a 3-dimensional $C^k$ vector field $F: \mathbb{R}^3 \longrightarrow \mathbb{R}^3$ is an operator
\[\curl: C^k (\mathbb{R}^3; \mathbb{R}^3) \longrightarrow C^{k-1} (\mathbb{R}^3; \mathbb{R}^3)\]
defined
\[\curl{F} \equiv \nabla \times F \equiv \begin{pmatrix}
\frac{\partial}{\partial x} \\ \frac{\partial}{\partial y}\\ \frac{\partial}{\partial z} \end{pmatrix} \equiv \begin{pmatrix}
\frac{\partial F_3}{\partial y} - \frac{\partial F_2}{\partial z} \\
\frac{\partial F_1}{\partial z} - \frac{\partial F_3}{\partial x} \\
\frac{\partial F_2}{\partial x} - \frac{\partial F_1}{\partial y}
\end{pmatrix}\]
\end{definition}

Note that unlike the gradient and divergence operators, curl does not generalize as simply to other dimensions. 

\begin{definition}
A vector field $F$ is \textit{irrotational} if 
\[\curl{F} = 0\]
\end{definition}
It has been shown that fluid draining from a tub is usually irrotational except for right at the center, which is surprising since the fluid itself is "rotating" around the drain. 

\begin{theorem}
For any $C^2$ vector field $F$, 
\[\Div{\curl{F}} = \nabla\cdot (\nabla \times F) = 0\]
That is, the divergence of any curl is 0. 
\end{theorem}
\begin{proof}
Also proved by equality of mixed partials. 
\end{proof}

\begin{definition}
The \textit{Laplace operator}, or \textit{Laplacian}, of a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ is the divergence of the gradient. 
\[\nabla^2 f \equiv \nabla \cdot (\nabla f) \equiv \sum_{i=1}^n \frac{\partial^2 f}{\partial x_i^2}\]
\end{definition}

\subsubsection{Conservative, Solenoidal Vector Fields}
\begin{definition}[Conservative Vector Fields]
A vector field $F: U \subset \mathbb{R}^n \longrightarrow \mathbb{R}^n$ is a \textit{conservative vector field} if and only if there exists a scalar field $f: U \subset \mathbb{R}^n \longrightarrow \mathbb{R}$ such that 
\[F = \nabla f\]
on $U$. 
\end{definition}

Conservative vector fields appear naturally in mechanics: they are vector fields representing forces of physical systems in which energy is conserved. 

\begin{theorem}
Given a $C^2$-function $f: \mathbb{R}^3 \longrightarrow \mathbb{R}$,
\[\nabla \times ( \nabla f) = 0\]
That is, the curl of any gradient vector field is the zero vector. 
\end{theorem}
\begin{proof}
$\nabla \times \nabla f$ can be expanded to
\[\bigg( \frac{\partial^2 f}{\partial y \partial z} - \frac{\partial^2 f}{\partial z \partial y}, \; \frac{\partial^2 f}{\partial z \partial x} - \frac{\partial^2 f}{\partial x \partial z}, \; \frac{\partial^2 f}{\partial x \partial y} - \frac{\partial^2 f}{\partial y \partial x}\bigg) = (0, 0, 0)\]
by equality of mixed partials. 
\end{proof}

\begin{definition}[Solenoidal Vector Fields]
A \textit{solenoidal, or incompressible, vector field} is a vector field $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ such that
\[\Div F = \nabla \cdot F = 0\]
at all point in the field. That is, the field has no sources or sinks. 
\end{definition}

\begin{example}
The vector field $F: (x, y) \mapsto (y, -x)$ is solenoidal. 
\begin{center}
    \includegraphics[scale=0.17]{Solenoidal_vector_field.png}
\end{center}
\end{example}

\subsection{Differentials of Functions}
Note that differentials of functions are not to be confused with differential forms. 
\subsubsection{One Variable Functions}
Given a continuous real valued function $f: \mathbb{R} \longrightarrow \mathbb{R}$, let the parameter for the input be labeled $x$ and the output parameter be labeled with the variable $y$. This is conventional, leading to the well known expression 
\[y = f(x)\]
Now, note that even though the function itself is $f$, we can choose to represent its output values with either $f$ or $y$. 

\begin{definition}
A given change in $x$ is denoted $\Delta x$. Given that the input value changes by $\Delta x$ (i.e. the input changes from $x \rightarrow x + \Delta x$), the change in the output is denoted with $\Delta y$. That is,
\[\Delta y \equiv f(x + \Delta x) - f(x)\]
\end{definition}
Note that the behavior of $\Delta y$ is completely independent from $\Delta x$. We cannot assume that, for example, an increase in $x$ (i.e. $\Delta x > 0$) corresponds to an increase in $y$. Note that $\Delta y$ is really a function of two independent variables, which is $x$ (the initial point where the change happens) and $\Delta x$ (how much $x$ is changing). That is,
\[\Delta y (x, \Delta x) \equiv f(x + \Delta x) - f(x)\]

Now we continue to introduce the differential. 

\begin{definition}
An \textit{infinitesimal} is a real number $\epsilon > 0$ such that $\epsilon$ is less than any real positive number. It can also be defined as a positive real number $\epsilon$ such that
\[\epsilon < \frac{1}{n} \text{ for all } n \in \mathbb{N}\]
\end{definition}

Since $f \in C^0 \mathbb{R}$, we can assume that an infinitesimal change in input value $\Delta x$  corresponds to an infinitesimal change in output value $\Delta y$. This infinitesimal change is now denoted $d x$ and $d y$, respectively. Therefore, the instantaneous rate of change of $y$ (or $f$) with respect to the change of $x$ is really just the ratio of the infinitesismal changes of both $x$ and $y$. This is denoted by the fraction 
\[\frac{d y}{d x} \equiv \lim_{\Delta x \rightarrow 0} \frac{ \Delta y}{\Delta x}\]
This is precisely the \textit{Leibniz Notation} of the derivative of a function $f$. Note that the quotient $d y / d x$ is not infinitesimally small, but it is rather a real number. 

\begin{definition}
The \textit{differential} of a function $f$ of a single real variable $x$ is the linear function $d f$ of two independent variables $x$ and $\Delta x$ given by 
\[d y \equiv d f \equiv d f (x, \Delta x) \equiv f^\prime (x) \, \Delta x\]
Note that since $y$ and $f$ both denote the ouput of the function $f$, we can use them iterchangeably in this notation. Note also that $f^\prime (x)$ is just the derivative of $f$ with respect to $x$. Note that since 
\[d x (x, \Delta x) \equiv \Delta x\]
it is conventional to substitute $\Delta x = d x$ to get the equivalent expression 
\[d f \equiv f^\prime (x) \, dx \text{ or } d y \equiv \frac{d y}{d x} d x\]
\end{definition}

Note that the differential of $f$ of a point $x$ is a linear approximation of $f$ at the point $x$ since $d f$ is linear and the error bound $\epsilon$ of the equality 
\[\Delta y = f^\prime (x) \, \Delta x + \epsilon = d f(x) + \epsilon\]
satisfies 
\[\lim_{\Delta x \rightarrow 0} \frac{\epsilon}{\Delta x} = \lim_{\Delta x \rightarrow 0} \frac{ \Delta y - d y}{\Delta x} = 0\]
$\implies d y \approx \Delta y$, where we can make the approximation arbitrarily small by constraining $\Delta x$ to be sufficiently small. Therefore, the differential of a function is known as the \textit{principal (linear) part} in the increment of a function. That is, $d f$ is linear with respect to $d x$, the increment (but not with respect to $x$ itself. Although the error $\epsilon$ may be nonlinear, it tends to $0$ rapidly as $\Delta x$ tends to $0$. 
\\

We can visually compare the secant line and the differential of an arbitrary function. We can plot the graph of $f$ as the set
\[l \equiv \{\big( x, f(x)\big) \in \mathbb{R} \oplus \mathbb{R}\} \subset \mathbb{R}^2\]
and observe the unqiue secant line that connects the two points $\big( x, f(x)\big)$ and $\big(x + \Delta x, y + \Delta y \big) = \big( x + \Delta x, f(x + \Delta x)\big)$. This line is labeled in blue. The differential, on the other hand, is labeled in red. 
\begin{center}
\begin{tikzpicture}[scale=0.7]
\begin{axis}[
    axis lines = left,
    xlabel = $x$,
    ylabel = {$y$},
    xmin=0,
    xmax=4,
    ymin=0,
    ymax=30,]
\addplot [
    domain=0:10,
    samples=100, ]
{x^3 + 5};
\addplot [
    domain=0:10,
    samples=100, 
    color=red]
{6.75*(x-1.5) + 8.375};
\addplot [
    domain=0:10,
    samples=100, 
    color=blue]
{10.6875*(x-1.5) + 8.375};
\coordinate[label={150:$(x, y)$}] (x, y) at (axis cs:1.5,8.375);
\coordinate[label={130:$(x+\Delta x, y+\Delta y)$}] (A) at (axis cs:2.25, 16.3901);
\coordinate[label={-80:$(x + \Delta x, x + d y)$}] (B) at (axis cs:2.25, 13.4375);
\draw (A) -- (B);
\coordinate[label={0:$\epsilon = \Delta y - d y$}] (C) at (axis cs:2.25, 15.3);
\addplot[only marks] table {
1.5 8.375
2.25 16.3901
2.25 13.4375
};
\coordinate[label={-60:$l$}] (D) at (axis cs:3.2, 27);
\coordinate[label={0:$d y$}] (E) at (axis cs:3.5, 21);
\end{axis}
\end{tikzpicture}
\end{center}

\subsubsection{Multivariable Functions}
\begin{definition}
For functions $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ in the form 
\[y = f(x_1, x_2, ..., x_n)\]
the \textit{partial differential} of $y$ (or $f$) with respect to any one of the variables $x_i$ is the principal part of change in $y$ resulting in the change $d x_1$. Therefore, the partial differential is 
\[\frac{\partial f}{\partial x_1} d x_1\]
where $\partial f / \partial x_1$ is the partial derivative of $f$. The sum of all the partial differentials is called the \textit{total differential} of $f$. 
\[d y = \frac{\partial y}{\partial x_1} \,d x_1+ \frac{\partial y}{\partial x_2} \,d x_2 + ... + \frac{\partial y}{\partial x_n} \,d x_n\]
\end{definition}
More precisely, in vector calculus, if $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ is a differentiable function, then by definition of differentiability (i.e. a linear approximation exists), 
\begin{align*}
    y & \equiv f(x_1 + \Delta x_1, x_2 + \Delta x_2, ..., x_n + \Delta x_n) - f(x_1, x_2, ..., x_n) \\
    & \equiv \frac{\partial f}{\partial x_1}\, d x_1 + \frac{\partial f}{\partial x_2} \, d x_2 + ... + \frac{\partial f}{\partial x_n} \, d x_n + \epsilon_1 \Delta x_1 + ... + \epsilon_n \Delta x_n
\end{align*}
where the $\epsilon_i$ can be made arbitrary close to $0$ by constraining $\Delta x_i$ to $0$. Similar to the one variable case,  we can therefore see that $d y \approx \Delta y$.

\section{Integration}

\subsection{Geometric Interpretations of Integration}
The concept of integration in one variable calculus limits the applicability of the operation to finding only areas of functions under curves. We will replace the reader's intuition of integration with the following description. Given a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, we interpret it as a scalar field that assigns a "weight" to each point in $\mathbb{R}^n$. Now, given any "shape" $B$ in $\mathbb{R}^n$ that is closed (but not necessarily bounded), an integral can calculate the "weighed" volume of $B$ by cutting $B$ into infinitesimally small points, multiplying them by their respective weights determined by $f$, and then summing up the weighed points. Integrating $B$ in $\mathbb{R}$, $\mathbb{R}^2$, and $\mathbb{R}^3$ with a constant scalar field equal to $1$ is equivalent to finding the length, area, and volume of $B$, respectively. We deconstruct specific types of iterated integrals. 

\subsubsection{Single Integral as Weighed Length or Area}
A single integral is calculated from a function $f: \mathbb{R} \longrightarrow \mathbb{R}$. Given some intervals (or a collection of intervals) $B \subset \mathbb{R}$, the integration notation is familiar to us. 
\[\int_B f(x) \; d x\]
We can interpret this integration in two ways. First, we imagine that the function $f$ is a scalar field in $\mathbb{R}$. Therefore, every point $x$ in $\mathbb{R}$ has a certain real number $f(x)$ associated to it. Therefore, the interval $B \in \mathbb{R}$ now consists of points that now have different densities each (which can be negative). The entire $B$ can now be thought of as a 1-dimensional "rod" in $\mathbb{R}$ that has an uneven distribution of mass determined by $f$. The total mass of the rod $B$ is calculated by the integral. In the diagram below, we use different "thickness" to represent different densities. 
\begin{center}
    \includegraphics[scale=0.3]{Integral_As_Stick_with_Density.PNG}
\end{center}
Secondly, we can visualize the entire graph of $f$ in $\mathbb{R} \oplus \mathbb{R}$. This represents a curve in the $x y$-axis that most beginner calculus students are familiar with. Note that the interval $B$ exists in the x-axis, and in this case, the "weight" of each point $x$ in $B$ is represented as the "height" of the infinitesimally thin bar at $x$. It is easy to see that the weight of the rod at point $x$ and the height of the bar at point $x$ are really the same measure determined by $f$. Therefore, the density distribution in the rod is now modeled as the height of the function at each point. Calculating the integral of this function now calculates the "area" under the curve.

It is important to point out that $B$ does not necessarily need to be a length in the form of $[a,b]$. It can be any union of disjoint lengths, too. However, adding a finite number of single points to $B$ will not affect the integral. It is also customary for $B$ to be closed. 

\subsubsection{Double Integral as Weighed Area or Volume}
The double integral is calculated from function $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$. Given a certain closed subset $B \subset \mathbb{R}^2$, the integration notation is
\[\iint_B f(x, y) \; d A\]

Again, we can interpret double integration in two ways. First, we think of $f$ as a scalar field assigning a density to every point in $\mathbb{R}^2$. Then, the 2-dimensional shape $B$ itself should have a certain density distribution on it determined by $f$. The double integral above then determines the mass of $B$. 

The second way to interpret this is to imagine the 2-dimensional shape $B$ lying in the extended space $\mathbb{R}^2 \oplus \mathbb{R}$. We then model the density distribution as merely the height of the infinitesimally thin bar at each point $x$. Again, the height of this bar at $x$ is precisely its density described in the first interpretation. Therefore, integrating this shape is equivalent to finding the volume of the infinite union of the infinitesimally thin bars at each point in $B$. 
\\

Note again that $B$ need not be one solid region. It can be a union of multiple disjoint ones. However, adding a single point $p$ or a 1-dimensional path $p$ to $B$ will not affect the integral since they have an area of $0$.

\subsubsection{Triple Integral as Weighed Volumes or Hyper-Volumes}
The double integral is calculated from function $f: \mathbb{R}^3 \longrightarrow \mathbb{R}$. Given a certain closed subset $B \subset \mathbb{R}^3$, the integration notation is
\[\iiint_B f(x, y, z) \; d V\]
Following the logic of the previous two examples, the function $f$, interpreted as a scalar field, assigns a scalar at each point $x$ in the solid $B$. Therefore, we can visualize $B$ as a solid, 3-dimensional object in $\mathbb{R}^3$ with a certain density distribution defined by $f$. The total mass of $B$ is therefore determined by the triple integral above.

Following similar logic, we can interpret this integral as the hypervolume of a 4 dimensional object, but this is not often used. 

\subsection{Reduction to Iterated Integrals}
We first state a basic condition of integration. 

\begin{theorem}
Any function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ that is continuous over a certain region $B \subset \mathbb{R}^n$ can be integrated over $B$. 
\end{theorem}
That is, if $f$ is discontinuous at a certain subset $D \subset B$, then the infinitesimal neighborhoods around each point $d \in D$ is not well defined, since they would always contain two values of $f$ that do not converge to each other at $d$. 

However, there are some discontinuous functions that are in fact integrable. Assuming $B \subset \mathbb{R}^n$ is the region that we are integrating over, 
\begin{enumerate}
    \item Given that there is a subset $N$ in $B$ with volume $0$ over which $f$ is not defined, we can integrate over $B \setminus N$. In the one and two dimensional cases, 
    \[\int_{B \setminus N} f(x) dx \text{ and } \iint_{B\setminus N} f(x) dA\]
    are well-defined. Visually, 
    \begin{center}
        \includegraphics[scale=0.2]{Integrable_Hole_Function.jpg}
    \end{center}
    \item The function is defined for all values in the region, but there is a jump in the value of the function. 
    \begin{center}
        \includegraphics[scale=0.23]{Integrable_Jump_Function.PNG}
    \end{center}
\end{enumerate}
Informally, if we can visualize the Riemann sum converging to a well-defined area as the rectangles get thinner and thinner, then a discontinuous function is integrable. Indeed, all continuous functions (over a bounded set) are integrable since their Riemann sums are well defined. 

\subsubsection{Integration over Intervals, Rectangles, Boxes}
The simplest region that we can integrate over is a single interval 
\[B \equiv [a,b] \subset \mathbb{R}\]
a rectangle 
\[B \equiv [a, b] \times [c,d] \subset \mathbb{R}^2\]
and a box 
\[B \equiv [a,b] \times [c,d] \times [e,f] \subset \mathbb{R}^3\]
Clearly, this extends to integration over any dimension. 
\[B \equiv \prod_{i=1}^n [\alpha_i, \beta_i] \subset \mathbb{R}^n\]

Solving these integrals are quite simple. However, to rigorously define the methodology, we must use the following theorems. 

\begin{theorem}[Cavalieri's Principle]
Let $S$ be a bounded $n$-dimensional solid in $\mathbb{R}^n$ (note that $S$ can be an interval in $\mathbb{R}$). Define an $n-1$ subspace $P$ in $\mathbb{R}^n$ and given the quotient space $\mathbb{R}^n / P$ with elements $P_x$, let 
\[S \subset \bigcap_{a \leq x \leq b} P_x\]
That is, $S$ is "in between" affine subspaces $P_a$ and $P_b$. The cross section of $S$ cut by $P_x$ is the intersection of it with $S$
\[\text{Cross Section at } P_x \equiv P_x \cap S\]
Denote the area of this cross section as $A(x)$. Then, 
\[\text{Volume of } S = \int_a^b A(x) \; d x\]
\end{theorem}
This theorem basically says that the volume of $S$ is the sum of the areas of its infinitesimal cross sections. 
\begin{center}
    \includegraphics[scale=0.27]{Cavalieri_Principle .PNG}
\end{center}
This clearly works for an interval in $\mathbb{R}$, which is computed by the sum of all its "points" (rigorously speaking, infinitesimally thin intervals). The integral works for a shape in $\mathbb{R}^2$, which is computed by the sum of its "line segments" (rigorously speaking, infinitesimally thin rectangles) that add up to the shape. In $\mathbb{R}^3$, the solid is computed by the sum of its cross sections (infinitesimally thin "molded" cylinders). This analogy continues into higher dimensions. 
\\

Given a solid $S \subset \mathbb{R}^n$, it is easy to see that no matter what subspace $P$ we choosethat is, no matter what orientation we choose to "cut" the solid the sum of all of its cross sections should be equal to the true volume of $S$. In the case when $S$ is a box in $\mathbb{R}^n$, Fubini's theorem states that whether we cut $S$ up along the $x_1$-axis, $x_2$-axis, ..., or the $x_n$-axis, the symmetry in volume is always preserved. This theorem is really just a specific case of this general symmetry in volume. 

\begin{theorem}[Fubini's Theorem]
Given a function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, let 
\[B \equiv \prod_{i=1}^n [\alpha_i, \beta_i]\]
and let 
$p$ be any permutation of the elements $\{x_1, x_2, ..., x_n\}$. Then 
\begin{align*}
    \int_B f \; d V & = \int_{\alpha_n}^{\beta_n} ... \int_{\alpha_1}^{\beta_1} f(x_1,x_2,...,x_n) \; d x_1 ... d x_n \\
    & = \int_{p(\alpha_n)}^{p(\beta_n)} ... \int_{p(\alpha_1)}^{p(\beta_1)} f(x_1,x_2, ..., x_n) \; d p(x_1) ... d p(x_n) 
\end{align*}
In the two dimensional case, we have
\begin{align*}
    \iint_B f \; d A & = \int_c^d \int_a^b f(x, y) \; d x \, d y = \int_a^b \int_c^d f(x, y) \; d y \, d x 
\end{align*}
\begin{center}
    \includegraphics[scale=0.27]{Fubini_Theorem.PNG}
\end{center}
In the three dimensional case, we have
\begin{align*}
    \iiint_B f \; d V & 
    = \int_e^f \int_c^d \int_a^b f(x, y, z) \; d x \, d y \, d z = \int_e^f \int_a^b \int_c^d f(x, y, z) \; d y \, d x \, d z \\
    & = \int_c^d \int_a^b \int_e^f f(x, y, z) \; d z \, d x \, d y = \int_c^d \int_e^f \int_a^b f(x, y, z) \; d x \, d z \, d y \\
    & = \int_a^b \int_e^f \int_c^d f(x, y, z) \; d y \, d z \, d x = \int_a^b \int_c^d \int_e^f f(x, y, z) \; d z \, d y \, d x 
\end{align*}
\end{theorem}

Computation of these integrals is simple. You do the innermost integral first with respect to the corresponding variable, while treating the rest of the variables constant. Evaluating each integral outputs a formula for a higher dimensional cross section of the solid $S$. It is clear that computing iterated integrals is really just doing Cavalieri's principle repeatedly. 

\subsubsection{Integration over Solids Bounded by Curves}
We must first define the different types of \textit{elementary regions} first. 
\begin{definition}
A bounded region $D$ in $\mathbb{R}^n$ is said to be $x_i$-simple if it is bounded by the graphs of two continuous functions $u_1, u_2: \mathbb{R}^{n-1} \longrightarrow \mathbb{R}$ of the variables 
\[x_1, x_2, ..., x_{i-1}, x_{i+1}, ..., x_n\]
That is, $D$ can be expressed in the form 
\[\{ x \in \mathbb{R}^n \; | \; u_1 (x_1,..., x_{i-1}, x_{i+1}, ... , x_n) \leq x_i \leq u_2 (x_1, ..., x_{i-1}, x_{i+1}, ..., x_n)\}\]
If a region is simple in all of its variables, it is simply called \textit{simple}. Note that $n$-dimensional boxes are simple regions. 
\end{definition}

\begin{example}
In $\mathbb{R}^2$, the region on the left graph is an $y$-simple region and the region on the right is a $x$-simple region. \\
\begin{center}
\begin{tikzpicture}[scale=0.8]
    \draw[<->] (-1,0)--(5,0);
    \draw[<->] (0,-1)--(0,5);
    \draw[<->] (6,0)--(12,0);
    \draw[<->] (7,-1)--(7,5);
    \draw plot [smooth] coordinates {(0.6, 1.2) (1,1) (2,1.4) (3,1.3) (4,1.5) (4.3,1.7)};
    \draw plot [smooth] coordinates {(0.6, 3.9) (1,4.1) (2,4) (3,4.3) (4,4.2) (4.3,4.1)};
    \draw[dashed] (0.6,1.2)--(0.6,3.9);
    \draw[dashed] (4.3,1.7)--(4.3,4.1);
    \draw plot [smooth] coordinates {(8.2,0.6) (8,1) (8.4,2) (8.3,3) (8.5,4) (8.7,4.3)};
    \draw plot [smooth] coordinates {(10.9,0.6) (11.1,1) (11,2) (11.3,3) (11.2,4) (11.1,4.3)};
    \draw[dashed] (8.2,0.6)--(10.9,0.6);
    \draw[dashed] (8.7,4.3)--(11.1,4.3);
    \node[below] at (4.8,0) {$x$};
    \node[below] at (11.8,0) {$x$};
    \node[left] at (0,4.8) {$y$};
    \node[left] at (7,4.8) {$y$};
    \node[above] at (3,4.2) {$u_1$};
    \node[above] at (3,1.3) {$u_2$};
    \node[left] at (8.3, 3) {$v_1$};
    \node[right] at (11.3, 3) {$v_2$};
    \draw[fill] (0.6,0) circle (0.05);
    \node[below] at (0.6,0) {$a$};
    \draw[fill] (4.3,0) circle (0.05);
    \node[below left] at (4.3,0) {$b$};
    \draw[fill] (7,0.6) circle (0.05);
    \draw[fill] (7,4.3) circle (0.05);
    \node[left] at (7,0.6) {$c$};
    \node[left] at (7,4.3) {$d$};
\end{tikzpicture}
\end{center}
\end{example}
We now describe the method of calculating double integrals over elementary regions. 
\begin{theorem}
The double integral over a $y$-simple region $D$ bounded by functions $u_1$ and $u_2$ in $\mathbb{R}^2$ and the $x$-values $a$ and $b$ (as shown in the left graph of example 2.1) is
\[\iint_D f(x, y) = \int_a^b \int_{u_2 (x)}^{u_1 (x)} f(x, y) \, dy \, dx\]
The double integral over an $x$-simple region $D$ bounded by functions $v_1$ and $v_2$ in $\mathbb{R}^2$ and the $y$-values $c$ and $d$ (shown in the right of graph of example 2.1) is 
\[\iint_D f(x, y) = \int_c^d \int_{v_2 (y)}^{v_1 (y)} f(x, y) \, dx \, dy\]
\end{theorem}

\begin{example}
Integrating $f(x, y)$ over the unit disk would have the form
\[\int_{-1}^1 \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} f(x,y) \, dy\, dx \text{ or } \int_{-1}^1 \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}} f(x,y) \, dx\, dy \]
Note that the unit disk is both $x$ and $y$ simple. 
\end{example}
\subsection{Change of Basis}
Sometimes, integrating a region over a different basis would make the integral computation much more simpler. In this case, we may be able to transform more complicated regions into elementary regions. We first introduce a change of basis in 2 dimensions and then generalize it into higher dimensions. 
\\
Let $\mathbb{R}^2$ have the standard orthonomal basis $e_1, e_2$, commonly known as the $x, y$ basis. Now, let us construct new basis vectors of $\mathbb{R}^2$, denoted $f_1, f_2$ such that $f_1, f_2$ are functions of $e_1, e_2$. Since they are both bases that span $\mathbb{R}^2$, we can equally represent $e_1, e_2$ as functions of $f_1, f_2$. 
\begin{align*}
    &e_1 = g(f_1, f_2)\\
    &e_2 = h(f_1, f_2) 
\end{align*}
Note that this change of basis does not necessarily have to be linear, as in the context of passive transformation in linear algebra. Then, every point $(x,y)$ in the $(e_1, e_2)$-basis can be rewritten as
\begin{align*}
    (x, y) & = x e_1 + y e_2 \\
    & = x \, g(f_1, f_2) + y \, h(f_1, f_2) \\
    & = u f_1 + v f_2
\end{align*}
Note that it is customary to denote $x, y$ as the coefficients in the $e_1, e_2$ basis and $u, v$ as the coefficients in the new $f_1, f_2$ basis. This way, we can not only write $e_1$ and $e_2$ as functions of $f_1$ and $f_2$, but we can also write the coefficents $x, y$ as functions of the coeffiecents $u, v$! That is, 
\begin{align*}
    & x = x(u, v) \\
    & y = y(u, v)
\end{align*}
which is really just a function 
\[B: \mathbb{R}^2 \longrightarrow \mathbb{R}^2, \;\; B(u, v) = \begin{pmatrix} x(u, v) \\ y(u, v) \end{pmatrix}\]
Notice that $B$ changes the $u, v$ coordinates to the $x, y$ coordinates, and $B^{-1}$ changes the $x, y$ coordinates to the $u, v$ coordinates. 
\[B^{-1}: \mathbb{R}^2 \longrightarrow \mathbb{R}^2, \;\; B^{-1} (x, y) = \begin{pmatrix} u (x, y) \\ v (x, y) \end{pmatrix}\]
Note that these coefficients actually change \textit{contravariantly}, that is, they change inversely with respect to how the basis vectors are changed. In vector calculus, it is conventional to represent a change of basis with functions that relate the coefficients $x, y$ with $u, v$, rather than the bases $f_1, f_2$ with $e_1, e_2$. 

\begin{theorem}[Integration over Change of Bases in $\mathbb{R}^2$]
Let $\mathbb{R}^2$ have the standard orthonomal basis $e_1, e_2$. Now, let us construct new basis vectors of $\mathbb{R}^2$, denoted $f_1, f_2$ such that the coefficients of the vectors in $\mathbb{R}^2$ are related by the change of basis function 
\[B = \begin{pmatrix} x \\ y \end{pmatrix} \implies B(u, v) = \begin{pmatrix} x(u, v) \\ y(u, v) \end{pmatrix}\]
Given region $D \subset \mathbb{R}^2$ and $S = B(D)$ is the region transformed by $B$, the integral of function $f(x, y)$ over region $D$ can be expressed as 
\[\iint_D f(x, y) \, dA = \iint_S f \big( x(u, v), y(u, v) \big) \, \big| J B(u, v) \big| \, d \bar{A}\]
where $\big| J B(u, v) \big|$ is the determinant of the Jacobian matrix of $B$. Expanding the Facobian determinant gives
\[\big| J B(u, v) \big| = \frac{\partial x}{\partial u} \frac{\partial y}{\partial v} - \frac{\partial x}{\partial v} \frac{\partial y}{\partial u}\]
\end{theorem}

\begin{theorem}[Integration over Change of Bases in $\mathbb{R}^3$]
Given that we have the change of basis function 
\[B: \mathbb{R}^3 \longrightarrow \mathbb{R}^3, \;\;\; B(u, v, w) = \begin{pmatrix} x(u, v, w) \\ y(u, v, w) \\ z(u, v, w) \end{pmatrix}\]
a region $D \in \mathbb{R}^3$ and $S = B(D)$, the region transformed by $B$, the integral of $f(x, y, z)$ over region $D$ can be expressed as 
\[\iiint_D f(x, y, z)\, dV = \iiint_S f\big( x(u, v, w), y(u, v ,w), z(u, v, w) \big) \big| J B (u, v, w)\big| \, d \bar{V}\]
where $\big| J B (u, v, w)\big|$ is the Jacobian determinant of $B$. 
\end{theorem}

\begin{example}
Given a real-valued function $f$ defined over the region $D \subset \mathbb{R}^2$, we can perform a change of basis of the $x, y$ coordinates into polar ones within a new region $S$. The change of basis 
\begin{align*}
    & x = r \cos{\theta} \\
    & y = r \sin{\theta} 
\end{align*}
\begin{center}
\begin{tikzpicture}
    \draw[thick, fill=lightgray] (7.5,2) circle (1.5);
    \draw[<->] (-1,0)--(3,0);
    \draw[<->] (0,-1)--(0,5);
    \draw[thick, fill=lightgray] (0,0) rectangle (2,4);
    \node at (1,2) {$S$};
    \draw[fill] (0,4) circle (0.05);
    \draw[fill] (2,0) circle (0.05);
    \node[below] at (2,0) {$1$};
    \node[left] at (0,4) {$2 \pi$};
    \node[above] at (3,0) {$r$};
    \node[right] at (0,5) {$\theta$};
    \draw[->] (2.5, 2)--(5,2);
    \node[above] at (4,2.5) {$T: (r, \theta) \mapsto$};
    \node[above] at (4,2) {$ (r \cos{\theta}, r \sin{\theta})$};
    \draw[<->] (5.5,2)--(9.5,2);
    \draw[<->] (7.5,0)--(7.5,4);
    \node at (8,2.5) {$D$};
\end{tikzpicture}  
\end{center}
\end{example}

\begin{theorem}[Integration over Change of Bases in $\mathbb{R}^n$]
Let $\mathbb{R}^n$ have the standard orthonormal basis $e_1, e_2, ..., e_n$, and let us construct a new basis $f_1, f_2, ..., f_n$ such that the coefficients of the vectors in $\mathbb{R}^n$ are related with the functions
\[B: \mathbb{R}^n \longrightarrow \mathbb{R}^n, \;\;\;\; B(u_1, u_2, \ldots, u_n) = \begin{pmatrix}
x_1 (u_1, \ldots, u_n) \\x_2 (u_1, \ldots, u_n) \\ \vdots \\ x_n (u_1, \ldots, u_n)
\end{pmatrix}\]
Given that the region $D \subset \mathbb{R}^n$ is transformed into a new region $S = B(D) \subset \mathbb{R}^n$ under this basis transformation, the integral of function $f(x_1, \ldots, x_n)$ over region $D$ can be expressed as 
\[\int_D f(x) \, dH = \int_S f \big( x_1(u), x_2(u), ..., x_n (u) \big) \big| J B(u_1, \ldots, u_n)\big| \, d \bar{H}\]
where the integral on both the left and right hand side represents integration over an $n$-dimensional region, $x$ represents the $n$-tuple $(x_1, \ldots, x_n)$, $u$ represents the $n$-tuple $(u_1, \ldots, u_n)$, and $\big| J B(u_1, \ldots, u_n)\big|$ represents the Jacobian determinant of function $B$. 
\end{theorem}

We now describe some common change of basis formulas for polar, cylindrical, and spherical coordinates. 

\begin{theorem}[Integration in Polar Coordinates]
\[\iint_{D} f(x, y) \, dx \,dy = \iint_S f(r \cos{\theta}, r \sin{\theta}) r \, dr \, d\theta\]
\end{theorem}

\begin{definition}[Cylindrical, Spherical Coordinates]
In $\mathbb{R}^3$, \textit{cylindrical coordinates} have the following relation to rectangular coordinates. 
\begin{align*}
    & x = r \cos{\theta} \\
    & y = r \sin{\theta} \\
    & z = z
\end{align*}
In $\mathbb{R}^3$, \textit{spherical coordinates} have the following relation to rectangular coordinates. 
\begin{align*}
    & x = \rho \sin{\phi} \cos{\theta} \\
    & y = \rho \sin{\phi} \sin{\theta} \\
    & z = \rho \cos{\phi}
\end{align*}
\end{definition}

\begin{corollary}[Integration in Cylindrical Coordinates]
\[\iiint_D f(x, y, z) \, dx \, dy \, dz = \iiint_S f( r \cos{\theta}, r \sin{\theta}, z) r \, dr \, d\theta \, dz\]
\end{corollary}

\begin{corollary}[Integration in Spherical Coordinates]
\[\iiint_D f(x, y, z) \,dx\,dy\,dz = \iiint_S f(\rho \sin{\phi} \cos{\theta}, \rho \sin{\phi} \sin{\theta}, \rho \cos{\phi}) \rho^2 \sin{\theta} \, d\rho \, d\theta \, d\phi\]
\end{corollary}

\begin{example}[Gaussian Integral]
The following is the (un-normalized) probability distribution function of the Gaussian distribution. 
\[\int_{-\infty}^{\infty} e^{-x^2} \, dx = \sqrt{\pi}\]
\end{example}

\subsection{Average Values, Centers of Mass}
\begin{definition}
The \textit{average value} of a function defined over a region $D \subset \mathbb{R}^n$ is 
\[[f]_{av} = \bigg(\int_D f(x) \,d V \bigg) \bigg/ \bigg( \int_D \, d V \bigg) \]
where both integrals represent integration over the $n$-dimensional region $D$. Informally, the integral above represents the infinitesimal sum of all the values of the function $f$ over $D$ and divides it by the hypervolume of $D$ to average it out. More specifically, the average value of $f: \mathbb{R} \longrightarrow \mathbb{R}$ in the interval $[a,b]$ is defined
\[ [f]_{av} = \bigg(\int_a^b f(x) \,d x \bigg) \bigg/ \bigg( \int_a^b \, d x \bigg) = \frac{1}{b-a} \int_a^b f(x) \,d x \]
For a function $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$ over a two dimensional region $D$, we have 
\[[f]_{av} = \bigg(\iint_D f(x, y) \,dx\,dy \bigg) \bigg/ \bigg( \iint_D \, dx\,dy \bigg)\]
For $f: \mathbb{R}^3 \longrightarrow \mathbb{R}$ over a three dimensional region $V$, we have
\[[f]_{av} = \bigg(\iiint_V f(x, y, z) \,dx\,dy\,dz \bigg) \bigg/ \bigg( \iiint_V \, dx\,dy\,dz \bigg)\]
\end{definition}

It is quite easy to get the center of mass of a system of $n$-distinct points in $\mathbb{R}^n$. We can solve each $x_i$ coordinate for the center of mass by averaging out the $x_i$ coordinates scaled by their respective masses. That is, given points $x_1, x_2, ..., x_n$ with respective masses $m_1, ..., m_n$, the center of mass is defined as
\[\bar{x} = \frac{\sum m_i x_i}{\sum m_i}\]

\begin{definition}
Given an $n$-dimensional continuous mass density distribution, denoted $\delta(x)$, defined over a region $D \subset \mathbb{R}^n$, the center of mass of $D$ can be determined through coordinates.
\[\bar{x_i} = \bigg( \int_D x_i \, \delta(x) d V\bigg) \bigg/ \bigg(\int_D \delta(x) d V \bigg), \; i = 1, 2, 3, ..., n\]
Note that $\delta$ must be continuous (in order for it to be integrable). More specifically, the center of mass of a one dimensional interval $I \subset \mathbb{R}$ is
\[\bar{x} = \bigg(\int_I x\, \delta(x) \, dx\bigg) \bigg/ \bigg(\int_I \delta(x) \, dx\bigg)\]
For a two dimensional region (which we can visualize as a "disk" or "plate," the $x$ and $y$ coordinates for the center of mass is
\begin{align*}
    & \bar{x} = \bigg(\iint_D x\, \delta(x, y) \, dx\,dy\bigg) \bigg/ \bigg(\iint_D \delta(x, y) \, dx\,dy \bigg) \\
    & \bar{y} = \bigg(\iint_D y\, \delta(x, y) \, dx\,dy\bigg) \bigg/ \bigg(\iint_D \delta(x, y) \, dx\,dy \bigg)
\end{align*}
For a three dimensional mass, the $x, y, z$ coordinates of the center of mass of volume $V$ can be found with
\begin{align*}
    & \bar{x} = \bigg(\iiint_V x\, \delta(x, y, z) \, dx\,dy\,dz\bigg) \bigg/ \bigg(\iiint_V \delta(x, y, z) \, dx\,dy \,dz\bigg) \\
    & \bar{y} = \bigg(\iiint_V y\, \delta(x, y, z) \, dx\,dy\,dz\bigg) \bigg/ \bigg(\iint_V \delta(x, y, z) \, dx\,dy\,dz \bigg) \\
    & \bar{z} = \bigg(\iiint_V z\, \delta(x, y, z) \, dx\,dy\,dz\bigg) \bigg/ \bigg(\iint_V \delta(x, y, z) \, dx\,dy\,dz \bigg)
\end{align*}
\end{definition}

\subsection{Improper Integrals}
There are generally two types of improper integrals. 
\begin{enumerate}
    \item The region $D$ integrated over is unbounded. 
    \item The function $f$ that is integrated is unbounded within the region $D$.
\end{enumerate}
\subsubsection{Single Variable Improper Integrals}
These types of improper integrals are usually evaluated using a limiting process. When the interval $I$ is unbounded, say $(1, \infty)$, the integral can be evaluated as 
\[\int_1^\infty \frac{1}{x^2} \,dx = \lim_{b \rightarrow \infty} \int_1^b \frac{1}{x^2} \, dx = \lim_{b\rightarrow \infty} \bigg( 1 - \frac{1}{b} \bigg) = 1\]
In case 2, we can add a limit at the point where the function $f$ diverges as such. 
\[\int_0^1 \frac{1}{\sqrt{x}} \, dx = \lim_{a \rightarrow 0} \int_a^1 \frac{1}{\sqrt{x}} \, dx = \lim_{a \rightarrow 0} (2 - 2\sqrt{a}) = 2\]
We now describe how to integrate over a certain path $p$ embedded in a higher dimensional space $\mathbb{R}^n$, possibly with a scalar or vector field $f$. We must first go over oriented paths. 

\subsubsection{Two Variable Improper Integrals}
Extending the previous case, we use a multivariate limiting process in $\mathbb{R}^2$. We will first work with case 2, when $f$ is unbounded within the region $D$. Let us define an elementary region $D$ in $\mathbb{R}^2$; without loss of generality, we will make it $y$-simple, meaning that $D$ can be expressed as
\[D \equiv \{ (x, y) \in \mathbb{R}^2 \; | \; a \leq x \leq b, \; \phi_1 (x) \leq y \leq \phi_2 (x)\}\]
We can actually assume that the region in which $f$ is unbounded lies in the boundary $\partial D$. This is because if it lied in the interior of $D$, we could split $D$ into pieces across a path that intersects this region with divergent values, evaluate the integrals over the pieces separately, and then sum the integrals. For example, in the rectangular region below, let the dashed line represent the values where the function $f$ diverges. Then, we can split the region into two rectangular regions shown in the right. \\
\begin{center}
\begin{tikzpicture}
    \draw (0,0) rectangle (3,2);
    \draw[dashed] rectangle (2,0)--(2,2);
    \draw[->] (3.5,1)--(5,1);
    \draw (8,0)--(6,0)--(6,2)--(8,2);
    \draw[dashed] (8,0)--(8,2);
    \draw[dashed] (9,0)--(9,2);
    \draw (9,0)--(10,0)--(10,2)--(9,2);
\end{tikzpicture}
\end{center}
Therefore, assuming that $f$ is unbounded in $\partial D$, we can construct a new region 
\[D_{\eta, \delta} \equiv \{(x, y) \in \mathbb{R}^2 \; | \; a + \eta \leq x \leq b - \eta, \; \phi_1 (x) + \delta \leq y \leq \phi_2 (x) - \delta\}\]
for some arbitrarily small numbers $\eta, \delta >0$, meaning that the integral (reduced to iterated integrals using Fubini's theorem) 
\[F(\eta, \delta) \equiv \iint_{D_{\eta, \delta}} f(x, y) \, dA = \int_{a + \eta}^{b - \eta} \int_{\phi_1 (x) + \delta}^{\phi_2 (x) - \delta} f(x, y) \, dy\,dx\]
is well defined. 
\begin{center}
\begin{tikzpicture}
    \draw[<->] (-0.5,0)--(5,0);
    \draw[<->] (0,-0.5)--(0,5);
    \draw (1,1.5)--(1,3);
    \draw plot [smooth] coordinates {(1,3) (1.5,3.3) (2,3.1) (3,3.8) (4,4.2) (4.5,4)};
    \draw (4.5, 4)--(4.5,1);
    \draw plot [smooth] coordinates {(1,1.5) (2,1.7) (3, 1.6) (3.7, 1.3) ( 4.5,1)};
    \draw[dashed] (1.3,1.85)--(1.3,2.9);
    \draw[dashed] (4.2, 3.8)--(4.2,1.4);
    \draw[dashed] plot [smooth] coordinates {(1.3,2.9) (1.5,3) (2,2.8) (3,3.5) (4,3.9) (4.2,3.8)};
    \draw[dashed] plot [smooth] coordinates {(1.3,1.85) (2,2) (3, 1.9) (3.7, 1.6) ( 4.2,1.4)};
    \node at (3,2.5) {$D_{\eta, \delta}$};
    \node[below left] at (2,1) {$D$};
    \draw[->] (2,1)--(2.5,1.85);
\end{tikzpicture}
\end{center}
Clearly, the function $F( \eta, \delta)$ is a function of two variables $\eta$ and $\delta$. So, if the limit 
\[\lim_{(\eta, \delta) \rightarrow (0, 0)} F(\eta, \delta)\]
is well defined, then so is the improper integral. For it to exist, the iterated limits must both equal to a well-defined real number $\mathcal{L}$ (and to each other). That is, 
\[\lim_{\eta \rightarrow 0} \lim_{\delta \rightarrow 0} F(\eta, \delta) = \lim_{\delta \rightarrow 0} \lim_{\eta \rightarrow 0} F(\eta, \delta) = \mathcal{L} \implies \lim_{(\eta, \delta) \rightarrow (0,0)} F(\eta, \delta) = \mathcal{L}\]


It is also worthwhile to note that functions unbounded at isolated points can be evaluated using the methods above using a change of basis. Consider the example below. 

\begin{example}
In the unit disk $D \subset \mathbb{R}^2$, let the function $f$ be defined as 
\[f(x, y) \equiv \frac{1}{\sqrt{x^2 + y^2} }\]
Clearly, $f$ is continuous at every point except $0= (0,0)$, meaning that 
\[\iint_{D \setminus \{0\}} f(x, y)\, dA\]
is well-defined. In order to solve the integral over the entire disk, we convert to polar coordinates and evaluate the limit
\[\iint_{D \setminus \{0\}} f(x, y) \, dA = \lim_{\delta \rightarrow 0} \int_{\delta}^1 \int_0^{2 \pi} r \, f( r \cos{\theta}, r \sin{\theta}) \, d\theta \,dr\]
\end{example}
\begin{center}
\begin{tikzpicture}
    \draw[thick, fill=lightgray] (0,0) circle (1.5); 
    \draw[<->] (-2,0)--(2,0);
    \draw[<->] (0,-2)--(0,2);
    \draw[fill=white] (0,0) circle (0.08);
    \draw[->, thick] (2.5,0.5)--(4, 0.5); 
    \draw[<->] (4.5,-1)--(7,-1);
    \draw[<->] (5,-1.5)--(5,2);
    \draw[white, fill=lightgray] (5,-1) rectangle (6.5,1.5);
    \draw[thick] (5,-1)--(6.5,-1)--(6.5,1.5)--(5,1.5);
    \draw[thick, dashed] (5,-1)--(5,1.5);
    \draw[fill] (6.5,-1) circle (0.03);
    \node[below] at (6.5,-1) {$1$};
    \node[left] at (5,1.5) {$2 \pi$};
    \draw[fill] (5, 1.5) circle (0.03);
    \draw[fill] (1.5,0) circle (0.03);
    \draw[fill] (0,1.5) circle (0.03);
    \node[below right] at (1.5,0) {$1$};
    \node[above right] at (0,1.5) {$1$};
\end{tikzpicture}
\end{center}

If we are given an unbounded region $D \subset \mathbb{R}^2$, we can first create a bounded region and expand that region using a limit to cover all of $D$. 

\subsection{Line Integrals}
\begin{definition}[Orientations, Simple Curves, Closed Curves]
A path function $p: [a,b]\subset \mathbb{R} \longrightarrow \mathbb{R}^n$ determines a curve in $\mathbb{R}^n$ with endpoints $p(a)$ and $p(b)$. The direction the curve $p$ takes, that is from $p(a)$ to $p(b)$ in $\mathbb{R}^n$ is called the \textit{orientation} of $p$. A path or a curve with a defined orientation is called an \textit{oriented curve}. 

A \textit{simple curve} $C$ to be the image of an injective piecewise $C^1$ map $c: I \subset \mathbb{R} \longrightarrow \mathbb{R}^3$. Since it is inejctive, it does not intersect itself, and $C$ is piecewise smooth in $\mathbb{R}^n$. If $I = [a,b]$, then $c(a)$ and $c(b)$ are the endpoints of the curve. A simple curve with an orientation is called an \textit{oriented simple curve}. 

A closed curve $C$ is the image of piecewise $C^1$ map $c: [a,b] \longrightarrow \mathbb{R}^n$ such that $c(a) = c(b)$. That is, the endpoints of $C$ are equal. A \textit{simple closed curve} is a closed curve that is injective over the interval $[a,b)$. Note that a closed curve has two possible orientations. 
\end{definition}

If $C$ is an oriented simple curve or an oriented simple closed curve, then we can unambiguously define line integrals along them. 

\begin{definition}
Let $h$ be an injective function that takes $[\alpha,\beta] \subset \mathbb{R}$ to the interval $[a, b] \subset \mathbb{R}$. Given an oriented simple path function $p: [a,b]\subset \mathbb{R} \longrightarrow \mathbb{R}^n$, the composition
\[\rho = p \circ h: [\alpha, \beta] \longrightarrow \mathbb{R}^n\]
is called a \textit{reparamaterization} of $p$. Note that since $h$ is injective, it takes endpoints to endpoints. If $h$ preserves the direction in which the path travels, that is, if 
\[(p \circ h)(\alpha) = a \text{ and } (p \circ h)(\beta) = b\]
then $h$ is \textit{orientation preserving}. If
\[(p \circ h)(\alpha) = b \text{ and } (p \circ h)(\beta) = a\]
then $h$ is \textit{orientation reversing}. Note that a path $c$ having the same image as $p$ does not imply that $c$ is a reparamaterization of $p$, since $c$ may not be injective. 
\begin{center}
    \includegraphics[scale=0.25]{Orientation_Preserving_Reversing.PNG}
\end{center}
\end{definition}

\begin{definition}[Scalar Line Integral]
Let $f: \mathbb{R}^n \longrightarrow \mathbb{R}$, which can be interpreted as a scalar field. Now define a $C^1$ path function 
\[c: [a,b] \subset \mathbb{R} \longrightarrow \mathbb{R}^n \]
such that the composition of functions
\[f \circ c: [a, b] \subset \mathbb{R} \longrightarrow \mathbb{R}^n\]
is continuous. Then, the \textit{path integral}, or \textit{scalar line integral}, of $f$ along the path $c$. is defined
\begin{align*}
    \int_c f \;d s & = \int_a^b f\big(c(t)\big) ||c^\prime (t)|| \;d t \\
    & = \int_a^b f\big( x_1 (t), x_2 (t), ..., x_n (t)\big) ||c^\prime (t)|| \; d t
\end{align*}
If $c(t)$ is only piece-wise $C^1$, we can define the path integral by breaking $[a,b]$ into pieces over with $f\big( c(t)\big) ||c^\prime (t)||$ is continuous and then summing the integrals over the pieces. 
That is, 
\[\int_a^b f\big(c(t)\big) ||c^\prime (t)|| \;d t = \sum_{i = 0}^{n-1} \int_{\alpha_i}^{\alpha_{i+1}} f\big(c(t)\big) ||c^\prime (t)|| \; d t\]
\end{definition}
Note that since $f$ is a scalar-valued function, we can interpret a path integral as the sum of infinitesmal segments of the path $c$ having a weight determined by $f$ at each section. 
If $f$ is a constant function outputting $1$ at every point, then the path integral just outputs the length of the path $c$ in $\mathbb{R}^n$. 
\[L = \int_a^b f\big( c(t)\big) ||c^\prime (t)|| \; d t = \int_a^b ||c^\prime (t)|| \; d t\]

\begin{definition}[Vector Line Integral]
Let $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ be a vector field on $\mathbb{R}^n$ that is continuous on the $C^1$ oriented path $c: [a, b] \subset \mathbb{R} \longrightarrow \mathbb{R}^n$. The \textit{line integral} of $F$ along $c$ is defined by the formula 
\[\int_c F \cdot d s = \int_a^b F\big( c(t)\big) \cdot c^\prime (t) \; d t\]
where $\cdot$ represents the dot product of $F$ with $c^\prime$ over the interval $[a,b]$. It is also commonly written in differential notation, 
\[\int_c F \cdot ds = \int_c F \cdot (dx_1, \ldots, d x_n) = \int_c F_1 dx_1 + F_2 dx_2 + \ldots F_n dx_n\]
\begin{center}
    \includegraphics[scale=0.27]{Vector_Line_Integral.PNG}
\end{center}
 Similarly with path integrals, we can also define line integrals as the sum of integrals over piece-wise continuous sections of $c$. That is, given an oriented curve $C$ made up of several oriented component curves $C_i$, $i = 1, 2, ..., k$, we can paramaterize $C$ by paramaterizing the pieces $C_i$'s separately. Thus, we can treat $C = C_1 + ... C_k$ and get
\[\int_C F \cdot d s = \sum_{i = 1}^k \int_{C_i} F \cdot d s\]
Note that a vector line integral is a generalization of scalar line integrals, so any results holding for vector line integrals also holds for their scalar counterpart. 
\end{definition}

\begin{example}[Work]
In mechanics, work $W$ is defined as 
\[W = F \cdot d\]
where $F$ is force and $d$ is displacement. With this knowledge, the reader can easily see that the work done by vector field $F$ on a particle traveling along a path $c$ from time $a$ to time $b$ can be calculated by the line integral
\begin{align*}
    W & = \int_a^b F\big( c(t)\big) \cdot c^\prime (t) \; d t \\
    & = \int_c F_1 dx + F_2 dy + F_3 dz
\end{align*}
\end{example}

\begin{theorem}[Invariance of Path Paramaterizations on Vector Line Integrals]
Let $F$ be a vector field and $f$ be a scalar field, both continuous on the $C^1$ path function $p: [a,b] \longrightarrow \mathbb{R}^n$ and let $q: [\alpha, \beta] \longrightarrow \mathbb{R}^n$ be a reparamaterization of $p$. Then, 
\begin{align*}
    q \text{ is orientation preserving} & \implies \int_p F \cdot d s = \int_q F \cdot d s \\
    q \text{ is orientation reversing} & \implies \int_p F \cdot d s = - \int_q F \cdot d s
\end{align*}
\end{theorem}

\subsubsection{Conservative Vector Fields}
We now introduce a fundamental theorem about line integrals over gradient fields. Recall the fundamental theorem of calculus and it's equivalent form. 

\begin{theorem}[Fundamental Theorem of Single Variable Calculus]
Let function $\nabla g: \mathbb{R} \longrightarrow \mathbb{R}$ be the gradient of the single variable $C^1$ function $g: \mathbb{R} \longrightarrow \mathbb{R}$; that is, $\nabla g$ is a conservative vector field on $\mathbb{R}$. Then, 
\[\int_a^b \nabla g (x) \,dx = g(b) - g(a)\]
Note that in the single variable case, 
\[\frac{d}{dx} g(x) = \nabla g(x)\]
This means that the value of the integral of $\nabla g$ only depends on the value of $g$ at the endpoints of the interval $[a,b]$. 
\end{theorem}

We can extend this to line integrals for functions mapping $\mathbb{R}^n$ to $\mathbb{R}$. 

\begin{theorem}[Invariance of Line Integrals in Conservative Vector Fields]
Given that $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ is a $C^1$ conservative vector field with $\nabla f = F$ for $C^2$ function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ and path function $p: [a,b] \longrightarrow \mathbb{R}^n$ is a piecewise $C^1$ path, then 
\[\int_p F \cdot d s = \int_p \nabla f \cdot d s = f\big(p(b)\big) - f\big(p(a)\big)\]
That is, the line integral of any path in a conservative vector field is dependent on the value of $f$ at the endpoints $p(a)$ and $p(b)$. 
\begin{center}
    \includegraphics[scale=0.2]{Line_Integral_Independence_of_path.PNG}
\end{center}
\end{theorem}

In physics, calculating the work done by a force represented by a vector field requires us to know the path that it travels through. 
\[W = \int_p F \cdot ds\]
However, in many cases $F$ is assumed to be conservative, so it is only necessary that we find the displacement of the particle from its endpoints, resulting in the simplification of the formula.  
\[W = \int_p \nabla f \cdot ds = f\big( p(b)\big) - f \big(p(a)\big)\]

\begin{corollary}[Equivalent Conditions for Vector Field to be Conservative]
The following conditions are equivalent: 
\begin{enumerate}
    \item $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ is a conservative vector field. 
    \item The line integral of $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ in curve $C$ is path independent; that is, if $C_1$ and $C_2$ are two paramaterizations of $C$, 
    \[\int_{C_1} F \cdot ds = \int_{C_2} F \cdot ds\]
    \item Given that $C$ is a closed loop, the line integral of $F: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ across $C$ is $0$. 
    \[\oint_C F \cdot ds = 0\]
    \item The curl of $F: \mathbb{R}^3 \longrightarrow \mathbb{R}^3$ vanishes
    \[\curl{F} = \nabla \times F = \begin{pmatrix}
    \frac{\partial F}{\partial x} \\\frac{\partial F}{\partial y} \\\frac{\partial F}{\partial z} 
    \end{pmatrix} \times \begin{pmatrix}
    F_1\\F_2\\F_3
    \end{pmatrix}= 0\]
    \item The following partial derivatives of $F: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ are equal
    \[\frac{\partial F_1}{\partial y} = \frac{\partial F_2}{\partial x}\]
\end{enumerate}
\end{corollary}

We can develop a bit of intuition to determine whether a vector field is conservative or not. If vector field $F$ is conservative, then there exists a smooth scalar field $f$ such that $\nabla f = F$. For each latitude and longitude on a certain map, we can give it an altitude as a function of those coordinates (picture a map with a bunch of hills and valleys). The gradient and thus the vector field is all the vectors that point in the direction of highest ascent. he vector field is all the vectors that point in the direction of highest ascent. Extending the metaphor the path integral is like starting on at a point and climbing the hills and valleys, creating work as you go up a hill (proportional to the steepness and thus the dot product of your motion vector with the gradient vector field in the path integral) and decreasing the work you put in by going down a hill. Since the path is closed, it is like you are going up and down the same amount overall, so the path integral is zero. Following this analogy, the vector field determined by this function (marked as arrows in the $x, y$ plane) is conservative. 
\begin{center}
    \includegraphics[scale=0.28]{Conservative_Vector_Field.jpg}
\end{center}
If we can construct a closed loop around $F$ where the line integral is nonzero, then it means that we have ended up at a "higher" or "lower" (altitude) at the same point. This means that rather than being a certain landscape, there exist different "levels" of values at one point, like a spiraling staircase. For example, look at the solenoidal vector field below, where we can construct a closed loop (a circle going around the origin counterclockwise). There is no "surface" that can be defined such that it contains the solenoid. 
\begin{center}
    \includegraphics[scale=0.28]{Solenoid_nonconservative.jpg}
\end{center}
Clearly, as a particle travels through the vector field along the path, it does positive work while it has zero displacement, and clearly, there exists no function that can output both these values as determined by vector field $F$. 

\begin{theorem}[Helmholtz Decomposition]
Let $F: \mathbb{R}^3 \longrightarrow \mathbb{R}^3$ be a $C^2$ vector field. Then, $F$ can be decomposed into a curl-free component and a divergence-free component. That is, there exists vector fields $A$ and $\Phi$
\[F = - \nabla \cdot \Phi + \nabla \times A\]
\end{theorem}

\subsubsection{Curvature}
\begin{definition}[Curvature at a Point]
Let $c: [a, b] \longrightarrow C \subset \mathbb{R}^3$ be a unit-speed paramaterization of $C$, meaning that $||c^\prime (t)|| = 1$ for all $t \in [a,b]$, and let $p = c(t_0)$ be a point in $C$. The \textit{curvature} $\kappa(p)$ at $p$ is a mapping defined
\[\kappa: C \longrightarrow \mathbb{R}, \;\; \kappa(p) \equiv ||c^{\prime \prime} (t_0)||\]
Notice that since we require a unit speed paramaterization of $C$, we do not need to worry about how a given curve is paramaterized. 
\end{definition}

Since the curvature is defined pointwise for each point in curve $C$, we can integrate over all the curvatures in $C$ to define the total curvature. 

\begin{definition}[Total Curvature]
The \textit{total curvature} of a curve $c: [a,b] \longrightarrow C \subset \mathbb{R}^3$ is the scalar line integral 
\[\int_C \kappa \, ds\]
\end{definition}

We now present an important theorem in differential geometry. 
\begin{theorem}[Fary-Milnor Theorem]
Given a unit speed paramaterization $c: [a,b] \longrightarrow C \subset \mathbb{R}^3$, if $C$ is closed (that is, $c(a)=c(b)$), then 
\[\oint_C \kappa\, ds \geq 2 \pi\]
and equals $2\pi$ only when $C$ is a circle. Furthermore, if $C$ is a closed space curve with 
\[\oint_C \kappa\, ds \leq 4\pi\]
then $C$ is "unknotted." That is, $C$ can be continuously deformed without every intersecting itself into a planar circle. Therefore, for knotted curves $C$, we have
\[\oint_C \kappa \, ds > 4\pi\]
\end{theorem}

\subsection{Surface Integrals}
Surface integrals are the $2$-dimensional analogue, or the double integral version, of line integrals. It is the integration of surfaces. 

\subsubsection{2-Dimensional Paramaterizations of Surfaces}
Just like how we create path functions using a paramaterization function $p: [a, b] \subset \mathbb{R} \longrightarrow \mathbb{R}^n$, we can parameterize surfaces by defining a function 
\[\varphi: D \subset \mathbb{R}^2 \longrightarrow \mathbb{R}^n, \;\;\; \varphi (u, v) \equiv \begin{pmatrix} x_1 (u, v) \\ \vdots \\ x_n (u, v) \end{pmatrix}\]
The surface 
\[S = \varphi(D)\]
corresponding to the function $\varphi$ is its image. If $\varphi$ is differentiable or is of class $C^1$, then we call $S$ a \textit{differentiable} or $C^1$ surface, respectively. 

For those that are familiar with differential geometry, this makes every paramaterized surface a 2-manifold induced by the single homeormophism $\varphi$. In fact, it is more than just locally homeomorphic; it is \textit{globally} homeomorphic. 


\begin{definition}[Tangent Vectors of Surfaces Embedded in $\mathbb{R}^3$]
Given surface paramaterization 
\[\varphi: \mathbb{R}^2 \longrightarrow \mathbb{R}^3, \;\;\; \varphi(u, v) \equiv \begin{pmatrix}
x (u, v) \\ y(u, v) \\ z(u, v) 
\end{pmatrix}\]
it is visually clear that there can be up to two linearly independent tangent vectors at a point on the surface $S$. We can calculate these two vectors by embedding two nonparallel paths in $D \subset \mathbb{R}^2$ and taking the derivative with respect to a point traveling through these paths, which would give us a tangent vector on $S$. To keep things simple, we take the partial derivatives with respect to $u$ and $v$. 
\begin{center}
    \includegraphics[scale=0.28]{Partial_Derivatives_with_respect_to_U_V.PNG}
\end{center}
Clearly, these paths are functions 
\begin{align*}
    \frac{\partial \varphi}{\partial u} \equiv \begin{pmatrix}
     \frac{\partial x}{\partial u} \\ \frac{\partial y}{\partial u} \\ \frac{\partial z}{\partial u}
    \end{pmatrix} : \mathbb{R}^2 \longrightarrow \mathbb{R}^3\\
    \frac{\partial \varphi}{\partial v} \equiv \begin{pmatrix}
     \frac{\partial x}{\partial v} \\ \frac{\partial y}{\partial v} \\ \frac{\partial z}{\partial v}
    \end{pmatrix} : \mathbb{R}^2 \longrightarrow \mathbb{R}^3
\end{align*}
where 
\[\frac{\partial \varphi}{\partial u} (u_0 ,v_0), \; \frac{\partial \varphi}{\partial v} (u_0, v_0)\]
represent two vectors in $\mathbb{R}^3$ that are tangent to $S$ at the point $\varphi(u_0, v_0) \in \mathbb{R}^3$. 
\end{definition}

We must make sure that the surface $S$ is smooth in the sense that (informally) there aren't any wrinkles, points, folds, or self-intersections in such a way that the tangent plane to the surface is not well-defined. 

\begin{definition}[Regular Surfaces]
To formalize this concept, we say that $S$ is \textit{regular}, or \textit{smooth}, at point $(u_0, v_0)$ if
\[\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v} \neq 0\]
where $\times$ is the Euclidean cross product. That is, if the vector that is orthogonal to the two tangent vectors is well defined at a point, the surface is said to be smooth at that point. Note that $\frac{\partial \varphi}{\partial u}$ is parallel to $\frac{\partial \varphi}{\partial v}$ if and only if their cross product is $0$. 
\begin{center}
    \includegraphics[scale=0.3]{Cross_Product_Regular_Surfaces.PNG}
\end{center}
It is quite clear that $(\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v})(u_0, v_0) \neq 0 \implies \frac{\partial \varphi}{\partial u}$ and $\frac{\partial \varphi}{\partial v}$ are linearly independent. This means that an entire span of tangent vectors, i.e. a tangent plane, of the surface $S$ at $\varphi(u_0, v_0)$ exists. 
$S$ is said to be \textit{regular} if it is regular at all points $\varphi(u_0, v_0) \in S$. 
\end{definition}

In fact, the tangent plane at $\varphi(u_0, v_0)$ is the set of points 
\[\{\varphi(u_0, v_0) + \frac{\partial \varphi}{\partial u} (u_0, v_0) c_1 + \frac{\partial \varphi}{\partial v} (u_0, v_0) c_2 \; | \; c_1, c_2 \in \mathbb{R} \}\]
which is precisely the affine tangent plane spanned by $T_u$ and $T_v$. Note also that the vector $T_u \times T_v$, if nonzero, is normal to this plane, which leads to this equivalent definition. 

\begin{definition}[Tangent Planes of Surfaces]
Given a paramaterized surface $\varphi: D \subset \mathbb{R}^2 \longrightarrow \mathbb{R}^3$ that is regular at $\varphi(u_0, v_0)$, the tangent plane of the surface $S$ at $\varphi(u_0, v_0) = (x_0, y_0, z_0)$ is defined
\[\{(x, y, z) \in \mathbb{R}^3 \;|\; (x-x_0, y-y_0, z-z_0) \cdot n = 0\}\]
where $n = (\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v})(u_0, v_0)$. 
\end{definition}

We finally construct the concept of signed areas before defining surface integration. 
We have all the tools we need to calculate surface areas, but remember that integration also covers the concept of \textit{signed areas}, which could be negative. In order to define this, we define the concept of orientation on surfaces. 

\subsubsection{Orientation of Surfaces}

\begin{definition}[Oriented Surfaces]
An \textit{oriented surface} is a two-sided surface with one side specified as the \textit{outside/positive} side and the other side as the \textit{inside/negative} side. Note that an oriented surface is not guaranteed to have two sides (e.g. a Mobius strip). To ensure that there exist two sides, $S$ must be regular. 

Surprisingly, a paramaterization does not have an intrinsic orientation. Rather, we determine the orientation ourselves by choosing a unit vector that generally points towards the outside of the surface $S$. Again, this choice is arbitrary, but it is customary to choose a vector that generally points "out." Either way, the orientation (unit) vector at every point $\varphi(u, v) \in S$, denoted as $n$, is 
\[n\big(\varphi(u, v)\big) = \pm \frac{\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}}{\big|\big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\big|\big|}\]
which can be visually calculated using the right hand rule. 
\begin{center}
    \includegraphics[scale=0.23]{Orientation_Unit_Vector.PNG}
\end{center}
\end{definition}

\begin{definition}[Orientation Preserving, Reversing Paramaterizations]
Given an oriented surface $S$ with its positive side determined by the direction of unit vector $n\big( \varphi(u,v)\big)$, the paramaterization $\varphi$ is said to be \textit{orientation preserving} if 
\[n \big( \varphi(u, v)\big) = \frac{\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}}{\big|\big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\big|\big|}\]
and \textit{orientation reversing} if
\[n \big( \varphi(u, v)\big) = - \frac{\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}}{\big|\big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\big|\big|}\]
\end{definition}

So, to find whether a paramaterization is orientation preserving or reversing, it suffices to find the cross product $T_u \times T_v$ and see if it points in the same direction of the normal vector $n$ (which should have already been determined when deciding the orientation of $S$). 

Given a paramaterization $\varphi$ and an un-oriented surface $S$, we can also just construct $\varphi$ to be orientation-preserving (or reversing) by \textit{defining} the normal vector $n$ to be 
\[n\big( \varphi(u, v)\big) = \frac{\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}}{\big|\big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\big|\big|} \;\; \bigg( \text{or } n\big( \varphi(u, v)\big) = - \frac{\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}}{\big|\big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\big|\big|} \bigg)\]
So rather than finding out whether a paramaterization $\varphi$ is orientation preserving or reversing by comparing $T_u \times T_v$ with $n$, we have defined $n$ in a way such that $\varphi$ must be orientation preserving (or reversing). We can utilize these tools of paramaterization to now define the surface integral. 

\subsubsection{Scalar, Vector Surface Integrals}

A physical interpretation of a scalar surface integral is the weighted surface area of a certain surface. 

\begin{definition}[Scalar Surface Integrals]
Let $f: \mathbb{R}^3 \longrightarrow \mathbb{R}$ be a $C^1$ scalar field defined on a paramaterized surface $S \subset \mathbb{R}^3$ with paramaterization $\varphi: D \subset \mathbb{R}^2 \longrightarrow \mathbb{R}^3$. That is, $\varphi(D) = S$. We define the integral $f$ over $S$ to be
\begin{align*}
    \iint_S f \; dS & = \iint_S f(x, y, z) \; dS \\
    & = \iint_D f\big( \varphi(u, v)\big) \bigg|\bigg|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\bigg|\bigg| \; du \,dv
\end{align*}
Note that this will require us to transform $f$, a function of $x, y, z$, into the function $f \circ \varphi$ of $u, v$. Additionally, if the paramaterization of the surface $S$ is not defined, then it one must be constructed. It is also clear that if $S$ is a union of surfaces $S_i$, then its surface integral is the sum of the surface integrals of the $S_i$'s. 
\end{definition}

Letting the scalar field $f$ be the constant field equal to $1$, the scalar surface integral measures the surface area of $S$. 
\[A(S) = \iint_S \; dS = \iint_D \Big|\Big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\Big|\Big| \; du\, dv\]
It is easy to see that the orientation of the paramaterization $\varphi$ does not affect scalar surface integrals, since the sign of the orientation gets nullified by the absolute value sign over $||\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}||$. 

Its physical interpretation is to measure the rate at which a fluid (determined by a vector field $F$) is crossing a given surface $S$. It also has many applications in electromagnetism. 

\begin{definition}[Vector Surface Integrals]
Let $F$ be a vector field defined on surface $S$, the image of a paramaterized surface $\varphi$. The \textit{surface integral} of $F$ over $S$ is defined below, which is equivalent to summing up the dot product of the vector field and the normal vector to the surface. 
\begin{center}
    \includegraphics[scale=0.3]{Vector_Surface_Integral.jpg}
\end{center}
It can be calculated with the following formulas by converting it into a scalar surface integral where the scalar field is the value of the dot product of the vector field with the normal vectors of the surface. 
\begin{align*}
    \iint_{S} F \cdot d S & = \iint_S (F \cdot n) \; dS \\
    & = \iint_D \Bigg( F\big( \varphi(u, v)\big) \cdot \frac{\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}}{\Big|\Big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v} \Big|\Big|} \Bigg) \, \bigg|\bigg|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\bigg|\bigg|\; du\,dv \\
    & = \iint_D F\big(\varphi(u, v)\big) \cdot \bigg( \frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\bigg) \; du\,dv
\end{align*}
\end{definition}

Since we are now talking about vector fields, the orientation of the paramaterization is now significant. Visually, if the orientation of the surface $S$ generally aligns with the vector field $F$, then the integral will be positive (since two vectors $\alpha, \beta$ generally pointing in the same direction implies that $\alpha \cdot \beta > 0$). The orientation of the paramaterization, which is dependent on $\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}$, determines the direction of the normal vector $n$ (since it is defined to be $(\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}) / \big|\big|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\big|\big|$. Therefore, changing the orientation of $\varphi$ will reverse the direction of $n$, which will then reverse the sign of the integral since $n$ now points in the opposite direction of the vector field $F$ than it previously did (by reversing the sign of the dot products). This is formalized in the theorem below. 

\begin{theorem}[Invariance of Surface Paramaterizations on Vector Surface Integrals]
Let $S$ be an oriented surface and let $\varphi_1$ and $\varphi_2$ be two regular paramaterizations with $F$ a continuous vector field defined on $S$. Then, assuming $\varphi_1$ is orientation preserving, 
\begin{align*}
    \varphi_2 \text{ is orientation preserving } & \implies \iint_{\varphi_1} F \cdot d S = \iint_{\varphi_2} F \cdot d S \\
    \varphi_2 \text{ is orientation reversing } & \implies - \iint_{\varphi_1} F \cdot d S = \iint_{\varphi_2} F \cdot d S 
\end{align*}
\end{theorem}

\subsubsection{Surface Integrals over Graphs}
Given that we have the graph of a function $g: \mathbb{R}^2 \longrightarrow \mathbb{R}$ rather than a general surface, we can paramaterize it simply as
\[\varphi(u, v) \equiv \big(u, v, g(u, v) \big)\]
\begin{center}
    \includegraphics[scale=0.25]{Paramaterize_Surfaces_as_Graphs.PNG}
\end{center}
This means that 
\[\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v} = 
\begin{pmatrix}
-\frac{\partial g}{\partial u} \\ -\frac{\partial g}{\partial v} \\ 1
\end{pmatrix} \implies \bigg|\bigg|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v} \bigg|\bigg| = \sqrt{1 + \Big(\frac{\partial g}{\partial u}\Big)^2 + \Big( \frac{\partial g}{\partial v}\Big)^2}\]
So we can simplify the equation for the surface area $S$ of the graph of $g$ over the region $D$ in the $x y$-plane, as 
\begin{align*}
    A(S) & = \iint_S \; d S = \iint_D \bigg|\bigg|\frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v} \bigg|\bigg| \; d A \\
    & = \iint_D \sqrt{1 + \Big(\frac{\partial g}{\partial u}\Big)^2 + \Big( \frac{\partial g}{\partial v}\Big)^2} \; d u \, d v
\end{align*}
With the same $g$, we can find the weighed surface area of $S$ over the scalar function $f: \mathbb{R}^3 \longrightarrow \mathbb{R}$ with the formula
\[\iint_S f \; d S = \iint_D f\big(u, v, g(u, v)\big) \sqrt{1 + \Big(\frac{\partial g}{\partial u}\Big)^2 + \Big( \frac{\partial g}{\partial v}\Big)^2} \; d u \, d v\]
Finally, with the same graph $g$, the surface integral over the vector field $F$ is
\begin{align*}
    \iint_S F \cdot d S & = \iint_D F\big(\varphi(u, v)\big) \cdot \bigg( \frac{\partial \varphi}{\partial u} \times \frac{\partial \varphi}{\partial v}\bigg) \; d u \, d v \\
    & = \iint_D \bigg( F_1(u, v) \Big(- \frac{\partial g}{\partial u}\Big) + F_2 (u, v) \Big( - \frac{\partial g}{\partial v} \Big) + F_3 (u, v) \bigg) \; d u \, d v
\end{align*}

\subsection{Integral Theorems}
Recall the differential notation for writing line integrals. For 2 and 3 dimensions, it is written as
\begin{align*}
    & \int_C F \cdot d s = \int_C F \cdot (d x, d y) = \int_C F_1 \, d x + F_2 \, d y \\
    & \int_C F \cdot d s = \int_C F \cdot (d x, d y, d z) = \int_C F_1 \, d x + F_2 \, d y + F_3 \, d z 
\end{align*}
\subsubsection{Green's Theorem}
Green's Theorem gives the relationship between a line integral around a simple closed curve $C$ and a double integral over the plane region $D$ bounded by $C$. 

\begin{theorem}[Green's Theorem in $\mathbb{R}^2$]
Let there be a 2-dimensional $C^1$ vector field $F$ on $\mathbb{R}^2$ defined on a simple oriented closed piecewise-smooth curve $C$ and its bounded region $D \subset \mathbb{R}^2$ (that is, $C = \partial D$). Let the orientation of the path of $C$ be such that it is traveling \textit{counterclockwise}, i.e. a point traveling through $C$ would see the region $D$ to its \textit{left}, denoted as $C^+$ and the clockwise orientation as $C^-$.  Then, 
\[\oint_{C^+} F_1 \, d x + F_2 \, d y = \iint_D \bigg( \frac{\partial F_2}{\partial x} - \frac{\partial F_1}{\partial y} \bigg) \; d x \, d y\]
By reversing the orientation, it is clear that we have
\[\oint_{C^-} F_1 \, d x + F_2 \, d y = - \iint_D \bigg( \frac{\partial F_2}{\partial x} - \frac{\partial F_1}{\partial y} \bigg) \; d x \, d y\]
Note that this theorem is expressed in terms of the components of the vector field $F$. 
\begin{center}
\begin{tikzpicture}
    \draw[fill=lightgray] plot [smooth cycle] coordinates {(2,3) (3,4) (5,4) (5,3) (3,2)};
    \node [above left] at (4,3) {D};
    \begin{axis}[view={0}{90}]
    \addplot3 [lightgray,-stealth,samples=10,
        quiver={
            u={3*x/pow(x^2 + y^2,1/2)},
            v={-2*y/pow(x^2 + y^2,1/2)},
            scale arrows=0.2,
        },] { 1};
    \end{axis}
    \node at (2,1) {$F = (F_1, F_2)$};
    \node at (5,4.7) {$C^+ = \partial D$};
    \draw (4.3,2.4)--(4.45,2.6)--(4.2,2.6);
\end{tikzpicture}
\end{center}
\end{theorem}

Green's theorem has many applications in physics. For example, in order to solve two-dimensional flow integrals measuring the sum of fluid outflowing from a volume, Green's theorem allows us to calculate the total outflow summed about an enclosing area . 

\begin{corollary}
Let $D$ be a region for which Green's theorem applies with positively oriented boundary $\partial D$. Then, the area of $D$ can be computed with the formula
\[A(D) = \frac{1}{2} \oint_{\partial D} x \, d y - y \, d x\]
\end{corollary}

Green's theorem can be used to determine the area of centroid of plane figures solely by integrating over the perimeter. 

\subsubsection{Stokes' Theorem}
Green's theorem relates line integrals to double integrals. Stokes' theorem generalizes Green's theorem by relating line integrals to surface integrals of 2-dimensional surfaces embedded in $\mathbb{R}^3$. 

\begin{theorem}[Stokes' Theorem]
Let $S$ be an oriented regular surface defined by paramaterization $\varphi: D \subset \mathbb{R}^2 \longrightarrow \mathbb{R}^3$, and let the image of the boundary $\partial D$ under $\varphi$ be the boundary $\partial S$ of $S$. We can interpret $\partial S$ as a path mapping from $\mathbb{R} \longrightarrow S \subset \mathbb{R}^3$. 
\begin{center}
    \includegraphics[scale=0.3]{Boundary_Mapping.PNG}
\end{center}
The orientation unit vector $n$ of $S$ induces the positive orientation of $\partial S$, denoted $\partial S^+$. Visually, if you are walking along the curve with your head is pointing in the same direction as the unit normal vectors while the surface is on the left then you are walking in the positive direction on $\partial S$. 
\begin{center}
    \includegraphics[scale=0.8]{Stokes_Theorem_Orientation.png}
\end{center}
Given that $F$ is a $C^1$ vector field defined on $S$, then
\[\iint_S \curl{F} \cdot dS = \iint_S \big( \nabla \times F \big) \cdot d S = \oint_{\partial S^+} F \cdot d s\]
If $S$ has no boundary, that is, if the image of $p^\prime = \partial S$ is not a simple closed curve, then the integral is $0$. 
\end{theorem}

The above theorem implies that the vector surface integral of a surface without a boundary (i.e. a closed graph, such as a sphere) is always $0$ along the curl of any $C^1$ field. Geometrically, this means that given a closed solid $S$ with field $\nabla \times F$, the rate of flow of the vector field into $S$ is equal to the flow out of $S$. 

\subsubsection{Gauss' Theorem}
The divergence theorem relates the flux of a vector field through a closed surface to the divergence of the field in the volume enclosed. 

\begin{theorem}[Gauss' Divergence Theorem]
Let $V$ be a subset of $\mathbb{R}^3$. Denote by $\partial V$ the oriented closed surface that bounds $V$ (with outward pointing normal orientation vectors), and let $F$ be a $C^1$ vector field defined on a neighborhood of $V$. Then, 
\[\iiint_V \Div{F} \; d V = \iiint_V (\nabla \cdot F) \; d V = \oiint_{\partial V} F \cdot d S = \oiint_{\partial V} (F \cdot n) \; dS\]
where the two left-most integrals are volume integrals, and the two right-most integrals are surface integrals. Intuitively, this makes sense; the volume integrals represent the total of the sources in volume $V$, and the right hand side represents the total flow across the boundary $\partial V$. 
\begin{center}
    \includegraphics[scale=0.35]{Gauss_Theorem_Volume.png}
\end{center}
\end{theorem}


\chapter{Abstract Algebra}
An introduction to a two-semester course in abstract algebra. 
\section{Algebraic Structures}

\begin{definition}
An \textit{operation} $*$ on a set $M$ is a map 
\[ *: M \times M \longrightarrow M \]
\end{definition}

\begin{example}
Regular addition $+$ and multiplication $\times$ are operations in $\mathbb{R}$, $\mathbb{Q}$, and $\mathbb{N}$, but multiplication is not defined in $\mathbb{R_{-}}$, since the product of 2 negative numbers is a positive number. 
\end{example}

\begin{example}
The product of functions $f: N \longrightarrow M$ and $g: P \longrightarrow N$ is defined as the composition of them
\[ (f \circ g)(x) \equiv f(g(x)) \; \forall x\in P \]
\end{example}

\begin{example}
$\mathbb{R}^{3}$ can have operations of vector addition and the cross product. The inner product is \textit{not} an operation on $\mathbb{R}^3$.
\end{example}

\begin{definition}
Let $(M, \circ)$ and $(N, *)$ be two sets with their respective operations. The mapping $f: (M, \circ) \longrightarrow (N, *)$ is a \textit{homomorphism} if
\[f(a \circ b) = f(a) * f(b) \; \forall a, b \in M\]
A homomorphism is an \textit{isomorphism} if and only if it is bijective. If an isomorphism $f$ exists between two algebraic structures $M$ and $N$, then $M$ and $N$ are said to be \textit{isomorphic}, denoted $M \simeq N$. An homomorphism from structure $G$ to itself is called an \textit{endomorphism}, and an endomorphism that is also an isomorphism is called an automorphism. 
\end{definition}

\begin{example}
The map $a \mapsto 2^{a}$ is an isomorphism between $(\mathbb{R}, +)$ and $(\mathbb{R}^{+}, \times)$ since 
\[2^{a+b} = 2^a \times 2^b \]
\end{example}

We now define a crucial type of measure on a set, called a relation.  

\begin{definition}
given a set $M$, any subset $R \subset M \times M$ is called a \textit{relation} on the set $M$. If $(a, b) \in R$, then $a$ and $b$ are \textit{related}, denoted $a R b$. 
\end{definition}

\begin{definition}
An \textit{equivalence relation} $R$, also written $\sim$, is a relation which is:
\begin{enumerate}
    \item Reflexive. $a R a$ 
    \item Symmetric. $a R b \iff b R a$ 
    \item Transitive. $a R b, b R c \implies a R c$ 
\end{enumerate}
An equivalence relation $R$ defines an \textit{equivalence class} $R(a)$, defined 
\[ R(a) \equiv \{ b \in M | a\sim b \} \]
which directly implies that the set of equivalence classes $\{R(a)\}$ form a partition of $M$. 
\end{definition}

\begin{definition}
The set of equivalence classes under relation $R$ is called the \textit{quotient set} of $M$ by $R$, denoted $\frac{M}{R}$.
The map 
\[q: M \longrightarrow \frac{M}{R}, \; a \mapsto R(a)\] 
is called the \textit{quotient map}. We can also define an operation $*$ on the quotient set $\frac{M}{R}$ to get $\big( \frac{M}{R}, * \big)$, defined as
\[ \{a \} * \{ b \} \equiv \{ a * b \} \]
to turn this quotient set into an algebraic structure. In words, $*$ applied on two classes takes arbitrary representatives of each class, does the operation on each of them, and finally outputs the class of the resulting product. 
\end{definition}

\begin{example}
$M$ is the set of circles in $\mathbb{R}^{2}$. Given $a, b \in M$, $a \sim b$ iff the radii are equal in length. We can denote each equivalence class by $\{ r \}$, where $r$ is the length of the radius. We can define addition as 
\[ \{ a \} + \{ b \} \equiv \{ a + b\} \]
\end{example}

\subsection{Group-like Structures}
\begin{definition}
A \textit{groupoid}, also called a \textit{magma}, is a set with operation $(M, *)$ where the operation $*$ is closed. No other properties are imposed. 
\end{definition}

\begin{definition}
A \textit{semigroup} $(M, *)$ is a groupoid where the binary operation $*$ must be associative.  
\end{definition}

\begin{definition}
A \textit{monoid} $(M, *)$ is a semigroup with an identity element $I \in M$ such that given a $m \in M$
\[I * m = m * I = m \]
\end{definition}

\begin{definition}
A \textit{group} is a monoid where every element has an inverse element. That is, $(G, *)$ is a set with binary operation having the properties of closure, associativity, existence of an identity and existence of inverses, in the following order: 
\begin{enumerate}
    \item $x, y \in S \implies x*y, \;y*x \in G$ but not necessarily $x*y  = y*x$
    \item $a*(b*c) = (a*b)*c \; \forall a, b, c \in G$
    \item $\exists I \in G : x*I = I*x = x \; \forall x \in G $
    \item $\forall x \in G \; \exists x^{-1} \in G : x * x^{-1} = x^{-1} * x = I$
\end{enumerate}
\end{definition}

\begin{proposition}
The identity and the inverse is unique, and for any $a, b$, the equation $x*a = b$ has the unique solution $x = b* a^{-1}$.
\end{proposition}
\begin{proof}
 Assume that there are two identities of group $(G,*)$, denoted $I_{1}, I_{2}$, where $I_{1} \neq I_{2}$. According to the properties of identities, $I_{1} = I_{1} * I_{2} = I_{2} \implies I_{1} = I_{2}$. \\
As for uniqueness of a inverses, let $a$ be an element of $G$, with its inverses $a_{1}^{-1}, a_{2}^{-1}$. Then, 
\begin{align*}
a * a_{1}^{-1} = I & \implies a_{2}^{-1} * \Big(a * a_{1}^{-1} \Big)= a_{2}^{-1} * I \\
 & \implies \Big(a_{2}^{-1} * a \Big) * a_{1}^{-1} = a_{2}^{-1} \\
 & \implies I * a_{1}^{-1} = a_{2}^{-1}
\end{align*}
Since the inverse is unique, we can operate on each side of the equation $x*a = b$ to get $x*a*a^{-1} = b*a^{1} \implies x * I = x = b*a^{-1}$. Clearly, the derivation of this solution is unique since the elements that we have operated on are unique.
\end{proof}

\begin{definition}
An \textit{abelian group} $(A, +)$ is a group where $+$ is commutative. That is, 
\[x+y = y+x \; \forall x, y \in A \]
The abstract operation for an abelian group is usually called addition. 
\end{definition}

\begin{example}
$\mathbb{Z}, \mathbb{Q}, \mathbb{R}$ are all abelian groups with respect to addition. $\mathbb{Q}^{*} \equiv \mathbb{Q} \setminus \{0\}$ and $\mathbb{R}^{*} \equiv \mathbb{R} \setminus \{0\}$ are abelian groups with respect to multiplication.
\end{example}

\begin{example}
The set of all functions on a given interval $F[a,b]$ is abelian with respect to addition, defined as $(f+g)(x) \equiv f(x) + g(x)$. 
\end{example}

\subsection{Ring-like Structures}

\begin{definition}
A \textit{ring} is a set $(R, +, \times)$ equipped with two operations, called addition and multiplication. It has properties: 
\begin{enumerate}
    \item $R$ is an abelian group with respect to $+$.
    \item Multiplication $\times$ is distributive with respect to addition $+$
\[a \times (b + c) = a\times b + a\times c, (a+b)\times c = a\times c + b\times c \; \forall a, b, c \in R\]
    \item There is an absorbing element, denoted $0$ such that 
\[ 0\times a = a\times 0 = 0 \; \forall a \in R \]
    \item Equivalence of Additive Inverses
\[ a \times (-b) = (-a) \times b = - (a\times b) \]
\end{enumerate}
\end{definition}

\begin{definition}
A ring $R$ is a \textit{commutative ring} if and only if multiplication is commutative, i.e. $a\times b = b \times a \; \forall a, b \in R$. It is an \textit{associative ring} if and only if multiplication is associative, i.e. $a \times (b \times c) = (a \times b) \times c \; \forall a, b, c \in R$.
\end{definition}

\begin{definition}
The \textit{unity} of a ring $R$ is the multiplicative identity, denoted as $1$. 
\[a \times 1 = 1 \times a = a \; \forall a \in R \]
Note that a ring cannot have more than 1 unity, but it may not exist at all. But usually, a ring has a unity.
\end{definition}

This is not to be confused with the unit of a ring. 

\begin{definition}
A \textit{unit} of a ring $R$ is an element $u \in R$ that has a multiplicative inverse in $R$. 
\end{definition}

\begin{example}
$\mathbb{Z}, \mathbb{Q}, \mathbb{R}$ are commutative, associative rings with respect to ordinary addition and multiplication.
\end{example}

\begin{example}
The set of even integers $2\mathbb{Z}$ is a commutative, associative ring without unity.
\end{example}

\begin{proposition}
Given a set $X$, let $2^X$ be its power set, that is the set of all subsets of $X$. Then, $2^X$ is a commutative associative ring with respect to the operations of symmetric difference (i.e. the set of elements which is in exactly one of the sets) 
\[ M \bigtriangleup N \equiv (M \setminus N) \cup (N \setminus M) \]
and intersection $\cap$, taken for addition an multiplication, respectively. 
\end{proposition}
\begin{proof}
We will not prove all of the axioms of the ring, but we can state some important facts about this structure. The additive identity is $\emptyset$ and the multiplicative identity is $X$. Finally, it is clear that 
\begin{align*}
    & M \bigtriangleup N \equiv (M \setminus N) \cup (N \setminus M) \equiv N \bigtriangleup M \\
    & M \cap N = N \cap M \\
    & M \cap N \cap P = (M \cap N) \cap P = M \cap (N \cap P)
\end{align*}
\end{proof}

\begin{example}
A \textit{division ring}, also called a \textit{skew field}, is an associative ring with unity where every nonzero element is invertible with respect to $\times$. Division rings differ from fields in that multiplication is not required to be commutative. 
\end{example}

At first, a division ring may not seem different from a field. However, a classic example is the ring of invertible matrices, which is not necessarily commutative, but is a ring in which "division" can be done by right and left multiplication of a matrix inverse. 
\[ a a^{-1} = a^{-1} a = I \]
This implies that every element in the division ring commutes with the identity, but again commutativity does not necessarily hold for arbitrary elements $a, b$. 

\begin{definition}
A \textit{field} $(F, +, \times)$ is a commutative, associative ring with unity where every nonzero element is invertible (with respect to $\times$). It is usually denoted as $\mathbb{F}$. Note that $F$ is now an abelian group with respect to $\times$. 
\end{definition}

\begin{definition}
An element a of a ring $R$ is called a \textit{left zero divisor} if there exists a nonzero $x$ such that $a x = 0$ and a \textit{right zero divisor} if there exists a nonzero $x$ such that $x a = 0$. 
\end{definition}

\begin{definition}
A ring $R$ with no zero divisors for every element is called a \textit{domain}. 
\end{definition}

\begin{proposition}
Every field is a domain. 
\end{proposition}
\begin{proof}
Given $x, y \in \mathbb{F}$, assume $x y = 0$ with $x \neq 0$. Since $x$ is invertible,
\[ 0 = x^{-1} 0 = x^{-1} (x y) = y\]
Now assuming that $y \neq 0$, since $y$ is invertible, 
\[ 0 = 0 y^{-1} = (x y) y^{-1} = x \]
\end{proof}

While the converse is not true, we can state the following result. 

\begin{theorem}[Wedderburn's little theorem]
Every finite domain is a field. 
\end{theorem}

\subsection{Vector Space Structures}
\begin{definition}
 A \textit{vector space over a field $F$} consists of an abelian group $(V, +)$ and an operation called \textit{scalar multiplication} 
\[ \cdot: F \times V \rightarrow V \]
such that for all $x, y\in V$ and $\lambda, \mu \in F$, we have 
\begin{enumerate}
    \item $\lambda \cdot (x + y) = \lambda \cdot x + \lambda \cdot y$
    \item $(\lambda + \mu) \cdot x = \lambda \cdot x + \mu \cdot x$ 
    \item $(\lambda \mu) \cdot x = \lambda \cdot (\mu \cdot x )$, which equals $(\mu \lambda) \cdot x = \mu \cdot (\lambda \cdot x)$ since $F$ is commutative 
    \item $1 \cdot x = x$ , where $1$ is the unity of $F$
\end{enumerate}
\end{definition}

\begin{definition}
 A \textit{left R-module} $M$ consists of an abelian group $(M, +)$ and an operation called \textit{scalar multiplication}
\[ \cdot: R \times M \longrightarrow M \] 
such that for all $\lambda, \mu \in R$ and $x, y \in M$, we have 
\begin{enumerate}
    \item $\lambda \cdot (x + y) = \lambda \cdot x + \lambda \cdot y$
    \item $(\lambda + \mu) \cdot x = \lambda \cdot x + \mu \cdot x$ 
    \item $(\lambda \mu) \cdot x = \lambda \cdot (\mu \cdot x )$, not necessarily equaling $(\mu \lambda) \cdot x = \mu \cdot (\lambda \cdot x)$
    \item $1 \cdot x = x$ , where $1$ is the unity of $R$
\end{enumerate}
Note that a left $R$-module is a vector space if and only if $R$ is a field.
\end{definition}

\begin{definition}
A \textit{right $R$-module} $M$ is defined analogously to a left $R$-module, except that the scalar multiplication operation is defined
\[ \cdot: M \times R \longrightarrow M \]
\end{definition}

\begin{definition}
Let $A$ be a vector space over a field $F$ equipped with an additional binary operation 
\[ \times: A \times A \longrightarrow A \]
$A$ is an \textit{algebra over $F$} if the following identities hold for all $x, y, z \in A$ and all $\lambda, \mu \in F$. 
\begin{enumerate}
    \item Right distributivity. $(x + y) \times z = x \times z + y \times z$ 
    \item Left distributivity. $z \times (x + y) = z \times x + z \times y$
    \item Compatibility with scalars. $(\lambda \cdot x ) \times (\mu \cdot y) = (\lambda \mu) \cdot (x \times y)$ 
\end{enumerate}
\end{definition}

Note that vector multiplication of an algebra does not need to be commutative. 

\begin{example}
The set of all $n \times n$ matrices with matrix multiplication is a noncommutative, associative algebra. Similarly, the set of all linear endomorphisms of a vector space $V$ with composition is a noncommutative, associative algebra. 
\end{example}

\begin{example}
$\mathbb{R}^3$ equipped with the cross product is an algebra, where the cross product is \textit{anticommutative}, that is $x \times y = - y \times x$. $\times$ is also nonassociative, but rather satisfies an alternative identity called the \textit{Jacobi Identity}. 
\end{example}

\begin{example}
The set of all polynomials defined on an interval $[a,b]$ is an infinite-dimensional subalgebra of the set of all functions $f: \mathbb{R} \longrightarrow \mathbb{R}$ defined on $[a,b]$.
\end{example}

\begin{definition}
Similar to division rings, a \textit{division algebra} is an algebra where the operation of "division" defined as such: Given any $a \in A$, nonzero $b \in A$, there exists solutions to the equation
\[A = bx\]
that are unique. If we wish, we can distinguish left and right division to be the solutions of $A = b x$ and $A = x b$. 
\end{definition}

\begin{definition}
Here are examples of division algebras.
\begin{enumerate}
    \item $\mathbb{R}$ is a $1$-dimensional algebra over itself. 
    \item $\mathbb{C}$ is a $2$-dimensional algebra over $\mathbb{R}$. 
    \item There exists no $3$-dimensional algebra. 
    \item Quaternions forms a $4$-dimensional algebra over $\mathbb{R}$. 
\end{enumerate}
\end{definition}

\subsection{Subgroups, Subrings, Subfields}

\begin{definition}
Given a set $M$ and a subset $N \subseteq M$, the subset $N$ is closed with respect to $*$ if $a, b \in N \implies a * b \in N$
\end{definition}

\begin{definition}
A \textit{subgroup of group $G$} is a group that is a subset $G$. The \textit{trivial subgroups} of a group $G$ are $0$ and $G$. 
\end{definition}

\begin{example}
$\mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R}$ are all groups. 
\end{example}

\begin{theorem}
The subgroup $(N, *)$ of every abelian group $(M, *)$ is also an abelian group. 
\end{theorem}

\begin{corollary}
Any subspace within a vector space is a subgroup. 
\end{corollary}

\begin{definition}
A subset $L$ of a ring $R$ is a \textit{subring} if and only if it is a ring. 
\end{definition}

\begin{example}
For any $n \in \mathbb{Z}_{+}$, the set $n\mathbb{Z}$ is a subring of $\mathbb{Z}$. 
\end{example}

\begin{definition}
A \textit{subfield of field $F$} is a field that is a subset of $F$.
\end{definition}

\begin{example}
$\mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}$. 
\end{example}

\section{Group Theory}
\subsection{Classes of Groups}
\subsubsection{Symmetric Group}
\begin{definition}
The \textit{symmetric group}, also called the \textit{permutation group}, is the set of all bijective transformations from any set $X$ to the same set, denoted either Sym$(X)$ or $S_n$. If $X = \{1, 2, 3 ,... , n\}$, known as the set of all permutations of $X$, with cardinality $n!$. 
\end{definition}

\begin{proposition}
Every element in finite $S_{n}$ can be decomposed into a partition of cyclic rotations.
\end{proposition}

\begin{example}
\begin{enumerate}
    \item $(1 2)$ is a mapping $1 \rightarrow 2,\; 2 \rightarrow 1$. 
    \item $(1 2 3)$ is a mapping $1\rightarrow 2,\; 2 \rightarrow 3,\; 3 \rightarrow 1$. 
    \item $(1 2 3) (4 5)$ is a mapping $1\rightarrow 2,\; 2 \rightarrow 3,\; 3 \rightarrow 1, \;4 \rightarrow 5, \;5 \rightarrow 4$. 
\end{enumerate}
\end{example}

\begin{definition}
The \textit{conjugacy class} of $S_{n}$ correspond to the cycle structures of $S_{n}$. Two elements of $S_{n}$ are conjugate in $S_{n}$ if and only if they consist of the same number of disjoint cycles of the same lengths. 
\end{definition}

\begin{example}
\begin{enumerate}
    \item $(1 2 3) (4 5)$ is conjugate to $(1 4 3) (2 5)$.
    \item $(1 2) (4 5)$ is not conjugate to $(1 4 3) (2 5)$. 
\end{enumerate}
\end{example}

\begin{definition}
The \textit{signature} of a permutation is a homomorphism
\[ \text{sgn}: S_{n} \longrightarrow \{1, -1\} \]
\end{definition}

\begin{proposition}
The signature of a permutation changes for every transposition that is applied to it. 
\end{proposition}

\begin{definition}
The \textit{alternating group} of order $n$ is the set of all \textit{even permutations} (permutations that have signature $1$) of $\{1, 2, ..., n\}$. It is denoted $A_{n}$ or Alt$(n)$ and its cardinality is $\frac{1}{2} n!$. Note that the set of odd permutations do not form a group, since the composition of two odd permutations (each having signature $-1$ is an even permutation. 
\end{definition}

\begin{example}[Low Order Symmetric Groups]
\begin{enumerate}
    \item $S_{0}$ is the set of all permutations on the \textit{null set}. $S_{1}$ is the set of all permutations on the \textit{singleton set}. Both sets have cardinality 1 and the element is \textit{trivial}. Note that $S_{1} = A_{1}$. 
    \item $S_{2}$ is a cyclic, abelian group of order 2 consisting of the identity permutation and the transposition of two elements. 
    \item $S_{3}$ is the first cyclic, nonabelian group, with order 6.$S \simeq \text{Dih}(3)$, which can be seen as the group of rotations and reflections on the equilateral triangle, and the elements of $S_{3}$ equate to permuting the vertices on the triangle. 
\end{enumerate}
\end{example}

\begin{definition}
A \textit{permutation group} is some subgroup of Sym$(X)$. 
\end{definition}

\subsubsection{General Linear and Affine Groups}
\begin{definition}
The \textit{general linear group}, denoted GL$(V)$, is the set of all bijective linear mappings from $V$ to itself. Similarly, GL$_{n}(\mathbb{F})$, or GL $(n, \mathbb{F})$ is the set of all nonsingular $n \times n$ matrices over the field $\mathbb{F}$. Due to the same dimensionality of the following spaces, it is clear that GL$(V) \simeq$ GL$(\mathbb{F}^{n}) \simeq$ GL$_{n}(\mathbb{F})$. The \textit{special linear group}, denoted SL$_{n} (\mathbb{F})$ or SL$(n, \mathbb{F})$, is the set of $n\times n$ matrices a with determinant $1$. SL$_{n}(\mathbb{F})$ is a subgroup of GL$_{n}(\mathbb{F})$, which is a subset of the ring of all $n \times n$ matrices over field $\mathbb{F}$, denoted $\mathbb{L}_{n}(\mathbb{F})$. 
\end{definition}

\begin{definition}
The \textit{general affine group} is the pair of all transformations
\[ \text{GA} (V) \equiv \text{Tran}(V) \times \text{GL}(V)\]
\end{definition}

\subsubsection{Isometries}

\begin{definition}
The group of all translations in the space $V$ is denoted Tran$\,V$. Its elements are usually denoted as $t_{u}$, where $u$ is the vector that is being translated by. It can also be interpreted as shifting the origin by $-u$. It is clear that Tran$\,V \simeq V$. 
\end{definition}

\begin{definition}
The \textit{Euclidean group} of \textit{isometries} in the Euclidean space $\mathbb{E}^{n}$ (with the Euclidean norm), denoted Isom$\, \mathbb{E}^{n}$ or $\mathbb{E}(n)$, consists of all distance-preserving bijections from $\mathbb{E}^{n}$ to itself, called \textit{motions} or \textit{rigid transformations}. It consists of all combinations of rotations, reflections, and translations. The \textit{special Euclidean group} of all isometries that preserve the \textit{handedness} of figures is denoted $\mathbb{SE}(n)$, which is comprised of all combinations rotations and translations called \textit{rigid motions} or \textit{proper rigid transformations}.
\end{definition}

\begin{definition}
The \textit{orthogonal group}, denoted O$(n)$ or O$_{n}$, consists of all isometries that preserve the origin, i.e. consists of rotations and reflections. The \textit{special orthogonal group}, denoted SO$(n)$, is a subgroup of O$(n)$ consisting of only rotations. We can see that 
\[\text{O}(n)=\frac{\text{Isom}\, \mathbb{E}^{n}}{\text{Tran}\,V} \]
\end{definition}

\subsubsection{Geometrical Groups}

\begin{definition}
A \textit{polytope} in $n$-dimensions is a geometrical object with "flat sides, " called an n-polytope. It is a generalization of a polygon or a polyhedron to an arbitrary number of dimensions. 
\end{definition}

\begin{definition}
A \textit{n-simplex} is a n-polytope which is the n-dimensional convex hull of its $n+1$ vertices. Moreover, the $n+1$ vertices must be \textit{affinely independent}, meaning that
\[ \{u_1 - u_0, u_2 - u_0, ..., u_n - u_0 | \{u_i\}_{i=0}^{n} \text{ vertices} \} \]
are linearly independent vectors that span the n-dimensional space. 
\end{definition}

\begin{definition}
The \textit{symmmetry group} of a geometrical object is the group of all transformations in which the object is invariant. Preserving all the relevant structure of the object. A common example of such groups is the \textit{dihedral group}, denoted D$_{n}$ or Dih$(n)$, which is the group of symmetries of a n-simplex, which includes rotations and reflections. 
\end{definition}

\begin{example}
We introduce some low order Dihedral groups. 
\begin{enumerate}
    \item Dih$(3)$ is the group of all rotations and reflections that preserve the structure of the equilateral triangle in $\mathbb{R}^2$, a regular 2-simplex. 
    \begin{center}
    \begin{tikzpicture}[scale=0.7]
        \draw (-1,0)--(1,0)--(0,1.732)--(-1,0);
        \draw (-3.5,0)--(-1.5,0)--(-2.5,1.732)--(-3.5,0);
        \draw (-6,0)--(-4,0)--(-5,1.732)--(-6,0);
        \draw (4,0)--(6,0)--(5,1.732)--(4,0);
        \draw (1.5,0)--(3.5,0)--(2.5,1.732)--(1.5,0);
        \draw (6.5,0)--(8.5,0)--(7.5,1.732)--(6.5,0);
        \node[below] at (-5.05, 1.732) {$A$};
        \node[below] at (-2.55, 1.732) {$A$};
        \node[below] at (-0, 1.732) {$B$};
        \node[below] at (2.5, 1.732) {$B$};
        \node[below] at (5, 1.732) {$C$};
        \node[below] at (7.5, 1.732) {$C$};
        \node[above right] at (-6,0) {$B$};
        \node[above right] at (-3.5,0) {$C$};
        \node[above right] at (-1,0) {$A$};
        \node[above right] at (1.5,0) {$C$};
        \node[above right] at (4,0) {$A$};
        \node[above right] at (6.5,0) {$B$};
        \node[above left] at (-4.05,0) {$C$};
        \node[above left] at (-1.55,0) {$B$};
        \node[above left] at (0.95,0) {$C$};
        \node[above left] at (3.45,0) {$A$};
        \node[above left] at (5.95,0) {$B$};
        \node[above left] at (8.45,0) {$A$};
    \end{tikzpicture}
    \end{center}
    \item Dih$(4)$ is the group of all rotations and reflections that preserve the structure of the regular tetrahedron in $\mathbb{R}^{3}$. An incorrect, yet somewhat useful, way of visualizing this group is to imagine a square in $\mathbb{R}^{2}$. However, the points are not pairwise equidistant and therefore does not preserve symmetry between all points.
    \item Dih$(n)$ is similarly the group of all rotations and reflections that preserve the structure of a regular $(n-1)$-simplex in $\mathbb{R}^{n}$. 
\end{enumerate}
\end{example}

\subsection{Direct Product of Groups}

\begin{definition}
The \textit{direct product} of two groups $G$ and $H$ is denoted
\[G \times H \equiv \{ (g, h)\;|\; g \in G, h \in H \} \]
Note that the product need not be binary (nor must it be of finite arity). 
\end{definition}

\begin{definition}
The \textit{general affine group} is defined 
\[ \text{GA}(V) \equiv \text{Tran}\,V \times \text{GL}(V)\]
\end{definition}

\begin{definition}
The \textit{Galileo Group} is the transformation group of spacetime symmetries that are used to transform between two reference frames which differ only by constant relative motion within the constructs of Newtonian physics. It is denoted 
\[ \text{Tran}\;\mathbb{R}^{4} \times H \times \text{O} (3)\]
where $H$ is the group of transformations of the form 
\[ (x, y, z, t) \longmapsto (x+at, y+bt, z+ct, t)\]
\end{definition}

\begin{definition}
The \textit{Poincar Group} is the symmetry group of spacetime within the principles of relativistic mechanics, denoted
\[ G = \text{Tran}\; \mathbb{R}^{4} \times \text{O}_{3,1}\]
where O$_{3,1}$ is the group of linear transformations preserving the polynomial 
\[ x^{2} + y^{2} + z^{2} - t^{2}\]
\end{definition}

\subsection{Generating Sets and Group Presentations}
\subsubsection{Cyclic Groups}
\begin{definition}
A \textit{word} is any written product of group elements and inverses. They are generally in the form
\[s_{1}^{\epsilon_{1}} s_{2}^{\epsilon_{2}} s_{3}^{\epsilon_{3}}... s_{k}^{\epsilon_{k}}\]
\end{definition}

\begin{example}
Given a set $\{x,y,z\}$, $x y, x z^{-1} y y x^{-2},...$ are words. 
\end{example}

\begin{definition}
The \textit{generating set} $\langle S \rangle$ of a group $G$ is a subset of $G$ such that every element of the group can be expressed as a word of finitely many elements under the group operations. The elements of the generating set are called \textit{generators}.
\end{definition}

\begin{definition}
A \textit{cyclic group}, denoted $C_{n}$, is a group generated by a single element. In a \textit{finite cyclic group}, there exists a $k \in \mathbb{N}$ such that $g^{k} = g^{0} = 1$ (or in additive notation, $kg = 0g = 0$), where $g$ is the generator. A \textit{finitely generated group} is a group generated by a finite number of elements. In \textit{infinite cyclic groups}, all elements are distinct for distinct $k$. 
\end{definition}

\begin{example}
A representation of a cyclic group of $n$th order is the $n$th roots of unity in $\mathbb{C}$.
\end{example}

\begin{example}
Another representation of a cyclic group of $n$th order is the set of discrete angular rotations in $SO(2)$, in the form of 
\[ R =  \bigg\{ \begin{pmatrix}
\sin{\theta} & \cos{\theta} \\
\cos{\theta} & -\sin{\theta}
\end{pmatrix}\; \bigg| \; \theta \in \Big\{\frac{2 \pi}{n} k\Big\}_{k = 0}^{n-1} \bigg\} \]
\end{example}

\begin{example}
$\mathbb{Z}$ is an infinite cyclic group with generator $1$. Furthermore, $\mathbb{Z}/m\mathbb{Z}$ is a finite cyclic group with generator $1$. In fact, the generator of $\mathbb{Z}/m\mathbb{Z}$ can be any integer relatively prime to $m$ (and less than $m$). 
\end{example}

\begin{example}
The set of all \textit{transpositions} forms a generating set of $S_{n}$. 
\end{example}

It is actually a fact that every finite cyclic group of order $m$ is isomorphic to $\mathbb{Z}/m\mathbb{Z}$. Every infinite cyclic group is isomorphic to $\mathbb{Z}$. This implies that any two cyclic group of the same order are isomorphic, since we can define a mapping $f:a\longrightarrow b$, where $a$ and $b$ are generating elements of their respective groups. 

\begin{example}
Dih$(3) \simeq S_{3}$, since permutations of the vertices of a triangle are isomorphic to a permutations of a 3-element set. 
\end{example}

\begin{definition}
The \textit{free group} $F_{S}$ over a given set $S$ consists of all words that can be built from elements of $S$. Clearly, $S$ is the generating set of $F_{S}$. 
\end{definition}

\subsubsection{Group Presentations}
One method of specifying a group is to put it in the form
\[ \big\langle \; S \; | \; R \;\big\rangle \]
where $S$ is the generating set and $R$ is a set of relations. 

\begin{example}
The cyclic group of order $n$ could be presented as
\[ \big\langle \; a \; | \; a^{n} = 1 \;\big\rangle \]
\end{example}

\begin{example}
Dih $(8)$, with $r$ representing a rotation by $45$ degrees in the direction of the orientation and $f$ representing a flip over any axis, is presented by
\[ \big\langle \; \{ r, f\} \; | \; r^{8} = 1, f^{2} = 1, (r f)^{2} = 1 \;\big\rangle \]
\end{example}

\subsection{Cayley's Theorem}

\begin{lemma}
Let $G$ be a group with $a \in G$. We define the map
\[ \phi: G \longrightarrow G, \; \phi (x) = a x a^{-1}\]
Then, $\phi$ is an automorphism of $G$. 
\end{lemma}
\begin{proof}
The map $\psi: G \longrightarrow G, \; \psi(x) = a^{-1} x a$ is clearly the inverse of $\phi$, with $\phi \psi = \psi \phi = I$ for all $x \in G \implies \phi$ is bijective. Secondly, $\phi(x) \phi(y) = a x a^{-1} a y a^{-1} = a (x y) a ^{-1} = \phi (x y) \implies \phi$ preserves the group structure. 
\end{proof}

\begin{theorem}[Cayley's Theorem]
Every group $G$ is isomorphic to a subgroup of its symmetric group. If $G$ is finite, then so is Sym$(G)$, so every finite group is a subgroup of $S_{n}$, for some $n$.
\end{theorem}
\begin{proof}
Let $H =$ Sym$(G)$. We define the map
\[ \phi: G \longrightarrow H \]
by the following rule. For $a \in G$, map it to permutation $\sigma = \phi (a) \in H$ defined as $\sigma(g) = a g$ for all $g \in G$. Note that given an $a \in G$, $a g$ must also be in $G$, meaning that a corresponding $\sigma \in H$ exists. It is sufficient to prove that $\phi$ is an isomorphism onto its image. We first prove injectivity. Given $a \neq b \in G$, $\phi(a)=\sigma, \phi(b) = \tau$. Assume $\sigma = \tau \implies a = a e =  \sigma(e) = \tau (e) = b e = b \implies a = b$, a contradiction. We now check that $\phi(a b) = \phi(a) \phi(b)$. Given $g \in G, \phi(a) \phi(b) (g) = \phi(a) (bg) = a(bg)= (ab) g = \phi(ab) (g).$
\end{proof}

\subsection{Group Actions}
\begin{definition}
Let $G$ be a group, $X$ a set. Then, a (left) group action of $G$ on $X$ is a function: 
\[ \varphi: G \times X \longrightarrow X, \; (g,x) \longmapsto \varphi(g,x)\]
satisfying two axioms:
\begin{enumerate}
    \item Identity. $\forall x \in X, \varphi(e, x) = x$. 
    \item Compatibility. $\forall g, h \in G \text{ and } \forall x \in X, \varphi(gh, x) = \varphi(g, \varphi(h, x))$.
\end{enumerate}
The group $G$ is said to \textit{act on} $X$. $X$ is called a \textit{G-set}. The two axioms, furthermore, imply that for every $g \in G$, the function that maps $x \in X$ to $ \varphi(g, x) \in X$ is a bijective map, since the inverse is the function mapping $x \mapsto \varphi(g^{-1}, x)$. \\
$(g, x)$ can be interpreted as the element $g$ in the transformation group $G$ acting on an element $x$ in $X$.
\end{definition}

\begin{example}
Isom$\,\mathbb{R}^{3}$ acts on $\mathbb{R}^{3}$ since every element $g \in$ Isom$\,\mathbb{R}^{3}$ acts on the entire space $\mathbb{R}^{3}$. 
\end{example}

\begin{example}
$S_n$ acts on $\{1, 2, ..., n\}$by permuting its elements.
\end{example}

\begin{example}
The GA$(V)$ acts transitively on the points of an affine space.
\end{example}

\textbf{Equivalent Interpretation of Group Actions}
Note that this group action $G$ on space $X$ identifies a group homomorphism into the group of automorphisms of that space. Given an abstract group element $g \in G$, $\varphi(g, \cdot): X \longrightarrow X$ is defined accordingly, where $\varphi(g, \cdot) \in $ Aut$(X)$. So alternatively, we can interpret a group action as a homomorphism from $G$ to Aut$(X)$. 
\[ \phi: G \longrightarrow \text{Aut}(X), \; g \mapsto \phi(g) = \varphi(g,\cdot)\]

\begin{definition}
A group action on a finite-dimensional vector space $X$ is called a \textit{representation} of that group. 
\end{definition}

\subsection{Equivalence and Congruence}

\begin{definition}
A transformation group $G$ is called \textit{transitive} if for any $x, y \in X$, there exists a $\phi \in G$ such that $y = \phi(x)$. 
\end{definition}

\begin{example}
Tran$(V)$ and GA$(V)$ are transitive groups. 
\end{example}

\begin{definition}
Let $X$ be a set and $G$ its transformation group on $X$. The way we define $G$ determines the \textit{geometry} of $X$. More specifically, a figure $F_{1} \subset X$ is \textit{equivalent} or \textit{congruent} to $F_{2} \subset X$ iff there exists $\phi \in G$ such that $F_{2} = \phi (F_{1})$ (or equivalently, $F_{1} = \phi (F_{2})$). This is an equivalence relation since
\begin{enumerate}
    \item $F \sim F$. 
    \item $F \sim H \implies H \sim F$. 
    \item $F \sim H, H \sim K \implies F \sim K$
\end{enumerate}
Two figures that are in the same equivalence class are known to be \textit{congruent} with respect to the geometry of $X$ induced by $G$. 
\end{definition}
Clearly, if two figures are congruent in Euclidean geometry, then they are congruent in Affine geometry, since E$(n) \subset$ GA$(n)$. 

\subsection{Cosets and Lagrange's Theorem}

\begin{definition}
Given a group $G$ and a subgroup $H$, $g_1$ and $g_2$ are congruent modulo $H$, denoted $g_1 \equiv g_2 \pmod{H}$. The equivalence classes are known as \textit{cosets}. A coset of somprised of all the products obtained by multiplying each element of $H$ by a particular element in $G$. Since group multiplication is not necessarily commutative, we must distinguish between right and left cosets. 
\begin{enumerate}
    \item A \textit{left coset} is 
    \[ g H \equiv \{g h \;| \;h \in H \} \]
    \item A \textit{right coset} is 
    \[H g \equiv \{h g \;|\; h \in H \} \]
\end{enumerate}
It is easy to see that the cosets form a partition of the set $X$, with each coset of the same cardinality. 
\end{definition}

\begin{definition}
A subgroup $N \subset G$ is a \textit{normal subgroup} iff the left cosets equal the right cosets. Every subgroup of an abelian group is normal. 
\end{definition}

\begin{theorem}[Lagrange's Theorem]
Let $G$ be a finite group and $H$ its subgroup. Then 
\[ |G| = |G:H| |H|\]
where $|G:H|$ is the number of cosets in $G$. 
\end{theorem}

\begin{corollary}
The order of a subgroup of a finite group divides the order of the group. 
\end{corollary}

\begin{definition}
The order of an element is the order of the cyclic subgroup that it generates. 
\end{definition}

\begin{corollary}
The order of any element of a finite group divides the order of the group. 
\end{corollary}

\begin{corollary}
Every finite group of a prime order is cyclic. 
\end{corollary}

\begin{theorem}[Fermant's Little Theorem]
Let $p$ be a prime number. The multiplicative group $\mathbb{Z}_{p} \setminus \{0\}$ of the field $\mathbb{Z}_{p}$ is an abelian group of order $p-1 \implies g^{p-1} = 1$ for all $g \in \mathbb{Z}_{p} \setminus \{0\}$. So,
\[ a^{p-1} \equiv 1 \iff a^{p} \equiv a \pmod{p} \]
\end{theorem}

\begin{corollary}
If $|G| = n$, then $g^{n} = e$ for all $g \in G$. 
\end{corollary}

\begin{definition}
\textit{Euler's Totient Function}, denoted $\varphi(n)$, consists of all the numbers less than or equal to $n$ that are coprime to $n$. 
\end{definition}

\begin{theorem}[Euler's Theorem (Generalization of Fermant's Little Theorem)]
For any $n$, the order of the group $\mathbb{Z}_{n} \setminus \{0\}$ of invertible elements of the ring $\mathbb{Z}_{n}$ equals $\varphi(n)$, where $\varphi$ is Euler's totient function. In other words with $G = \mathbb{Z}_{n} \setminus \{0\}$, 
\[ a^{\varphi(n)} \equiv 1 \pmod{n}, \; \text{ where $a$ is coprime to $n$}\]
\end{theorem}

\begin{example}
In $\mathbb{Z}_{125} \setminus \{0\}$, $\varphi(125) = 125 - 25 = 100 \implies 2^{100} \equiv 1 \pmod{125}$
\end{example}

\begin{definition}
Let $G$ be a transformation group on set $X$. Points $x, y \in X$ are equivalent with respect to $G$ if there exists an element $g \in G$ such that $y = g x$. This has already been defined through the equivalence of figures before. This relation splits $X$ into equivalence classes, called \textit{orbits}. Note that cosets are the equivalence classes of the transformation group $G$; oribits are those of $X$. We denote it as
\[ Gx \equiv \{ g x \;|\;g \in G \} \]
\end{definition}
By definition, transitive transformation groups have only one orbit.

\begin{definition}
The subgroup $G_{x} \subset G$, where $G_{x} \equiv \{ g \in G | g x = x\}$ is called the \textit{stabilizer} of $x$.
\end{definition}

\begin{example}
The orbits of $O(2)$ are concentric circles around the origin, as well as the origin itself. The stabilizer of the point $p \neq 0$ is the identity and the reflection across the line $\vv{0p}$. The stabilizer of $0$ is the entire $O(2)$.
\end{example}

\begin{example}
The group $S_n$ is transitive on the set $\{1, 2, ..., n\}$. The stabilizer of $k, (1 \leq k \leq n)$ is the subgroup $H_{k} \simeq S_{n-1}$, where $H_k$ is the permutation group that does not move $k$ at all. 
\end{example}

\begin{theorem}
There exists a 1-to-1 injective correspondence between an orbit $G_x$ and the set $G / G_{x}$ of cosets, which maps a point $y = g x \in G x $ to the coset $g G_x$. 
\end{theorem}

\begin{definition}
The \textit{length of an orbit} is the number of elements in it. 
\end{definition}

\begin{corollary}
If $G$ is a finite group, then 
\[ |G| = |G_x| |G x| \]
In fact, there exists a precise relation between the stabilizers of points of the same orbit, regardless of $G$ being finite or infinite: 
\[ G_{g x} = g G_{x} g^{-1} \]
\end{corollary}

\subsection{Abelian Groups}
First, note that the successive addition of elements of an additive abelian group can be represented by integer multiplication. 
\[ x + x + ... + x = n x, \; n \in \mathbb{Z}\]
Similarly, we can take the integer power of an element to represent successive multiplication in a multiplicative abelian group. 

\begin{proposition}
It is easy to check that in an additive abelian group $A$, with $a, b \in A$ and $k, l \in \mathbb{Z}$, 
\begin{align}
    & k (a + b) = k a + k b \\
    & (k + l) a = k a + l a \\
    & (k l) a = k (l a)
\end{align}
which implies
\begin{equation}
    k(a - b) = k a - k b, \; (k - l) a = k a - l a
\end{equation}
\end{proposition}

\begin{definition}
For any subset $S \subset A$, the collection of all linear combinations 
\[k_1 a_1 + k_2 a_2 + ... + k_n a_n, \; k_i \in \mathbb{Z}, a_i \in S\]
is the smallest subgroup of $A$ containing $S$, called the \textit{subgroup generated by $S$} and denoted $\langle S \rangle$. If $\langle S \rangle = A$, then we say that $A$ is \textit{generated} by $S$, or that $S$ is a \textit{generating set} of $A$. 
\end{definition}

\begin{definition}
An abelian group that has a finite generating set is called \textit{finitely generated}. Finitely generated abelian groups are similar to finite dimensional vector spaces. 
\end{definition}

\begin{definition}
A system $\{ a_1, a_2, ..., a_n\}$ of elements of a group $A$ is called \textit{linearly independent} if $k_1 a_1 + k_2 a_2 + ... + k_n a_n = 0 \implies k_1, k_2, ..., k_n = 0$. A system of linear independent elements that generates $A$ is called a \textit{basis}. 
\end{definition}

Note that every finite dimensional vector has a basis, but not every finitely generated abelian group has one. For example, $(\mathbb{Z}_n, +)$ is generated by one element, but it has no basis since every element $a \in \mathbb{Z}_n$ satisfies the nontrivial relation $n a = 0$. 
\begin{definition}
A finitely generated abelian group is \textit{free} if it has a basis. 
\end{definition}

\begin{theorem}
All bases of a free abelian group $L$ contain the same number of elements. 
\end{theorem}

\begin{definition}
The \textit{rank} of a free abelian group $L$ is the number of elements in its basis. It is denoted rk$L$. The zero group is regarded as a free abelian group of rank $0$. 
\end{definition}

\begin{theorem}
Every free abelian group $L$ of rank $n$ is isomorphic to the group $\mathbb{Z}^n$ of integer rows of length $n$. 
\end{theorem}

\begin{theorem}
Every subgroup $n$ of a free abelian group $l$ of rank $n$ is a free abelian group of rank $ \leq n$. 
\end{theorem}

Note that unlike a vector space, a free abelian group of positive rank contains subgroups of the same rank that do not conside with the whole group. For example, the subgroup $m \mathbb{Z} \subset \mathbb{Z}, m > 0$ has rank $1$, just as the whole group. 

Moreover, a free abelian group of rank $n$ can be embedded as a subgroup into an $n$-dimensional Euclidean vector space $E^n$. To do this, let $\{e_1, e_2, ..., e_n\}$ be a basis of $E^n$. Then, the subgroup generated by these basis vectors is the set of vectors with integer components, which is a free abelian group of rank $n$. This subgroup obtained as such is called a \textit{lattice} in $E^n$. 

\begin{definition}
A subgroup $L \subset E^n$ is \textit{discrete} if every bounded subset of $E^n$ contains a finite number of elements in $L$. Clearly, every lattice is discrete, and a subgroup generated by a linearly independent system of vectors (i.e. a lattice in a subspace of $E^n$) is discrete. 
\end{definition}

\begin{proposition}
A subgroup $L \subset E^n$ is discrete if and only if its intersection with any neighborhood of $0$ consists of $0$ itself. 
\end{proposition}

\begin{theorem}
Every discrete subgroup $L \subset E^n$ is generated by a linearly independent system of vectors of $E^n$. 
\end{theorem}

\begin{corollary}
A discrete subgroup $L \subset E^n$ whose linear span coincides with $E^n$ is a lattice in $E^n$. 
\end{corollary}

Lattices in $E^3$ play an important role in crystallography since the defining feature of a crystal structure is the periodic repetition of the configuration of atoms in all three dimensions. More explicitly, let $\Gamma$ be the symmetry group of the crystal structure and let $\mathcal{L}$ be the group of all vectors $a$ such that the parallel translation $t_a \in \Gamma$. Then, $\mathcal{L}$ is a discrete subgroup of $E^n$ and thus, is a lattice in $E^3$. More specifically, we can present 
\[ \Gamma \equiv \text{Dih}\,C \times \mathcal{L}\]
where Dih$\, C$ is the Dihedral group of the crystal structure that preserves its lattices. 

\begin{definition}
An \textit{integral elementary row transformation} of a matrix is a transformation of one of the following three types: 
\begin{enumerate}
    \item adding a row multiplied by an integer to another row
    \item interchanging two rows
    \item multiplying a row by $-1$ 
\end{enumerate}
An \textit{integral elementary column transformation} is defined similarly. 
\end{definition}

\begin{proposition}
Every integral rectangular matrix $C = (c_{i j})$ can be reduced by integral elementary row transformations to the diagonal matrix diag$(u_1, ..., u_p)$, where $u_1, u_2, ..., u_p \geq 0$ and $u_i | u_{i+1}$ for $i = 1, 2, ..., p -1$. 
\end{proposition}

\begin{example}
The following matrix can be reduced (with a few steps now shown) to the stated form. 
\[\begin{pmatrix} 2&6&2 \\ 2&3&4 \\ 4&2&4 \end{pmatrix} \rightarrow 
\begin{pmatrix} 2&3&4 \\ 0&-3&2 \\ 4&2&4 \end{pmatrix} \rightarrow
\begin{pmatrix} 1&0&0 \\ 0&6&14 \\ 0&8&12 \end{pmatrix} \rightarrow
\begin{pmatrix} 1&0&0 \\ 0&2&0 \\ 0&0&20\end{pmatrix}
\]
where $1|2$ and $2|20$. 
\end{example}

Note that for $n \times 1$ or $1 \times n$ matrices, this procedure is precisely the Euclidean algorithm that produces the GCD of $n$ integers. 

\begin{proposition}
Given square integral matrix $C$ with  reduced form diag$(u_1, ..., u_p)$, 
\[ u_i = \frac{d_i}{d_{i-1}}\]
where $d_i$ is the GCD of the minors of order $i$ of the original matrix $C$. Recall that a minor of a matrix is the determinant of the matrix with one of its rows and columns removed. $d_0$ is assumed to equal $1$. This implies that the numbers $u_1, u_2, ..., u_p$, along with the reduced form, are uniquely determined by $C$. 
\end{proposition}

\begin{theorem}
For any subgroup $N$ of a free abelian group $L$ of rank $n$, there exists a basis $\{e_1, ..., e_n\}$ of $L$ and natural numbers $u_1, ..., u_m, \; (m \leq n)$, such that $\{u_1 e_1, ..., u_m e_m\}$ is a basis fo the group $N$ and $u_i | u_{i+1}$ for $i = 1, 2, ..., m-1$. 
\end{theorem}

\section{Ring Theory}
\subsection{Field of Complex Numbers}
The impossibility of defining division on the ring of integers motivates its extension into the field of rational numbers. Similarly, the inability to take square roots of negative real numbers forces us to extend the field of real numbers to the bigger field of complex numbers. 

\begin{definition}
The \textit{field of complex numbers} is a field $\mathbb{C}$ such that 
\begin{enumerate}
    \item It contains the field $\mathbb{R}$ as a subfield. 
    \item It contains an element $i$ such that $i^2 = -1$.
    \item It is minimal with respect to properties (i) and (ii). That is, if $F$ is a subfield of $\mathbb{C}$ containing $\mathbb{R}$ and $i$, then $F = \mathbb{C}$. 
\end{enumerate}
\end{definition}

Note that the identity $x^2 + 1 \equiv (x + i) (x - i)$ implies that the equation $x^2 = -1$ has exactly two solutions in $\mathbb{C}$, $i$ and $-i$. Therefore, if a subfield of $\mathbb{C}$ contains one of these solutions, it must contain the other (since $i$ and $-i$ are additive and multiplicative inverses). 

Furthermore, since $i$ is defined to be $\sqrt{-1}$, we could replace $i$ with $-i$ and our calculations would still be consistent throughout the rest of mathematics. In fact, $i$ and $-i$ behave \textit{exactly} identically and cannot be distinguished in an abstract sense. Visually, the complex plane "flipped" across the real number axis produces the same complex plane. 

\begin{theorem}
$\mathbb{C}$ exists and is unique up to an isomorphism that maps all real numbers to themselves. Every complex number can be uniquely written as $a + bi$, where $a, b \in \mathbb{R}$ and $i$ is a fixed element such that $i^2 = -1$. 
\end{theorem}
\begin{proof}
We first assume that $\mathbb{C}$ exists. Consider the subset of $\mathbb{C}$
\[K \equiv \{ a + bi \; | \; a, b \in \mathbb{R}\} \]
By evaluating its operations, we can check for closure, identity, and invertibility of nonzero elements to conclude that $K$ is a subfield of $\mathbb{C} \implies$ by prop. (iii), $K = \mathbb{C} \implies$ every element in $\mathbb{C}$ can be written in form $a + bi$. To prove uniqueness, we assume that $p \in \mathbb{C}$ can be written in distinct forms $p = a + bi = a^{\prime} + b^\prime i$. Then
\begin{align*}
     a + bi = a^{\prime} + b^\prime i & \implies (a - a^\prime)^2 = (b^\prime i - b i)^2 = - (b^\prime - b)^2 \\
     & \implies a - a^\prime = b^\prime - b = 0
\end{align*}
To prove uniqueness of $\mathbb{C}$ up to ismorphism, we assume that $\mathbb{C}^\prime$ exists with $i^\prime$ such that $i^{\prime 2}$ containing elements $a + b i'$. Let $f: \mathbb{C} \longrightarrow \mathbb{C}^\prime$ defined 
\[ f( a + bi) = a + bi^\prime\]
Then, 
\begin{align*}
    f\big((a + b i) + (c + d i) \big) & = f\big( (a + c) + (b + d)i \big) \\
    & = (a + c) + (b + d) i^\prime \\
    & = (a + b i^\prime) + (c + d i^\prime) \\
    & = f(a + b i) + f( c + d i) \\
    f\big( \kappa (a + b i)\big) & = f\big( \kappa a + \kappa b i\big) \\
    & = \kappa a + \kappa b i^\prime \\
    & = \kappa (a + b i^\prime) \\
    & = \kappa f(a + b i)
\end{align*}
So, $f$ is an isomorphism, and $\mathbb{C} \simeq \mathbb{C}^\prime$. From analysis, we can construct and prove the existence of $\mathbb{R}$. We then define the map
\[ \rho: \mathbb{R}^2 \longrightarrow \mathbb{C}, \; \rho(a, b) \equiv a + bi\]
with $\rho(1, 0)$ as the multiplicative identity and $\rho(0,1) \equiv i$. Therefore, every element of $\mathbb{C}$ can be uniquely represented as an element of $\mathbb{R}^2$. 
\end{proof}

\begin{definition}
\textit{Complex conjugation} is an automorphism of $\mathbb{C}$ defined
\[ c = a + b i \mapsto \bar{c} = a - b i\]
This is identically defined by replacing $i$ with $-i$. Clearly, $\bar{\bar{c}} = c$. 
\end{definition}

\begin{definition}
Real numbers are elements in $\mathbb{C}$ that are equal to their own conjugates. 
\end{definition}

\begin{proposition}
For any $c \in \mathbb{C}$, $c + \bar{c}$ and $c \bar{c}$ are real. 
\end{proposition}
\begin{proof}
Using the fact that the complex conjugate is an isomorphism, 
\begin{align*}
    & \bar{c + \bar{c}} = \bar{c} + \bar{\bar{c}} = \bar{c} + c = c + \bar{c} \\
    & \bar{ c \bar{c}} = \bar{c} \bar{\bar{c}} = \bar{c} c = c \bar{c}
\end{align*}
\end{proof}
Note that we proved this abstractly using only the properties given above, and did not decompose $c$ to its \textit{algebraic form} $a + b i$. 

If $c = a + b i, \; a, b \in \mathbb{R}$, then 
\[ c + \bar{c} = 2a, \; c \bar{c} = a^2 + b^2\]

In case the reader is unaware, it is common to interpret complex numbers $c = a + b i$ as points or vectors $(a, b)$ on the complex plane. 

\subsubsection{Polar Representations of Complex Numbers}
\begin{definition}
The \textit{absolute value} of a complex number $c = a + b i$, denoted $|c|$, is the length of the vector representing $c$. 
\[ |c| \equiv \sqrt{a^2 + b^2}\]
\end{definition}

\begin{definition}
The \textit{argument} of a complex number $c = a + b i$, denoted arg$c$, is the angle formed by the corresponding vector with the polar axis. It is defined within the interval $[0, 2\pi)$. 
\[ \text{arg}(c) \equiv \tan^{-1}{\frac{b}{a}}\]
\end{definition}

\begin{definition}
The \textit{polar representation}, or \textit{trigonometric representation}, of a complex number $c = a + b i$ is defined using the equations 
\[ a = r \cos{\varphi}, \; b = r\sin{\varphi} \implies c = r (\cos{\varphi} + i \sin{\varphi})\]
This mapping can be defined 
\[ \rho: \mathbb{R} \times \frac{\mathbb{R}}{2 \pi} \longrightarrow \mathbb{C}, \; \rho(r, \varphi) = r (\cos{\varphi} + i \sin{\varphi})\]
\end{definition}

\begin{theorem}
$\rho$ is "similar" to a homomorphism in the following way. By defining the domain and codomain as groups, 
\[ \rho: \big( \mathbb{R}, \times \big) \times \Big( \frac{\mathbb{R}}{2 \pi} \Big) \longrightarrow \big( \mathbb{C}, \times \big)\]
we can see that
\[ \rho (r_1, \varphi_1) \times \rho(r_2, \varphi_2) = \rho(r_1 \times r_2, \varphi_1 + \varphi_2) \]
or equivalently, 
\[r_1 (\cos{\varphi_1} + i \sin{\varphi_1}) \cdot r_2 (\cos{\varphi_2} + i \sin{\varphi_2}) = r_1 r_2 (\cos{(\varphi_1 + \varphi_2)} + i \sin{(\varphi_1 + \varphi_2)})\]
\end{theorem}

\begin{corollary}
The formula for the ratio of complex numbers is defined
\[ \frac{r_1 (\cos{\varphi_1} + i \sin{\varphi_1})}{r_2 (\cos{\varphi_2} + i \sin{\varphi_2})} = \frac{r_1}{r_2} (\cos{(\varphi_1 - \varphi_2)} + i \sin{(\varphi_1 - \varphi_2)})\]
\end{corollary}

\begin{corollary}
The positive integer power of a complex number can be written using \textit{De Moivre's formula}. 
\[ \big(r(\cos{\varphi} + i \sin{\varphi})\big)^n = r^n (\cos{n \varphi} + i \sin{n \varphi})\]
\end{corollary}

We can use this formula to extract a root of $n$th degree from a complex number $c = r(\cos{\varphi} + i \sin{\varphi})$, which means to solve the equation $z^n = c$. Let $z = s (\cos{\psi} + i \sin{\psi})$. Then by De Moivre's formula, 
\begin{align*}
    z^n & = s^n (\cos{n \psi} + i \sin{n \psi}) = r(\cos{\varphi} + i \sin{\varphi}) \\
    & \implies s = \sqrt[n]{r}, \; \psi = \frac{\varphi + 2\pi k}{n} \\
    & \implies z = \sqrt[n]{r} \bigg( \cos{\frac{\varphi + 2\pi k}{n}} + i \sin{\frac{\varphi + 2\pi k}{n}}\bigg) \text{ for } k = 0, 1, ..., n-1
\end{align*}
Geometrically, the $n$ solutions lie at the vertices of a regular $n$-gon centered at the origin. When $c = 1$, the solutions are the $n$th roots of unity.

\subsection{Rings of Residue Class}
\begin{definition}
The quotient set $\mathbb{Z}$ by the relation of congruence modulo $n$ is denoted $\mathbb{Z}_{n}$. It is called the \textit{ring of residue class modulo n} or \textit{residue ring modulo n}. 
\[ \mathbb{Z}_{n} = \{ [0]_{n}, [1]_{n}, ... , [n-1]_{n} \} \]
\end{definition}
By definition of the relation, congruence modulo $n$ has properties: 
\begin{enumerate}
    \item $a \equiv a' \pmod{n}, b \equiv b' \pmod{n} \implies a + b \equiv a' + b' \pmod{n}$ . 
    \item With same hypothesis as (i) $a b \equiv a' b \equiv a b' \equiv a' b' \pmod{n}$. 
\end{enumerate}
We can furthermore define operations of addition and multiplication on the ring $\mathbb{Z}_{n}$ as such 
\begin{align*}
    & [a]_{n} + [b]_{n} \equiv [a + b]_{n} \\
    & [a]_{n} [b]_{n} \equiv [ab]_{n}
\end{align*}
making $\mathbb{Z}_{n}$ is a commutative, associative ring with unity. 

Note that the properties of the operation in $\frac{M}{R}$ inherits all the properties of the addition operation on $M$ that are expressed in the form of identities and inverses, along with the existence of the zero identity. 
\begin{align*}
0 \in M & \implies [0] \text{ is the additive identity in } \frac{M}{R} \\
a + (-a) = 0 & \implies [a] + [-a] = [0] \\
1 \in M & \implies [1] \text{ is the multiplicative identity in } \frac{M}{R}
\end{align*}

\begin{example}
In $\mathbb{Z}_{5}$, the elements $[2]$ and $[3]$ are multiplicative inverses of each other since $[2] [3] = [6] = [1]$, and $[4]$ is its own inverse since $[4] [4] = [16] = [1]$. The addition and multiplication tables for $\mathbb{Z}_5$ is shown below. 
\end{example}

The ring $\mathbb{Z}_n$ has all the properties of a field except the property of having inverses for all of its nonzero elements. This leads to the following theorem. 

\begin{theorem}
The ring $\mathbb{Z}_{n}$ is a field if and only if $n$ is a prime number. 
\end{theorem}
\begin{proof}
$(\rightarrow)$ Assume that $n$ is composite $\implies n = k l$ for $k, n \in \mathbb{N} \implies k, n \neq 0$, but 
\[ [k]_n [l]_n = [k l]_n = [n]_n = 0\]
meaning that $\mathbb{Z}_n$ contains $0$ divisors and is not a field. The contrapositive of this states $(\rightarrow)$. \\
$(\leftarrow)$ Given that $n$ is prime, let $[a]_n \neq 0$, i.e. $[a]_n \neq [0]_n, [1]_n$. The set of $n$ elements 
\[[0]_n, [a]_n, [2a]_n, ..., [(n-1)a]_n\]
are all distinct. Indeed, if $[k a]_n = [l a]_n$, then $[(k-l) a]_n = 0 \implies n = (k-l) a \iff n$ is not prime. Since the elements are distinct, exactly one of them must be $[1]_n$, say $[p a]_n \implies$ the inverse $[p]_n$ exists. 
\end{proof}

\begin{corollary}
For any $n$, $[k]_n$ is invertible in the ring $\mathbb{Z}_n$ if and only if $n$ and $k$ are relatively prime. 
\end{corollary}

\begin{definition}
The \textit{characteristic} of ring $R$ (or a field $F$), denoted char$(R)$, is the smallest number of times one must successively add the multiplicative identity $1$ to get the additive identity $0$. That is char$(R)$ is the smallest positive number $n$ such that 
\[ 1 + 1 + ... + 1 = 0 \]
If no such number $n$ exists, then char$(R) = 0$. The characteristic of $\mathbb{Z}_n = n$
\end{definition}

Note that the characteristic of the field $\mathbb{Z}_n$ must be prime. 

\begin{theorem}[Freshman's Dream]
Given a field $F$ with char$(F) = p$, 
\[(a + b)^p = a^p + b^p\]
\end{theorem}
\begin{proof}
\[(a + b)^p = \sum_{k = 0}^p {p\choose k} a^{p-k} b^{k}\]
It is clear that 
\[{p\choose k} = \frac{p (p-1) ... (p - k+1)}{k!}\]
is divisible by $p$ for all $k \neq 0, p$, so all the middle terms must cancel out to $0$. 
\end{proof}

\subsection{Polynomial Algebra}
\subsubsection{Construction and Basic Properties}
\begin{definition}
A \textit{polynomial $f$} of $x$ over a ring $R$ is defined as a formal expression 
\begin{equation}
    f(x) = a_0 + a_1 x^1 + a_2 x^2 + ...  + a_{n-1} x^{n-1} + a_n x^n
\end{equation}
where $n$ is a natural number, the coefficients $a_0, a_1, ..., a_n$ are elements of $R$, $x$ is a formal symbol, whose powers $x^i$ are just placeholders for the corresponding coefficients $a_i$ so that the given formal expression is a way to encode the infinite finitary sequence. 
\begin{equation}
    (a_0, a_1, a_2, ..., a_n, 0, 0, ...)
\end{equation}
Two polynomials are equal if and only if the sequences of their corresponding coefficients are equal.
\end{definition}

Note that this is really just a fancy way to write a finitary sequence. 

\begin{definition}
The set of polynomials with coefficients in the ring $R$ forms itself a ring, called the \textit{ring of polynomials over $R$}, denoted $R[x]$. Addition on $R[x]$ is defined component-wise, and it suffices, by the distributive law, to define multiplication as
\[x^k x^l = x^{k + l}\]
given that we have chosen $\{x^i\}$ as a basis of $R[x]$. If $R$ is a commutative associative ring (or a field), then $R[x]$ is called the \textit{polynomial algebra}. From now, we will treat $R[x]$ and $F[x]$ as an algebra with $R$ denoting a commutative associative ring and $F$ denoting a field, respectively. 
\end{definition}

Note that the map from $R \longrightarrow R[x]$ sending $r \mapsto r x^0$ is an injective homomorphism of rings, by which $R$ is viewed as a subring of $R[x]$. 

The ring of polynomials over field $\mathbb{R}$ is denoted $\mathbb{R}[x]$. $R[x]$ is a subalgebra within the algebra of all function of $\mathbb{R}$. 

However, for certain finite fields, some formally different polynomials may be indistinguishable in terms of mappings. For example, $x$ and $x^2$ are equivalent in the polynomial algebra defined on the domain $\mathbb{Z}_2$.

\begin{definition}
The last nonzero coefficient is called the \textit{leading coefficient}, and the degree of the polynomial $f$, denoted deg$f$, is the index of the leading coefficient. 
\end{definition}

\begin{theorem}
\begin{align}
    \text{deg}(f+g) & \leq \text{max}\{\text{deg}\,f, \text{deg} \,g\} \\
    \text{deg} \,f g & = \text{deg} \,f + \text{deg} \,g
\end{align}
\end{theorem}
\begin{proof}
Simple when presenting polynomials if form $(1)$. 
\end{proof}

\begin{definition}
The product of two finitary sequences $(a_0, a_1, a_2, ...)$ and $(b_0, b_1, b_2, ...)$ in the ring $F[x]$ is a sequence 
\[ (c_0, c_1, c_2, ...), \; c_k = \sum_{l = 0}^{k} a_l b_{k-l}\]
This formula works for infinite (non-finitary) sequences too, allowing us to define a commutative, associative algebra with unity called the \textit{algebra of formal power series over $F$}, denoted $F[[x]]$. The elements of $F[[x]]$ are written in the form 
\[ a_0 + a_1 x + a_2 x^2 + a_3 x^3...\]
\end{definition}

\begin{theorem}
If the field $F$ is infinite, then different polynomials in $F[x]$ determine different functions. 
\end{theorem}

\begin{theorem}
For any collection of given values $y_1, y_2, ..., y_n \in F$ at given distinct points $x_1, x_2, ..., x_n \in F$, there exists a unique polynomial $f \in F[x]$ with deg$\, f < n$ such that
\[ f(x_i) = y_i, \; i = 1, 2, ..., n\]
This is commonly known as the \textit{interpolation problem}, and when $n = 2$, this is called \textit{linear interpolation}. 
\end{theorem}

It is usually impossible to divide one polynomial by another in the algebra $F[x]$; the construction of it does not allow us to. However, division \textit{with remainder} is possible, similarly to the procedure of division with remainder in the ring of integers. 

\begin{theorem}
Let $f, g \in F[x]$ and $g \neq 0$. Then, there exists polynomials $q, r$ such that 
\[ f = q g + r, \; \text{deg}\, r < \text{deg}\, g \text{ (or } r = 0 \text{)}\]
This procedure of finding such polynomials $q, r$ is called \textit{division with a remainder}. A polynomial $f$ is divisible by $g$ in $F[x]$ if and only if $r = 0$. 
\end{theorem}

\begin{theorem}[Bezout's Theorem]
Given that one divides (with remainder) polynomial $f$ by $g = x - c$, let the remainder be $r \in F$. That is, 
\[f(x) = (x-c) q(x) + r, \; r \in F\]
This implies that the remainder equals the value of $f$ at point $c$. That is, 
\[f(c) = r\]
\end{theorem}

\subsubsection{Roots of Polynomials}
\begin{definition}
An element $c \in F$ is a \textit{root} of polynomial $f$ if and only if 
\[ f(c) = 0\]
\end{definition}

\begin{corollary}
An element $c$ of a field $F$ is a root of polynomial $f$ if and only if $f$ is divisible by $x - c$. 
\end{corollary}

\begin{definition}
A root $c$ of polynomial $f$ is called \textit{simple} if $f$ is not divisible by $(x-c)^2$ and \textit{multiple} otherwise. The \textit{multiplicity} of a root $c$ is the maximum $k$ such that $(x-c)^k$ divides $f$. 
\end{definition}

\begin{theorem}
The number of roots of a polynomial, counted with multiplicity, does not exceed the degree of this polynomial. Furthermore, these numbers are equal if and only if the polynomial is a product of linear factors.
\end{theorem}

\begin{definition}
A \textit{monic polynomial} is a polynomial with leading coefficient equal to $1$. 
\end{definition}

\begin{theorem}[Viete's Formulas]
Given that a polynomial $f$ factors into linear terms, that is 
\[f(x) = a_0 \prod_{i = 1}^{n} (x - c_i), c_i \text{ roots of } f\]
Then the coefficients of $f$ can be presented with the formulas
\begin{align*}
    & \sum_{i=1}^n c_i = - \frac{a_1}{a_0} \\
    & \sum_{i_1 < i_2} c_{i_1} c_{i_2} = \frac{a_2}{a_0} \\
    & \sum_{i_1< ...< i_k} \prod_{j = 1}^{k} c_{i_j} = (-1)^k \frac{a_k}{a_0} \\
    & c_1 c_2 c_3 ... c_n = (-1)^n \frac{a_n}{a_0}
\end{align*}
\end{theorem}

\begin{theorem}[Wilson's Theorem]
Let $n$ be a prime number. Then 
\[ (n-1)! \equiv -1 \pmod{n}\]
\end{theorem}

\begin{definition}
The \textit{derivative} of a polynomial is a map $D: \mathbb{R}[x] \longrightarrow \mathbb{R}[x]$ with the following properties:
\begin{enumerate}
    \item It is linear. 
    \item $D(f g) = (D f) g + f (D g)$. 
    \item $D x = 1$. 
\end{enumerate}
\end{definition}

In fact, there exists a unique map $D: F[x] \longrightarrow F[x]$ satisfying these properties for any field $F$. 

\begin{proposition}
If char$F = 0$, then the coefficients of $f \in F[x]$ regarded as a polynomial in $x - c$ can be expressed as 
\begin{equation}
    b_k = \frac{ f^{(k)} (c)}{k!}
\end{equation}
where $f^{(k)}$ is the $k$th derivative of $f$. 
\end{proposition}
\begin{proof}
We make the substitution $ y = x-c$ in the polynomial $f \in F[x]$ and then express it as a polynomial in $y$ 
\begin{equation}
    f = b_0 + b_1 (x-c) + b_2 (x-c)^2 + ... + b_n (x-c)^n
\end{equation}
We differentiate this equation $k$ times and substitute at $x = c$ to get the corresponding values of the coefficients.
\end{proof}

\subsubsection{Fundamental Theorem of Algebra of Complex Numbers}
While we have defined an upper bound for the number of roots for a polynomial, we have not determined whether a polynomial has any roots at all. Fortunately, it is sufficient to extend the field to $\mathbb{C}$ in order to strongly define a lower limit, too. 

\begin{definition}
A field $F$ is \textit{algebraically closed} if every polynomial of positive degree (i.e. non-constant) in $F[x]$ has at least one root in $F$. This is equivalent to saying that every polynomial can be expressed as a product of first degree polynomials.
\end{definition}

\begin{proposition}
A field $F$ is algebraically closed if and only if for each natural number $n$, every endomorphism of $F^n$ (that is, ever linear map from $F^n$ to itself) has at least one eigenvector. 
\end{proposition}
\begin{proof}
An endomorphism of $F^n$ has an eigenvector if and only if its characteristic polynomial has some root. $(\rightarrow)$ So, when $F$ is algebraically closed, every characteristic polynomial, which is an element of $F[x]$, must have a root. $(\leftarrow)$ Assume that every characteristic polynomial has some root, and let $p \in F[x]$. Dividing the polynomial by a scalar doesn't change its roots, so we can assume $p$ to have leading coefficient $1$. If $p(x) = a_0 + a_1 x + ... + x^n$, then we can identify matrix 
\[A = \begin{pmatrix}
0 & 0 & ... & 0 & -a_0 \\
1 & 0 & ... & 0 & -a_1 \\
0 & 1 & ... & 0 & -a_2 \\
... & ... & ... & ... & ... \\
0 & 0 & ... & 1 & -a_{n-1}
\end{pmatrix}\]
such that the characteristic polynomial of $A$ is $p$. 
\end{proof}

\begin{proposition}
$\mathbb{R}$ is not algebraically closed. 
\end{proposition}
\begin{proof}
$x^2 + 1$ doesn't have any roots in $\mathbb{R}$. 
\end{proof}

\begin{theorem}
Every polynomial of positive degree over field $\mathbb{C}$ has a root. 
\end{theorem}

\begin{corollary}
In the algebra $\mathbb{C}[x]$, every polynomial splits into a product of linear factors. 
\end{corollary}

\begin{corollary}
Every polynomial of degree $n$ over $\mathbb{C}$ has $n$ roots, counted with multiplicities. 
\end{corollary}

\begin{corollary}
$\mathbb{C}$ is algebraically closed. 
\end{corollary}

\subsubsection{Roots of Polynomials with Real Coefficients}
\begin{theorem}
If $c$ is a complex root of polynomial $f \in \mathbb{R}[x]$, then $\bar{c}$ is also a root of the polynomial. Moreover, $\bar{c}$ has the same multiplicity as $c$. 
\end{theorem}

\begin{corollary}
Every nonzero polynomial in $\mathbb{R}[x]$ factors into a product of linear terms and quadratic terms with negative discriminants. 
\end{corollary}

\begin{example}
\begin{align*}
    x^5 - 1 & = (x-1) \bigg( x - \Big( \cos{\frac{2\pi}{5}} + i \sin{\frac{2\pi}{5}}\Big) \bigg) \bigg( x - \Big( \cos{\frac{2\pi}{5}} - i \sin{\frac{2\pi}{5}}\Big) \bigg) \\
    & \times \bigg( x - \Big( \cos{\frac{4\pi}{5}} + i \sin{\frac{4\pi}{5}}\Big) \bigg) \bigg( x - \Big( \cos{\frac{4\pi}{5}} - i \sin{\frac{4\pi}{5}}\Big) \bigg) \\
    & = (x-1) \bigg( x^2 - \frac{\sqrt{5} - 1}{2} x + 1\bigg) \bigg( x^2 + \frac{\sqrt{5} + 1}{2} x + 1\bigg) 
\end{align*}
\end{example}

\begin{corollary}
Every polynomial $f \in \mathbb{R}[x]$ of odd degree has at least one real root. 
\end{corollary}
\begin{proof}
This is a direct result of Theorem **. Alternatively, without loss of generality we can assume that the leading coefficient of $f$ is positive. Then
\[ \lim_{x \rightarrow + \infty} f(x) = + \infty, \; \lim_{x \rightarrow -\infty} f(x) = -\infty\]
By the intermediate value theorem, there must be some point where $f$ equals $0$. 
\end{proof}

\begin{theorem}[Descartes' Theorem]
The number of positive roots (counted with multiplicities) of a polynomial $f \in \mathbb{R}[x]$ (denote this $N(f)$) does not exceed the number of changes of sign in the sequence of its coefficients (denote this $L(f)$). Additionally, $L(f) \equiv N(f) \pmod{2}$. If all the complex roots of $f$ are real, then $L(f) = N(f)$. 
\end{theorem}

Note that if a polynomial has a multiple root but its coefficients are known only approximately (but with any degree of precision), then it is impossible to prove that the multiple roots exists because under any perturbation of the coefficients, however small, it may separate into simple roots or simply cease to exist. This fact leads to the "instability" of the Jordan Normal form because under any perturbation of the elements of a matrix $A$, the change may drastically affect the characteristic polynomial, hence affecting the geometric multiplicities of its eigenvectors. 

\subsubsection{Factorization in Euclidean Domains}
Factorization of polynomials over $\mathbb{C}$ into linear factors and polynomials over $\mathbb{R}$ into linear and quadratic factors is similar to the factoring of the integers to prime numbers. In fact, such a factorization exists for polynomials over any field $F$, but their factors can be of any degree. Moreover, there exists no general solution for the factoring of polynomials over any field. 

\begin{definition}
A commutative associative ring with unity and without zero divisors is called an \textit{integral domain}. That is, the product of any two nonzero elements $x, y \in A$ must be nonzero. Integral domains are generalizations of the ring of integers $\mathbb{Z}$ and provide a natural setting for studying divisibility. 
\end{definition}

\begin{example}
$\mathbb{Z}$ and $F[x]$ over field $F$ are integral domains. Any field $F$ is also an integral domain. 
\end{example}

\begin{example}
The quotient ring $\mathbb{Z}_n$ is not an integral domain when $n$ is composite. 
\end{example}

\begin{example}
A product of two nonzero commutative rings with unity $R \times S$ is not an integral domain since $(1,0) \cdot (0, 1) = (0, 0) \in R \times S$. 
\end{example}

\begin{example}
The ring of $n \times n$ matrices over any nonzero ring when $ n \geq 2$ is not an integral domain. Given matrices $A, B$, if the image of $B$ is in the kernel of $A$, then $A B = 0$.
\end{example}

\begin{example}
The ring of continuous functions on the interval is not an integral domain. To see why, notice that given the piecewise functions 
\[ f (x) = \begin{cases}
1 - 2x & x \in [0, \frac{1}{2}] \\
0 & x \in [\frac{1}{2}, 1] 
\end{cases}, \; \;\;g (x) = \begin{cases}
0 & x \in [0, \frac{1}{2}] \\
2x - 1 & x \in [\frac{1}{2}, 1] 
\end{cases}\]
$f, g \neq 0$, but $f g = g f = 0$. 
\end{example}

We can classify the rings
\[\text{Integral Domains} \subset \text{Commutative Rings} \subset \text{Rings}\]

\begin{proposition}
An integral domain is a ring that is isomorphic to a subring of a field. 
\end{proposition}

\begin{proposition}
The characteristic of an integral domain is either $0$ or a prime number. 
\end{proposition}

\begin{definition}
 An element $r$ of a ring $R$ is \textit{regular} if the mapping 
\[ \rho: R \longrightarrow R, \; x \mapsto x r \]
is injective for all $x \in R$. 
\end{definition}

\begin{proposition}
An integral domain is a commutative associative ring where every element is regular. 
\end{proposition}

\begin{definition}
Let $A$ be an integral domain. An element $a \in A$ is \textit{divisible} by $b \in A$, denoted $b | a$ if there exists an element $q \in A$ such that $a = q b$. Elements $a$ and $b$ are \textit{associated}, denoted $a \sim b$ if either of the following equivalent conditions holds
\begin{enumerate}
    \item $a | b \text{ and } b | a$
    \item $a = c b, \text{ where } c$ is invertible
\end{enumerate}
The two conditions are equivalent because $c$ and $c^{-1}$ are both in $A$. 
\end{definition}

\begin{definition}
Let $A$ be an integral domain which is not a field. $A$ is \textit{Euclidean} if there exists a function 
\[ N: A \setminus \{ 0 \} \longrightarrow \mathbb{Z}_+\]
called a \textit{norm} that satisfies the following conditions. 
\begin{enumerate}
    \item $N(a b) \geq N(a)$ and the equality holds if and only if $b$ is invertible. 
    \item For any $a, b \in A, \; b \neq 0$, there exist $q, r \in A$ such that $a = q b + r$ with either $r = 0$ or $ N(r) < N(b)$, known as division with remainder. 
\end{enumerate}
Uniqueness of $q, r$ is not required in property 2. 
\end{definition}

\begin{example}
The subring of $\mathbb{C}$, defined
\[ \mathbb{Z}[i] \equiv \{ a + b i \; | \; a, b \in \mathbb{Z} \} \]
is a Euclidean integral domain with respect to the norm 
\[ N(c) \equiv a^2 + b^2\]
since $N(c d) = N(c) N(d)$ and the invertible elements of $\mathbb{Z}[i]$ are $\pm 1, \pm i$. 
\end{example}

\begin{example}
The ring of rational numbers of the form $2^{-n} m, \; n \in \mathbb{Z}_+, m \in \mathbb{Z}$, is a Euclidean domain. To define the norm, we can first assume that $m$ can be prime factorized into the form 
\[ m = \pm \prod_{i} p_{i}^{k_i}, \; p \text{ prime}\]
and the norm is defined 
\[ N(\frac{m}{2^n}) \equiv 1 + \sum_i k_i\]
We must further show that division with remainder is possible, but we will not show it here. 
\end{example}

\begin{definition}
The \textit{greatest common divisor} of elements $a$ and $b$ of an integral domain is a common divisor of $a$ and $b$ divisible by all their common divisors. It is denoted GCD$(a, b)$. 
\end{definition}

\begin{definition}
A \textit{Gaussian integer} is a complex number whose real part and imaginary part are both integers. That is, 
\[\mathbb{Z}[i] \equiv \{a + b i \;|\; a, b \in \mathbb{Z} \}\]
\end{definition}

\subsubsection{Polynomials in Several Variables}

\begin{definition}
A function of real variable $x_1, x_2, ..., x_n$ is called a \textit{polynomial} if it can be represented as 
\[f(x_1, ..., x_n) =  \sum_{k_1, ..., k_n} a_{k_1 ... k_n} x_1^{k_1} x_2^{k_2} ... x_n^{k_n}\]
where the summation is taken over a finite set of collections $(k_1, ..., k_n)$. The algebra of polynomials in $x_1, x_2, ..., x_n$ over $\mathbb{R}$ is denoted $\mathbb{R}[x_1, x_2, ..., x_n]$. 
\end{definition}

\begin{definition}
More generally, an infinite dimensional polynomial algebra of variables $x_1, ..., x_n$ over field $\mathbb{F}$ is denoted
\[\mathbb{F}[x_1, ..., x_n]\]
Like polynomials of one variable, it can be naturally identified with an abstract multi-dimensional "sequence." It has basis 
\[\{e_{k_1 k_2 ... k_n} \;|\; k_1, k_2, ..., k_n \in \mathbb{Z}_+\]
with addition defined component-wise and the multiplication rule defined with the table
\[e_{k_1...k_n} e_{l_1 ... l_n} = e_{k_1 + l_1, k_2 + l_2, ..., k_n + l_n}\]
Clearly each polynomial in its usual presentation is gotten by the linear mapping
\[e_{k_1 ... k_n} \mapsto x_1^{k_1} x_2^{k_2} ... x_n^{k_n}\]
\end{definition}

However, note that different polynomials may define the same functions if the field $\mathbb{F}$ is finite, similarly to polynomials with one variable. If $\mathbb{F}$ is infinite, then every polynomial will determine a different function. 

\begin{definition}
A polynomial is called \textit{homogeneous} if degree $d$ if 
\[a_{k_1 k_2 ... k_n} = 0 \text{ for } k_1 + k_2 + ... + k_n \neq d\]
The space of all homogeneous polynomials of fixed degree $d$ forms a finite dimensional subspace in $\mathbb{F}[x_1, ..., x_n]$ with dimension 
\[\frac{n(n+1)...(n+d-1)}{d!}\]
The dimension can be calculated by thinking of the combinatorics problem of having $d$ indistinguishable balls to put into $n$ distinguishable urns. 
\end{definition}

\subsubsection{Symmetric Polynomials}

\begin{definition}
A polynomial $f \in \mathbb{F}[x_1, ..., x_n]$ is called \textit{symmetric} if it is invariant under any permutation of the variables $x_i$. 
\end{definition}

\begin{example}
Power sums are symmetric polynomials. 
\[p(x_1, x_2, ..., x_n) = \sum_{i=1}^n x_i^k\]
\end{example}

\begin{definition}
An \textit{elementary symmetric polynomial} is a symmetric polynomial of one of these forms: 
\begin{align*}
    \sigma_1 & = x_1 + x_2 + ... + x_n \\
    \sigma_2 & = x_1 x_2 + x_1 x_3 + ... + x_{n-1} x_n \\
    ... & = ... \\
    \sigma_k & = \sum_{i_1 < ... < i_k} x_{i_1} x_{i_2} ... x_{i_k} \\
    ... & = ... \\
    \sigma_n & = x_1 x_2 ... x_n
\end{align*}
\end{definition}

The following theorem presents an extremely useful result about the decomposition of symmetric polynomials. 

\begin{theorem}
Every symmetric polynomial can be written as a polynomial of elementary symmetric polynomials $\sigma_i$. 
\end{theorem}

\begin{example}
The polynomial 
\[f \equiv \sum_{i=1}^n x_i^3\]
can be expressed as 
\[f = \sigma_1^3 - 3 \sigma_1 \sigma 2 + 3 \sigma_3\]
\end{example}

\subsubsection{Cubic Equations}
The well known discriminant of a quadratic equation 
\[f(x) = ax^2 + bx + c\]
is known in the form $\nabla = b^2 - 4ac$. However, we will present it in a slightly different manner. 

\begin{definition}
The \textit{discriminant} $D(\varphi)$ of a quadratic polynomial
\[\varphi = a_0 x^2 + a_1 x + a_2 \in \mathbb{C}[x]\]
with $c_1, c_2 \in \mathbb{C}$ as its roots is defined
\[D(\varphi) = a_1^2 - 4 a_0 a_2 = a_0^2 \bigg( \Big(\frac{a_1}{a_0} \Big)^2 - \frac{4 a_2}{a_0} \bigg) = a_0^2 \big( (c_1 + c_2)^2 - 4 c_1 c_2 \big) = a_0^2 (c_1 - c_2)^2\]
Clearly, the value of $D(\varphi)$ can tell us three things
\begin{enumerate}
    \item $c_1, c_2 \in \mathbb{R}, c_1 \neq c_2$. Then $c_1 - c_2$ is a nonzero real number and $D(\varphi) > 0$. 
    \item $c_1 = c_2 \in \mathbb{R}$. Then $c_1 - c_2 = 0$ and $D(\varphi) = 0$. 
    \item $c_1, c_2 \in \mathbb{C}, c_1 = \bar{c}_2$. Then, $c_1 - c_2$ is a nonzero strictly imaginary number and $D(\varphi) < 0$. 
\end{enumerate}
\end{definition}

\begin{definition}
We can generalize this notion of the discriminant to arbitrary polynomials
\[\varphi = a_0 x^n + a_1 x^{n-1} + ... + a_{n-1} x + a_n \in \mathbb{F}[x], \; a_0 \neq 0\]
The discriminant $D(\varphi)$ of the polynomial above is defined
\[D(\varphi) \equiv a_0^{2n-2} \prod_{i>j} (c_i - c_j)^2\]
The $a_0$ term isn't very important in this formula, since it does not affect whether $D(\varphi)$ is positive, negative, or zero. 
\end{definition}

\begin{definition}
A polynomial 
\[\varphi = a_0 x^n + a_1 x^{n-1} + ... + a_{n-1} x + a_n \in \mathbb{F}[x], \; a_0 \neq 0\]
where $a_1 = 0$ is called \textit{depressed}. A depressed cubic polynomial is of form
\[\varphi = x^3 + p x + q\]
\end{definition}

\begin{proposition}
Every monic (leading coefficeint $=1$) polynomial (and non-monic ones) 
\[\varphi = x^n + a_1 x^{n-1} + ... + a_{n-1} x + a_n \in \mathbb{F}[x], \; a_0 \neq 0\]
can be turned into a depressed polynomial with the change of variable
\[x = y - \frac{a_1}{n}\]
to get the polynomial 
\[\psi = y^n + b_2 y^{n-2} + ... + b_{n-1} y + b_n\]
\end{proposition}

\begin{lemma}
A cubic polynomial 
\[\varphi = a_0 x^3 + a_1 x^2 + a_2 x + a_3 \in \mathbb{R}[x]\]
with roots $c_1, c_2, c_3 \in \mathbb{C}$ has discriminant
\[D(\varphi) \equiv a_0^4 (c_1 - c_2)^2 (c_1 - c_3)^2 (c_2 - c_3)^2\]
With a bit of evaluation, it can also be expressed in terms of its coefficients as
\[D(\varphi) = a_1^2 a_2^2 - 4a_1^3 a_3 - 4a_0 a_2^3 + 18 a_0 a_1 a_2 a_3 - 27 a_0^2 a_3^2\]
Again, three possibilities can occur (up to reordering of its roots). 
\begin{enumerate}
    \item $c_1, c_2, c_3$ are distinct real numbers. Then $D(\varphi) > 0$. 
    \item $c_1, c_2, c_3 \in \mathbb{R}, c_1 = c_2$. Then $D(\varphi) = 0$. 
    \item $c_1 \in \mathbb{R}, c_2 = \bar{c}_3 \not\in \mathbb{R}$. Then $D(\varphi) < 0$. 
\end{enumerate}
Furthermore, the cubic formula used to find the roots of the polynomial is 
\[c_{1, 2, 3} = \sqrt[3]{-\frac{q}{2} + \sqrt{\frac{p^3}{27} + \frac{q^2}{4}}} + \sqrt[3]{-\frac{q}{2} - \sqrt{\frac{p^3}{27} + \frac{q^2}{4}}}\]
known as \textit{Cardano's formula}, after the mathematician Gerolamo Cardano. 
\end{lemma}

\subsection{Ideals and Quotient Rings}
\begin{definition}
For an arbitrary ring $(R,+, \cdot)$, let $(R, +)$ be its additive group. A subset $I$ is called a \textit{left ideal} of $R$ if it satisfies the two conditions. 
\begin{enumerate}
    \item $(I, +)$ is a subgroup of $(R, +)$. 
    \item For every $r \in R$ and every $x \in I$ the left product $r \cdot x \in I$. 
\end{enumerate}
Similarly, a \textit{right ideal} $I$ of $R$ satisfies
\begin{enumerate}
    \item $(I, +)$ is a subgroup of $(R, +)$. 
    \item For every $r \in R$ and every $x \in I$, the right product $r \cdot x \in I$. 
\end{enumerate}
Note that left and right modules are equivalence relations defined on a ring. 
\end{definition}

A left/right ideal can also be seen as a left/right $R$-submodule of $R$ viewed as an $R$-module. 

\begin{definition}
A \textit{two-sided ideal}, or more simply an \textit{ideal}, is a left ideal that is also a right idea. 
\end{definition}

\begin{proposition}
Every right or left ideal of a commutative ring is a two sided ideal. 
\end{proposition}
\begin{proof}
Trivial. 
\end{proof}

\begin{example}
The set of even integers $2 \mathbb{Z}$ is an ideal in the ring $\mathbb{Z}$, since the sum of any even integers is even and the product of any even integer with an integer is an even integer. However, the odd integers do not form an ideal. 
\end{example}

\begin{example}
The set of all polynomials with real coefficients which are divisible by the polynomial $x^2 + 1$ is an ideal in the ring of all polynomials. 
\end{example}

\begin{example}
The set of all $n \times n$ matrices whose last row is zero forms a right ideal in the ring of all $n \times n$ matrices. However, it is not a left ideal.

The set of all $n\times n$ matrices whose last column is zero is a left ideal, but not a right ideal. 
\end{example}

\begin{proposition}
The only ideals that exist in a field $\mathbb{F}$ is $\{0\}$ and $\mathbb{F}$ itself. 
\end{proposition}
\begin{proof}
Given a nonzero element $x \in \mathbb{F}$, every element of $\mathbb{F}$ can be expressed in the form of $a x$ or $x a$ for some $a \in \mathbb{F}$. 
\end{proof}

\begin{definition}
A left ideal generated by a single element $x$ is called the \textit{principal left ideal generated by $x$} and is denoted $R x$. Principal right ideals are denoted $x R$, and principal (two-sided) ideals are denoted $R x R$. 
\end{definition}

\begin{definition}
A \textit{principal ideal domain}, also called a \textit{PID}, is an integral domain in which every ideal is principal (i.e. can be generated by a single element). 

More generally, a \textit{principal ideal ring} is a nonzero commutative ring in which every ideal is principal (i.e. can be generated by a single element). 
\end{definition}

The distinction is that a principal ideal ring may have zero divisors whereas a principal ideal domain cannot. Principal ideal domains are thus mathematical objects that behave somewhat like the integers. That is, 
\begin{enumerate}
    \item Any element of a PID has a unique decomposition into prime elements. 
    \item Any two elements of a PID have a greatest common divisor. 
    \item If $x$ and $y$ are elements of a PID without common divisors, then every element of the PID can be written in the form 
    \[a x + b y\]
\end{enumerate}

\begin{proposition}
Every Euclidean domain is also a principal ideal domain. 
\end{proposition}

\begin{example}
The following are all examples of principal ideal domains. 
\begin{enumerate}
    \item Any field $\mathbb{F}$. 
    \item The ring of integers $\mathbb{Z}$. 
    \item $\mathbb{F}[x]$, rings of polynomials in one variable with coefficients in a field $\mathbb{F}$. 
    \item Rings of formal power series $\mathbb{F}[[x]]$. 
    \item The ring of Gaussian integers $\mathbb{Z}[i]$. 
\end{enumerate}
\end{example}

It is quite easy to see that a field $\mathbb{F}$ is a PID since the only two possible ideals are $\{0\}$ and $\mathbb{F}$, both of which are principal. For the integers $\mathbb{Z}$, every ideal is of the form $n\mathbb{Z}$, which is principal since it is generated by the integer $n$. The ring of polynomials $\mathbb{F}[x]$ is a PID since we can imagine a minimal polynomial $p$ in each ideal $I$. Every element in $I$ must be divisible by $p$, which means that the entire ideal $I$ can be generated by the minimal polynomial $p$, making $I$ principal. 

\subsection{The Algebra of Quaternions}
\begin{definition}
The \textit{quaternions} form an algebra of $4$-dimensional vectors over $\mathbb{R}$, with elements of the form
\[(a, b, c, d) \equiv a + bi + cj + dk\]
where $a$ is called the \textit{scalar portion} and $bi + cj + dk$ is called the \textit{vector/imaginary portion}. The algebra of quaternions is denoted $\mathbb{H}$, which stands for "Hamilton." $\mathbb{H}$ is a $4$-dimensional associative normed division algebra over $\mathbb{R}$. 
\end{definition}

From looking at the multiplication table, we can see that multiplication in $\mathbb{H}$ is not commutative. 
\begin{center}
\renewcommand\arraystretch{1.3}
\setlength\doublerulesep{0pt}
\begin{tabular}{r||*{4}{2|}}
$\times$ & 1 & i & j & k \\
\hline\hline
1 & 1 & i & j & k \\ 
\hline
i & i & -1 & k & -j \\ 
\hline
j & j & -k & -1 & i \\ 
\hline
k & k & j & -i & -1 \\ 
\hline
\end{tabular}
\end{center}
Note the identity 
\[i^2 = j^2 = k^2 = -1\]
The algebra of quaternions are in fact the first noncommutative algebra to be discovered! 

\begin{proposition}
$\mathbb{H}$ and $\mathbb{C}$ are the only finite-dimensional divisions rings containing $\mathbb{R}$ as a proper subring. 
\end{proposition}

\begin{definition}
The \textit{quaternion group}, denoted $Q_8$ is a nonabelian group of order $8$, isomorphic to a certain $8$-element subset in $\mathbb{H}$ under multiplication. It's group presentation is 
\[Q_8 = \big\langle \bar{e}, i, j, k \;|\; \bar{e}^2 = e, i^2 = j^2 = k^2 = ijk = \bar{e} \big\rangle\]
\end{definition}

Going back to the algebra, we can set $\{1, i, j, k\}$ as a basis and define addition and scalar multiplication component-wise, and multiplication (called the \textit{Hamilton product}) with properties
\begin{enumerate}
    \item The real quaternion $1$ is the identity element. 
    \item All real quaternions commute with quaternions: $a q = q a$ for all $a \in \mathbb{R}, q \in \mathbb{H}$. 
    \item Every quaternion has an inverse with respect to the Hamilton product. 
    \[(a + bi + cj + dk)^{-1} = \frac{1}{a^2 + b^2 + c^2 + d^2} \big( a - bi - cj - dk\big)\]
\end{enumerate}
Note that property 3 allows $\mathbb{H}$ to be a division algebra. 

\begin{proposition}[Scalar and Vector Components]
Let the quaternion be divided up into a scalar and vector part with the bjective mapping $a + bi + cj + dk \mapsto \big(a, (b, c, d)\big)$. 
\[q = (r, v), r \in \mathbb{R}, v \in \mathbb{R}^3\]
Then, the formulas for addition and multiplication are
\begin{align*}
    q_1 + q_2 & = (r_1, v_1) + (r_2, v_2) = (r_1 + r_2, v_1 + v_2) \\
    q_1 \cdot q_2 & = (r_1, v_1) \cdot (r_2, v_2) = (r_1 r_2 - v_1 \cdot v_2, r_1 v_2 + r_2 v_1 + v_1 \times v_2)
\end{align*}
where the $\cdot$ and $\times$ on the right hand side represnts the dot product and cross product, respectively. 
\end{proposition}

\begin{definition}
The conjugate of a quaternion $q = a + bi + cj + dk$ is defined 
\[\bar{q}, q^* \equiv a - bi - cj - dk\]
It has properties
\begin{enumerate}
    \item $q^{**} = q$
    \item $(q p)^* = p^* q^*$
\end{enumerate}
$q^*$ can also be expressed in terms of addition and multiplication. 
\[q^* = -\frac{1}{2} \big( q + iqi + jqj + kqk \big)\]
\end{definition}

\begin{definition}
The \textit{norm} of $q$ is defined
\[||q|| \equiv \sqrt{q^* q} = \sqrt{q q^*} = \sqrt{a^2 + b^2 + c^2 + d^2}\]
with properties
\begin{enumerate}
    \item Scaling factor. $||\alpha q|| = |\alpha| ||q||$
    \item Multiplicative. $||p q|| = ||p|| ||q||$
\end{enumerate}
\end{definition}

The norm allows us to define a metric 
\[d(p, q) \equiv ||p - q||\]
This makes $\mathbb{H}$ a metric space, with addition and multiplication continuous on the metric topology. 

\begin{definition}
The \textit{unit quaternion} is defined to be
\[U_q = \frac{q}{||q||}\]
\end{definition}

\begin{corollary}
Every quaternion has a polar decomposition
\[q = U_q \cdot ||q||\]
With this, we can redefine the inverse as
\[q^{-1} = \frac{q^*}{||q||^2}\]
\end{corollary}

\subsubsection{Matrix Representations of Quaternions}
We can represent $q$ with $2 \times 2$ matrices over $\mathbb{C}$ or $4\times 4 $ matrices over $\mathbb{R}$. 

\begin{proposition}
The following representation is an injective homomorphism $\rho: \mathbb{H} \longrightarrow \GL(2, \mathbb{C})$. 
\[\rho: a + bi + cj + dk \mapsto \begin{pmatrix}
a+bi & c+ di \\ -c + di & a - bi
\end{pmatrix}\]
It has properties
\begin{enumerate}
    \item Constraining any two of $b, c, d$ to $0$ produces a representation of the complex numbers. When $c = d = 0$, this is called the \textit{diagonal representation}. 
    \begin{align*}
        \begin{pmatrix}
        a+bi & 0 \\ 0 & a-bi
        \end{pmatrix},  \begin{pmatrix}
        a & c \\ -c & a
        \end{pmatrix},  \begin{pmatrix}
        a & di \\ di & a
        \end{pmatrix}
    \end{align*}
    \item The norm of a quaternion is the square root of the determinant of its corresponding matrix representation. 
    \[||q|| = \sqrt{\det \begin{pmatrix}
    a+bi & c+di \\ -c+di & a-bi
    \end{pmatrix}} = \sqrt{(a^2 + b^2) + (c^2 + d^2)}\]
    \item The conjugate of a quaternion corresponds to the conjugate (Hermitian) transpose of its matrix representation. 
    \[\rho(q^*) = \rho(q)^H \iff a-bi-cj-dk \mapsto \begin{pmatrix}
    a-bi & -c-di \\ c-di & a+bi
    \end{pmatrix}\]
    \item The restriction of this representation to only unit quaternions leads to an isomorphism between the subgroup of unit quaternions and their corresponding image in SU$(2)$. Topologically, the unit quaternions is the $3$-sphere, so the underlying space SU$(2)$ is also a $3$-sphere. More specifically, 
    \[\frac{\text{SU}(2)}{2} \simeq \text{SO}(3)\]
\end{enumerate}
\end{proposition}

\begin{proposition}
The following representation of $\mathbb{H}$ is an injective homomorphism $\rho: \mathbb{H} \longrightarrow \GL(4, \mathbb{R})$. 
\[\rho: a+bi+cj+dk \mapsto \begin{pmatrix}
a&-b&-c&-d \\
b&a&-d&c\\
c&d&a&-b\\
d&-c&b&a
\end{pmatrix}\]
or also as
\[a \begin{pmatrix}
1 &0 &0 &0 \\
0& 1&0&0\\
0&0&1&0\\
0&0&0&1
\end{pmatrix} + b \begin{pmatrix}
0&-1&0&0\\1&0&0&0\\0&0&0&-1\\0&0&1&0
\end{pmatrix} + c\begin{pmatrix}
0&0&-1&0\\0&0&0&1\\1&0&0&0\\0&-1&0&0
\end{pmatrix} + d \begin{pmatrix}
0&0&0&-1\\0&0&-1&0\\0&1&0&0\\1&0&0&0
\end{pmatrix}\]
It has properties
\begin{enumerate}
    \item $\rho(q^*) = \rho(q)^T$
    \item The fourth power of the norm is the determinant of the matrix 
    \[||q||^4 = \det\big( \rho (q)\big)\]
    \item Similarly, with the $2\times 2$ representation, complex number representations can be produced by restricting $2$ of $b, c, d$ to $0$. 
\end{enumerate}
\end{proposition}

Note that this representation in $\GL(4, \mathbb{R})$ is not unique. There are in fact 48 distinct representation of this form where one of the component matrices represents the scalar part and the other 3 are skew symmetric. 

\subsubsection{Square Roots of -1}
In $\mathbb{C}$, there are two numbers, $i$ and $-i$, whose square is $-1$. However, in $\mathbb{H}$, infinitely many square roots of $-1$ exist, forming the unit sphere in $\mathbb{R}^3$. To see this, let $q = a+bi+cj+dk$ be a quaternion, and assume that its square is $-1$. Then this implies that
\[a^2 - b^2 -c^2 -d^2 = -1, 2ab = 2ac = 2ad = 0\]
To satisfy the second equation, either $a=0$ or $b=c=d=0$. The latter is impossible since then $q$ would be real. Therefore, 
\[b^2 + c^2 + d^2 = 1\]
which forms the unit sphere in $\mathbb{R}^3$. 

\section{Affine and Projective Spaces}
\subsection{Affine Spaces}
Modeling the space of points as a vector space can be unsatisfactory for a number of reasons. 
\begin{enumerate}
    \item The origin $0$ plays a special role, when it doesn't necessarily need to have one. 
    \item Certain notions, such as parallelism, are handled in an awkward manner. 
    \item The geometries of vector and affine spaces are intrinsically. That is, 
    \[\GL(V) \subset \GA(V)\]
\end{enumerate}

In the ordinary Euclidean geometry, one can define the operation of the addition of a point and a vector. That is, the "sum" of a point $p$ and a vector $x$ is the endpoint of a vector that starts at $p$ and equals $x$. We formalize it in the following definition. 

\begin{definition}
Let $V$ be a vector space over field $\mathbb{F}$. The \textit{affine space associated to $V$} is a set $S$ with an operation of addition $+: S \times V \longrightarrow S$ satisfying 
\begin{enumerate}
    \item $p + (x + y) = (p + x) + y$ for $p \in S, x, y \in V$
    \item $p + 0 = p$ where $p \in S$, $0$ is the zero vector 
    \item For any $p, q \in S$, there exists a unique vector $x$ such that $p + x = q$
\end{enumerate}
Elements of the set $S$ are called \textit{points}. The vector in condition 3 is called the \textit{vector connecting points $p$ and $q$}, denoted $\overline{pq}$. The dimension of an affine space is defined as the dimension of the corresponding vector space. 
\end{definition}

The first condition implies that
\[\overline{pq} + \overline{qr} = \overline{pr} \text{ for all } p, q, r \in S\]
Every vector space $V$ can be regarded as an affine one if we view vectors both as points and as points and define the operation of addition of a vector to a point as addition of vectors. Under this interpretation, the vector $\overline{pq}$ is the difference between the vectors $p$ and $q$. 

\begin{definition}
Conversely, if we fix a point $o$ (the origin) in an affine space $S$, we can identify a point $p$ with its \textit{position vector} $\overline{op}$. Then, addition of a vector to a point just becomes the addition a vectors. This identification of points with vectors is called the \textit{vectorization} of an affine space. 
\end{definition}

\begin{definition}
A point $o$ (the origin) together with a basis $\{e_1, ..., e_n\}$ of the space $V$ is called a \textit{frame} of the affine space $S$. Each frame is related to an \textit{affine system of coordinates} in the space $S$. That is, a point $p$ would get the coordinates equal to those of the vector $\overline{op}$ in the basis $\{e_1, ..., e_n\}$. It is easy to see that 
\begin{enumerate}
    \item Coordinates of the point $p+x$ are equal to the sums of respective coordinates of the point $p$ and the vector $x$. 
    \item Coordinates of the vector $\overline{pq}$ are equal to the differences of respective coordinates of the points $q$ and $p$. 
\end{enumerate}
\end{definition}

Linear combinations of points are not defined in the affine space since the values of linear combinations are actually dependent on the choice of the origin. However, an analogous structure can be. 

\begin{definition}
The \textit{barycentric linear combination} of points $p_1, ..., p_k \in S$ is a linear combination of the form
\[p = \sum_i \lambda_i p_i, \text{ where } \sum_i \lambda_i = 1\]
This linear combination is equal to the point $p$ such that
\[\overline{op} = \sum_i \lambda_i \overline{op_i}\]
where $o \in S$ is any origin point.
\end{definition}

\begin{definition}
In particular, the specific barycentric combination of points where $\lambda_1 = ... = \lambda_k = \frac{1}{k}$ is called the \textit{center of mass} of the collection of points $p_i$. 
\end{definition}

\begin{definition}
Let $p_0, p_1, ..., p_n$ be points of an $n$-dimensional affine space $S$ such that the vectors $\overline{p_0 p_1}, ..., \overline{p_0 p_n}$ are linearly independent (that is, forms a basis). Then, every point $p \in S$ can be uniquely presented as 
\[p = \sum_{i=0}^n x_i p_i, \text{ where } \sum_{i=0}^n x_i = 1\]
This equality can be rewritten
\[\overline{p_0 p} = \sum_{i=1}^n x_i \overline{p_0 p_i}\]
implying that we can take the coordinates of the vector $\overline{p_0 p}$ in the basis $\{ \overline{p_0 p_1}, ..., \overline{p_0 p_n}\}$ as $x_1, ..., x_n$. Then, $x_0$ is determined as 
\[x_0 = 1 - \sum_{i=1}^n x_i\]
The numbers $x_0, x_1, ..., x_n$ are called the \textit{barycentric coordinates} of the point $p$ with respect to $p_0, p_1, ..., p_n$. 
\end{definition}

\begin{definition}
A \textit{plane} in an affine space $S$ is a subset of the form 
\[p = p_0 + U\]
where $p_0$ is a point and $U$ is a subspace of the space $V$. Note that we can choose any point $p_0$ in the plane in this representation. $U$ is called the \textit{direction subspace} for $P$. 
\end{definition}

\begin{lemma}
If the intersection of two planes in an affine space is nonempty, then the intersection is also a plane. 
\end{lemma}

\begin{theorem}
Given any $k+1$ points of an affine space, there is a plane of dimension $\leq k$ passing through these points. If these points are not contained in a plane of dimension $< k$, then there exists a unique $k$-dimensional plane passing through them. 
\end{theorem}

\begin{definition}
Points $p_0, p_1, ..., p_k \in S$ are \textit{affinely dependent} if they lie in a plane of dimension $<k$, and \textit{affinely independent} otherwise. It is clear that the points $p_0,..., p_k$ are affinely independent if and only if the vectors $\overline{p_0p_1}, ..., \overline{p_0 p_k}$ are linearly independent. 
\end{definition}

\begin{theorem}
Points $p_0, ..., p_k \in S$ are affinely independent if and only if the rank of the matrix of their barycentric coordinates (with respect to some predetermined affinely independent points) equals $k+1$. 
\end{theorem}

It is easy to see that the previous theorem is true, since the determinant represents the hypervolume of the parallelopiped spanned by the vectors $\overline{p_0p_1}, ..., \overline{p_0 p_k}$, which must be nonzero if they are indeed affinely independent. 

\begin{corollary}[Menelaus' Theorem]
Let points $x, y, z$ line on the sides $bc, ca, ab$ of the triangle $abc$ or their continuations. 
\[\begin{tikzpicture}[scale=1.3]
    \draw (-1,0)--(3,0)--(2.2, 1.5)--(0.6,0);
    \node[below] at (0.6, 0) {$a$};
    \node[below right] at (3,0) {$b$};
    \node[above] at (2.2, 1.5) {$c$};
    \draw[dashed] (-0.8,-0.3)--(3,1.4);
    \node[above] at (-0.3, 0) {$z$};
    \node[above] at (1.3, 0.7) {$y$};
    \node[right] at (2.4, 1.1) {$x$};
\end{tikzpicture}\]
Suppose that they divide these sides in the ratio 
\[\lambda: 1, \mu: 1, \nu: 1\]
respectively. Then, the points $x, y, z$ lie on the same line if and only if 
\[\lambda \mu \nu = -1\]
\end{corollary}
\begin{proof}
By the previous theorem, the points $x, y, z$ are linearly dependent (i.e. lies on a line) if and only if the matrix of barycentric coordinates of $x, y, z$ with respect to $a, b, c$, which is
\[\begin{pmatrix}
0 & \frac{1}{\lambda + 1} & \frac{\lambda}{\lambda + 1} \\
\frac{\mu}{\mu + 1} & 0 & \frac{1}{\mu + 1} \\
\frac{1}{\nu + 1} & \frac{\nu}{\nu+1} & 0
\end{pmatrix}\]
has nonzero determinant. The determinant of the above matrix is $0$ if and only if $\lambda \mu \nu = -1$. 
\end{proof}

\begin{corollary}[Ceva's Theorem]
In the triangle above, the lines $ax, by, cz$ intersect at one point if and only if 
\[\lambda \mu \nu = 1\]
\end{corollary}
\begin{proof}
The proof can be done using barycentric coordinates. 
\end{proof}

\begin{theorem}
A nonempty subset $P \subset S$ is a plane if and only if for any two distinct points $a, b \in P$, the line through $a$ and $b$ also lies in $P$. 
\end{theorem}

\begin{theorem}
Given an inhomogeneous system of linear equations of form 
\[A x = b\]
the set of solutions is an affine plane of dimension $n-r$, where $n$ is the number of variables and $r$ is the rank of the matrix $A$. More precisely, given that the plane is in the form $P = p_0 + U$, $p_0$ is one solution and $U$ is the set of vectors that satisfy the homogeneous system
\[Ax = 0 \]
\end{theorem}

Let us observe the relative position of two planes. 

\begin{theorem}
Given two planes 
\begin{align*}
    P_1 = p_1 + U_1, & P_2 = p_2 + U_2
\end{align*}
$P_1$ and $P_2$ intersect if and only if 
\[\overline{p_1 p_2} \subset U_1 + U_2\]
where $U_1 + U_2$ is the set of all vectors of form $u_1 + u_2$, where $u_1 \in U_1, u_2 \in U_2$. 
\end{theorem}

Now, consider the class of functions on an affine space corresponding to the class of linear functions on a vector space. 

\begin{definition}
An \textit{affine-linear} function on an affine space $S$ is a function $f: S \longrightarrow \mathbb{F}$ such that
\[f(p + x) = f(p) + \alpha (x), \;\; p \in S , x \in V\]
where $\alpha$, called the \textit{differential}, is a linear function on the vector space $V$. Let $o \in S$ be a fixed origin. By setting $p = o$, we can express an affine linear function in vectorized form as 
\[f(x) = \alpha (x) + b, \;\; b \in \mathbb{F}\]
where $b = f(o)$. This implies the following coordinate form of $f$. 
\[f(x) = b + \sum_i a_i x_i\]
\end{definition}

A particular case of affine-linear functions are constant functions, where the defining characteristic is the zero differential. 

\begin{proposition}
Given that $\dim{S} = n$, affine-linear functions on $S$ form a $(n+1)$-dimensional subspace on the space of all linear functions on $S$. 
\end{proposition}

\begin{proposition}
Barycentric coordinates are affine-linear functions. 
\end{proposition}

\begin{proposition}
Let $f$ be an affine-linear function. Then
\[f \bigg( \sum_i \lambda_i p_i \bigg) = \sum_i \lambda_i f(p_i)\]
for any barycentric linear combination $\sum_i \lambda_i p_i$ of points $p_1, ..., p_k$. 
\end{proposition}

\begin{definition}
An affine space associated with a Euclidean vector space is called a \textit{Euclidean affine space}. The \textit{distance $\rho$} between two points in a Euclidean space is defined as
\[\rho(p, q) = ||\overline{pq}||\]
This definintion of $\rho$ satisfies the axioms of a metric space. 
\end{definition}

\subsection{Convex Sets}
Let $S$ be an affine space over the field of real numbers and $V$, the associated vector space. 

\begin{definition}
The \textit{(closed) interval} connecting points $p, q \in S$ is the set
\[pq = \{\lambda p + (1-\lambda) q \;|\; 0 \leq \lambda \leq 1\}\]
Geometrically, we can think of this as the straight line segment connecting point $p$ with point $q$. 
\end{definition}

\begin{definition}
A set $M \subset S$ is \textit{convex} if for any two points $p, q \in S$, it contains the whole interval $p, q$. 
\end{definition}

Clearly, the intersection of convex sets is convex. However, the union of them is not. 

\begin{definition}
A \textit{convex linear combination} of points in $S$ is their barycentric linear combination with nonnegative coefficients. 
\end{definition}

It is clear to visualize the following proposition. 

\begin{proposition}
For any points $p_0, ..., p_k$ in a convex set $M \subset S$, the set $M$ also contains every convex linear combination 
\[p = \sum_i \lambda_i p_i\]
Furthermore, for any set $M \subset S$, the set $\conv{M}$ of all convex linear combinations of points in $M$ is convex. 
\end{proposition}

\begin{definition}
Given $M \subset S$, the set $\conv M$ is the smallest convex set containing $M$. It is called the \textit{convex hull} of $M$. 
\end{definition}

\begin{definition}
The convex hull of a system of affinely independent points $p_0, p_1, ..., p_n$ in an $n$-dimensional affine space is called the \textit{$n$-dimensional simplex} with vertices $p_0, ..., p_n$. 
\end{definition}

It is clear that the interior points of a simplex is precisely the set of all points whose barycentric coordinates with respect to the vertices are all positive. 

\begin{example}
Here are common examples of simplices.
\begin{enumerate}
    \item A $0$-dimensional simplex is a point. 
    \item A $1$-dimensional simplex is a closed line interval. 
    \item A $2$-dimensional simplex is a triangle. 
    \item A $3$-dimensional simplex is a tetrahedron. 
\end{enumerate}
\end{example}

\begin{proposition}
A convex set $M$ has interior points if and only if $\aff M = S$. 
\end{proposition}

\begin{definition}
A convex set that has interior points is called a \textit{convex body}. Clearly, every convex body in $n$-dimensional affine space $S$ is $n$-dimensional. 
\end{definition}

The set of interior points of a convex body $M$, denoted $M^\circ$, is an open convex body. 

\begin{definition}
For any nonconstant affine-linear function $f$ on the set $S$, let
\begin{align*}
    H_f \equiv \{p \in S \;|\; f(p) = 0\} \\
    H^+_f \equiv \{p \in S \;|\; f(p) \geq 0\} \\
    H^-_f \equiv \{p \in S \;|\; f(p) \leq 0\}
\end{align*}
The set $H_f$ is a hyperplane, and $H^+_f, H^-_f$ are called \textit{closed half spaces}. 
\end{definition}

\begin{definition}
A hyperplane $H_f$ is a \textit{supporting hyperplane} of a closed convex body $M$ if $M \subset H^+_f$ and $H_f$ contains at least one (boundary) point of $M$. The half space $H^+_f$ is then called the \textit{supporting half-space} of $M$. 
\end{definition}

\begin{proposition}
A hyperplane $H$ that passes through a boundary point of a closed convex body $M$, is supporting if and only if $H \cap M^\circ = \emptyset$. 
\end{proposition}

A key theorem of convex sets is the following separation theorem. 

\begin{theorem}[Separation Theorem]
For every boundary point of a closed convex body, there exists a supporting hyperplane passing through this point. 
\end{theorem}

This theorem leads to the following one. 

\begin{theorem}
Every closed convex set $M$ is an intersection of (perhaps infinitely many) half-spaces. 
\end{theorem}

\begin{definition}
A \textit{polyhedron} is the intersection of a finite number of half-spaces. A convex polyhedron which is also a body is called a \textit{convex solid}. 
\end{definition}

\begin{example}
A simplex with vertices $p_0, p_1, ..., p_n$ is a convex polyhedron since it is determined by linear inequalities $x_i \geq 0$ for $i = 0, 1, ..., n$, where $x_0, x_1, ..., x_n$ are barycentric coordiantes with respect to $p_0, p_1,..., p_n$. 
\end{example}

\begin{example}
A convex polyhedron determined by linear inequalities $0 \leq x_i \leq 1$ for $i = 1, ..., n$, where $x_1,..., x_n$ are affine coordinates with respect ot some frame, is called an $n$-dimensional parallelopiped. 
\end{example}

\begin{definition}
A point $p$ of a convex set $M$ is \textit{extreme} if it is not an interior point of any interval in $M$. 
\end{definition}

\begin{theorem}
A bounded closed convex set $M$ is the convex hull of the set $E(M)$ of its extreme points. 
\end{theorem}

We can create a stronger statement with the following theorem. 

\begin{theorem}[Minkowski-Weyl Theorem]
The following properties of a bounded set $M \subset S$ is equivalent.
\begin{enumerate}
    \item $M$ is a convex polyhedron. 
    \item $M$ is a convex hull of a finite number of points. 
\end{enumerate}
\end{theorem}

\begin{definition}
A \textit{face} of a convex polyhedron $M$ is a nonempty intersection of $M$ with some of its supporting hyperplanes. Given that $\dim \aff M = n$, 
\begin{enumerate}
    \item A $0$-dimensional face is called a \textit{vertex}. 
    \item A $1$-dimensional face an \textit{edge}. 
    \item ...
    \item An $(n-1)$-dimensional face a \textit{hyperface}. 
\end{enumerate}
\end{definition}

Therefore, if a convex polyhedron is determined by a system of linear inequalities, we can obtain its faces by replacing some of these inequalities with equalities (in such a way that we do not get the empty set). 

The following theorem demonstrates that in order to find its faces, it suffices to consider only the hyperplanes $H_{f_1}, ..., H_{f_m}$. 

\begin{theorem}
Every face $\Gamma$ of the polyhedron $M$ is of the form
\[\Gamma = M \cap \bigg( \bigcap_{j \in J} H_{f_j} \bigg)\]
where $J = \{1, 2, ..., m\}$
\end{theorem}

\begin{proposition}
The extreme points of a convex polyhedron $M$ are exactly its vertices. 
\end{proposition}

The following theorem is used often in linear programming and in optimization. 

\begin{theorem}
The maximum of an affine-linear function on a bounded convex polyhedron $M$ is attained at a vertex. 
\end{theorem}

\subsection{Affine Transformations and Motions}
Let $S$ and $S^\prime$ be affine spaces associated with vector spaces $V$ and $V^\prime$, respectively, over the same field $\mathbb{F}$. 

\begin{definition}
An \textit{affine map} from the space $S$ to the space $S^\prime$ is a map $f: S \longrightarrow S^\prime$ such that
\[f(p+x) = f(p) + \varphi(x), \;\; p \in S, x \in V\]
for some linear map $\varphi: V \longrightarrow V^\prime$. It follows that
\[\varphi(\overline{pq}) = \overline{f(p) f(q)}, \;\; p, q \in S\]
Thus, $f$ determines the linear map $\varphi$ uniquely. Similarly, $\varphi$ is called the \textit{differential} of $f$, denoted $df$. 
\end{definition}

\begin{proposition}
Let $f: S \longrightarrow S^\prime$ and $g: S^\prime \longrightarrow S^{\prime \prime}$ be two affine maps. Then the map
\[g \circ f : S \longrightarrow S^{\prime\prime}\]
is also affine. Also
\[d(g \circ f) = dg \cdot df\]
where $dg$ and $df$ are the differentials of $g$ and $f$, respectively. 
\end{proposition}

For $\mathbb{F} = \mathbb{R}$, the differential of an affine map is a particular case of a differential of a smooth map in analysis. That is, the differential is the linear approximation of the function $f$. 

\begin{proposition}
An affine map is bijective if and only if its differential is bijective. 
\end{proposition}

\begin{definition}
Similar to linear transformations between vector spaces, bijective affine transformations are called \textit{isomorphisms} of affine spaces. Affine spaces are \textit{isomorphic} if there exists an isomorphism between them. 
\end{definition}

\begin{corollary}
Finite-dimensional affine spaces over the same field are isomorphic if and only if they have the same dimension. 
\end{corollary}

\begin{definition}
An affine map from an affine space $S$ to itself is called an \textit{affine transformation}. Bijective affine transformations form a group called the \textit{affine group of $S$}, denoted $\GA(S)$. 
\end{definition}

It follows that given affine space $S$ with associated vector space $V$, the projection map
\[d: \GA(S) \longrightarrow \GL(V)\]
is a group homomorphism. It's kernel is the group of parallel translations, called Tran$(S)$. 
\[t_a : p \mapsto p + a, \;\; a \in V\]

\begin{proposition}
For any $f \in \GA(S)$ and $a \in V$, 
\[f t_a f^{-1} = t_{df(a)}\]
\end{proposition}

\begin{definition}
A \textit{homothety} with the center $o$ and coefficient $\lambda$ is an affine transformation defined as
\[f( o + x ) \equiv o + \lambda x\]
In its vectorized form, it is expressed
\[f(x) = \lambda x + b, \;\; b \in V\]
A homothety with coefficient $-1$ is called a \textit{central symmetry}. 
\end{definition}

The group of affine transformations determines the \textit{affine geometry} of the space. The following theorem shows that all simplices are equal in affine geometry. 

\begin{theorem}
Let $\{p_0, ..., p_n\}$ and $\{q_0, ..., q_n\}$ be two systems of affinely independent points in an $n$-dimensional affine space $S$. Then there exists a unique affine transformation $f$ that maps $p_i$ to $q_i$ for $i = 0, 1, ..., n$. 
\end{theorem}
\begin{proof}
It is easy to see once we realize that there exists a unique linear map $\varphi$ of the space $V$ that maps the basis $\{\overline{p_0 p_1}, ..., \overline{p_0 p_n}\}$ to the basis $\{\overline{q_0 q_1}, ..., \overline{q_0 q_n}\}$. If we vectorize $S$ by taking $p_0$ as the origin, the affine transformation in question has the form 
\[f(x) = \varphi(x) + \overline{p_0 q_0}\]
\end{proof}

\begin{corollary}
In real affine geometry all parallelopipeds are equal. 
\end{corollary}

\begin{definition}
A \textit{motion} of the space $S$ is an affine transformation of $S$ whose differential is an orthogonal operator (i.e. an origin preserving isometry). Every motion is bijective. 
\end{definition}

Motions of a Euclidean space $S$ form a group denoted Isom$\,S$. A motion is called \textit{proper (orientation preserving)} if its differential belongs to SO$(V)$ and improper otherwise. 

\begin{lemma}
The group Isom$\,S$ is generated by reflections through hyperplanes. 
\end{lemma}

\begin{definition}
Let $M$ be a solid convex polyhedron in an $n$-dimensional Euclidean space. A \textit{flag of $M$} is a collection of its faces $\{F_0, F_1, ..., F_{n-1}\}$ where $\dim{F_k} = k$ and $F_0 \subset F_1 \subset ... \subset F_{n-1}$. 
\end{definition}

\begin{definition}
A convex polyhedron $M$ is \textit{regular} if for any two of its flags, there exists a motion $f \in$ Sym$\,M$ mapping the first to the second, where 
\[\text{Sym}\,M \equiv \{f \in \text{Isom}\,S \;|\; f(M) = M \}\]
\end{definition}

Two dimensional regular polyhedra are the ordinary \textit{regular polygons}. Their symmetry groups are known as the dihedral groups.

Three dimensional regular polyhedra are \textit{Platonic solids}, which are the regular tetrahedron, cube, octahedron, dodecahedron, and icosahedron. 

\begin{definition}
A real vector space $V$ with a fixed symmetric bilinear function $\alpha$ of signature $(k, l)$, where $k, l > 0$ and $\dim{V} = k+l$, is called the \textit{pseudo-Euclidean vector space} of signature $(k, l)$. The group of $\alpha$-preserving linear transformations of $V$ is called the \textit{pseudo-orthogonal group} and is denoted O$(V, \alpha)$. In an orthonormal basis, the corresponding matrix group is denoted $O{k,l}$. 
\end{definition}


\subsection{Quadrics}
Planes are the simplest objects of affine and Euclidean geometry, which are determined by systems of linear equations. The second simplest are quadratic functions. These types of objects are studied futher in algebraic geometry. 

\begin{definition}
An \textit{affine-quadratic function} on an affine space $S$ is a function $Q: S \longrightarrow \mathbb{F}$ such that its vectorized form is
\[Q(x) = q(x) + l(x) + c\]
for a quadratic function $q$, linear function $l$, and constant $c$. 
\end{definition}

\subsection{Projective Spaces}
\begin{definition}
An $n$-dimensional \textit{projective space $PV$} over a field $\mathbb{F}$ is the set of one-dimensional subspaces of an $(n+1)$-dimensional vector space $V$ over $\mathbb{F}$. For every $(k+1)$-dimensional subspace $U \subset V$, the subset $PU \subset PV$ is called a $k$-dimensional \textit{plane} of the space $PV$. 
\begin{enumerate}
    \item $0$-dimensional planes are the points of $PV$. 
    \item $1$-dimensional planes are called \textit{lines}
    \item ...
    \item $(n-1)$-dimensional planes are called \textit{hyperplanes}
\end{enumerate}
\end{definition}

\begin{definition}
$\mathbb{RP}^1$ is called the real projective line, which is topologically equivalent to a circle. 
\end{definition}

\begin{example}
The real projective space of $\mathbb{R}^2$ is the set of all lines that pass through the origin. It is denoted $\mathbb{R P}^2$ and called the \textit{real projective plane}. 
\end{example}

\begin{example}
$\mathbb{RP}^3$ is diffeomorphic to SO$(3)$. 
\end{example}

\begin{example}
The space $\mathbb{RP}^n$ is formed by taking the quotient of $\mathbb{R}^{n+1} \setminus \{0\}$ under the equivalence relation 
\[x \sim \lambda x \text{ for all real numbers } \lambda \neq 0\]
The set of these equivalence classes is isomorphic to $\mathbb{RP}^n$. 
\end{example}

\section{Tensor Algebras}
Remember that an algebra is (loosely) a vector space $V$ with a multiplication operation
\[\times: V \times V \longrightarrow V\]
\begin{definition}
The \textit{tensor algebra} of vector space $V$ over field $\mathbb{F}$ is 
\begin{align*}
    T(V) \equiv \bigoplus_{n = 0}^{\infty} V^{\otimes n} & = V^{\otimes 0} \oplus V^{\otimes 1} \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus ... \\
    & = \mathbb{F} \oplus V \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus V^{\otimes 4} \oplus ...
\end{align*}
with elements being infinite-tuples
\[ (a, B^\mu, C^{\nu \gamma}, D^{\alpha \beta \epsilon}, ...)\]
The addition operation is defined component-wise, and the multiplication operation is the tensor product 
\[\otimes: T(V) \times T(V) \longrightarrow T(V)\]
and the identity element is
\[I = (1, 0, 0, ...) \]
Linearity can be easily shown. 
\end{definition}

The tensor algebra is often used to "add" differently ranked tensors together. But in order to do this rigorously, we must define the canonical injections
\[i_j: V^{\otimes j} \longrightarrow T(V), \; i_j (T^{\kappa_1, ..., \kappa j}) = (0, ...,0, T^{\kappa_1, ..., \kappa j}, 0, ..., 0) \]
shown in the diagram
\[\begin{tikzcd}
    & & T(V) & & \\
    \mathbb{F} \arrow{urr}{i_0} & V \arrow{ur}{i_1} & V^{\otimes 2} \arrow{u}{i_2} & V^{\otimes 3} \arrow{ul}{i_3} & ... \arrow{ull}
\end{tikzcd}\]
Therefore, with these $i_j$'s, we can implicitly define the addition of arbitrary tensors $A \in V^{\otimes n}$ and $B \in V^{\otimes m}$ as 
\[ A + B \equiv i_n (A) + i_m (B) \in T(V)\]
along with multiplication of tensors as
\[ A \otimes B \equiv i_n(A) \otimes i_m(B) \equiv i_{n+m} (A \otimes B)\]
We can also redefine the tensor product operation between two spaces to be an operation within $T(V)$ itself. 
\[i_i(V^{\otimes i}) \otimes i_j( V^{\otimes j}) = i_{i+j} (V^{\otimes (i+j)})\]
We can now proceed to define Exterior and Symmetric algebras as quotient algebras. 

\begin{definition}
The \textit{exterior algebra} $\Lambda(V)$ of a vector space $V$ over field $\mathbb{F}$ is the quotient algebra of the tensor algebra $T(V)$
\[\Lambda(V) \equiv \frac{T(V)}{I}\]
where $I$ is the two-sided ideal generated by all elements of the form $x \otimes x$ for $x \in V$ (i.e. all tensors that can be expressed as the tensor product of a vector in V by itself). 

The \textit{exterior product} $\wedge$ of two elements of $\Lambda(V)$ is the product induced by the tensor product $\otimes$ of $T(V)$. That is, if 
\[\pi: T(V) \longrightarrow \Lambda(V)\]
is the canonical projection/surjection and $a, b \in \Lambda(V)$ ,then there are $\alpha, \beta \in T(V)$ such that $a = \pi(\alpha), b = \pi(\beta)$, and 
\[a \wedge b = \pi(\alpha \otimes \beta)\]
We can define this quotient space with the equivalence class
\[x \otimes y = - y \otimes x \pmod{I}\]
\end{definition}

\begin{definition}
The \textit{symmetric algebra} Sym$(V)$ of a vector space $V$ over a field $\mathbb{F}$ is the quotient algebra of the tensor algebra $T(V)$ 
\[\Lambda(V) \equiv \frac{T(V)}{J}\]
where $J$ is the two-sided ideal generated by all elements in the form 
\[v \otimes w - w \otimes v\]
(i.e. commutators of all possible pairs of vectors). 
\end{definition}

\section{Representation Theory}
We will assume that $V$ is a finite-dimensional vector space over field $\mathbb{C}$. 
\begin{definition}
The \textit{general linear group} of vector space $V$, denoted $\GL(V)$, is the group of all automorphisms of $V$ to itself. The \textit{special linear group} of vector space $V$, denoted $\SL(V)$ is the subgroup of automorphisms of $V$ with determinant $1$. 
\end{definition}
When studying an abstract set, it is often useful to consider the set of all maps from this abstract set to a well known set (e.g. $\GL(V)$). 

\begin{definition}
A \textit{representation} of an (algebraic) group $\mathcal{G}$ is a homomorphism 
\[\rho: G \longrightarrow \GL(V)\]
for some vector space $V$. That is, given an element $g \in \mathcal{G}$, $\rho(g) \in \GL (V)$, meaning that $\rho(g)(v) \in V$. Additionally, since it is a homomorphism, the algebraic structure is preserved. 
\[\rho(g_1 \cdot g_2) = \rho(g_1) \cdot \rho(g_2)\]
where $\cdot$ on the left hand side is the abstract group multiplication while the $\cdot$ on the right hand side is matrix multiplication. To shorten the notation, we will denote 
\[g v = \rho(g) v, \; v \in V\]
Since $\rho$ is a group morphism, we have 
\[g_2 (g_1 v) = (g_2 g_1) v \; \iff \rho(g_2) \big( \rho(g_1) (v) \big) = \big( \rho(g_2) \rho(g_1) \big) (v)\]
Additionally, since $g$ (that is, $\rho(g)$) is a linear map, 
\[g(\lambda_1 v_1 + \lambda_2 v_2) = \lambda_1 g v_1 + \lambda_2 g v_2\]
Usually, we refer to the map as the representation, but if the map is well-understood, we just call the vector space $V$ the representation and say that the group acts on this vector space. 
\end{definition}

\begin{example}
The group $\GL(2, \mathbb{C})$ can be represented a by the vector space $\mathbb{C}^2$, or explicitly, by the group of $2 \times 2$ matrices over $\mathbb{C}$ with nonzero determinant.
\[\GL(2, \mathbb{C}) \xmapsto{id} \text{Mat}(2, \mathbb{C})\]
This is a trivial representation. 
\end{example}

We now show a nontrivial representation of $\GL(2, \mathbb{C})$. 
\begin{example}
We take Sym$^2 \mathbb{C}^2$, the second symmetric power of $\mathbb{C}^2$. Note that given a basis $x_1, x_2 \in \mathbb{C}^2$, the set
\[\{x_1 \odot x_1, x_1 \odot x_2, x_2 \odot x_2\}\]
forms a basis of Sym$^2 \mathbb{C}^2 \implies \dim\,$Sym$^2 \mathbb{C}^2 = 3$. So, we want to represent $\GL(2, \mathbb{C})$ by associating its element with elements of $\GL(Sym^2 \mathbb{C}^2)$. More concretely, we are choosing to represent a $2 \times 2$ matrix over $\mathbb{C}$ with a $3 \times 3$ matrix group (since $\GL(Sym^2 \mathbb{C}^2) \simeq \GL(3, \mathbb{C})$. Clearly,
\begin{align*}
    & \rho(g) (x_1 \odot x_1) = g(x_1) \odot g(x_1) \in Sym^2 \mathbb{C}^2 \\
    & \rho(g) (x_1 \odot x_2) = g(x_1) \odot g(x_2) \\
    & \rho(g) (x_2 \odot x_2) = g(x_2) \odot g(x_2)
\end{align*}
To present this in matrix form, let us have an element in $\GL (2, \mathbb{C})$
\[\mathcal{A} \equiv \begin{pmatrix}
a & b \\
c & d
\end{pmatrix}\]
We evaluate the corresponding representation in $\GL( Sym^2 \mathbb{C}^2)$. Using the identities above, we have 
\begin{align*}
    \rho(g) (x_1 \odot x_1) & = g(x_1) \odot g(x_1) \\
    & = (a x_1 + c x_2) \odot (a x_1 + c x_2) \\
    & = a^2 x_1 \odot x_1 + 2ac x_1 \odot x_2 + c^2 x_2 \odot x_2 \\
    \rho(g) (x_1 \odot x_2) & = g(x_1) \odot g(x_2) \\
    & = (a x_1 + c x_2) \odot (b x_1 + d x_2) \\
    & = ab x_1 \odot x_1 + (ad + bc) x_1 \odot x_2 + cd x_2 \odot x_2 \\
    \rho(g) (x_2 \odot x_2) & = g(x_2) \odot g(x_2) \\
    & = (b x_1 + d x_2) \odot (b x_1 + d x_2) \\
    & = b^2 x_1 \odot x_1 + 2bd x_1 \odot x_2 + d^2 x_2 \odot x_2
\end{align*}
And this completely determines the matrix. So, 
\[\rho \begin{pmatrix}
a&b\\c&d
\end{pmatrix} = \begin{pmatrix}
a^2&ab&b^2\\2ac&ad+bc&2bd\\c^2&cd&d^2
\end{pmatrix}\]
is the $3 \times 3$ representation of $\mathcal{A}$ in $\GL(Sym^2 \mathbb{C}^2)$. 
\end{example}

We continue to define maps between two representations of $\mathcal{G}$. 

\begin{definition}
A \textit{morphism} between 2 representations 
\begin{align*}
    & \rho_1: \mathcal{G} \longrightarrow \GL(V_1) \\
    & \rho_2: \mathcal{G} \longrightarrow \GL(V_2) 
\end{align*}
of some group but not necessarily the same vector space is a linear map $f: V_1 \longrightarrow V_2$ that is \textit{compatible} with the group action. That is, $f$ satisfies the property that for all $g \in \mathcal{G}$
\[f \circ g = g \circ f\]
Again, we use the shorthand notation that $g = \rho(g)$, meaning that the statement above really translates to $ f \circ \rho(g) = \rho(g) \circ f$. This is equivalent to saying that the following diagram commutes. 
\[\begin{tikzcd}
V_1 \arrow{r}{\rho_1(g)} \arrow{d}{f} & V_1 \arrow{d}{f} \\
V_2 \arrow{r}{\rho_2 (g)} & V_2
\end{tikzcd}\]
\end{definition}

\begin{definition}
Let $V$ be a representation of $\mathcal{G}$. A \textit{subrepresentation} is a subspace $W \subset V$ such that for all $g \in \mathcal{G}$ and for all $w \in W$, 
\[\rho(g)(w) \in W\]
\end{definition}

\begin{example}
$V$ and $\{0\}$ are always subrepresentations of $V$. 
\end{example}

We now introduce the "building blocks" of all representations. 
\begin{definition}
A representation $W$ is \textit{irreducible representation} if $\{0\}$ and $W$ are the only subrepresentations of $W$. 
\end{definition}

\begin{lemma}[Schur's Lemma]
Let $V_1, V_2$ be irreducible representations and let $f: V_1 \longrightarrow V_2$ be a morphism (of representations). Then, either
\begin{enumerate}
    \item $f$ is an isomorphism. 
    \item $f = 0$
\end{enumerate}
Furthermore, any 2 isomorphisms differ by a constant. That is, 
\[f_1 = \lambda f_2\]
\end{lemma}
\begin{proof}
$\ker{f}$ is clearly a vector space. Furthermore, it is a subrepresentation (since it is a subspace of $V_1$) $\implies \ker{f} = V$ or $\ker{f} = 0$. If $\ker{f} = V$, then $f = 0$ and the theorem is satisfied. If $\ker{f} = 0$, then $f$ is injective, and $\im{f}$ is a subrepresentation of $V_2 \implies \im{f} = 0$ or $\im{f} = V_2$. But $\im{f} \neq 0$ since $f$ is injective, so $\im{f} = V_2 \implies f$ is surjective $\implies f$ is bijective, that is, $f$ is an isomorphism of vector spaces. So, the inverse $f^{-1}$ exists, and this map $f^{-1}$ satisfies
\[f^{-1} \circ \rho_2(g) = \rho_1 (g) \circ f^{-1}\]
To prove the second part, without loss of generality, assume that the first isomorphism is the identity mapping. That is, 
\[f_1 = id\]
Since we are working over the field $\mathbb{C}$, we can find an eigenvector of $f_2$. That is, there exists a $v \in V_1$ such that 
\[f_2 (v) = \lambda v\]
Now, we define the map
\[f: V_1 \longrightarrow V_2, \; f \equiv f_2 - \lambda f_1\]
Clearly, $\ker{f} \neq 0$, since $v \in \ker{f}$. That is, we have a map $f$ between 2 irreducible representations that has a nontrivial kernel. This means that $f = 0 \implies f_2 = \lambda f_1$.  
\end{proof}

\begin{theorem}[Mache's Theorem]
Let $V$ be finite dimensional, with $\mathcal{G}$ a finite group. Then, $V$ can be decomposed as 
\[V = \bigoplus_{i} V_i\]
where each $V_i$ is an irreducible representation of $\mathcal{G}$. 
\end{theorem}
\begin{proof}
By induction on dimension, it suffices to prove that if $W$ is a subrepresentation of $V$, then there exists a subrepresentation $W^\prime \subset V$ such that $W \oplus W^\prime = V$. So, if $V$ isn't an irreducible representation, it can always be decomposed into smaller subrepresentations $W$ and $W^\prime$ that direct sum to $V$. Now, we define the canonical (linear) projection 
\[\pi: V \longrightarrow W\]
Then, we define the new map 
\[\Tilde{\pi}: V \longrightarrow W, \; \Tilde{\pi}(v) \equiv \frac{1}{|\mathcal{G}|} \sum_{g \in \mathcal{G}} \rho(g)\big|_W \circ \pi \circ \rho(g)^{-1}\]
This "averaging" of the group elements are done so that this mapping is a map of representations. This implies that 
\[V = W \oplus \ker{\Tilde{\pi}}\]
meaning that $V$ can indeed be decomposed into direct sums of subrepresentations. 
\end{proof}

\section{Lie Groups and Lie Algebras}

\begin{definition}
A \textit{Lie group} is a group $\mathcal{G}$ that is also a finite-dimensional smooth manifold, in which the group operations of multiplication and inversion are smooth maps. Smoothness of the group multiplication
\[\mu: \mathcal{G} \times \mathcal{G} \longrightarrow \mathcal{G}, \; \mu(x, y) = x y\]
means that $\mu$ is a smooth mapping of the product manifold $\mathcal{G} \times \mathcal{G}$ into $\mathcal{G}$. These two requirements can be combined to the single requirement that tahe mapping 
\[(x, y) \mapsto x^{-1} y\]
be a smooth mapping of the product manifold into $\mathcal{G}$. 
\end{definition}

\begin{definition}
A \textit{Lie Algebra} is a vector space $\mathfrak{g}$ with an operation called the \textit{Lie Bracket} 
\[[\cdot, \cdot]: \mathfrak{g} \times \mathfrak{g} \longrightarrow \mathfrak{g}\]
Satisfying
\begin{enumerate}
    \item Bilinearity: $[ax + by, z] = a[x,z] + b[y,z], \; [z, ax + by] = a[z, x] + b[z,y]$
    \item Anticommutativity: $[x,y] = -[y,x]$
    \item Jacobi Identity: $[x,[y,z]] + [y,[z,x]] + [z,[x,y]] = 0$
\end{enumerate}
Clearly, this implies that $\mathfrak{g}$ is a nonassociative algebra. Note that a Lie Algebra does not necessarily need to be an algebra in the sense that there needs to be multiplication operation that is closed in $\mathfrak{g}$. 
\end{definition}

\begin{example}
A common example of a Lie Braket in the algebra of matrices is defined
\[[A, B] \equiv AB - BA\]
called the \textit{commutator}. Note that in this case, the definition of the Lie bracket is dependent on the definition of the matrix multiplication. Without defining the multiplication operation, we wouldn't know what $AB$ or $BA$ means. Therefore, we see that the Lie algebra of $n \times n$ matrices has three operations: matrix addition, matrix multiplication, and the commutator (along with scalar multiplication). But in general, it is not necessary to have that multiplication operation for abstract Lie algebras. $\mathfrak{g}$ just needs to be a vector space with the bracket.  
\end{example}

\begin{example}
The set of all symmetric matrices is a vector space, but it is \textit{not} a Lie algebra since the commutator $[A,B]$ is not symmetric unless $A B = B A$. 
\end{example}

We will first talk about groups of matrices as a more concerete example before we get into abstract Lie groups. Recall that the matrix exponential map is defined
\[exp: \text{Mat}(n, \mathbb{C}) \longrightarrow \text{mat}(n, \mathbb{C}), \; exp(A) = e^A = \sum_{p \geq 0} \frac{A^p}{p!}\]
Note that this value is always well defined. This lets us define
\[exp(t A) \equiv e^{t A} \equiv I + tA + \frac{1}{2} t^2 A^2 + \frac{1}{3!} t^3 A^3 + ... \]
where if $t$ is small, we can expect a convergence. Note that exp maps addition to multiplication. That is, we can interpret it as a homomorphism from 
\[exp: \mathfrak{g} \longrightarrow \mathcal{G}\]
where $\mathfrak{g}$ is the Lie algebra and $\mathcal{G}$ is the Lie group (which we will treat just as a matrix group). To find the inverse of the exponential map, we can take the derivative of $e^{tA}$ at $t=0$. That is, 
\begin{align*}
    \bigg(\frac{d}{d t} e^{tA} \bigg) \bigg|_{t=0} & = \bigg(\sum_{k=0}^\infty \frac{1}{k!} t^k A^{k+1} \bigg) \bigg|_{t=0} = A
\end{align*}
So, the mapping
\[\frac{d}{dt} \bigg|_{t=0}: \mathcal{G} \longrightarrow \mathfrak{g}\]
maps the Lie group back to the algebra. We can interpret this above mapping by visualizing the Lie Algebra as a tangent (vector) space of the abstract Lie group $\mathcal{G}$ at the identity element of the Lie group. The visualization below isn't the most abstract one, but it may help:
\begin{center}
    \includegraphics[scale=0.2]{Lie_Algebra_Tangent_Space.PNG}
\end{center}
For example, say that the Lie group $\mathcal{G}$ is a unit circle in $\mathbb{C}$, then the Lie algebra of $\mathcal{G}$ is the tangent space at the identity $1$, which can be identified as the imaginary line in the complex plane $\{i t \; | \; t \in \mathbb{R}\}$, with 
\[i t \mapsto exp(it) \equiv e^{it} \equiv \cos{t} + i \sin{t}\]
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw[thick] (0,0) circle (2);
    \node[below right] at (-2,2) {$\mathcal{G}$};
    \draw[<->] (-3,0)--(3,0);
    \draw[<->] (0,-3)--(0,3);
    \draw[fill] (2,0) circle (0.05);
    \node[below right] at (2,0) {$1$};
    \draw[thick, <->] (2,-3)--(2,3);
    \node[right] at (2,-2) {$\mathfrak{g}$};
\end{tikzpicture}
\end{center}
So, analyzing the Lie group by looking at its Lie algebra turns a nonlinear problem to a linear one; this is called a \textit{linearization} of the Lie group. The existence of this exponential map is one of the primary reasons that Lie algebras are useful for studying Lie groups. 
\begin{example}
The exponential map 
\[exp: \mathbb{R} \longrightarrow \mathbb{R}^+, \; x \mapsto e^x\]
is a group homomorphism that maps $(\mathbb{R}, +)$ to $(\mathbb{R}^+, \times)$. This means that $\mathbb{R}$ is the Lie algebra of the Lie group $\mathbb{R}^+$. 
\end{example}

\begin{theorem}
If $A$ and $B$ are commuting square matrices, then 
\[e^{A + B} = e^A \, e^B\]
In general, the solution $C$ to the equation
\[e^{A} \, e^B = e^C\]
is given by the \textit{Baker-Campbell-Hausdorff formula}, defined
\[C = A + B + \frac{1}{2}[A,B] + \frac{1}{12} [A,[A,B]] - \frac{1}{12} [B,[A,B]] + ...\]
consisting of terms involving higher commutators of $A$ and $B$. The full series is much too complicated to write, so we ask the reader to be satisfied with what is shown. 
\end{theorem}
The BCH formula is messy, but it allows us to compute products in the Lie Group as long as we known the commutators in the Lie Algebra. 

Therefore, we can describe the process of constructing a Lie group from a Lie Algebra (which a vector space) as such. We take a vector space $V$ and endow it the additional bracket operation. We denote this as
\[\mathfrak{g} \equiv (V, [\cdot, \cdot])\]
Then, we take every element of $\mathfrak{g}$ and apply the exponential map to them to get an another set $\mathcal{G}$. We then endow a group structure on $\mathcal{G}$ by defining the multiplication as 
\[\cdot: \mathcal{G} \times \mathcal{G} \longrightarrow \mathcal{G}, \; e^A \cdot e^B = e^{A * B}\]
where $A*B$ is defined by the BCH formula up to a certain $k$th order. Since the $*$ operation is completely defined by the bracket in the Lie algebra, it tells us how to multiply in the Lie group. This process can be made more abstractly, depending on what $A, B$ and $[\cdot,\cdot]$ is, beyond matrices. 

\subsection{Lie Algebras of Classical Lie Groups}

\begin{definition}
The \textit{general linear group} of vector space $V$ is the group of all automorphisms of $V$, denoted $\GL(V)$. Additionally, $\GL(n, \mathbb{R})$ is the group of real $n \times n$ matrices with nonzero determinant, and $\SL(n, \mathbb{R})$ is the group of real $n \times n$ matrices with determinant $= 1$.
\end{definition}

\subsubsection{Lie Algebras of $\SL(2, \mathbb{R})$ and $\SL(2, \mathbb{C})$}
Given the group $\SL(2, \mathbb{R})$, there must be a corresponding Lie algebra of matrices such that $g = e^A \in \SL(2, \mathbb{R})$. We attempt to find this Lie algebra. Let $g \in \SL(2, \mathbb{R})$, with $g = e^A$. So, if $\det{g} = 1$, what is the corresponding restriction on $A$ in the algebra? We use the following proposition. 

\begin{proposition}
\[\det{(e^A)} = e^{\Tr{(A)}}\]
\end{proposition}
\begin{proof}
Put $A$ in Jordan Normal Form: $A = S^{-1} J S \implies A^n = S^{-1} J^n S \implies exp(A) = S^{-1} exp(A) S \implies \det{(exp(A))} = \det{e^J}$. But since $J$ is upper trianglar, $J^n$ is upper triangular $\implies e^J$ is upper triangular, which implies that 
\[\det{e^J} = \prod_i e^{\lambda_i} = e^{\Tr{(J)}} = e^{\Tr{(A)}}\]
since trace is invariant under a change of basis. 
\end{proof}

So, $\det{(e^A)} = 1 \implies \Tr{(A)} = 2 \pi i n$ for $n \in \mathbb{Z}$. Since we want to component connected to the identity, we choose $n=0$ meaning that $\Tr{(A)} = 0$. And we are done. That is, the Lie algebra of $\SL(2, \mathbb{R})$ consists of traceless $2 \times 2$ matrices, denoted $\mathfrak{sl}_2 \mathbb{R}$. $\mathfrak{sl}_2 \mathbb{R}$ has basis (chosen arbitrarily) 
\[\bigg\{ H = \begin{pmatrix}
1&0\\0&-1
\end{pmatrix}, X = \begin{pmatrix}
0&1\\0&0
\end{pmatrix}, Y = \begin{pmatrix}
0&0\\1&0
\end{pmatrix}\bigg\}\]
and the identity in the Lie algebra is the zero matrix, which translates to the $2 \times 2$ identity matrix in the Lie group. 
\[exp \begin{pmatrix}
0&0\\0&0
\end{pmatrix} = I\]
We must not forget to define the bracket structure in $\mathfrak{sl}_2 \mathbb{R}$, so we define it as the commutator, which gives the identity
\begin{align*}
    & [H,X] = HX - XH = 2X \\
    & [H,Y] = HY - YH = -2Y \\
    & [X,Y] = XY - YX = H
\end{align*}
Note that regular matrix multiplication is not closed within this Lie algebra. For example, 
\[X Y = \begin{pmatrix}
1&0\\0&0
\end{pmatrix}\]
is clearly not traceless. However, the bracket operation keeps the matrices within this traceless condition (and thus, within this algebra), so you can't just stupidly multiply matrices together in a Lie algebra. Remember that regular matrix multiplication does not have anything to do with the Lie bracket and does not apply to this group. This algebra also simplifies the multiplicative inverse of a group to a simple additive inverse, making calculations easier. 

Similarly, the Lie algebra of $\SL(2, \mathbb{C})$ also has the same basis 
\[\bigg\{ H = \begin{pmatrix}
1&0\\0&-1
\end{pmatrix}, X = \begin{pmatrix}
0&1\\0&0
\end{pmatrix}, Y = \begin{pmatrix}
0&0\\1&0
\end{pmatrix}\bigg\}\]
but we choose the field to be $\mathbb{C}$, meaning that we take complex linear combinations rather than real linear ones. 

\subsubsection{Lie Algebra of SU(2)}
$g \in $ SU$(2) \implies \det{g} = 1 \implies \Tr{A} = 0$. We also see that by definition $e^A$, 
\[(e^A)^\dagger = e^{A^\dagger} \text{ and } (e^A)^{-1} = e^{-A}\]
which implies that $A^\dagger = - A$. That is, the unitary condition implies that the Lie algebra elements in $\mathfrak{su}(2)$ are traceless, anti-self adjoint $2 \times 2$ matrices over $\mathbb{C}$. 

\begin{definition}
The \textit{Pauli matrices} are the three matrices
\[\bigg\{ \sigma_x = \begin{pmatrix}
0&1\\1&0
\end{pmatrix}, \sigma_y = \begin{pmatrix}
0&-i\\i&0
\end{pmatrix}, \sigma_z = \begin{pmatrix}
1&0\\0&-1
\end{pmatrix}\bigg\}\]
Note that with some calculation, 
\begin{align*}
    & [\sigma_x, \sigma_y] = 2 i \sigma_z \\
    & [\sigma_y, \sigma_z] = 2 i \sigma_x \\
    & [\sigma_z, \sigma_x] = 2 i \sigma_y
\end{align*}
\end{definition}
To identify the basis of $\mathfrak{su}(2)$, we take the Pauli matrices and let 
\begin{align*}
    & A_x \equiv - \frac{i}{2} \sigma_x = \begin{pmatrix} 0&-i/2\\-i/2&0 \end{pmatrix} \\
    & A_y \equiv - \frac{i}{2} \sigma_y = \begin{pmatrix}0&-1/2\\1/2&0\end{pmatrix} \\
    & A_z \equiv -\frac{i}{2} \sigma_z = \begin{pmatrix}-i/2&0\\0&i/2\end{pmatrix}
\end{align*} 
be the basis of $\mathfrak{su}(2)$. Clearly, $A_x, A_y, A_z$ are all traceless, anti-self adjoint $2 \times 2$ matrices. Moreover, they also satisfy
\begin{align*}
    & [A_x, A_y] = A_z \\
    & [A_y, A_z] = A_x \\
    & [A_z, A_x] = A_y
\end{align*}
However, note that the algebra $\mathfrak{su}(2)$ consists of all \textit{real} linear combinations of $A_x, A_y, A_z$. That is, $\mathfrak{su}(2)$ is a 3 dimensional \textit{real} vector space, even though it has basis elements containing complex numbers. 

However, we can always complexify this space by simply replacing real scalar multiplication in $\mathfrak{su}(2)$ with complex scalar multiplication. By complexifying $\mathfrak{su}(2)$, the Lie group SU$(2)$ formed by taking the exponential map on this complexified space is actually identical to $\SL(2, \mathbb{C})$. Indeed, this is true because first, the basis $\{H, X, Y\}$ of $\mathfrak{sl}_2 \mathbb{C}$ and the basis $\{A_x, A_y, A_z\}$ of $\mathfrak{su}(2)$ span precisely the same subspace in the vector space Mat$(2, \mathbb{C})$, meaning that the two Lie algebras are the same vector space. Secondly, the bracket operation $[\cdot, \cdot]$ in both $\mathfrak{sl}_2 \mathbb{C}$ and $\mathfrak{su}(2)$ are equivalent since the operation defined to be the commutator in both cases, resulting in the similarities in the bracket behaviors. 
\begin{align*}
    [H,X] = 2X & \iff [A_x, A_y] = A_z \\
    [H,Y] = - 2Y & \iff [A_y, A_z] = A_x\\
    [X,Y] = H & \iff  [A_z, A_x] = A_y 
\end{align*}
Therefore, the complexification of SU$(2)$ and $\SL(2, \mathbb{R})$ both leads to the construction of $\SL(2, \mathbb{C})$. 
\begin{center}
\begin{tikzpicture}
    \node[left] at (0,0.5) {$\SL(2, \mathbb{R})$};
    \node[left] at (-0.2,-0.5) {SU$(2)$};
    \node[right] at (2,0) {$\SL(2,\mathbb{C})$};
    \draw[->] (0,0.5)--(2,0.1);
    \draw[->] (0,-0.5)--(2,-0.1);
    \node at (1,-0.7) {complexify};
\end{tikzpicture}
\end{center}
We can interpret the "real forms" of $\SL(2, \mathbb{C})$ as "slices" of some complex group. However, this does not mean that the real version of these groups are equal. That is, 
\[\SL(2, \mathbb{R}) \neq \text{SU}(2)\]

\subsubsection{Lie Algebra of SO(3)}
It is easy to see that for SO$(2)$, it is easy to see that its Lie algebra $\mathfrak{so}(2)$ has 
\[\bigg\{ \begin{pmatrix}
0&-1\\1&0
\end{pmatrix}\bigg\}\]
as its only basis, since 
\[exp  \bigg( \begin{pmatrix}
0&-1\\1&0
\end{pmatrix} \theta \bigg) = \begin{pmatrix}
\cos{\theta} & - \sin{\theta} \\
\sin{\theta} & \cos{\theta}
\end{pmatrix}\]
meaning that the dimension of SO$(2)$ is $1$. By adding a component, we can get a rotation in $\mathbb{R}^3$. 
\begin{align*}
    & R_x = \begin{pmatrix}0&0&0\\0&0&-1\\0&1&0\end{pmatrix} \implies e^{R_x} = \begin{pmatrix}
    1&0&0\\ 0&\cos{\theta}&-\sin{\theta}\\0&\sin{\theta}&\cos{\theta}
    \end{pmatrix}\\
    & R_y = \begin{pmatrix}0&0&1\\0&0&0\\-1&0&0\end{pmatrix} \implies e^{R_y} = \begin{pmatrix}
    \cos{\theta} & 0 & -\sin{\theta}\\ 0&1&0 \\
    \sin{\theta}& 0 & \cos{\theta} \end{pmatrix} \\
    & R_z = \begin{pmatrix}0&-1&0\\1&0&0\\0&0&0\end{pmatrix} \implies e^{R_z} = \begin{pmatrix}
    \cos{\theta} & -\sin{\theta} & 0\\
    \sin{\theta}& \cos{\theta} & 0 \\ 0 & 0 & 1\end{pmatrix}
\end{align*}
That is, $e^{R_x}, e^{R_y}$, and $e^{R_z}$ generates a rotation around the $x, y$, and $z$ axis, respectively, which completely generates the group SO$(3)$. Therefore, the Lie algebra $\mathfrak{so}(3)$ consists of the basis 
\[\{R_x, R_y, R_z\}\]
The bracket structure (again, defined as the commutator) of this Lie algebra is 
\begin{align*}
    & [R_x, R_y] = R_z \\
    & [R_y, R_z] = R_x \\
    & [R_z, R_x] = R_y
\end{align*}
which is similar to the brakcet structure of $\mathfrak{su}(2)$. Therefore, SO$(3)$ and SU$(2)$ have the \textit{same} Lie algebra, which is the algebra of dimension 3 with the same bracket structure. Note that Lie algebras are uniquely determined by the bracket structure and dimension. However, having the same Lie algebra does not imply that the groups are identical (obviously) nor isomorphic. For example, 
\[exp(2\pi R_z) = \begin{pmatrix}
\cos{2\pi} & -\sin{2\pi} & 0 \\
\sin{2\pi} & \cos{2\pi} & 0 \\
0 & 0 & 1
\end{pmatrix} = I\]
while 
\[exp(2\pi A_z) = 
exp(-i \pi \sigma_z) = exp \bigg(-i \pi \begin{pmatrix}
1&0\\0&-1
\end{pmatrix} \bigg) = -I\]
There is discrepancy by a factor of $-1$. In fact, it turns out that
\[\text{SO}(3) = \frac{\text{SU}(2)}{\pm I}\]
We justify this in the following way. Let $v \in \mathbb{R}^3$ have components $(x, y, z)$. Consider
\[M = x \sigma_x + y \sigma_y + z \sigma_z\]
$M$ is clearly traceless and $M^\dagger = M$. Now, let $S \in$ SU$(2)$ and let $M^\prime = S^{-1} M S$. Then, $\Tr{M^\prime} = \Tr{S^{-1} M S} = \Tr{M} = 0$ and $(M^\prime)^\dagger = (S^{-1} M S)^\dagger = S^\dagger M^\dagger (S^{-1})^\dagger = S^{-1} M S = M^\prime$. Therefore, since $M^\prime$ is self adjoint and traceless, it can be expressed in the form
\[x^\prime \sigma_x + y^\prime \sigma_y + z^\prime \sigma_z\]
for some $(x^\prime, y^\prime, z^\prime)$. Now, since 
\[M^2 = (-x^2 - y^2 - z^2) I\]
we have 
\begin{align*}
    (M^\prime)^2 & = S^{-1} M^2 S = (-x^2 - y^2 - z^2) I \\
    & = (-x^{\prime 2} - y^{\prime 2} - z^{\prime 2}) I 
\end{align*}
So, $x^2 + y^2 + z^2 = x^{\prime 2} + y^{\prime 2} + z^{\prime 2}$, implying that the lengths of $v$ stayed the same. (The proof of linearity of $S$ is easy.) Therefore, the transformation $M \mapsto M^\prime$, i.e. $(x, y, z) \mapsto (x^\prime, y^\prime, z^\prime)$ is a linear transformation preserving length in $\mathbb{R}^3$ (with respect to the usual inner product and norm) $\implies$ it is in SO$(3)$. If we have
\[S  = \begin{pmatrix}
-1&0\\0&-1
\end{pmatrix}\]
then $M^\prime = M$, which explains why SO$(3)$ is a coset deviating by both $I$ and $-I$. Visually, if we let SU$(2)$ be a circle, points that are diametrically opposite of each other are "equivalent" in SO$(3)$. That is, SU$(2)$ is a three-dimensional sphere, and $g$ and $-g$ are identified onto the same element in SO$(3)$. This map
\[\rho: \text{SU}(2) \longrightarrow \text{SO}(3)\]
in which 2 points are mapped to 1 point is a surjective map with
\[\ker{\rho} = \{I, -I\}\]
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0) circle (2);
    \draw[fill] (2,0) circle (0.05);
    \draw[fill] (-2,0) circle (0.05);
    \node[right] at (2,0) {$I$};
    \node[left] at (-2,0) {$-I$};
    \draw[fill] (1,1.732) circle (0.05);
    \draw[fill] (-1,-1.732) circle (0.05);
    \node[above right] at (1, 1.732) {$g$};
    \node[below left] at (-1, -1.732) {$-g$};
    \draw[dashed] (-2,0)--(2,0);
    \draw[dashed] (1, 1.732)--(-1, -1.732);
    \node[above left] at (-1.414, 1.414) {SU$(2)$};
\end{tikzpicture}
\end{center}

We can in fact explicitly describe exponential map from $\mathfrak{so}(3)$ to SO$(3)$ with the following lemma. 

\begin{lemma}[Rodrigues' Formula]
The exponential map $exp: \mathfrak{so}(3) \longrightarrow$ SO$(3)$ is defined by 
\[e^A = \cos{\theta} I_3 + \frac{\sin{\theta}}{\theta} A + \frac{(1 - \cos{\theta})}{\theta^2} B\]
where 
\[A = \begin{pmatrix}
0&-c&b\\c&0&-a\\-b&a&0
\end{pmatrix}, B = \begin{pmatrix}
a^2&ab&ac\\ab&b^2&bc\\ac&bc&c^2
\end{pmatrix}\]
This formula has many applications in kinematics, robotics, and motion interpolation. 
\end{lemma}

\begin{theorem}
The Lie algebras for the following classical Lie groups are summarized as follows. 
\begin{enumerate}
    \item $\mathfrak{sl}_n \mathbb{R}$ is the real vector space of real $n \times n$ matrices with null trace.
    \item $\mathfrak{so}(n)$ is the real vector space of real $n \times n$ skew-symmetric matrices. 
    \item $\mathfrak{gl}_n \mathbb{R}$ is the real vector space of all real $n \times n$ matrices.
    \item $\mathfrak{o}(n) = \mathfrak{o}(n)$
\end{enumerate}
\end{theorem}
Note that the corresponding groups $\GL(n, \mathbb{R}), \SL(n, \mathbb{R}), \mathfrak{gl}_n \mathbb{R}, \mathfrak{sl}_n \mathbb{R}$ are Lie groups, meaning that they are smooth real manifolds. We can view each of them as smooth real manifolds embedded in the $n^2$ dimensional vector space of real matrices, which is isomorphic to $\mathbb{R}^{n^2}$. 

\begin{theorem}
The Lie algebras $\mathfrak{gl}_ \mathbb{R}, \mathfrak{sl}_n \mathbb{R}, \mathfrak{o}(n), \mathfrak{so}(n)$ are well-defined, but only 
\[exp: \mathfrak{so}(n) \longrightarrow \text{SO}(n)\]
is surjective. 
\end{theorem}

\begin{theorem}
The Lie algebras for the following classical Lie groups are summarized as follows. 
\begin{enumerate}
    \item $\mathfrak{sl}_2 \mathbb{C}$ is the real (or complex) vector space of traceless complex $n \times n$ matrices. 
    \item $\mathfrak{u}(n)$ is the real vector space of complex $n \times n$ skew-Hermitian matrices. 
    \item $\mathfrak{su}(n) = \mathfrak{u} \cap \mathfrak{sl}_2 \mathbb{C}$. It is also a real vector space. 
    \item $\mathfrak{gl}_n \mathbb{C}$ is the real (or complex) vector space of complex $n \times n$ matrices. 
\end{enumerate}
Note that even though the matrices in these Lie algebras have complex coefficients, we have assigned them to be in a \textit{real} vector space, which means that we are only allowed to take real linear combinations of these elements. That is, the field we are working over is $\mathbb{R}$ (this does not contradict any of the axioms for vector spaces). For example an element $A$ in $\mathfrak{u}(n)$ or $\mathfrak{su}(n)$ must be anti-self adjoint, but $iA$ is self adjoint. 
\end{theorem}

Similarly, the Lie groups $\GL(n, \mathbb{C}), \SL(n, \mathbb{C}), \mathfrak{gl}_n \mathbb{C}, \mathfrak{sl}_n \mathbb{C}$ are also smooth real manifolds embedded in Mat$(n, \mathbb{C}) \simeq \mathbb{C}^{n^2} \simeq \mathbb{R}^{2 n^2}$. So, we can view these four groups as manifolds embedded in $\mathbb{R}^{2 n^2}$. 

Note some of the similarities and differences between the real and complex counterparts of these Lie groups and algebras. 
\begin{enumerate}
    \item $\mathfrak{o}(n) = \mathfrak{so}(n)$, but $\mathfrak{u}(n) \neq \mathfrak{su}(n)$. 
    \item $exp: \mathfrak{gl}_n \mathbb{R} \longrightarrow \GL(n, \mathbb{R})$ is not surjective, but $exp: \mathfrak{gl}_n \mathbb{C} \longrightarrow \GL(n, \mathbb{C})$ is surjective due to the spectral theorem and surjectivity of $exp: \mathbb{C} \longrightarrow \mathbb{C}^*$.
    \item The exponential maps $exp: \mathfrak{u}(n) \longrightarrow \text{U}(n)$ and $exp: \mathfrak{su}(n) \longrightarrow \text{SU}(n)$ are surjective. 
    \item Still, $exp: \mathfrak{sl}_2 \mathbb{C} \longrightarrow \SL(2, \mathbb{C})$ is not surjective. This will be proved now. 
\end{enumerate}

\begin{theorem}
$exp: \mathfrak{sl}_2 \mathbb{C} \longrightarrow \SL(2, \mathbb{C})$ is not surjective. 
\end{theorem}
\begin{proof}
Given $M \in \SL(n, \mathbb{C})$, assume that $M = e^A$ for some matrix $A \in \mathfrak{sl}_2 \mathbb{C}$. Putting $A$ into the Jordan Normal Form $J = N A N^{-1}$ means that $J$ can either be of form
\[J = \begin{pmatrix}
0&1\\0&0
\end{pmatrix}, \begin{pmatrix}
\lambda&0\\0&-\lambda
\end{pmatrix} \implies e^J = \begin{pmatrix}
1&1\\0&1
\end{pmatrix}, \begin{pmatrix}
e^\lambda&0\\0&e^{-\lambda}
\end{pmatrix}\]
which is also in JNF in $\SL(2, \mathbb{C})$. But a matrix $P \in \SL(2, \mathbb{C})$ may exist with JNF of 
\[K = \begin{pmatrix}
-1&1\\0&-1
\end{pmatrix}\]
which is not one of the 2 forms. So, $K \not\in \im{exp} \implies exp$ is not surjective. 
\end{proof}

\begin{theorem}
The exponential maps 
\begin{align*}
    & exp: \mathfrak{u}(n) \longrightarrow \text{U}(n) \\
    & exp: \mathfrak{su}(n) \longrightarrow \text{SU}(n)
\end{align*}
are surjective. 
\end{theorem}

\subsubsection{Lie Algebra of SE(n)}
Recall that the group of affine rigid isometries is denoted SE$(n)$. That is, 
\[\text{SE}(n) \equiv \text{SO}(n) \ltimes \text{Tran}\,\mathbb{R}^n\]
We can define the matrix representation of this affine transformation as such. Given an element $g \in$ SE$(n)$ such that
\[g(x) \equiv R x + U, \; R \in \text{SO}(n), U \in \text{Tran}\, \mathbb{R}^n \]
we define the representation
\[\rho: \text{SE}(n) \longrightarrow \GL(n+1, \mathbb{R}), \rho(g) \equiv \begin{pmatrix}
R&U\\0&1
\end{pmatrix}\]
where $R$ is a real $n\times n$ matrix in SO$(n)$ and $U$ is a real $n$-vector in Tran$\,\mathbb{R}^n \simeq \mathbb{R}^n$. We would then have
\[\rho(g) \begin{pmatrix}
x\\1
\end{pmatrix} \equiv \begin{pmatrix}
R&U\\0&1
\end{pmatrix} \begin{pmatrix}
x\\1
\end{pmatrix} = \begin{pmatrix}
R x + U\\1
\end{pmatrix} \in \mathbb{R}^{n+1}\]

Clearly, SE$(n)$ is a Lie group, and the matrix representation $\varrho$ of its Lie algebra $\mathfrak{se}(n)$ can be defined as the vector space of $(n+1) \times (n+1)$ matrices of the block form 
\[A = \begin{pmatrix}
\Omega & U \\0 & 0
\end{pmatrix}\]
where $\Omega$ is an $n \times n$ skew-symmetric matrix and $U \in \mathbb{R}^n$. Note that there are two different exponential maps here: one belonging to the abstract Lie group SE$(n)$ and another belonging to the concrete, matrix group $\GL(n+1, \mathbb{R})$. This can be represented with the commutative diagram. 
\[\begin{tikzcd}
\mathfrak{se}(n) \arrow{r}{exp} \arrow{d}{\varrho} & SE(n) \arrow{d} {\rho}\\
\mathfrak{gl}_{n+1} \mathbb{R} \arrow{r}{exp} & \GL(n+1, \mathbb{R})
\end{tikzcd}\]
\begin{lemma}
Given any $(n+1) \times (n+1)$ matrix of form 
\[A = \begin{pmatrix}
 \Omega & U \\0&0
\end{pmatrix}\]
where $\Omega$ is any matrix and $U \in \mathbb{R}^n$, 
\[A^k = \begin{pmatrix}
\Omega^k & \Omega^{k-1} U \\0&0
\end{pmatrix}\]
where $\Omega^0 = I_n$, which implies that
\[e^A = \begin{pmatrix}
e^\Omega & V U \\ 0 & 1
\end{pmatrix}, \; V = I_n + \sum_{k \geq 1} \frac{\Omega^k}{(k+1)!}\]
\end{lemma}

\begin{theorem}
The exponential map
\[exp: \mathfrak{se}(n) \longrightarrow SE(n)\]
is well-defined and surjective. 
\end{theorem}
\subsection{Representations of Lie Groups and Lie Algebras}
Let $\mathcal{G}$ be an abstract group and let
\[\rho: \mathcal{G} \longrightarrow \GL(V)\]
be the representation of $\mathcal{G}$. Then, let $\mathfrak{g}$ be the Lie algebra of $\mathcal{G}$, and $\mathfrak{gl}(V)$ be the Lie algebra of $\GL(V)$. Then, $\rho$ induces another homomorphism 
\[\varrho: \mathfrak{g} \longrightarrow \mathfrak{gl}(V)\]
where the bracket structure (in this case, the comutator in the matrix algebra) is preserved. 
\[\varrho([X,Y]) = [\varrho(X), \varrho(Y)]\]
We can visualize this induced homomorphism with the following commutative diagram, which states that $\rho \circ exp = exp \circ \varrho$. 
\[\begin{tikzcd}
\mathcal{G} \arrow{r}{\rho} & \GL(V)\\
\mathfrak{g} \arrow{u}{exp} \arrow{r}{\varrho} & \mathfrak{gl}(V) \arrow{u}{exp}
\end{tikzcd}\]
Note that there are very crucial differences between $\rho$ and $\varrho$. First, $\rho$ is a homomorphism between \textit{groups}, while $\varrho$ is a homomorphism between \textit{vector spaces}. Additionally, $\GL(V)$ is a group, not a linear space, while $\mathfrak{gl}(V)$ is a linear space. Finally, note that $\GL(V)$ is restricted to only matrices with nonzero determinants, while the elements of $\mathfrak{gl}(V)$ can be any matrix. 

\begin{example}
The representation of SE$(n)$ to $\GL(n+1 \mathbb{R}$ and $\mathfrak{se}(n)$ to $\mathfrak{gl}_{n+1} \mathbb{R}$ induces the second homomorphism $\varrho: \mathfrak{gl}_{n+1} \mathbb{R} \longrightarrow \GL(n+1, \mathbb{R})$. 
\end{example}

\begin{definition}
The direct sum of representations is a representation. That is, if $U$ is a representation and $V$ is a representation, then $U \oplus V$ is a representation. That is, if 
\[\rho_1: \mathcal{G} \longrightarrow U, \; \rho_1 (g) = \begin{pmatrix}
u_1&u_2\\u_3&u_4
\end{pmatrix}\]
and
\[\rho_2: \mathcal{G} \longrightarrow V, \; \rho_2 (g) = \begin{pmatrix}
v_1 & v_2 \\ v_3 & v_4
\end{pmatrix}\]
are two representations of the same group element $g \in \mathcal{G}$, then 
\[(\rho_1 \oplus \rho_2): \mathcal{G} \longrightarrow (U \oplus V), \;(\rho_1 \oplus \rho_2) (g) = \begin{pmatrix}
u_1 & u_2 & 0 & 0 \\
u_3 & u_4 & 0 & 0 \\
0 & 0 & v_1 & v_2 \\
0 & 0 & v_3 & v_4 
\end{pmatrix}\]
is a bigger representation of $g$ in $U \oplus V$. 
\end{definition}

\begin{definition}
$V$ is irreducible if the only subspaces which are representations are only $V$ and $\{0\}$. 
\end{definition}
For our case, we will consider that any representation can be written as a direct sum of irreducible representations. We will now proceed to find an irreducible representation of $\mathfrak{sl}_2 \mathbb{C}$. This means that we want to find the smallest (lowest dimensional) vector space $V$ such that there exists a representation
\[\varrho: \mathfrak{sl}_2 \mathbb{C} \longrightarrow \mathfrak{gl}(V)\]
We will write, as shorthand notation, that 
\[H = \varrho(H), X = \varrho(X), Y = \varrho(Y)\]
Clearly, $H, X, Y \in \mathfrak{gl}(V) \simeq \mathfrak{gl}(\mathbb{C}^n)$. By the spectral theorem, we can find an orthonormal basis of eigenvectors $e_1, e_2, ..., e_n$ of the mapping $H$ such that
\[H e_i = \lambda_i e_i, \; \lambda_i \in \mathbb{C}\]
Since $[H,X] = 2X$, it follows that
\[HX e_i - X H e_i = 2X e_i \implies H (X e_i) = (\lambda_i + 2) (X e_i)\]
$\implies Xe_i$ for all $i = 1, 2, ..., n$ are also eigenvectors of $H$ with eigenvalue $(\lambda_i + 2)$, or $X e_i = 0$. So, $X$ is a "ladder operator" that maps each eigenvector $e_i$ with eigenvalue $\lambda_i$ to a different eigenvector $e_j$ with eigenvalue $\lambda_j = \lambda_i + 2$. Having nowhere to be mapped to, the eigenvector with the largest eigenvalue (which must exist since $V$ is finite dimensional) will get mapped to the $0$ vector by $X$. Let us denote this eigenvector having the maximum eigenvalue $m$, as $v_m$. 

Similarly, $[H,Y] = -2Y$ implies that
\[HY e_i - YH e_i = -2Y e_i \implies H(Y e_i) = (\lambda_i - 2)(Y e_i)\]
implying that $Y$ maps each eigenvector $e_i$ with eigenvaue $\lambda_i$ to another eigenvector $e_j$ with eigenvalue $\lambda_j = \lambda_i - 2$, except for the eigenvector with smallest eigenvalue, which gets mapped to $0$. Since $Y$ clearly maps each eigenvector to a different eigenvector that has a strictly decreasing eigenvalue, we can construct a basis of $V$ to be
\[\{v_m, Y v_m, Y^2 v_m, Y^3 v_m, ..., Y^{n-1} v_m\}\]
(remember that $Y^n v_m = 0$). So, elements of $\mathfrak{sl}_2 \mathbb{C}$ acts on the space $V$ with basis above. To continue, we introduce the following proposition. 
\begin{proposition}
\[X Y^j v_m = j(m-j+1) Y^{j-1} v_m\]
\end{proposition}
\begin{proof}
By induction on $j$ using bracket relations.
\end{proof}
$V$ is $n$-dimensional. Since $Y^n v_m = 0$ and $Y^{n-1} v_m \neq 0$, we use the proposition above to get
\[0 = X Y^n v_m = n (m-n+1) Y^{n-1} v_m \implies m-n+1=0\]
So, $n = m+1$, which means that the eigenvalues of $H$ are
\[m, m-2, m-4, ..., m - 2(n-1) = -m\]
and we are done. We now classify the 1, 2, and 3 dimensional irreducible representations of $\mathfrak{sl}_2 \mathbb{C}$. 
\\
\\
When $n = 1$ (i.e. dimension is 1), $m = n-1 = 0$, meaning that the greatest (and only) eigenvalue is $0$. That is, 
\[H v_0 = 0,\; X v_0 = 0,\; Y v_0 = 0\]
which is the trivial representation of $\mathfrak{sl}_2 \mathbb{C}$. Explicitly, we can completely define the representation (which is a linear homomorphism) with the three equations. 
\[\varrho(H) = (0),\; \varrho(X) = (0),\; \varrho(Y) = (0)\]
When $n = 2$ and $m=1$. We now look for a 2 dimensional irreducible representation. The eigenvalues are $1$ and $-1$, with $\{v_1, v_{-1}\}$ as a basis of 2 dimensional space $V$. Then we have 
\begin{align*}
    & Hv_1 = v_1, \; Hv_{-1} = - v_{-1} \\
    & X v_1 = 0, \; X v_{-1} = v_1 \\
    & Y v_1 = v_{-1}, \; Y v_{-1} = 0
\end{align*}
which explicitly translates to the representation $\varrho$ being defined
\[\varrho(H) = \begin{pmatrix}
1&0\\0&-1
\end{pmatrix}, \; \begin{pmatrix}
0&1\\0&0
\end{pmatrix}, \; \begin{pmatrix}
0&0\\1&0
\end{pmatrix}\]
When $n=3 \implies m=2$, the basis is $\{v_{-2}, v_0, v_2\}$ with eigenvalues $2, 0, -2$, and the irreducible representation $\varrho$ is defined
\[\varrho(H) = \begin{pmatrix}
2&&\\&0&\\&&-2
\end{pmatrix}, \varrho(Y) = \begin{pmatrix}
0&0&0\\1&0&0\\0&1&0
\end{pmatrix}, \varrho(X) = \begin{pmatrix}
0&1&0\\0&0&1\\0&0&0
\end{pmatrix}\]
The same process continues on for $n=4, 5, ...$, and this entirely classifies the irreducible representations of $\mathfrak{sl}_2 \mathbb{C}$. 
\subsubsection{Tensor Products of Group Representations}
\begin{definition}
If $V$ and $W$ are two different representations of a group $\mathcal{G}$, then we know that $V \oplus W$ is also a representation of $\mathcal{G}$. Furthermore, the tensor product space $V \otimes W$ also defines a representation of $\mathcal{G}$. That is, given representations
\begin{align*}
    & \rho_V: \mathcal{G} \longrightarrow \GL(V) \\
    & \rho_W: \mathcal{G} \longrightarrow \GL(W)
\end{align*}
The homomorphism 
\[\rho_V \otimes \rho_W: \mathcal{G} \longrightarrow \GL(V \otimes W)\]
is also a representation of $\mathcal{G}$, which is defined
\[(\rho_V \otimes \rho_W)(g) (v \otimes w) \equiv \rho_V (g) (v) \otimes \rho_W (g) (w)\]
or represented in shorthand notation, 
\[g(v \otimes w) \equiv (g v) \otimes (g w)\]
We know that exp$(H)$ acts on $V$ and $W$ since it is an element of $\GL(V)$ and $\GL(W)$. This means that
\[exp(H)(v \otimes w) \equiv \big( exp(H)(v)\big) \otimes \big( exp(H)(w)\big)\]
If $H$ ($= \rho_V (H)$ or $\rho_W(H)$) has an eigenvalue $\lambda$ on $v$ in $V$ and eigenvalue $\mu$ on $w$ in $W$, then 
\[exp(H) (v \otimes w) = (e^\lambda v) \otimes (e^\mu w) = e^{\lambda + \mu} v \otimes w\]
That is, eigenvalues of $H$ \textit{add} on tensor products. 
\end{definition}

\begin{example}
Recall that the $2$ dimensional representation $V$ of $\mathfrak{sl}_2 \mathbb{C}$ has eigenvalues $1$ and $-1$ (with corresponding eigenvectors $e_1$ and $e_{-1}$). So, $V \otimes V$ has eigenvalues 
\begin{align*}
    & (-1) + (-1) = -2, \;\; (-1) + 1 = 0 \\
    & 1 + (-1) = 0, \;\; 1 + 1 = 2
\end{align*}
Therefore, the eigenvalues of $V \otimes V$ is $-2$ (geometric multiplicity of 1), $0$ (geometric multiplicity of 2), and $2$ (geometric multiplicity of 1), (Notation-wise, the $n$-dimensional irreducible representation of $\mathfrak{sl}_2 \mathbb{C}$ is denoted $\mathbf{n}$.) which means that
\[\bold{2} \otimes \bold{2} = \bold{3} \oplus \bold{1}\]
We can decompose $V \otimes V$ into its symmetric and exterior power components. Sym$^2 V$ has basis (of eigenvectors)
\[\{e_{-1} \odot e_{-1}, \; e_{-1} \odot e_1, \; e_1 \odot e_1\}\]
where the corresponding eigenvalues are $-2$, $0$, and $2$, respectively. So, $\dim{Sym^2 V} = 3$, which means that $Sym^2 V = \bold{3}$. As for the exterior power component of $V$, $\Lambda^2 V$ has basis 
\[\{e_{-1} \wedge e_1\}\]
with eigenvalue $= 0 \implies \dim{\Lambda^2 V} = 1$, meaning that $\Lambda^2 V = \bold{1}$. Therefore, 
\[V \otimes V = Sym^2 V \oplus \Lambda^2 V = \bold{3} \oplus \bold{1}\]
\end{example}

\subsection{Topological Decompositions of Lie Groups}
\begin{definition}
Let us define 
\begin{enumerate}
    \item S$(n)$ is the vector space of real, symmetric $n \times n$ matrices. 
    \item SP$(n)$ is the set of symmetric, positive semidefinite matrices. 
    \item SPD$(n)$ is the set of symmetric, positive definite matrices. 
\end{enumerate}
Note that SP$(n)$ and SPD$(n)$ are not even vector spaces at all. 
\end{definition}

\begin{lemma}
The exponential map 
\[exp: S(n) \longrightarrow SPD(n)\]
is a homeomorphism. One may be tempted to call S$(n)$ the Lie algebra of SPD$(n)$, but this is not the case. S$(n)$ is not even a Lie algebra since the commutator is not algebraically closed. Furthermore, SPD$(n)$ is not even a multiplicative group (since matrix multiplication is not closed). 
\end{lemma}

Recall from linear algebra the Polar Decomposition. We express this result in a slightly modified way. 

\begin{theorem}[Polar Decomposition]
Given a Euclidean space $\mathbb{E}^n$ and any linear endomorphism $f$ of $\mathbb{E}^n$, there are two positive definite self-adjoint linear maps $h_1, h_2 \in$ End$(\mathbb{E}^n)$ and $g \in$ O$(n)$ such that
\[f = g \circ h_1 = h_2 \circ g\]
That is, such that $f$ can be decomposed into the following compositions of functions that commute. 
\[\begin{tikzcd}
\mathbb{E}^n \arrow{r}{h_2} & \mathbb{E}^n \\
\mathbb{E}^n \arrow{u}{g} \arrow{ur}{f} \arrow{r}{h_1} & \mathbb{E}^n \arrow{u}{g}
\end{tikzcd}\]
This means that there is a bijection between $Mat(n, \mathbb{R})$ and $O(n) \times SP(n)$. If $f$ is an automorphism, then this decomposition is unique. 
\end{theorem}

\begin{corollary}
The two topological groups are homeomorphic. 
\[GL(n, \mathbb{R}) \cong O(n) \times SPD(n)\]
\end{corollary}

\begin{corollary}
For every invertible real matrix $A \in GL(n, \mathbb{R})$, there exists a unique orthogonal matrix $R$ and unique symmetric matrix $S$ such that
\[A = R e^S\]
$\implies$ there is a bijection between $\GL(n, \mathbb{R})$ and $O(n) \times S(n) \simeq \mathbb{R}^{n(n+1)/2}$. Moreover, they are homeomorphic. That is, 
\[\GL(n, \mathbb{R}) \simeq O(n) \times S(n) \simeq O(n) \times \mathbb{R}^{n(n+1)/2}\]
This essentially reduces the study of $\GL(n, \mathbb{R})$ to the study of $O(n)$, which is nice since $O(n)$ is compact. 
\end{corollary}

\begin{corollary}
Given a real matrix $A$, if $\det{A} > 0$, then we can decompose $A$ as
\[A = R e^S\]
where $R \in SO(n)$ and $S \in S(n)$. 
\end{corollary}

\begin{corollary}
There exists a bijection between
\[\SL(n, \mathbb{R}) \text{ and } SO(n) \times (S(n) \cap \mathfrak{sl}_n \mathbb{R})\]
\end{corollary}
\begin{proof}
$A \in \SL(n, \mathbb{R}) \implies 1 = \det{A} = \det{R} \det{e^S} = \det{e^S} \implies \det{e^S} = e^{\Tr{S}} = 1 \implies \Tr{S} = 0 \implies S \in$ S$(n) \cap \mathfrak{sl}_n \mathbb{R}$. 
\end{proof}

\begin{definition}
Let us define
\begin{enumerate}
    \item H$(n)$ is the real vector space of $n \times n$ Hermitian matrices. 
    \item HP$(n)$ is the set of Hermitian, positive semidefinite $n \times n$ matrices. 
    \item HPD$(n)$ is the set of Hermitian, positive definite $n \times n$ matrices. 
\end{enumerate}
Similarly, HP$(n)$ and HPD$(n)$ are not vector space. They are just sets. 
\end{definition}

\begin{lemma}
The exponential mapping
\[exp: H(n) \longrightarrow HPD(n)\]
is a homeomorphism. 
\end{lemma}

However again, HPD$(n)$ is not a Lie group (multiplication is not algebraically closed) nor is H$(n)$ a Lie algebra (commutator is not algebraically closed). By the polar form theorem of complex $n \times n$ matrices, we have a (not necessarily unique) bijection between
\[\text{Mat}(n, \mathbb{C}) \text{ and } U(n) \times HP(n)\]
which implies that
\[\GL(n, \mathbb{C}) \cong U(n) \times HPD (n)\]
\begin{corollary}
For every complex invertible matrix $A$, there exists a unique decomposition
\[A = U e^S \]
where $U \in U(n)$ and $S \in H(n)$, which implies that the following groups are homeomorphic. 
\begin{align*}
    \GL(n, \mathbb{C}) & \cong U(n) \times H(n) \\
    & \cong U(n) \times \mathbb{R}^{n^2}
\end{align*} 
This essentially reduces the study of $\GL(n, \mathbb{C})$ to that of U$(n)$. 
\end{corollary}

\begin{corollary}
There exists a bijection between 
\[\SL(n, \mathbb{C}) \text{ and } SU(n) \times (H(n) \cap \mathfrak{sl}_n \mathbb{C})\]
\end{corollary}
\begin{proof}
Similarly, when $A = U e^S$, we know that $|\det{U}| = 1$ and $\Tr{S}$ is real (since by the Spectral theorem, every self adjoint matrix has a real spectral decomposition). Since $S$ is Hermitian, this implies that $\det{e^S} > 0$. If $A \in \SL(n, \mathbb{C})$, then $\det{A} = 1 \implies \det{e^S} = 1 \implies S \in H(n) \cap \mathfrak{sl}_n \mathbb{C}$. 
\end{proof}

\subsection{Linear Lie Groups}
We will assume that the reader has the necessary background knowledge in manifolds, chart mappings, diffeomorphisms, tangent spaces, and transition mappings. 

Recall that the algebra of real $n \times n$ matrices Mat$(n, \mathbb{R})$ is bijective to $\mathbb{R}^{n^2}$, which is a topological space. Therefore, this bijection 
\[i:(\mathbb{R}^{n^2}, \tau_E) \longrightarrow \text{Mat}(n, \mathbb{R})\]
induces a topology on Mat$(n, \mathbb{R})$, defined 
\[\tau_M \equiv \{U \in \text{Mat}(n, \mathbb{R}) \; | \; e^{-1} (U) \in \tau_E\}\]
With this, consider the subset
\[\GL(n, \mathbb{R}) \subset \text{Mat}(n, \mathbb{R})\]
where
\[\GL(n, \mathbb{R}) \equiv \{x \in \text{Mat}(n, \mathbb{R}) \;|\; \det{x} \neq 0\}\]
This set, as we expect, is a multiplicative group. 

\begin{definition}
The \textit{general linear group}, denoted $\GL(n, \mathbb{R})$ is the set of $n \times n$ matrices with nonzero determinant. The more technical definition is that $\GL(n, \mathbb{R})$ is really just the automorphism group of $\mathbb{R}^n$, 
\[\GL(n, \mathbb{R}) \equiv \text{Aut}(\mathbb{R}^n)\]
but it is customary to assume a basis on $\mathbb{R}^n$ in order to realize $\GL(n, \mathbb{R})$ as a matrix group. Note that the procedure of assuming a basis on $\mathbb{R}^n$ is the same as defining a representation of the abstract group $\GL(n, \mathbb{R})$. Both assigns a real $n \times n$ matrix to each element of $\GL(n, \mathbb{R})$. 
\end{definition}

In this way, we can view $\GL(n, \mathbb{R})$ as a topological space in $\mathbb{R}^{n^2}$, and it is fine to interpret $\GL(n, \mathbb{R})$ as a matrix group rather than an abstract group. 

Since the matrix representation of $\GL(n, \mathbb{R})$ is always well defined, the abstract subgroups of $\GL(n, \mathbb{R})$, which are $\SL(n, \mathbb{R}), O(n)$, and $SO(n)$, also have well defined matrix representations (that we are all familiar with). Additionally, since there exists a bijection
\[\text{Mat}(n, \mathbb{C}) \cong \mathbb{C}^{n^2} \cong \mathbb{R}^{2 n^2}\]
we can view $\GL(n, \mathbb{C})$ as a subset of $\mathbb{R}^{2n^2}$, meaning that the subgroups $\SL(n, \mathbb{C}), U(n)$, and $SU(n)$ of $\GL(n, \mathbb{C})$ can also be viewed as subsets of $\mathbb{R}^{2n^2}$. This also applies to $SE(n)$ since it is a subgroup of $\SL(n+1, \mathbb{R})$. We formally state it now. 

\begin{proposition}
SE$(n)$ is a linear Lie group. 
\end{proposition}
\begin{proof}
The matrix representation of elements $g \in SE(n)$ is 
\[\rho(g) \equiv \begin{pmatrix}
R_g & U_g \\ 0 & 1
\end{pmatrix}, \; R_g \in SO(n), U_g \in \mathbb{R}^n\]
But such matrices also belong to the bigger group $\SL(n+1, \mathbb{R}) \implies SE(n) \subset \SL(n+1, \mathbb{R})$. Moreover, this canonical embedding 
\[i: SE(n) \longrightarrow \SL(n+1, \mathbb{R})\]
is a group homomorphism since
\begin{align*}
    i\big( \rho(g_1 \cdot g_2) \big) & = \begin{pmatrix}
    RS & RV + U \\ 0 & 1
    \end{pmatrix} \\
    & = \begin{pmatrix}
    R & U \\ 0 & 1
    \end{pmatrix} \begin{pmatrix}
    S & V \\ 0 & 1
    \end{pmatrix} = \rho \big( i(g_1) \cdot i(g_2) \big) 
\end{align*}
and the inverse is given by 
\[\begin{pmatrix}
R & U \\ 0 & 1
\end{pmatrix}^{-1} = \begin{pmatrix}
R^{-1} & - R^{-1} U \\ 0 & 1
\end{pmatrix} = \begin{pmatrix}
R^T & - R^T U \\ 0 & 1
\end{pmatrix}\]
is also consistent between the inverse operation in SE$(n)$ and $\SL(n+1, \mathbb{R})$. Therefore, SE$(n)$ is a subgroup of $\SL(n+1, \mathbb{R})$, which is a subgroup of $\GL(n+1, \mathbb{R})$. 
\end{proof}

Note that even though SE$(n)$ is diffeomorphic (a topological relation) to SO$(n) \times \mathbb{R}^n$, it is \textit{not} isomorphic (an algebraic relation) sicne group operations are not preserved. Therefore, we write this "equality" as a semidirect product of groups. 
\[SE(n) \equiv SO(n) \ltimes \mathbb{R}^n\]

Therefore, all of the classical Lie groups that we have mentioned can be viewed as subsets of $\mathbb{R}^N$ (with the subspace topology) and as subgroups of $\GL(N, \mathbb{R})$ for some big enough $N$. This defines a special family of Lie groups, called linear Lie groups. 

\begin{definition}
A \textit{linear Lie group} is a subgroup of $\GL(n, \mathbb{R})$ for some $n \geq 1$ which is also a smooth manifold in $\mathbb{R}^{n^2}$. 
\end{definition}

\begin{theorem}[Von Neumann, Cartan]
A closed subgroup $\mathcal{G}$ of $\GL(n, \mathbb{R})$ is a linear Lie group. That is, a closed subgroup $\mathcal{G}$ of $\GL(n, \mathbb{R})$ is a smooth manifold in $\mathbb{R}^{n^2}$.
\end{theorem}

\begin{definition}
Since a linear Lie group $\mathcal{G}$ is a smooth submanifold in $\mathbb{R}^N$, we can take its tangent space at the identity element $I$, which is defined 
\[T_I \mathcal{G} \equiv \{p^\prime (0) \;|\; p: I \subset \mathbb{R} \longrightarrow \mathcal{G}, p(0) = I\}\]
where $p$ is a path function on $\mathcal{G}$. 
\end{definition}

Note that we haven't mentioned anything about the exponential map up to now. We mention the relationship between this map and the Lie algebra with the following theorem. 

\begin{theorem}
Let $\mathcal{G}$ be a linear Lie group. The set $\mathfrak{g}$ defined such that
\[\mathfrak{g} \equiv \{X \in \text{Mat}(n, \mathbb{R}) \; | \; e^{t X} \in \mathcal{G} \; \forall t \in \mathbb{R}\}\]
is equal to the tangent space of $\mathcal{G}$ at the identity element. That is, 
\[\mathfrak{g} = T_I \mathcal{G}\]
Furthermore, $\mathfrak{g}$ is closed under the commutator 
\[[A,B] \equiv A B - B A\]
\end{theorem}

This theorem ensures that given a linear Lie group $\mathcal{G}$, the tangent space $\mathfrak{g}$ exists and is closed under the commutator. We formally define this space. 

\begin{definition}
The Lie algebra of a linear Lie group is a real vector space (of matrices) together with a algebraically closed bilinear map 
\[[A,B] \equiv A B - B A\]
called the \textit{commutator}. 
\end{definition} 

The definition of $\mathfrak{g}$ given in the previous theorem shows that 
\[exp: \mathfrak{g} \longrightarrow \mathcal{G}\]
is well defined. In general, exp is neither injective nor surjective. Visually, this exponential mapping is what connects the Lie algebra, i.e. the tangent space of manifold $\mathcal{G}$ to the actual Lie group $\mathcal{G}$. To define the inverse map that maps Lie group elements to Lie algebra ones, we can simply just compute the tangent vectors of the manifold $\mathcal{G}$ at the identity $I$ by taking the derivative of arbitrary path functions in $\mathcal{G}$. That is, for every $X \in T_I \mathcal{G}$, we define the smooth curve 
\[\gamma_X: t \mapsto e^{tX}\]
where $\gamma_X(0) = I$. If we take the derivative of this curve, with respect to $t$ at $t = 0$, we will get the tangent vector $X$ corresponding to that group element $g = e^{X}$. More visually, we just need to take the collection of all smooth path functions $\gamma$ on manifold $\mathcal{G}$ such that $\gamma(0) = I$. Then, taking the derivative of all these paths at $t = 0$ will produce the collection of all tangent vectors at the identity element. We show this process in the following examples. 
\begin{theorem}
The matrix representation of $\mathfrak{sl}_n \mathbb{R}$ is precisely the set of traceless $n \times n$ matrices. 
\end{theorem}
\begin{proof}
Clearly, $\mathfrak{sl}_n \mathbb{R}$ is a vector space since it is a Lie algebra. So, $X \in \mathfrak{sl}_n \mathbb{R} \implies t X \in \mathfrak{sl}_n \mathbb{R}$ for all $t \in \mathbb{R} \implies \det{e^{tX}} = 1$ for all $t \in \mathbb{R}$, for all $X \in \mathfrak{sl}_n \mathbb{R}$. But we use the identity 
\begin{align*}
    \det{e^{tX}} = e^{\Tr{(tX)}} & \implies 1 = e^{\Tr{(t X)}} \\
    & \implies \Tr{(tX)} = 0 \\
    & \implies \Tr{(X)} t = 0 \implies \Tr{X} = 0
\end{align*}
\end{proof}
We now provide an alternative, better proof. We first need a lemma. 

\begin{lemma}
$\det^\prime (I) = \Tr$. That is, the differential of the $\det$ operator, evaluated at the identity matrix, is equal to the trace. That is, given any matrix $T$ in the vector space of matrices, 
\begin{proof}
\begin{align*}
    \det^\prime (I) (T) = \nabla_T \det(I) \\
    & = \lim_{\varepsilon \rightarrow 0} \frac{\det{(I + \varepsilon T)} - \det{I}}{\varepsilon} \\
    & = \lim_{\varepsilon \rightarrow 0} \frac{\det{(I + \varepsilon T)} - 1}{\varepsilon}
\end{align*}
Clearly, $\det(I + \varepsilon(T)) \in \mathbb{R}[\varepsilon]$, where the constant term of the polynomial approaches $1$ and the linear term (coefficient of $\varepsilon$) is $\Tr{T}$. So, 
\[\nabla_T \det{I} = \lim_{\varepsilon \rightarrow 0} ... + \Tr{T} = \Tr{T}\]
\end{proof}
\end{lemma}
This means that the instantaneous rate at which $\det$ changes at $I$ when traveling in direction $T$ is directly proportional to $\Tr{T}$. Now, we provide an alternative proof of the theorem. 
\begin{proof}
Let $R: \mathbb{R} \longrightarrow \SL(n, \mathbb{R})$ such that $R(0) = I$. Then, by definition, $\im{R} \subset \SL(n, \mathbb{R}) \implies \det{(R(t))} = 1$ for all $t \in (-\varepsilon, \varepsilon)$. Compute the derivative of the mapping $\det \circ R$. 
\begin{align*}
    (\det \circ  R) (t) = 1 & \implies \det^\prime \big( R(t) \big) \cdot R^\prime (t) \\ 
    & \implies \det^\prime (I) = \det^\prime \big(R(t)\big) = 0 
\end{align*}
We now use the previous lemma get that 
\[\det^\prime \big( R^\prime(0)\big) = \det^\prime (I)=0 \implies \Tr{R^\prime(0)} = 0\]
\end{proof} 

\begin{theorem}
The matrix representation of $\mathfrak{so}(n)$ is precisely the set of antisymmetric matrices. 
\end{theorem}
\begin{proof}
Let $R: \mathbb{R} \longrightarrow SO(n)$ be a arbitrary smooth curve in $\SL(n)$ such that $R(0) = I$. Then, for all $t \in (-\epsilon, \epsilon)$, 
\[R(t) R(t)^T = I\]
Taking the derivative at $t = 0$, we get
\[R^\prime (0) R(0)^T + R(0) R^\prime(0)^T = 0 \implies R^\prime (0) + R^\prime(0)^T = 0\]
which states that the tangent vector $X = R^\prime (0)$ is skew symmetric. Since the diagonal elements of a skew symmetric matrix are $0$, the trace is $0$ and the condition that $\det{R} = 1$ yields nothing new. This shows that $\mathfrak{o}(n) = \mathfrak{so}(n)$. 
\end{proof}




We have only worked with linear Lie groups so far. The reason that linear Lie groups are so nice to work with is because they have well defined matrix representations. This allows us to have concrete structures on these groups and their Lie algebras. 
\begin{enumerate}
    \item A linear Lie group is concretely defined as a submanifold of $\mathbb{R}^N$, while a general one is an abstract manifold. 
    \item The Lie bracket with regards to a linear Lie group is defined to be the commutator 
    \[[A,B] \equiv A B - B A\]
    but for elements that are not matrices this doesn't make sense. 
    \item The exponential map from the algebra to the group is defined
    \[e^A \equiv \sum_{k=0}^\infty \frac{1}{k!} A^k\]
    but if $A$ is not a matrix, then exp cannot be defined this way.
\end{enumerate}
We seek to generalize these concepts to abstract Lie groups, but we will do this in the next section. 

\subsubsection{Lie Algebras of SO(3) and SU(2), Revisited}
\begin{example}
The Lie algebra $\mathfrak{so}(3)$ is the real vector space of $3 \times 3$ skew symmetric matrices of form 
\[\begin{pmatrix}
0 & -d & c \\ d & 0 & -b \\ -c & b & 0
\end{pmatrix}\]
where $b, c, d \in \mathbb{R}$. The Lie bracket $[A,B]$ of $\mathfrak{so}(3)$ is also just the usual commutator. 

We can define an isomorphism of Lie algebras $\psi: (\mathbb{R}^3, \times) \longrightarrow \mathfrak{so}(3)$ (where $\times$ is the cross product) by the formula 
\[\psi(b, c, d) \equiv \begin{pmatrix}
0 & -d & c \\
d & 0 & -b \\
-c & b & 0
\end{pmatrix}\]
where, by definition, 
\[\psi(u \times v) = [\psi(u), \psi(v)]\]
It is also easily verified that for all $u, v \in \mathbb{R}^3$, 
\[\psi(u) (v) = u \times v\]
\end{example}

\begin{example}
Similarly, we can see that $\mathfrak{su}(2)$ is the real vector space consisting of all complex $2 \times 2$ skew Hermitian matrices of null trace, which is of form
\[i(d \sigma_1 + c \sigma_2 + b \sigma_3) = \begin{pmatrix}
i b & c + i d\\
-c + i d & - i b
\end{pmatrix}\]
where $\sigma_1, \sigma_2, \sigma_3$ are the Pauli spin matrices. We can also define an isomorphism of Lie algebras $\varphi: (\mathbb{R}^3, \times) \longrightarrow \mathfrak{su}(2)$ by the formula
\[\varphi(b, c, d) = \frac{i}{2} (d \sigma_1 + c \sigma_2 + b \sigma_3) = \frac{1}{2} \begin{pmatrix}
i b & c + i d\\
-c + i d & - i b
\end{pmatrix}\]
where, by definition of ismorphism, we have
\[\varphi(u \times v) = [\varphi(u), \varphi(v)]\]
\end{example}

We now restate the connection between the groups SO$(3)$ and SU$(2)$. Note that letting $\theta = \sqrt{b^2 + c^2 + d^2}$, we can write 
\[A = \frac{1}{\theta} (d \sigma_1 + c \sigma_2 + b \sigma_3) = \frac{1}{\theta} \begin{pmatrix}
i b & c + i d\\
-c + i d & - i b
\end{pmatrix}\]
such that $A^2 = I$. With this, we can rewrite the exponential map as 
\[exp: \mathfrak{su}(2) \longrightarrow SU(2), \; exp(i \theta A) = \cos{\theta} I  + i \sin{\theta} A\]
As for the isomorphism $\varphi: (\mathbb{R}^3, \times) \longrightarrow \mathfrak{su}(2)$, we have
\[\varphi(b, c, d) \equiv \frac{1}{2} \begin{pmatrix}
i b & c + i d\\
-c + i d & - i b
\end{pmatrix} = i \frac{\theta}{2} A\]
Similarly, we can view the exponential map $exp: (\mathbb{R}^3, \times) \longrightarrow SU(2)$ as 
\[exp(\theta v) = \]


\begin{example}
The lie algebra $\mathfrak{se}(n)$ is the set of all matrices of form 
\[\begin{pmatrix}
B & U \\ 0 & 0
\end{pmatrix}\]
where $B \in \mathfrak{so}(n)$ and $U \in \mathbb{R}^n$. The Lie bracket is given by
\[\begin{pmatrix}
B & U \\ 0 & 0
\end{pmatrix} \begin{pmatrix}
C & V \\ 0 & 0
\end{pmatrix} - \begin{pmatrix}
C & V \\ 0 & 0
\end{pmatrix} \begin{pmatrix}
B & U \\ 0 & 0
\end{pmatrix} = \begin{pmatrix}
BC - CB & BV - CU \\ 0 & 0
\end{pmatrix}\]
\end{example}


\subsection{Abstract Lie Groups}

\begin{definition}
A (real) \textit{Lie group} $\mathcal{G}$ is a group $\mathcal{G}$ that is also a real, finite-dimensional smooth manifold where  group multiplication and inversion are smooth maps. 
\end{definition}


\begin{definition}
A (real) Lie algebra $\mathfrak{g}$ is a real vector space with a map 
\[[\cdot, \cdot]: \mathfrak{g} \times \mathfrak{g} \longrightarrow \mathfrak{g}\]
called the Lie bracket satisfying bilinearity, antisymmetricity, and the Jacobi Identity. 
\end{definition}

To every Lie group $\mathcal{G}$ we can associate a Lie algebra $\mathfrak{g}$ whose underlying vector space is the tangent space of $\mathcal{G}$ at the identity element. Additionally, the exponential map allows us to map elements from the Lie algebra to the Lie group. These concrete definitions in the context of linear Lie groups is easy to work with, but has some minor problems: to use it we first need to represent a Lie group as a group of matrices, but not all Lie groups can be represented in this way. 

To do this, we must introduce further definitions. 

\begin{definition}
Let $M_1$ ($m_1$-dimensional) and $M_2$ ($m_2$ dimensional) be manifolds in $\mathbb{R}^N$. For any smooth function $f: M_1 \longrightarrow M_2$ and any $p \in M_1$, the function 
\[f^\prime_p: T_p M_1 \longrightarrow T_{f(p)} M_2\]
called the \textit{tangent map, derivative, or differential} of $f$ at $p$, is defined as follows. For every $v \in T_p M_1$ and every smooth curve $\gamma: I \longrightarrow M_1$ such that $\gamma(0) = p$ and $\gamma^\prime (0) = v$ , 
\[f^\prime_p(v) \equiv (f \circ \gamma)^\prime (0)\]
The map $f^\prime_p$ is also denoted $d f_p$ and is a linear map. 
\end{definition}

\begin{definition}
Given two Lie groups $\mathcal{G}_1$ and $\mathcal{G}_2$, a \textit{homomorphism of Lie groups} is a function 
\[f: \mathcal{G}_1 \longrightarrow \mathcal{G}_2\]
that is both a group homomorphism and a smooth map (between manifolds $\mathcal{G}_1$ and $\mathcal{G}_2$). An \textit{isomorphism of Lie groups} is a bijective function $f$ such that both $f$ and $f^{-1}$ are homomorphisms of Lie groups. 
\end{definition}

\begin{definition}
Given two Lie algebras $\mathfrak{g}_1$ and $\mathfrak{g}_2$, a \textit{homomorphism of Lie algebras} is a function 
\[f: \mathfrak{g}_1 \longrightarrow \mathfrak{g}_2\]
that is a linear homomorphism that preserves Lie brackets; that is, 
\[f([A,B]) = [f(A), f(B)]\]
for all $A, B \in \mathfrak{g}$. An \textit{isomorphism of Lie algebras} is a bijective function $f$such that both $f$ and $f^{-1}$ are homomorphisms of Lie algebras. 
\end{definition}

\begin{proposition}
If $f: \mathcal{G}_1 \longrightarrow \mathcal{G}_2$ is a homomorphism of Lie groups, then 
\[f_I^\prime: \mathfrak{g}_1 \longrightarrow \mathfrak{g}_2\]
is a homomorphism of Lie algebras. 
\end{proposition}

We have explained how to construct the Lie bracket (as the commutator) of the Lie algebra of a linear Lie group, but we have not defined how to construct the Lie bracket for general Lie groups. There are several ways to do this, and we describe one such way through \textit{adjoint representations}. 

\begin{definition}
Given a Lie group $\mathcal{G}$, we define a \textit{left translation} as the map
\[L_a: \mathcal{G} \longrightarrow \mathcal{G}, \; L_a (b) \equiv a b\]
for all $b \in \mathcal{G}$. Similarly, the \textit{right translation} is defined
\[R_a: \mathcal{G} \longrightarrow \mathcal{G}, \; R_a (b) \equiv b a\]
for all $b \in \mathcal{G}$. 
\end{definition}

Both $L_a$ and $R_a$ are diffeomorphisms. Additionally, given the automorphism
\[R_{a^{-1}} L_a \equiv R_{a^{-1}} \circ L_a, \; R_{a^{-1}} L_a (b) \equiv a b a^{-1}\]
the derivative
\[(R_{a^{-1}} L_a)^\prime_I: \mathfrak{g} \longrightarrow \mathfrak{g}\]
is an ismorphism of Lie algebras, also denoted 
\[\text{Ad}_a: \mathfrak{g} \longrightarrow \mathfrak{g}\]
\begin{definition}
This induces another map $a \mapsto$ Ad$_a$, which is a map of Lie groups
\[Ad: \mathcal{G} \longrightarrow \GL(\mathcal{\mathfrak{g}})\]
which is called the \textit{adjoint representation of $\mathcal{G}$}. In the case of a linear map, we can verify that 
\[\text{Ad}(a) (X) \equiv \text{Ad}_a (X) \equiv a X a^{-1}\]
for all $a \in \mathcal{G}$ and for all $X \in \mathfrak{g}$. 
\end{definition}

\begin{definition}
Furthermore, the derivative of this map at the identity 
\[\text{Ad}_I^\prime: \mathfrak{g} \longrightarrow \mathfrak{gl}(\mathfrak{g})\]
is a map between Lie algebras, denoted simply as 
\[\text{ad}: \mathfrak{g} \longrightarrow \mathfrak{gl}(\mathfrak{g})\]
called the \textit{adjoint representation} of $\mathfrak{g}$. It is easily visualized with the following commutative diagram. 
\[\begin{tikzcd}
\mathcal{G} \arrow{r}{Ad} & \GL(\mathfrak{g}) \\
\mathfrak{g} \arrow{u}{exp} \arrow{r}{ad} & \mathfrak{gl}(\mathfrak{g}) \arrow{u}{exp}
\end{tikzcd}\]
We define the map ad to be 
\[ad(A)(B) \equiv [A,B]\]
where $[A,B]$ is the Lie bracket (of $\mathfrak{g}$) of $A, B \in \mathfrak{g}$. We can actually conclude something stronger about this mapping. Since the Lie bracket of $\mathfrak{g}$ satisfies the properties of the bracket, the Jacobi identity of $[\cdot, \cdot]$ implies that ad is a Lie algebra homomorphism. 
\begin{align*}
    & [x, [y,z]] + [y,[z,x]] + [z, [x,y]] = 0 \\
    \implies & [x, ad(y)(z)] + [y, ad(z)(x)] + [z, ad(x)(y)] = 0 \\
    \implies & ad(x)\big(ad(y)(z)\big) + ad(y) \big( ad(z)(x)\big) + ad(z) \big(ad(x)(y)\big) = 0 \\
    \implies & ad(x) ad(y) (z) - ad(y) ad(x) z - ad \big(ad(x)(y)\big) (z) = 0 \\
    \implies & \big( ad(x) ad(y) - ad(y) ad(x) \big) (z) = ad\big( ad(x)(y) \big) (z) \\
    \implies & [ad(x), ad(y)] (z) = ad ([x,y]) (z) \\
    \implies & [ad(x), ad(y)] = ad([x,y])
\end{align*}
Therefore, ad preserves brackets and thus ad is a Lie algebra homomorphism. That is, 
\[\text{ad}([A,B]) = [\text{ad}(A), \text{ad}(B)]\]
Note that the bracket on the left side represents the bracket of $\mathfrak{g}$, while the bracket on the right represents the Lie bracket from the Lie algebra $\mathfrak{gl}(\mathfrak{g})$. The fact that ad is a Lie algebra homomorphism indicates that it is a representation of $\mathfrak{g}$, which is why it's called the adjoint representation. 
\end{definition}

\begin{definition}
This construction finally allows us to define the Lie bracket in the case of a general Lie group. The Lie bracket on $\mathfrak{g}$ is defined as 
\[[A,B] \equiv \text{ad} (A) (B)\]
\end{definition}

We would also need to introduce a general exponential map for non-linear Lie groups, but we will not do it here. 


\chapter{Real Analysis}

\section{The Real Numbers}
The entirety of calculus is founded on the definition of the real numbers $\mathbb{R}$. Therefore, we must properly construct and define it. Before we do, we define order. 

\subsubsection{Order}
\begin{definition}[Partial, Total/Linear Order]
A \textit{partial order} on a set $X$ is a relation $\leq$ such that for any elements $x, y \in X$, 
\begin{enumerate}
    \item Reflexive: $x \leq x$ 
    \item Antisymmetric: $x \leq y, y \leq x \implies x = y$
    \item Transitivity: $x \leq y, y \leq z \implies x \leq z$
\end{enumerate}
Note that when we say $x \leq y$, this means "$x$ is related to $y$" (but does not necessarily mean that $y$ is related to $x$), or "$x$ is less than or equal to $y$." A set $X$ with a partial order is called a partially ordered set. 

Additionally, given elements $x, y$ of partially order set $X$, if either $x \leq y$ or $y \leq x$, then $x$ and $y$ are \textit{comparable}. Otherwise, they are \textit{incomparable}. A partial order in which every pair of elements is comparable is called a \textit{total order}, or \textit{linear order}. Note that from this $\leq$ relation, we can similarly define 
\begin{enumerate}
    \item $\leq$: less than or equal to 
    \item $\geq$: greater than or equal to 
    \item $<$: strictly less than ($x < y$ iff $x\leq y, x \neq y$)
    \item $>$: strictly greater than ($x > y$ iff $x \geq y, x \neq y$)
\end{enumerate}
\end{definition}

\begin{example}[Partially Ordered Sets]
We list some examples of partially ordered sets. 
\begin{enumerate}
    \item The real numbers ordered by the standard "less-than-or-equal" relation $\leq$ (totally ordered set as well). 
    \item The set of subsets of a given set $X$ ordered by inclusion. That is, the power set $2^X$ with the partial order $\subseteq$ is partially ordered. 
    \item The set of natural numbers equipped with the relation of divisibility. 
    \begin{center}
        \includegraphics[scale=0.5]{Natural_Numbers_Ordered_by_Divisibility.png}
    \end{center}
    \item The set of subspaces of a vector space ordered by inclusion. 
    \item For a partially ordered set $P$, the sequence space containing all sequences of elements from $P$, where sequence $a$ precedes sequence $b$ if every item in $a$ precedes the corresponding item in $b$. 
\end{enumerate}
\end{example}

\begin{definition}[Extrema]
We list 2 types of extrema of partially ordered sets. 
\begin{enumerate}
    \item \textit{Greatest/Least Element}: An element $g \in P$ is a greatest element if 
    \[\text{for all } a \in P, a \leq g\]
    and a least element if
    \[\text{for all } a \in P, g \leq a\]
    This means that the relation must exist between $g$ and every other element in $P$. This also implies that a partially ordered set can only have one greatest and least element. 
    \item \textit{Maximal/Minimal Elements}: An element $g \in P$ is a maximal element if 
    \[\text{there exists no } a \in P \text{ such that } a > g\]
    and a least element if 
    \[\text{there exists no } a \in P \text{ such that } a < g\]
\end{enumerate}
The difference between these two can be seen in the following visual. In here, $A \rightarrow B$ means that $A \leq B$. 
\[
  \begin{tikzcd}
    & \{x, y, z\} & \\
    \{x, y\} \arrow{ru}{}& \{x, z\} \arrow{u}{}& \{y, z\} \arrow{lu}{}\\
    \{x\} \arrow{ru}{} \arrow{u}{}& \{y\} \arrow{lu}{} \arrow{ru}{}& \{z\} \arrow{lu}{} \arrow{u}{}\\
    & \emptyset \arrow{lu}{} \arrow{u}{} \arrow{ru}{}& 
  \end{tikzcd}
\]
In here, the greatest and maximal element of $2^{\{x, y, z\}}$ is $\{x, y, z\}$ and the least and minimal element is $\emptyset$. However, in the following set 
\[
  \begin{tikzcd}
    \{x, y\} & \{x, z\} & \{y, z\} \\
    \{x\} \arrow{ru}{} \arrow{u}{}& \{y\} \arrow{lu}{} \arrow{ru}{}& \{z\} \arrow{lu}{} \arrow{u}{}
  \end{tikzcd}\]
there exists no greatest nor least element. Furthermore, the maximal elements are $\{x, y\}, \{x, z\}, \{y, z\}$ while the minimal elements are $\{x\}, \{y\}, \{z\}$. 
\end{definition}

\begin{definition}[Upper, Lower Bounds]
We list two definitions for bounds. 
\begin{enumerate}
    \item \textit{Upper/Lower Bounds}: For a subset $A \subset P$, an element $x \in P$ is an upper bound of $A$ if 
    \[a \leq x \text{ for all } a \in A\]
    and is a lower bound of $A$ if
    \[a \geq x \text{ for all } a \in A\]
    \item \textit{Supremum/Infimum}: For a subset $A \subset P$, an element $x \in P$ is a least upper bound, or supremum, if it is the smallest possible upper bound, and is a greatest lower bound, or infimum, if it is the greatest possible lower bound. 
    \begin{align*}
        \sup(X) &\equiv \min{\{c\in Z\;|\; \forall x \in X, x \leq c\}} \\
        \inf(X) &\equiv \max{\{c\in Z\;|\; \forall x \in X, x \geq c\}}
    \end{align*}
\end{enumerate}
The main difference between the supremum/infimum and greatest/least element is that the supremum/infimum accounts for limit points of the subset $A$. 
\end{definition}

\subsection{Completeness}
Intuitively, completeness implies that there are not any "gaps" or "missing points" in the real number line. This contrasts with the rational numbers, whose corresponding number line has a "gap" at each irrational value (this is formalized with Dedekind cuts). In the decimal number system, completeness is equivalent to the statement that any infinite string of decimal digits is actually a decimal representation of some number. 

\subsubsection{Least Upper Bound Property}
\begin{definition}[Least Upper Bound Completeness]
A totally ordered algebraic field $F$ is complete if every nonempty set of $F$ having an upper bound must have a least upper bound (supremum) in $F$. 
\end{definition}

\begin{lemma}[Least Upper Bound Completeness of $\mathbb{R}$]
$\mathbb{R}$ is least upper bound complete. 
\end{lemma}

On the contrary, the rational number line $\mathbb{Q}$ does not have the least upper bound property. Take the subset of rational numbers
\[S = \{x \in \mathbb{Q} \;|\; x^2 <2 \}\]
The least upper bound is $\sqrt{2}$, but this does not exist in $\mathbb{Q}$. We can try constructing smaller and smaller upper bounds of $S$ in $\mathbb{Q}$, but by denseness of the rationals in $\mathbb{R}$, there is no end to this; we can always construct a smaller upper bound, infinitely. 
\begin{center}
    \includegraphics[scale=0.3]{Least_Upper_Bound_Property.PNG}
\end{center}
In the example above, we first construct rational upper bound $1.42$, then $1.415$, then $1.4143$, and so on infinitely. 

\subsubsection{Dedekind Completeness}
\begin{definition}[Dedekind Cut]
A \textit{Dedekind cut} is a partition of the rational numbers into two sets $A$ and $B$, such that all elements of $A$ are less than all elements of $B$, and $A$ contains no greatest element. The set $B$ may or may not have a smallest element among the rationals. 
\begin{enumerate}
    \item If $B$ has a smallest among the rationals, the cut corresponds to that rational, or in other words, the cut is generated by the rational number. 
    \begin{center}
        \includegraphics[scale=0.3]{Dedekind_Cut_Rational.PNG}
    \end{center}
    In the visual above, this Dedekind cut of $\mathbb{Q}$ is generated by $4/3$. 
    \item Otherwise, that cut defines a unique irrational number which, loosely speaking, fills the "gap" between $A$ and $B$. An irrational cut is equated to an irrational number which is in neither set. 
    \begin{center}
        \includegraphics[scale=0.3]{Dedekind_Cut_Irrational.PNG}
    \end{center}
    In the visual above, this Dedekind cut of $\mathbb{Q}$ is generated by $\sqrt{2}$, which is not in $\mathbb{Q}$. 
\end{enumerate}
Note that Dedekind cuts can be generalized from the rational numbers to any totally ordered set by defining the partition $A$ and $B$, where every element in $A$ is less than every element in $B$, and $A$ contains no greatest element. 
\end{definition}

\begin{definition}[Dedekind Completeness]
A totally ordered algebraic field $F$ is complete if every Dedekind cut of $F$ is generated by an element of $F$. 
\end{definition}

\begin{lemma}[Dedekind Completeness of $\mathbb{R}$]
$\mathbb{R}$ is Dedekind complete. 
\end{lemma}

\subsubsection{Cauchy Completeness}
Cauchy completeness actually allows us to generalize completeness for any metric space, which may not need to be ordered. The reader may skip ahead to learn about Cauchy sequences before visiting this definition. 

\begin{definition}[Cauchy Completeness]
A metric space $(X, d)$ is complete if every Cauchy sequence in that space converges to an element in $X$. 
\end{definition}

\begin{lemma}[Cauchy Completeness of $\mathbb{R}$]
$\mathbb{R}$ is Cauchy complete. 
\end{lemma}

We can see that $\mathbb{Q}$ is not Cauchy complete since the following rational sequence of successive approximations of $\pi$
\[3, \;\;\;3.1, \;\;\;3.14, \;\;\;3.142, \;\;\;3.1416, \ldots\]
does not converge to any rational number since $\pi \not\in \mathbb{Q}$. 

\subsubsection{Nested Intervals Theorem}

\begin{definition}[Nested Interval Completeness]
Let $F$ be a totally ordered algebraic field. Let $I_n= [a_n, b_n]$ ($a_n < b_n$) be a sequence of closed intervals, and suppose that these intervals are nested in the sense that
\[I_1 \supset I_2 \supset I_3 \supset \ldots\]
where 
\[\lim_{n \rightarrow + \infty} b_n - a_n = 0\]
$F$ is complete if the intersection of all of these intervals $I_n$ contains exactly one point. That is, 
\[\bigcup_{n=1}^\infty I_n \in F\]
\end{definition}

\begin{lemma}[Nested Interval Completeness of $\mathbb{R}$]
$\mathbb{R}$ is Nested Interval complete. 
\end{lemma}

We can also see that $\mathbb{Q}$ is not nested interval complete since the sequence, derived from the digits of $\pi$, 
\[[3,4] \supset [3.1, 3.2] \supset [3.14, 3.15] \supset [3.141, 3.142] \supset \ldots\]
is a nested sequence of closed intervals in the rational numbers whose intersection is empty in $\mathbb{Q}$. 

\subsection{Construction of the Real Numbers}

\begin{definition}[The Real Numbers]
The \textit{set of real numbers}, denoted $\mathbb{R}$, is a totally ordered algebraic field equipped with operations $+$ and $\cdot$, along with relation $\leq$. Finally, it must satisfy the completeness axiom. Note that
\begin{enumerate}
    \item Without the axiom of completeness, the set of rational numbers $\mathbb{Q}$ would satisfy the axioms. 
    \item The fact that the reals are ordered eliminates the complex numbers $\mathbb{C}$, quaternions $\mathbb{H}$, and higher-dimensional numbers as candidates.  
    \item These axioms \textit{uniquely} defines the real numbers up to isomorphism. That is, if two individuals construct sets  $\mathbb{R}_A$ and $\mathbb{R}_B$ that satisfy these properties, then 
    \[\mathbb{R}_A \simeq \mathbb{R}_B\]
    For example, let us construct three distinct sets satisfying these axioms: 
    \begin{enumerate}
        \item A line $\mathbb{L}$ with $+$ associated with the translation of $\mathbb{L}$ along itself and $\cdot$ associated with the "stretching/compressing" of the line around the additive origin $0$. 
        \begin{center}
            \includegraphics[scale=0.25]{Real_Number_Line_Ordered.PNG}
        \end{center}
        \item An uncountable list of numbers with possibly infinite decimal points, known as the decimal number system. 
        \[\ldots, -2.583\ldots, \ldots , 0, \ldots, 1.2343\ldots, \ldots, \sqrt{2}, \ldots\]
        \item A circle with a point removed, with addition and multiplication defined similarly as the line. 
        \begin{center}
            \includegraphics[scale=0.3]{Real_Number_Circle_Ordered.PNG}
        \end{center}
    \end{enumerate}
    By the axioms of geometry there exists an isomorphism 
    \[f: \mathbb{L} \longrightarrow \mathbb{R}\]
    between the arbitrary line $\mathbb{L}$ and $\mathbb{R}$. 
    \begin{center}
        \includegraphics[scale=0.3]{LIne_to_Circle_Isomorphism.PNG}
    \end{center}
    \item Additional structures can be put on $\mathbb{R}$, such as a topology, metric, and norm. 
    \begin{enumerate}
        \item The basis of the topology of $\mathbb{R}$ consists of open intervals
        \[(a, b) = \{x \in \mathbb{R} \;|\; a < x < b\}\]
        The \textit{$\delta-$neighborhood} of a point $x$ is the open interval $(x - \delta, x + \delta)$. 
        \item The metric $d: \mathbb{R} \times \mathbb{R} \longrightarrow \mathbb{R}^+_0$ will be defined
        \[d(a, b) = |b-a|\]
        \item The norm $\rho: \mathbb{R} \longrightarrow \mathbb{R}^+_0$ is defined 
        \[\rho(x) = |x|\]
    \end{enumerate}
    Note that a norm induces a metric which induces a topology, so we can define the open interval topology of $\mathbb{R}$ by simply defining $\rho$. 
\end{enumerate}
\end{definition}

\subsection{Compactness}

We now proceed to describe a fundamental topological property of sets that comes up a lot in analysis. 

\begin{definition}
A \textit{cover} of a set $X$ is a family of sets $X_1, X_2, ..., X_n$ such that 
\[ X = \bigcup_{i =1}^n U_i\]
That is, every point in $X$ must be in at least one of the $X_i$'s. 
\end{definition}

\begin{definition}
A subset $X$ of $Z$ is said to be \textit{compact} if each of its open covers has a finite subcover. That is, for every collection $C$ of open subsets of $X$ such that 
\[ X = \bigcup_{x \in C} x\]
there exists a finite subset $F \subset C$ such that
\[X = \bigcup_{x \in F} x\]
\end{definition}

The general notion of compactness for topological spaces is not needed for analysis. Rather, we make use of the following theorem which allows us to focus on the compactness of subsets in Euclidean spaces $\mathbb{R}^n$. 

\begin{theorem}[Heine-Borel Theorem] 
A subset $S$ of Euclidean space $\mathbb{R}^n$ is compact if and only if it is closed and bounded. 
\end{theorem}

\begin{example}
An open set in $\mathbb{R}^2$ is not compact. Take the open rectangle $ R = (0,1)^2 \subset \mathbb{R}^2$. There exists an infinite cover of $R$
\[R = \bigcup_{n=0}^\infty \big(0,1\big) \times \bigg( 0, \frac{ 2^{n+1} - 1}{2^{n+1}} \bigg) \]
that does not have a finite subcover. 
\end{example}

We can view the topological concept of compactness as a generalization of the notion of a Euclidean subset being closed (i.e. containing all its limit points) and bounded (i.e. having all its point lie within a some fixed distance from each other). 

According to Terry Tao, a compact set is "small," in the sense that it is easy to deal with. While this may sound counterintuitive at first, since $[0,1]$ is considered compact while $(0,1)$, a subset of $[0,1]$, is considered noncompact. More generally, a set that is compact may be large in area and complicated, but the fact that it is compact means we can interact with it in a finite way using open sets, the building blocks of topology. That finite collection of open sets makes it possible to account for all the points in a set in a finite way. This is easily noticed, since functions defined over compact sets have more controlled behavior than those defined over noncompact sets. Similarly, classifying noncompact spaces are more difficult and less satisfying. 

\begin{example}
Any finite space is trivially compact. 
\end{example}

We will describe two more equivalent definitions of the completeness of the real numbers. 

\begin{definition}
A function $f: \mathbb{N} \longrightarrow X$ is called an \textit{infinite sequence}, or a \textit{sequence} of elements of $X$. It is usually denoted $\{a_n\}$, which is shorthand for
\[a_1, a_2, a_3, ...\]
A \textit{subsequence} of $\{ a_n\}$ is a sequence $\{a_{\gamma_k}\}$, where $\{\gamma_k\}$ is a strictly increasing infinite subset of $\mathbb{N}$.
\end{definition}

\begin{definition}
Let $X_1, X_2, X_3, ... $ be a sequence of sets. If $X_1 \supset X_2 \supset X_3 \supset ... $, then the sequence $\{X_n\}$ is \textit{nested}. 
\end{definition}

\begin{theorem}[Cantor's Intersection Theorem]
Let $\{I_n\}$ be a nested sequence of intervals $[a_n, b_n]$ in $X$ such that $b_n - a_n \rightarrow 0$ as $n \rightarrow +\infty$. $X$ is \textit{complete} if there exists exactly one point $c \in X$ such that 
\[c \in \bigcap_{n=1}^\infty I_n \]
\end{theorem}

The set of rational numbers is not complete according to this theorem since the nested sequence leading to the digits of pi
\[[3,4] \supset [3.1,3.2] \supset [3.14,3.15] \supset ... \]
has an empty intersection in $\mathbb{Q}$. 

\begin{definition}
A point $p \in Z$ is a \textit{limit point} of $X \subset Z$ if every open neighborhood of $p$ has a nontrivial intersection with $X$. This is equivalent to saying that every open neighborhood of $p$ contains an infinite number of elements of $X$.  
\end{definition}

Clearly, the limit point of an open set is its boundary points. Note that a sequence of points can also have a limit point. 

\begin{theorem}[Bolzano-Weierstrass Theorem]
Every bounded infinite sequence in $\mathbb{R}^n$ has an accumulation point. That is, there exists a point $p \in \mathbb{R}^n$ such that every open neighborhood $U_p$ contains an infinite subset of the sequence. 
\end{theorem}
\begin{proof}
The fact that the infinite sequence is bounded means that there exists some closed subset $I \in \mathbb{R}^n$ that contains all point of the sequence. By definition $I$ is compact, so by the Heine-Borel theorem, every cover of $I$ has a finite subcover. 

Now, assume that there exists an infinite sequence in $I$ that is not convergent, i.e. has no limit point. Then, each point $x_i \in I$ would have a neighborhood $U(x_i)$ containing at most a finite number of points in the sequence. We can define $I$ such that the union of the neighborhoods is a cover of $I$. That is, 
\[I \subset \bigcup_{i=1}^\infty U(x_i)\]
However, since every $U(x_i)$ contains at most a finite number of points, we must have an infinite open neighborhoods to cover $I \implies$ we cannot have a finite subcover. This contradicts the fact that $I$ is compact. 
\end{proof}


\subsection{Natural Numbers}
\begin{definition}[Inductive Set, Natural Numbers]
A set $X \subset \mathbb{R}$ is inductive if for each number $x \in X$, it also contains $x + 1$. The set of \textit{natural numbers}j, denoted $\mathbb{N}$, is the smallest inductive set containing $1$. 
\end{definition}

We can use this inductive property of natural numbers to prove properties of them. 

\begin{lemma}[Induction Principle]
Given $P(n)$, a property depending on positive integer $n$, 
\begin{enumerate}
    \item if $P(n_0)$ is true for some positive integer $n_0$, and
    \item if for every $k \geq n_0$, $P(k)$ true implies $P(k+1)$ true, 
\end{enumerate}
then $P(n)$ is true for all $n \geq n_0$. 
\end{lemma}

\begin{lemma}[Strong Induction Principle]
Given $P(n)$, a property depending on a positive integer $n$, 
\begin{enumerate}
    \item if $P(n_0), P(n_0 + 1), \ldots, P(n_0 + m)$ are true for some positive integer $n_0$, and nonnegative integer $m$, and 
    \item if for every $k > n_0 + m, P(j)$ is true for all $n_0 \leq j \leq k$ implies $P(k)$ is true, 
\end{enumerate}
then $P(n)$ is true for all $n \geq n_0$. 
\end{lemma}

The idea behind the strong induction principle leads to the proof using infinite descent. Infinite descent combines strong induction with the fact that every subset of the positive integers has a smallest element, i.e. there is no strictly decreasing infinite sequence of positive integers. 

\begin{lemma}[Infinite Descent]
Given $P(n)$, a property depending on positive integer, assume that $P(n)$ is false for a set of integers $\mathcal{S}$. Let the smallest element of $\mathcal{S}$ be $n_0$. If $P(n_0)$ false implies $P(k)$ false, where $k < n_0$, then by contradiction $P(n)$ is true for all $n$. 
\end{lemma}

\subsubsection{Countable, Uncountable Sets}
\begin{definition}
A set $X$ is \textit{countable} if it is bijective to $\mathbb{N}$. The cardinality of a countable set with infinite elements is called \textit{countably infinite}. Clearly, all finite sets are countable. 
\end{definition}

\begin{theorem}[Induced Countable Sets]
Given a countable sets $X, Y$. 
\begin{enumerate}
    \item A subset $\hat{X} \subset X$ is countable. 
    \item The union $X \cup Y$ is countable. 
    \item The direct product $X \times Y$ is countable. 
\end{enumerate}
Recursively, we can see that any finite union and direct products of countable sets are countable. 
\end{theorem}

\begin{corollary}
$\mathbb{Z}, \mathbb{Q}$ are countably infinite.
\end{corollary}
\begin{proof}
It is easy to see that $\mathbb{Z} = \mathbb{N} \cup \{0\} \cup \mathbb{N}$ and $\mathbb{Q} = \mathbb{Z} \times \mathbb{N}$. 
\end{proof}

\begin{theorem}[Uncountability of $\mathbb{R}$]
The reals are uncountably infinite. 
\[card\,\mathbb{R} > card \, \mathbb{N}\]
Therefore, irrational numbers exist. 
\end{theorem}
\begin{proof}
Since $(0, 1) \subset \mathbb{R}$, it suffices to prove for $(0, 1)$ uncountable. Assume that $(0, 1)$ is countable. Then, fix a bijection 
\[f: \mathbb{N} \longrightarrow (0, 1)\]
Then, for each natural number $n$ we have some decimal sequence that $n$ maps to
\begin{align*}
    0 & \mapsto a_{0,0} a_{0,1} a_{0,2} a_{0,3} a_{0,4} \ldots \\
    1 & \mapsto a_{1,0} a_{1,1} a_{1,2} a_{1,3} a_{1,4} \ldots \\
    2 & \mapsto a_{2,0} a_{2,1} a_{2,2} a_{2,3} a_{2,4} \ldots \\
    3 & \mapsto a_{3,0} a_{3,1} a_{3,2} a_{3,3} a_{3,4} \ldots \\
    4 & \mapsto a_{4,0} a_{4,1} a_{4,2} a_{4,3} a_{4,4} \ldots \\
    \vdots & \mapsto \vdots
\end{align*}
We will show that this is not a surjection by constructing a number 
\[b = 0. b_1 b_2 b_3 b_4 \ldots\]
that is not in the image of $f$. We must also realize that decimal numbers do not uniquely represent real numbers since, for example, 
\[0.49999\ldots = 0.50000\ldots\]
For each $b_i$ ($i = 0, 1, 2, \ldots$), we let $b_i$ be any number such that
\[b_i \neq a_{i,i}\]
and that $b_i \neq 9$ (this is to ensure that every $b_i$ past a certain point equals $9$). This ensures that 
\begin{enumerate}
    \item $b \neq f(0)$ since $b_0 \neq a_{0,0}$
    \item $b \neq f(1)$ since $b_1 \neq a_{1,1}$
    \item $b \neq f(2)$ since $b_2 \neq a_{2,2}$
    \item $\ldots$
\end{enumerate}
and therefore $b \not\in\;$ Im$f$. 
\end{proof}

\section{Limits of Sequences}
\subsection{Sequences, Basic Properties}
\begin{definition}[Sequence]
A function $f: \mathbb{N} \longrightarrow X$ is a \textit{sequence}, denoted $\{a_n\} = a_1, a_2, a_3, ...$. Even though we can just let $X$ be ordered, we simplify and assume that $X = \mathbb{R}$ from now on. Let $A$ be some real number. 
\begin{enumerate}
    \item $\{x_n\}$ is a \textit{constant sequence} if $a_i = A$ for all $i$
    \item $\{x_n\}$ is an \textit{ultimately constant sequence} if $a_i = A$ for all $i > N$ for some $N \in \mathbb{N}$. If $A = 0$, then $\{x_n\}$ is \textit{finary}.
    \item $\{x_n\}$ is \textit{bounded} if there exists $M$ such that $|x_n| < M$ for all $n \in \mathbb{N}$
\end{enumerate}
A \textit{subsequence} of $\{ a_n\}$ is a sequence $\{a_{\gamma_k}\}$, where $\{\gamma_k\}$ is a strictly increasing infinite subset of $\mathbb{N}$. 
\end{definition}

We can visualize a sequence $f: \mathbb{N} \longrightarrow X$ as the set of points in $\mathbb{N} \times X$. If, $X = \mathbb{R}$, then the sequence is easy to see in $\mathbb{N} \times \mathbb{R}$ embedded in $\mathbb{R}^2$. 
\begin{center}
    \includegraphics[scale=0.27]{Sequence_Visual.jpg}
\end{center}
Sometimes, it can be useful to visualize the extension of $f: \mathbb{N} \longrightarrow \mathbb{R}$, which we will denote as $F: \mathbb{R} \longrightarrow \mathbb{R}$. 
\begin{center}
    \includegraphics[scale=0.27]{Sequence_Extension_Visual.jpg}
\end{center}
Likewise, subsequences of $f$ and their extensions can be visualized as $F_1$ and $F_2$. 
\begin{center}
    \includegraphics[scale=0.27]{Subsequence_Extension_Visual.PNG}
\end{center}

\begin{definition}[Sequence Space]
The set of all real-valued sequences, denoted $\mathbb{R}^\mathbb{N}$, is an infinite dimensional vector space over $\mathbb{R}$, where addition and scalar multiplication of sequences are defined component-wise. 
\begin{align*}
    &\{x_n\} + \{y_n\} = \{x_n + y_n\}\\
    &\; c \{x_n\} = \{c x_n\}, \; c \in \mathbb{R}
\end{align*}
$X^\mathbb{N}$ is also equivalent to the function space of elements $f: \mathbb{N} \longrightarrow \mathbb{R}$. We can equip this space this additional operations. The product and quotient of sequences is defined component-wise. That is, given two numerical sequences $\{x_n\}$ and $\{y_n\}$ over $\mathbb{R}$, 
\begin{enumerate}
    \item $\{x_n\} \cdot \{y_n\} = \{(x_n \cdot y_n)\}$
    \item $\{x_n\} / \{y_n\} = \Big\{ \Big(\frac{x_n}{y_n}\Big) \Big\}$ which, of course, is defined only when $y_n \neq 0$ for all $n \in \mathbb{N}$. 
\end{enumerate}
\end{definition}

\begin{definition}[Limit of a Sequence]
A number $A \in \mathbb{R}$ is called the \textit{limit of the sequence} $\{x_n\}$, written 
\[ \lim_{n \rightarrow \infty} x_n = A,\]
if for every neighborhood $U_A$ there exists an index $N$ such that 
\[x_n \in U_A \text{ for all } n > N\]
Equivalently, $A$ is the limit of $\{x_n\}$ if for every $\epsilon>0$, there exists an index $N$ such that
\[ |x_n - A| < \epsilon \text{ for all } n > N\]
If $A$ is the limit of $\{x_n\}$, then we say that $\{x_n\}$ \textit{converges} to $A$. If the limit of $\{x_n\}$ is not well defined or finite, then we say that $\{x_n\}$ is \textit{divergent}. 

There are two ways we can visualize the limit of a sequence. The first way is to visualize the sequence on $\mathbb{N} \times X$ and imagine the various open neighborhoods of the limit $A$ getting smaller and smaller, albeit containing an infinite number of elements of $\{x_n\}$. For example, when $X = \mathbb{R}$, we have
\begin{center}
    \includegraphics[scale=0.33]{Limit_Sequence_R1.PNG}
\end{center}
The other way to visualize it is to just imagine the codomain space $X$ and the sequence as a collection of ordered points in $X$. We can then imagine an open neighborhood of limit $A$ getting smaller and smaller, albeit containing an infinite number of elements of $\{x_n\}$. When $X = \mathbb{R}^2$, we have
\begin{center}
    \includegraphics[scale=0.33]{Limit_Sequence_R2.PNG}
\end{center}
\end{definition}

\begin{theorem}[Properties of Limits]
Given that $\{x_n\}, \{y_n\}$ are numerical sequences with $y_n \neq 0$ for all $n$, and let 
\[\lim_{n \rightarrow \infty} x_n = A, \;\;\;\;\;\; \lim_{n \rightarrow \infty} y_n = B \neq 0\]
then, 
\begin{align*}
    & \lim_{n\rightarrow \infty} (x_n + y_n) = A + B \\
    & \lim_{n \rightarrow \infty} (c x_n) = c A \\
    & \lim_{n \rightarrow \infty} (x_n \cdot y_n) = A \cdot B \\
    & \lim_{n \rightarrow \infty} \frac{x_n}{y_n} = \frac{A}{B}
\end{align*}
It immediately follows that the set of all convergent sequences in $\mathbb{R}^\mathbb{N}$ is a subspace of $\mathbb{R}^\mathbb{N}$. 
\end{theorem}
\begin{proof}
Assume that 
\[\lim_{n \rightarrow \infty} x_n = A \text{ and } \lim_{n \rightarrow \infty} y_n = B \neq 0\]
This means that for every $\epsilon > 0$, there exists $N_1, N_2 \in \mathbb{N}$ such that
\begin{align*}
    |x_n - A| &< \epsilon \text{ for all } n > N_1 \\
    |y_n - B| &< \epsilon \text{ for all } n > N_2
\end{align*}
Therefore, for a given $\epsilon$, we wish to prove that there exists a $N$ such that for all $n > N$, 
\begin{align*}
    1. & |(x_n + y_n) - (A+B)| < \epsilon \\
    2. & |c x_n - cA| < \epsilon \\
    3. & |(x_n y_n) - (AB)| < \epsilon \\
    4. & \bigg| \frac{x_n}{y_n} - \frac{A}{B} \bigg| < \epsilon
\end{align*}
\begin{enumerate}
    \item By the triangle inequality, we can see that
    \[|(x_n + y_n) - (A+B)| = |x_n - A| + |y_n - B| \]
    Since we can choose the error between $x_n$ and $A$ for $n > N_1$, and $y_n$ and $B$ for $n>N_2$ as small as we want, we set it to $\epsilon/2$. Then, we have
    \[|(x_n + y_n) - (A+B)| = |x_n - A| + |y_n - B| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\]
    for all $n> N = \max\{N_1, N_2\}$. Therefore, for a given $\epsilon$, there exists an $N$ such that 
    \[|(x_n + y_n) - (A+B)| < \epsilon \text{ for all } n > N\]
    \item This proof is easy. For a given $\epsilon$, we choose the error to be $\frac{\epsilon}{c}$.
    \[|x_n - A| < \frac{\epsilon}{c} \text{ for all } n >N_1\]
    Then, there exists natural number $N_1$ such that
    \[|c x_n - c A| < c |x_n - A| =  c \frac{\epsilon}{c} = \epsilon \text{ for all } n > N_1\]
    \item We first observe that since the limit of $\{y_n\}$ exists, it must be bounded by a value, say $B$. That is, 
    \[|y_n| < Y \text{ for all } n \in \mathbb{N}\]
    Then, we see that
    \begin{align*}
        |x_n y_n - AB| & = |(x_n y_n - Ay_n) + (Ay_n - AB)| \\
        & < |x_n y_n - A y_n| + |A y_n - AB| \\
        & = |y_n| |x_n - A| + |A| |y_n - B|
    \end{align*}
    Suppose $\epsilon > 0$ is given. Then, we can set the error bounds freely; there exists $N_1, N_2 \in \mathbb{N}$ such that 
    \begin{align*}
        |x_n - A| < \frac{\epsilon}{2Y} \text{ for all } n > N_1 \\
        |y_n - B| < \frac{\epsilon}{2|A|} \text{ for all } n > N_2
    \end{align*}
    Then, we can see that 
    \[|x_n y_n - AB| \leq |y_n||x_n -A| + |A| |y_n - B| < Y \cdot \frac{\epsilon}{2Y} + |A| \frac{\epsilon}{2|A|} = \epsilon\]
    for all $n> N = \max\{N_1, N_2\}$.
    \item We use the estimate
    \[\bigg| \frac{A}{B} - \frac{x_n}{y_n} \bigg| = \frac{|x_n| |y_n - B| + |y_n||x_n - A|}{y_n^2} \cdot \frac{1}{1 - \delta(y_n)}, \;\;\; \delta(y_n) = \frac{|y_n - B|}{|y_n|}\]
    For a given $\epsilon > 0$, we find natural numbers $N_1, N_2$ such that 
    \begin{align*}
        |x_n - A| & < \min\Big\{ 1, \frac{\epsilon|B|}{8} \Big\} \text{ for all } n > N_1 \\
        |y_n - B| & < \min \Big\{ \frac{|B|}{4}, \frac{\epsilon B^2}{16(|A| + 1)} \Big\} \text{ for all } n > N_2 
    \end{align*}
    From this we can deduce that 
    \[|x_n| = |x_n - A + A| < |x_n - A| + |A| < |A| + 1\]
    and
    \begin{align*}
        |B| & = |y_n + B - y_n| < |y_n| + |B - y_n| \\
        \implies & |y_n| > |B| - |y_n - B| > |B| - \frac{|B|}{4} > \frac{|B|}{2} \\
        \implies & \frac{1}{|y_n|} < \frac{2}{|B|} \\
        \implies & 0 < \delta(y_n) = \frac{|y_n - B|}{|y_n|} < \frac{|B|/4}{|B|/2} = \frac{1}{2} \\
        \implies & 1 - \delta(y_n) > \frac{1}{2}\\
        \implies & 0 < \frac{1}{1 - \delta(y_n)} < 2
    \end{align*}
    So, we can substitute 
    \begin{align*}
        |x_n| \cdot \frac{1}{y_n^2} \cdot |y_n - B| & < (|A| + 1) \cdot \frac{4}{B^2} \cdot \frac{\epsilon \cdot B^2}{16(|A|+1)} = \frac{\epsilon}{4} \\
        \bigg|\frac{1}{y_n} \bigg| \cdot |x_n - A| & < \frac{2}{|B|} \cdot \frac{\epsilon |B|}{8} = \frac{\epsilon}{4} 
    \end{align*}
    into the final equation to get
    \[\bigg| \frac{A}{B} - \frac{x_n}{y_n}\bigg| < \epsilon \text{ for all } n > N= \max\{N_1, N_2\}\]
\end{enumerate}

\end{proof}

Interestingly, we can interpret the limit as a mapping itself
\[\lim: \mathbb{R}^\mathbb{N}_C \longrightarrow \mathbb{R}\]
The properties of the limit imply that 
\begin{enumerate}
    \item $\lim$ is a linear mapping between vector spaces, an element of Hom$(\mathbb{R}^\mathbb{N}_C, \mathbb{R})$
    \item $\lim$ is a multiplicative group homomorphism from $\mathbb{R}^\mathbb{N}_C$ to $\mathbb{R}$
\end{enumerate}

\begin{theorem}
Given convergent sequences $\{x_n\}$ and $\{y_n\}$, if 
\[ \lim_{n \rightarrow \infty} x_n < \lim_{n \rightarrow \infty} y_n\]
then there exists an index $N \in \mathbb{N}$ such that $x_n < y_n$ for all $n > N$. 
\end{theorem}

\begin{theorem}[Squeeze Theorem for Sequences]
Given sequences $\{x_n\}, \{y_n\}, \{z_n\}$ such that 
\[x_n \leq y_n \leq z_n\]
for all $n > N$, if $\{x_n\}$ and $\{z_n\}$ both converge to the same limit, then the sequence $\{y_n\}$ also converges to that limit. That is, 
\[\lim_{n \rightarrow \infty} x_n = \lim_{n \rightarrow \infty} z_n = A \implies \lim_{n \rightarrow \infty} y_n = A\]
This is quite easy to visualize. For convenience, we use the extension of the sequences $\{x_n\}, \{y_n\}, \{z_n\}$ onto the real numbers. 
\begin{center}
    \includegraphics[scale=0.3]{Sequence_Squeeze_Theorem.PNG}
\end{center}
\end{theorem}

\begin{definition}[Cauchy Sequence]
A sequence $\{x_n\}$ is called a \textit{Cauchy sequence} if for any $\epsilon > 0$ there exists an index $N \in \mathbb{N}$ such that $|x_m - x_n| < \epsilon$ whenever $n > N$ and $m > N$. That is, for any arbitrarily small interval of length $\epsilon$, there will always be an infinite number of elements of $\{x_n\}$ that all exist within that interval. The plot below shows a Cauchy sequence. 
\begin{center}
    \includegraphics[scale=0.18]{Cauchy_Example.png}
\end{center}
but the sequence below is not Cauchy since the elements of the sequence do not get arbitrarily close to each other as the sequence progresses. 
\begin{center}
    \includegraphics[scale=0.8]{Non_Cauchy_Example.png}
\end{center}
\end{definition}

Note that it is not sufficient to say that a sequence is Cauchy by claiming that each term becomes arbitrarily close to the preceding term. That is, 
\[ \lim_{n \rightarrow \infty} |x_{n+1} - x_{n}| = 0\]
For example, look at the sequence 
\[a_n = \sqrt{n} \implies a_{n+1} - a_{n} = \frac{1}{\sqrt{n+1} + \sqrt{n}} < \frac{1}{2\sqrt{n}}\]
However, it is clear that $a_n$ gets arbitrarily large, meaning that a finite interval can contain at most a finite number of terms in $\{a_n\}$. 
\begin{center}
    \includegraphics[scale=0.3]{Square_Root_Sequence.PNG}
\end{center}

Upon closer observation, the definition of a Cauchy sequence is really just the same as a sequence having a limit. 

\begin{theorem}[Cauchy Convergence Criterion]
A real-valued sequence converges if and only if it is a Cauchy sequence. 
\end{theorem} 

\subsubsection{Divergent Sequences}
Note that while a convergent sequence can be visualized quite easily by the Cauchy convergence criterion, there are many way in which a sequence can be divergent. 
\begin{enumerate}
    \item Increasing/decreasing indefinitely
    \item Oscillating between two constant values
    \item Oscillating between a value tending to $+\infty$ and a value tending to $-\infty$
    \item Many other classes of divergence
\end{enumerate}

\begin{definition}[Sequence Tending to Infinity]
The sequence $\{x_n\}$ \textit{tends to positive infinity} if for each number $c$ there exists $N \in \mathbb{N}$ such that $x_n > c$ for all $n > N$. It is denoted 
\[x_n \rightarrow + \infty \text{ or } \lim_{n \rightarrow \infty} x_n = + \infty\]
We define sequences that \textit{tend to negative infinity} similarly. 
\begin{center}
    \includegraphics[scale=0.3]{Positive_Negative_Infinity.PNG}
\end{center}
And $\{x_n\}$ \textit{tends to infinity} if for each $c$ there exists $N \in \mathbb{N}$ such that $|x_n| > c$ for all $n > N$, which is written 
\[x_n \rightarrow \infty\]
\begin{center}
    \includegraphics[scale=0.3]{Tending_to_Infinity.PNG}
\end{center}
\end{definition}

Note that 
\[x_n \rightarrow +\infty \text{ or } x_n \rightarrow -\infty \implies x_n \rightarrow \infty\]
but the converse is not necessarily true. The simple example is the sequence $x_n = (-1)^n n$. Also, it is important to know that a sequence may be unbounded and yet not tend to $+\infty$, $-\infty$, or $\infty$. 

\begin{example}[Unbounded Sequence that Doesn't tend to $\infty$]
The sequence $x_n = n^{(-1)^n}$ is divergent yet does not tend to positive infinity, negative infinity, nor infinity. 
\begin{center}
    \includegraphics[scale=0.3]{Neither_Divergent_Sequence.PNG}
\end{center}
\end{example}

\subsubsection{Monotonic Sequences}

\begin{definition}[Monotonic Sequences]
A sequence $\{x_n\}$ is \textit{increasing} if $x_{n+1} > x_n$ for all $n$. Similarly, it is \textit{nondecreasing} if $x_{n+1} \geq x_n$, \textit{decreasing} if $x_{n+1} < x_n$, and \textit{nonincreasing} if $x_{n+1} \leq x_n$. Sequences of these types are called \textit{monotonic}. 
\end{definition}


\begin{lemma}[Convergence Criterion for Monotonic Sequences]
In order for a nondecreasing (nonincreasing) sequence to be convergent, it is necessary and sufficient that it is bounded above (or below). 
\end{lemma}

\begin{theorem}[Bolzano-Weierstrass Theorem]
Every bounded sequence in $\mathbb{R}^n$ contains a convergent subsequence. 
\end{theorem} 
\begin{proof}
It suffices to prove that there exists a monotonic sequence within a bounded sequence $\{x_n\}$. 
\end{proof}

\begin{corollary}
From each sequence of real numbers there exists either a convergent subsequence or a subsequence tending to infinity. 
\end{corollary}

This allows us to measure the convergence or divergence of subsequences inside a more complicated sequence. We further define additional tools to do this. 

\begin{example}
We claim that 
\[\lim_{n\rightarrow \infty} \frac{n}{q^n} = 0 \text{ if } q>1\]
\end{example}
\begin{proof}
Since $x_n = \frac{n}{q^n} \implies x_{n+1} = \frac{n+1}{nq} x_n$ for $n \in \mathbb{N}$. Since 
\[\lim_{n\rightarrow \infty} \frac{n+1}{nq} = \lim_{n \rightarrow \infty} \bigg(1 + \frac{1}{n}\bigg) \frac{1}{q} = \lim_{n\rightarrow \infty} \bigg( 1 + \frac{1}{n} \bigg) \cdot \lim_{n\rightarrow \infty} \frac{1}{q} = 1 \cdot \frac{1}{q} = \frac{1}{q} < 1\]
there exists an index $N$ such that $\frac{n+1}{nq} < 1$ for $n>N$. Thus, we have 
\[x_n > x_{n+1} = x_n \cdot \frac{n+1}{nq} \text{ for } n > N\]
which means that the sequence will be monotonically decreasing from index $N$ on. The terms of the sequence
\[x_{N+1} > x_{N+2} > x_{N+3} > \ldots\]
are positive (bounded below) and are monotonically decreasing, so it must have a limit. 

Finding the actual limit is easy. Let $x = \lim_{n \rightarrow \infty} x_n$. It follows from the relation $x_{n+1} = \frac{n+1}{nq} x_n$ that
\[x = \lim_{n\rightarrow \infty} \big(x_{n+1}\big) = \lim_{n \rightarrow \infty} \bigg(\frac{n+1}{nq} x_n \bigg) = \lim_{n \rightarrow \infty} \frac{n+1}{nq} \cdot \lim_{n \rightarrow \infty} x_n = \frac{1}{q} x\]
which implies that $\big( 1 - \frac{1}{q}\big) = 0 \implies x = 0$.
\end{proof}

\begin{example}
We claim that
\[\lim_{n\rightarrow \infty} \sqrt[n]{n} = 1\]
\end{example}

\subsubsection{The Number e}

\subsubsection{Partial, Inferior, Superior Limits}

\begin{definition}[Partial Limits]
The \textit{partial limit} of a sequence $\{x_n\}$ is the limit of any of its subsequence.  
\begin{center}
    \includegraphics[scale=0.26]{Partial_Limit.PNG}
\end{center}
Two (out of the many) partial limits of the sequence above is $+\infty$ and $0$. 
\end{definition}


\begin{definition}[Inferior, Superior Limits]
The \textit{inferior limit} and \textit{superior limit} of a sequence $\{x_k\}$ are defined as follows, and they can be shown to be the smallest and largest partial limits of the sequence. That is, 
\begin{align*}
    \varliminf_{k \rightarrow \infty} x_k & \equiv \lim_{n \rightarrow \infty} \inf_{k \geq n}{x_k} = \min\{ \lim_{r \rightarrow \infty} y_r\}\\
    \varlimsup_{k \rightarrow \infty} x_k & \equiv \lim_{n \rightarrow \infty} \sup_{k \geq n}{x_k} = \max\{ \lim_{r \rightarrow \infty} y_r\}
\end{align*}
where $\{y_r\}$ is any subsequence of $\{x_n\}$. Despite the definition, it isn't too difficult to visualize this. For example, take a look at the superior and inferior limits of the divergent sequence below.
\begin{center}
    \includegraphics[scale=0.5]{Lim_sup_example.png}
\end{center}
In order to find the superior limit, we first look the whole sequence in $\mathbb{N}$ and find the supremum. We now "decrease" our domain from $\mathbb{N}$ to $\{2, 3, \ldots\}$, then $\{3, 4, \ldots\}$, then $\{4, 5, \ldots\}$ and so on, continuing to label the supremum of the sequence. The limit of this sequence of supremums is the superior limit. Informally, the superior limit tells us what the supremum of the "end terms" of $\{x_n\}$ will be, and similarly for the inferior limit. 

The second property of superior and inferior limits is that they represent the greatest and least possible partial limit of a sequence. For example, the six red lines marked in the middle (along with infinitely many others) are viable partial limits because one can choose a subsequence such that all of its points after a certain $n$ lie in some $\epsilon$-neighborhood of the limit. 
\begin{center}
    \includegraphics[scale=0.12]{Sup_Inf_Limits_as_Limit_Bounds.jpeg}
\end{center}
Therefore, the superior and inferior limits represent some sort of "bound" on the sequence in the long run. That is, on the long run, the terms of the sequence $\{x_n\}$ cannot be greater than its superior limit and cannot be less than its inferior limit. With this interpretation, the following theorem should be clear. 
\end{definition}

\begin{theorem}
A sequence has a limit or tends to $\pm \infty$ if and only if its inferior and superior limits are the same. 
\end{theorem}

\begin{corollary}
A sequence converges if and only if every subsequence of it converges. 
\end{corollary}

\subsection{Real Series}
Defining limits and convergence for series can be painstaking... unless we construct series as sequences. 

\begin{definition}[Series over $\mathbb{R}$]
Given a sequence of real numbers $\{a_n\}$, the \textit{series} of $\{a_n\}$ is defined
\[s = \sum_{k=1}^\infty a_k\]
The series can be interpreted as the sequence of partial sums $\{s_n\}$, where
\[s_n = \sum_{k=1}^n a_k\]
is the \textit{$n$th partial term of the series}. Therefore, we can interpret the sum of the series $s$ as the limit of $\{s_n\}$. 
\[\lim_{n \rightarrow \infty} s_n = s\]
If the sequence $\{s_n\}$ converges, the series is \textit{convergent} and \textit{divergent} otherwise. 
\end{definition}

It can be visualized as the Riemann sums of the smooth extension of the function representing $\{a_n\}$, as shown below, where the $a_n$'s represent the height of each bar and the $s_n$'s represent the sums of the area of each bar. 
\begin{center}
    \includegraphics[scale=0.3]{Series_as_Riemann_Sums.PNG}
\end{center}
Note that we are really just defining a series as an ordered pair $(\{a_n\}, \{s_n\})$ of sequences connected by the relation 
\[s_n = \sum_{k=1}^n a_k \text{ for all } n \in \mathbb{N}\]

Since the convergence of a series is equivalent to convergence of its sequence of partial sums, applying the Cauchy convergence criterion to the sequence $\{s_n\}$ leads to the following theorem. 

\begin{theorem}[Cauchy Convergence Criterion for Series]
The series $a_1 + \ldots + a_n + \ldots$ converges if and only if for every $\epsilon > 0$ there exists $N \in \mathbb{N}$ such that for all $m \geq n > N$, 
\[|a_n + \ldots + a_m| < \epsilon\]
\end{theorem}

\begin{definition}[Cauchy Product of Real Series]

\end{definition}

\begin{corollary}[nth Term Test]
A necessary (but not sufficient) condition for convergence of the series $a_1 + \ldots a_n + \ldots$ is that the terms tend to $0$ as $n \rightarrow \infty$. That is, it is necessary that
\[\lim_{n\rightarrow \infty} a_n = 0\]
\end{corollary}
\begin{proof}
It suffices to set $m = n$ in the Cauchy convergence criterion. This would mean that for every $\epsilon > 0$ there exists a $N \in \mathbb{N}$ such that 
\[|a_n| = |a_n - 0| < \epsilon \text{ for all } n > N\]
which, by definition, means that $\{a_n\}$ converges to $0$. 
\end{proof}

\begin{example}[Geometric Series]
The series 
\[1 + q + q^2 + \ldots + q^n + \ldots\]
is called the \textit{geometric series}. 

Since $|q^n| = |q|^n$, we have $|q^n| \geq 1$ when $|q| \geq 1$. So, if $|q| \geq 1$, the terms $q^n$ does not converge to $0$ and the Cauchy convergence criterion is not met. 

Now, suppose $|q|<1$. Then, 
\[s_n = 1 + q + \ldots + q^{n-1} = \frac{1 - q^n}{1-q}\]
which implies that
\[\lim_{n\rightarrow \infty} s_n = \frac{1}{1-q}\]
since $\lim_{n\rightarrow \infty} q^n = 0$ if $|q|<1$. This, the series converges to if and only if $|q|<1$, and its sum is $\frac{1}{1-q}$. 
\end{example}

\begin{example}[Harmonic Series]
The series 
\[1 + \frac{1}{2} + \frac{1}{3} + \ldots + \frac{1}{n} + \ldots\]
is called the \textit{harmonic series}, since each term from the second on is the harmonic mean of the two terms on either side of it. Clearly, 
\[\lim_{n \rightarrow \infty} a_n = \lim_{n \rightarrow \infty} \frac{1}{n} = 0\]
but the sequence of partial sums $s_n$ diverges, and thus the harmonic series diverges. 
\end{example}

\subsubsection{Convergence Tests}

\begin{definition}[Absolute Convergence]
The series $\sum_{n=1}^\infty a_n$ is \textit{absolutely convergent} if the series 
\[\sum_{n=1}^\infty |a_n|\]
converges. Clearly, every absolutely convergent series because 
\[\bigg|\sum_{n=1}^\infty a_n \bigg| \leq \sum_{n=1}^\infty |a_n|\]
\end{definition}

\begin{theorem}[Direct Comparison Test]
Let $\sum_{n=1}^\infty a_n$ and $\sum_{n=1}^\infty b_n$ be 2 series with nonnegative terms. If there exists an index $N \in \mathbb{N}$ such that $a_n \leq b_n$ for all $n >N$, then 
\begin{align*}
    \sum_{n=1}^\infty b_n \text{ convergent } & \implies \sum_{n=1}^\infty a_n \text{ convergent } \\
    \sum_{n=1}^\infty a_n \text{ divergent } & \implies \sum_{n=1}^\infty b_n \text{ divergent }
\end{align*}
\end{theorem}

\begin{theorem}[Limit Comparison Test]
Suppose the limit 
\[\lim_{n\rightarrow \infty} \bigg| \frac{a_{n+1}}{a_n} \bigg| = \alpha\]
exists for the series $\sum_{n=1}^\infty a_n$. Then, 
\begin{align*}
    \alpha < 1 & \implies \sum_{n=1}^\infty a_n \text{ converges absolutely} \\
    \alpha > 1 & \implies \sum_{n=1}^\infty a_n \text{ diverges} \\
    \alpha = 1 & \implies \text{ Inconclusive}
\end{align*}
\end{theorem}

\begin{theorem}[Root Test]
Let $\sum_{n=1}^\infty$ be a given series and 
\[\alpha = \limsup_{n\rightarrow \infty} \sqrt[n]{|a_n|}\]
Then, the following are true
\begin{align*}
    \alpha < 1 & \implies \sum_{n=1}^\infty \text{ converges absolutely} \\
    \alpha > 1 & \implies \sum_{n=1}^\infty \text{ diverges} \\
    \alpha = 1 & \implies \text{ Inconclusive} 
\end{align*}
\end{theorem}

\begin{theorem}[Weierstrass M-test for Absolute Convergence]
Let $\sum_{n=1}^\infty$ and $\sum_{n=1}^\infty b_n$ be series. Suppose there exists an index $N \in \mathbb{N}$ such that $|a_n| \leq b_n$ for all $n>N$. Then, 
\[\sum_{n=1}^\infty b_n \text{ converges } \implies \sum_{n=1}^\infty a_n \text{ converges absolutely}\]
\end{theorem}

The following theorem, while obvious, has interesting consequences. 

\begin{theorem}[Cauchy]
If $a_1 \geq a_2 \geq \ldots \geq 0$, the series $\sum_{n=1}^\infty a_n$ converges if and only if the series 
\[\sum_{k=0}^\infty 2^k a_{2^k} = a_1 + 2 a_2 + 4a_4 + 8a_8 + \ldots \]
converges. 
\end{theorem}
\begin{proof}
Letting $A_k = a_1 + a_2 + \ldots + a_k$ and $S_n = a_1 + 2a_2 + \ldots + 2^n a_{2^n}$, it is clear that by adding up the inequalities
\begin{align*}
    & a_2 \leq a_2 \leq a_1 \\
    & 2a_4 \leq a_3 + a_4 \leq 2a_2 \\
    & 4a_8 \leq a_5 + a_6 + a_7 + a_8 \leq 4a_4 \\
    & \ldots \\
    & 2^n a_{2^{n+1}} \leq a_{2^n + 1} + \ldots + a_{2^{n+1}} \leq 2^n a_{2^n}, 
\end{align*}
we get
\[\frac{1}{2}(S_{n+1} - a_1) \leq A_{2^{n+1}} - a_1 \leq S_n\]
Since the sequences $\{A_k\}$ and $\{S_k\}$ are nondecreasing, and hence from the inequalities we can conclude that they are either both bounded above (which means that they are both convergent since it is a bounded, nondecreasing series) or both unbounded above (which means that they are both divergent since they are nondecreasing and unbounded). 
\end{proof}

\begin{corollary}[p-series Test]
The series 
\[\sum_{n=1}^\infty \frac{1}{n^p}\]
converges for $p>1$ and diverges for $p \leq 1$. 
\end{corollary}
\begin{proof}
Suppose $p\geq 0$. By the previous theorem, the series converges or diverges simultaneously with the series 
\[\sum_{k=0}^\infty 2^k \frac{1}{(2^k)^p} = \sum_{k=0}^\infty (2^{1-p})^k\]
which is really just a geometric series. A necessary and sufficient condition for the convergence of this series is that $2^{1-p} < 1$, that is, $p>1$. 

Now suppose $p \leq 0$. The series is then clearly divergent since all of the terms are larger than $1$. 
\end{proof}

\subsubsection{Representation of Euler's Number as a Series}

\section{Limits of Functions}
Even though we can generalize the concept of limits to functions mapping between arbitrary topological spaces $f: X \longrightarrow Y$, we define this for functions $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$. 

\begin{definition}[Functions]
Given a real-valued function $f: E \longrightarrow \mathbb{R}$ defined on domain $E \subset \mathbb{R}$,
\begin{enumerate}
    \item $f$ is a \textit{constant function} if $f(x) = A$ for all $x \in E$
    \item $f$ is called \textit{ultimately constant} as $x \rightarrow a$ if it is constant in some deleted neighborhood $\mathring{U} (a)$, where $a$ is a limit point of $E$.
    \begin{center}
        \includegraphics[scale=0.28]{Ultimately_Constant_Function.PNG}
    \end{center}
    \item $f$ is \textit{bounded}, \textit{bounded above}, or \textit{bounded below} respectively if there is a number $C \in \mathbb{R}$ such that $|f(x)|<C$, $f(x)<C$, or $C<f(x)$ for all $x \in E$.
    \begin{center}
        \includegraphics[scale=0.25]{Bounded_Three.PNG}
    \end{center}
    \item $f$ is \textit{ultimately bounded}, \textit{ultimately bounded above}, or \textit{ultimately bounded below} as $x \rightarrow a$ if it is bounded, bounded above, or bounded below in some deleted neighborhood $\mathring{U}_E (a)$. 
    \begin{center}
        \includegraphics[scale=0.25]{Ultimately_Bounded_Three.PNG}
    \end{center}
\end{enumerate}
\end{definition}

\begin{example}
The function 
\[f(x) = \sin{\frac{1}{x}} + x \cos{\frac{1}{x}}\]
for $x \neq 0$ is not bounded on the domain of definition, but it is ultimately bounded as $x \rightarrow 0$. 

\end{example}

\begin{definition}[$\epsilon-\delta$ Definition of a Limit]
The function $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$ tends to $A \in \mathbb{R}$ as $x$ tends to $a$, or that 
\[\lim_{x \rightarrow a} f(x) = A\]
if for every $\epsilon > 0$ there exists $\delta > 0$ such that 
\[0<|x - a|<\delta \implies |f(x) - A| < \epsilon\]
Note that we set the $0<|x-a|$ to ensure that $x \neq a$. 

Therefore, in other words, for any arbitrarily small $\epsilon > 0$, if we can find a $\delta > 0$ such that the image of the \textit{deleted $\delta$-neighborhood of $a$} (defined to be $\mathring{U}_\delta (a) \equiv U_\delta (a) \setminus a$) is completely within the $\epsilon$-neighborhood $U_\epsilon (A)$, then 
\[\lim_{x \rightarrow a} f(x) = A\]
Visually, 
\begin{center}
    \includegraphics[scale=0.3]{Limit_of_Function_on_R.PNG}
\end{center}
In higher dimensional spaces, we have 
\begin{center}
    \includegraphics[scale=0.3]{Limit_of_Function_on_Euclidean_Space.PNG}
\end{center}
\end{definition}

\begin{example}[Limit of the Signum Function]
The function sgn$: \mathbb{R} \longrightarrow \mathbb{R}$ defined
\[\text{sgn}\,x = \begin{cases}
1, & x > 0 \\
0, & x = 0 \\
-1, & x < 0
\end{cases}\]
has no limit as $x \rightarrow 0$. 

First, it is ludicrous that the limit would be any number that is not $\{-1, 0, 1\}$. If we assume that $A \not\in \{-1,0,1\}$, then we can choose any arbitrarily small $\epsilon$-neighborhood of $A$ that does not include the three numbers. Clearly, there doesn't exist any $\delta>0$ such that the deleted $\delta$-neighborhood of $0$ maps to a set completely contained in the $\epsilon$-neighborhood of $A$. That is,
\[\text{sgn}\big( \mathring{U}_\delta (0)\big) = \{-1,1\} \not\subset U_\epsilon (A)\]
\begin{center}
    \includegraphics[scale=0.3]{Limit_of_Sign_Function_Ludicrous.PNG}
\end{center}
It doesn't even intersect the $\epsilon$-neighborhood at all. 
\begin{enumerate}
    \item If $A = 1$, we can construct a $\epsilon$-neighborhood $V_A$ for $\epsilon = \frac{1}{2}$. Clearly, there exists no open neighborhood $U_0$ of $0$ that is entirely mapped to $V$, since $U_0$ contains both negative numbers and $0$ and hence must be mapped to $0, -1$. 
    \item Similarly, given the $(\epsilon=\frac{1}{2})$-neighborhood of $A = -1$, there exists no open neighborhood $U_0$ of $0$ that is entirely mapped to it, since $U_0$ contains both positive numbers and $0$ and hence must be mapped to $0, 1$. 
    \item Finally, given the $(\epsilon=\frac{1}{2})$-neighborhood of $A = 0$, there exists no open neighborhood $U_0$ of $0$ that is entirely mapped to it, since $U_0$ contains both positive and negative numbers and hence must be mapped to $\pm1$. 
\end{enumerate}
\begin{center}
    \includegraphics[scale=0.3]{Limit_of_Sign_Function_1_0_-1.PNG}
\end{center}
Therefore, the limit does not exist. 
\end{example}

\begin{example}[Limit of Absolute Value of Signum Function]
We will show that 
\[\lim_{x \rightarrow 0} |\text{sgn}\,x| = 1\]
We construct a $\epsilon$-neighborhood $U_\epsilon (1)$ around $1$. Given this neighborhood, we can imagine choosing the deleted $\delta$-neighborhood $\mathring{U}_\delta (0)$ around $0$. Since every element in $\mathring{U}_\delta (0)$ maps to $1$, it is clearly in $U_\epsilon$. 
\begin{center}
    \includegraphics[scale=0.3]{Absolute_Value_of_Signum.PNG}
\end{center}
In fact, for arbitrarily small $\epsilon > 0$, we can choose \textbf{any} $\delta>0$ since everything in $\mathbb{R} \setminus 0$ maps to $1$. We can visualize this in $\mathbb{R}^2$ as
\begin{center}
    \includegraphics[scale=0.3]{Absolute_Value_of_Signum_2.PNG}
\end{center}
\end{example}

The following lemma nicely interweaves the concepts of limits of sequences and limits of functions. It can be nice for visualization to define the limit of a function using Cauchy sequences rather than the usual $\epsilon-\delta$ definition. 

\begin{lemma}[Cauchy Sequence Criterion of a Limit]
The relation 
\[\lim_{x \rightarrow a} f(x) = A\]
holds if and only if for every sequence $\{x_i\}$ of points $x_n \in E \setminus a$ converging to $a$, the sequence $\{f(x_n)\}$ converges to $A$. 
\begin{center}
    \includegraphics[scale=0.3]{Cauchy_Criterion_of_Limit_of_Function.PNG}
\end{center}
Note that we choose the the points $x_n$ to be in the "deleted" neighborhood $E\setminus a$ (neighborhood $E$ with point $a$ removed) to force us to choose a sequence that is not
\[a, a, a, a, a, a, a, \ldots\]
That is, it forces us to choose different points for the sequence. 
\end{lemma}

\begin{theorem}[Properties of Limits]
Given two numerical valued functions $f, g: E \subset \mathbb{R} \longrightarrow \mathbb{R}$ with a common domain where $g(x) \neq 0$ for all $x \in E$, let 
\[\lim_{x \rightarrow a} f(x) = A, \;\;\;\;\; \lim_{x \rightarrow a} g(x) = B\]
then, 
\begin{align*}
    & \lim_{x \rightarrow a} (f+g)(x) = A + B \\
    & \lim_{x \rightarrow a} (cf)(x) = cA \\
    & \lim_{x \rightarrow a} (f \cdot g)(x) = A \cdot B \\
    & \lim_{x \rightarrow a} \bigg(\frac{f}{g}\bigg) (x) = \frac{A}{B}
\end{align*}
\end{theorem}
\begin{proof}
The the Cauchy sequence criterion for a limit, this theorem is an immediate consequence on the corresponding theorem on limits of sequences.
\end{proof}

We end this with a theorem connecting the relationship between a limit of a function as $x \rightarrow a$ and its ultimate behavior as $x \rightarrow a$. 

\begin{theorem}
Let $f: E \longrightarrow \mathbb{R}$ be a function. Then, 
\begin{enumerate}
    \item $f$ is ultimately the constant $A$ as $x \rightarrow a$ implies that $\lim_{x \rightarrow a} f(x) = A$. 
    \item $\lim_{x \rightarrow a} f(x)$ implies that $f$ is ultimately bounded as $x \rightarrow a$. 
\end{enumerate}
\end{theorem}

\subsubsection{Infinitesimal Functions}

\begin{definition}[Infinitesimal Function]
A function $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$ is said to be \textit{infinitesimal} as $x \rightarrow a$ if 
\[\lim_{x \rightarrow a} f(x) = 0\]
\end{definition}

\begin{lemma}[Sums, Products of Infinitesimals]
It is clear that if $\alpha, \beta$ are infinitesimal as $x \rightarrow a$, then 
\begin{enumerate}
    \item $\alpha + \beta$ is infinitesimal as $x \rightarrow a$
    \item $\alpha \cdot \beta$ is infinitesimal as $x \rightarrow a$
\end{enumerate}
Furthermore, if $\alpha$ is infinitesimal and $\beta$ is ultimately bounded as $x \rightarrow a$, then the product $\alpha \cdot \beta$ is infinitesimal as $x \rightarrow a$. 
\end{lemma}
\begin{proof}
We prove all three statements. 
\begin{enumerate}
    \item Assume that $\alpha$ and $\beta$ are infinitesimal as $x \rightarrow a$. Then, let us fix a small $\epsilon>0$. This means that for every $\frac{\epsilon}{2}$ there exists an open deleted neighborhood $\mathring{U}^\prime (a)$ such that its image $\alpha\big(\mathring{U}^\prime (a)\big)\subset U^\prime_{\epsilon/2} (0) \subset \mathbb{R}$. Additionally, for every $\frac{\epsilon}{2}$ there exists an open deleted neighborhood $\mathring{U}^{\prime\prime} (a)$ such that its image $\beta\big(\mathring{U}^{\prime\prime} (a)\big)\subset U^\prime_{\epsilon/2} (0) \subset \mathbb{R}$.
    Thus, for the deleted neighborhood 
    \[\mathring{U}(a) \subset \mathring{U}^\prime (a) \cup \mathring{U}^{\prime\prime} (a)\]
    we can see that for all $x \in \mathring{U}(a)$, 
    \[|(\alpha + \beta)(x)| = |\alpha (x) + \beta(x)| \leq |\alpha (x)| + |\beta(x)| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\]
    and hence $(\alpha + \beta)\big( \mathring{U}(a)\big) \subset U_\epsilon (0)$. 
    \item This case is a special case of assertion 3. That is, every function that has a limit is ultimately bounded. 
    \item Since $\beta(x)$ is ultimately bounded, this means that there exists a constant $M$ and an open deleted neighborhood $\mathring{U}^\prime (a) \subset E$ such that for all $x \in \mathring{U}^\prime (a)$, its image is bounded: $|\beta(x)|<M$. Let us fix a small $\epsilon>0$. Then, by definition of the limit, for every $\frac{\epsilon}{M}$ there exists an open deleted neighborhood $\mathring{U}^{\prime\prime} (a)$ such that its image $\beta\big(\mathring{U}^{\prime\prime}(a)\big) \subset U_{\epsilon/M} (0) \subset \mathbb{R}$. Therefore, for the deleted neighborhood
    \[\mathring{U}(a) \subset \mathring{U}^\prime (a) \cup \mathring{U}^{\prime\prime}(a)\]
    we can see that for all $x \in \mathring{U} (a)$, 
    \[|(\alpha \cdot \beta)(x)| = |\alpha (x) \beta(x)| = |\alpha (x)| |\beta(x)| < \frac{\epsilon}{M} \cdot M = \epsilon\]
    Therefore, $(\alpha \cdot \beta)\big( \mathring{U} (a)\big) \subset U_\epsilon (0)$. 
\end{enumerate}
\end{proof}

Note that in proving these properties of the limits, we have used the following fact about open deleted neighborhoods around $a$. 
\begin{enumerate}
    \item $\mathring{U} (a)$ is not the empty set. 
    \item Given open deleted neighborhoods $\mathring{U}^\prime (a)$ and $\mathring{U}^{\prime\prime} (a)$, there exists an open deleted neighborhood in the intersections of these neighborhoods. 
    \[\mathring{U} (a) \subset \mathring{U}^\prime (a) \cup \mathring{U}^{\prime\prime} (a)\]
\end{enumerate}
These facts can be used to generalize the concept of limits as limits over a certain \textit{filter base}. 

\begin{theorem}[Representation of a Convergent Function as a Shift of its Infinitesimal]
Given a function $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$, its limit exists and 
\[\lim_{x \rightarrow a} f(x) = A\]
if and only if $f$ can be represented as 
\[f(x) = A + \alpha (x)\]
where $\alpha$ is infinitesimal as $x \rightarrow a$. We can visualize this theorem by thinking of a function $f$ that results from a "shift" of an infinitesimal. 
\begin{center}
    \includegraphics[scale=0.3]{Infinitesimal_Shift_Function.jpg}
\end{center}
\end{theorem}

Finally, we reiterate some limit theorems already stated for sequences, but now corresponding to functions. Interpreting the function limit as the Cauchy sequence definition of limits renders the proofs of these theorems trivial. 

\begin{theorem}[Behavior of Functions with Different Limits]
If the functions $f, g: E \rightarrow \mathbb{R}$ are such that
\[\lim_{x\rightarrow a} f(x) = A < B = \lim_{x \rightarrow a} g(x)\]
then there exists a deleted neighborhood $U_\delta (a)$ in $E$ at each point of which $f(x) < g(x)$. 
\end{theorem}

\begin{theorem}[Squeeze Theorem for Limits of Functions]
Given the functions $f, g, h: E \subset \mathbb{R} \longrightarrow \mathbb{R}$ such that
\[f(x) \leq g(x) \leq h(x) \text{ for all } x \in E\]
then, 
\[\lim_{x \rightarrow a} f(x) = \lim_{x \rightarrow a} h(x) = C \implies \lim_{x \rightarrow a} g(x) = C\]
\end{theorem}

\subsection{Asymptotic Behavior of Functions}

\begin{definition}[Little-O Notation]
The function $f: E \longrightarrow \mathbb{R}$ is said to be \textit{infinitesimal compared with the function $g: E \longrightarrow \mathbb{R}$} as $x \rightarrow a$, written (by abuse of notation) $f = o(g)$ as $x \rightarrow a$, if 
\[\lim_{x \rightarrow a} \frac{f(x)}{g(x)} = 1\]
or in other words, if $f/g$ is an infinitesimal function as $x \rightarrow a$. Therefore, $f = o(1)$ as $x \rightarrow a$ means that $f$ is infinitesimal as $x \rightarrow a$. 
\begin{center}
    \includegraphics[scale=0.25]{Little_o_Functions.jpg}
\end{center}
Note that writing $f = o(g)$ is again, an abuse of notation. $f = o(g)$ is really a shorthand way of writing that $f$ is in the class of functions that is infinitesimal compared with the function $g$. 
\end{definition}

Intuitively, $f = o(g)$ means that the ratio between $f(x)$ and $g(x)$ will tend to infinity as $x \rightarrow a$ (this does not mean that $f$ will be infinitely greater than $g$, however!). For example, looking at the two functions $f(x) = x^2$ and $g(x) = x$, we have 
\begin{enumerate}
    \item $x^2 = o(x)$ as $x \rightarrow 0$ (since $\frac{x^2}{x} = x$ is infinitesimal as $x \rightarrow 0$)
    \item $x = o(x^2)$ as $x \rightarrow \infty$ (since $\frac{x}{x^2} = \frac{1}{x}$ is infinitesimal as $x \rightarrow \infty$)
\end{enumerate}
We can visualize $g/f (x)$ tending to infinity within a neighborhood of $0$ and $f/g (x)$ tending to infinity within a neighborhood of $\infty$. 
\begin{center}
    \includegraphics[scale=0.25]{Comparison_of_Quadratic_and_Linear.PNG}
\end{center}

\begin{definition}[Orders of Infinitesimals, Infinities]
If $f = o(g)$ and $g$ is infinitesimal as $x \rightarrow a$, then $f$ is an \textit{infinitesimal of higher order than $g$ as $x \rightarrow a$}. Furthermore, if $f$ and $g$ are infinite functions as $x\rightarrow a$ and $f = o(g)$ as $x \rightarrow a$, then $g$ is a \textit{higher order infinity than $f$ as $x \rightarrow a$}. 
\end{definition}

\begin{definition}[Big-O Notation]
By abuse of notation, $f = O(g)$ as $x \rightarrow a$ means that 
\[\lim_{x \rightarrow a} \frac{f(x)}{g(x)} = \infty\]
or in other words, $f/g$ is ultimately bounded as $x \rightarrow a$. In particular, $f = O(1)$ as $x \rightarrow a$ means that $f$ is bounded within a certain neighborhood $U(a)$ of $a$. 

In the visual below, we can see that $f=O(g)$ as $x \rightarrow +\infty$ since the limit converges to constant $\frac{B}{A}$ which is bounded. In fact, at any other positive real number $x$, $(f/g)(x)$ is finite and is therefore bounded. However, at every neighborhood of $x = 0$, $(f/g)(x)$ is unbounded, meaning that $g \neq O(f)$ as $x \rightarrow 0$. 
\begin{center}
    \includegraphics[scale=0.25]{Big_O_Functions.PNG}
\end{center}
\end{definition}

\begin{definition}[Functions of Same Order]
The functions $f$ and $g$ are of the same over as $x \rightarrow a$, written 
\[f \asymp g \text{ as } x \rightarrow a\]
if $f = O(g)$ and $g = O(f)$ as $x \rightarrow a$. Intuitively, this means that the ratio between $f$ and $g$ within some deleted neighborhood of $a$ is finite. 

In the visual below, we can see that as long as $k \neq a$, $f = O(g)$ as $x \rightarrow k$ and as $x \rightarrow \infty$. In other words, the function $f/g$ becomes ultimately bounded at every other point other than $a$, and $f/g$ is unbounded within every neighborhood of $a$. When looking at $g/f$, we can see that this function is bounded for all $x \in \mathbb{R}$ and therefore $g = O(f)$ as $x \rightarrow k$ for all $k$. 
\begin{center}
    \includegraphics[scale=0.25]{Functions_of_Same_Order.PNG}
\end{center}
Therefore, we can see that as long as $k \neq a$, $f \asymp g$ as $x \rightarrow k$.

Note that the condition that $f$ and $g$ be of the same order as $x \rightarrow a$ is (by definition of ultimately bounded functions) equivalent to the condition that there exist $c_1, c_2 > 0$ and an open neighborhood $U (a)$ such that the relations
\[c_1 |g(x)| \leq |f(x)| \leq c_2 |g(x)|\]
is true for $x \in U(a)$. 
\end{definition}

\begin{definition}[Asymptotic Equivalence of Functions]
For functions $f$ and $g$, if 
\[\lim_{x \rightarrow a} \frac{f(x)}{g(x)} = 1\]
we say that \textit{$f$ behaves asymptotically like $g$ as $x \rightarrow a$}, or that \textit{$f$ is equivalent to $g$ as $x \rightarrow a$}, written 
\[f \sim g \text{ as } x \rightarrow a\]
Moreover, $\sim$ is an equivalence relation, which means that
\begin{enumerate}
    \item $f \sim f$ as $x \rightarrow a$
    \item $f \sim g$ as $x \rightarrow a \implies$ $g \sim f$ as $x \rightarrow a$
    \item $f \sim g$ and $g \sim h$ as $x \rightarrow a \implies f \sim h$ as $x \rightarrow a$
\end{enumerate}
\end{definition}

We list a few examples in order to develop some sort of visual intuition for when two functions are asymptotically equivalent. 
\begin{enumerate}
    \item If $f(a) = g(a) \neq 0$, then $f \sim g$ trivially since the ratio of $f$ and $g$ converges to $1$ within a neighborhood of $a$. 
    \begin{center}
        \includegraphics[scale=0.3]{trivial_case_equal_value.jpg}
    \end{center}
    \item When $f(a) = g(a) = 0$, it may be $f$ may be equivalent to $g$ or one function may be infinitesimally smaller than the other. 
    \begin{enumerate}
        \item When $f(x) = \sin{x}$ and $g(x) = x$, then $f \sim g$ since we see that 
        \[\lim_{x \rightarrow 0} \frac{sin{x}}{x} = 1\]
        and so $\sin{x} \sim x$ as $x \rightarrow 1$
        \begin{center}
            \includegraphics[scale=0.3]{x_vs_sin_x.PNG}
        \end{center}
        \item When $f(x) = x^2$ and $g(x) = x^4$, then  \[\lim_{x \rightarrow 0} \frac{x^4}{x^2} = 0\]
        and so $x^4 \not\sim x^2$. In fact, $x^4 = o(x^2)$. Therefore, since $x^4$ decreases to $0$ infinitely faster than $x^2$, they are not equivalent. 
        \begin{center}
            \includegraphics[scale=0.25]{x_fourth_vs_x_squared.jpg}
        \end{center}
        \item When $f(x) = x^2$ and $g(x) = x^3$, then  \[\lim_{x \rightarrow 0} \frac{x^3}{x^2} = 0\]
        and so $x^3 \not\sim x^2$. In fact, $x^3 = o(x^2)$. Therefore, since $x^4$ decreases to $0$ infinitely faster than $x^2$, they are not equivalent.  
        \begin{center}
            \includegraphics[scale=0.3]{x_squared_vs_x_cubed.jpg}
        \end{center}
        \item When $f(x) = x^2$ and $g(x) = 0.5x^2$, then 
        \[\lim_{x \rightarrow 0} \frac{0.5x^2}{x^2} = \frac{1}{2}\]
        and so $0.5x^2 \not\sim x^2$. Therefore, since $0.5x^2$ is always as twice as small as $x^2$, they are not equivalent. 
        \begin{center}
            \includegraphics[scale=0.3]{x_squared_vs_half_x_squared.PNG}
        \end{center}
    \end{enumerate}
    \item When analyzing the behavior of functions as $x \rightarrow \infty$, we can picture the two graphs of $f$ and $g$ on the plane and "zoom out" to see if the ratio of the values converge to $1$. This would mean that as $x \rightarrow \infty$, we should see the graphs overlapping more and more. For example, taking $f(x) = x^2$ and $g(x) = x^2 + 10x + 100$, we can see that the discrepancy is high around a neighborhood of $x = 0$. But as $x \rightarrow +\infty$, we get
    \[\lim_{x \rightarrow + \infty} \frac{x^2 + 10x + 100}{x^2} = 1\]
    and so the graphs look like they are overlapping. 
    \begin{center}
        \includegraphics[scale=0.3]{Behavior_of_Quadratics_of_Same_order_as_infinity.PNG}
    \end{center}
    Notice that even though the absolute difference $|(x^2 + 10x + 100) - x^2| = |10x + 100|$ tends to infinity, this difference increases infinitesimally compared to $f$ and $g$. 
\end{enumerate}

From this, we can see that if $f \sim g$ as $x \rightarrow a$, then their difference 
\[f - g = o(g) = o(f)\]
That is, $(f-g)(x)$ is infinitesimal compared to $g$ or $f$ (doesn't matter which one we compare it to). This leads to our next section, where we formalize this concept with absolute and relative errors. 

\subsubsection{Approximations of Functions}
It is useful to note that since the relation $\lim_{x \rightarrow a} \gamma(x) = 1$ is equivalent to 
\[\gamma (x) = 1 + \alpha(x), \text{ where } \lim_{x \rightarrow a} \alpha(x) = 0\]
the relation $f \sim g$ as $x\rightarrow a$ is equivalent to saying that
\[\frac{f(x)}{g(x)} = \gamma(x), \text{ where } \lim_{x \rightarrow a} \gamma(x) = 1\]
which implies 
\[f(x) = g(x) + \alpha(x) g(x) = g(x) + o(g(x)) \text{ as } x \rightarrow a\]
or, symmetrically, 
\[g(x) = f(x) + \alpha(x) f(x) = f(x) + o(f(x)) \text{ as } x \rightarrow a\]
This means that $f$ can be exactly represented by another function $g$, plus another (error) function $o(g(x))$ that is infinitesimal compared to $g$. 
\begin{center}
    \includegraphics[scale=0.28]{Error_Approximation_of_Function.PNG}
\end{center}
\textbf{Note that it is not a sufficient condition that the error function be infinitesimal!} The error function $f-g$ must be infinitesimal \textbf{compared to $g$}! This tells us that not only does the error function decrease infinitesimally, but also is infinitesimal compared to the approximation function we already have, which is in general a much stronger claim. This representation of certain types functions will provide the foundation for differential calculus when we talk about "good" approximations for a function. 


\begin{definition}[Relative Error]
Since $f \sim g$ as $x \rightarrow a$ means that 
\[f(x) = g(x) + \alpha(x) g(x) = g(x) + o(g(x))\]
we can define the \textit{relative error} of $g$ as an approximation of $f$ to be
\[|\alpha(x)| = \bigg| \frac{f(x) - g(x)}{g(x)} \bigg|\]
Clearly, since $f \sim g$, the relative error must be infinitesimal as $x \rightarrow a$. 
\end{definition}

We use the following lemma to check whether two functions are asymptotically equivalent. 
\begin{lemma}
$f \sim g$ as $x \rightarrow a$ if and only if the relative error of $g$ is infinitesimal as $x \rightarrow a$. 
\end{lemma}

\begin{example}
We claim that 
\[x^2 + x = \bigg(1 + \frac{1}{x} \bigg) x^2 \sim x^2 \text{ as } x \rightarrow \infty\]
We see that the absolute error of this approximation 
\[|(x^2 + x) - x^2| = |x|\]
tends to infinity, but the relative error
\[\frac{|x|}{x^2} = \frac{1}{|x|}\]
tends to $0$ as $x \rightarrow \infty$. 
\end{example}

\begin{theorem}[Prime Number Theorem]
Let $\pi(x)$ be the number of prime numbers strictly less than $x$. Then $\pi \sim \frac{x}{\ln{x}}$ as $x\rightarrow + \infty$, or more precisely, 
\[\pi(x) = \frac{x}{\ln{x}} + o \bigg( \frac{x}{\ln{x}}\bigg) \text{ as } x \rightarrow +\infty\]
\end{theorem}

\begin{example}
It is a fact that $\lim_{x\rightarrow 0} \frac{sin{x}}{x} = 1$, so we have $\sin{x} \sim x$ as $x \rightarrow 0$. So,
\[\sin{x} = x + o(x) \text{ as } x \rightarrow 0\]
\end{example}

The following theorem proves useful when computing limits. 
\begin{theorem}
If $f \sim \Tilde{f}$ as $x \rightarrow a$, then 
\[\lim_{x \rightarrow a} f(x) g(x) = \lim_{x \rightarrow a} \Tilde{f}(x) g(x)\]
provided one of these limits exist. 
\end{theorem}

\begin{theorem}[Properties of $o(g)$ and $O(g)$ Functions]
For $x \rightarrow a$, 
\begin{enumerate}
    \item $o(f) + o(f) = o(f)$
    \item $o(f)$ is also $O(f)$
    \item $o(f) + O(f) = O(f)$
    \item $O(f) + O(f) = O(f)$
    \item If $g(x) \not\equiv 0$, then 
    \[\frac{o(f(x))}{g(x)} = o \bigg( \frac{f(x)}{g(x)} \bigg), \text{ and } \frac{O(f(x))}{g(x)} = O \bigg( \frac{f(x)}{g(x)} \bigg)\]
\end{enumerate}
\end{theorem}


\section{Continuous Functions}
\begin{definition}[Continuity of a Function]
A function $f$ is \textit{continuous at point $a$} if for any neighborhood $V\big(f(a)\big)$ of $f(a)$, there is a neighborhood $U(a)$ of $a$ whose image under the mapping $f$ is contained in $V\big( f(a)\big)$. 

Generalizing this, we say that a function is \textit{(globally) continuous} if the preimage of every neighborhood in its codomain is an open set in its domain. 
\end{definition}

The equivalent of these statements for functions $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m$ follows from the fact that any neighborhood of a point contains a symmetric neighborhood of the point. 
\begin{center}
    \includegraphics[scale=0.35]{Symmetric_Neighborhood_in_Neighborhood.PNG}
\end{center}

\begin{lemma}[Existence of Limits of Continuous Functions]
$f: E \longrightarrow \mathbb{R}$ is continuous at $a \in E$, where $a$ is a limit point of $E$ if and only if 
\[\lim_{x \rightarrow a} f(x) = f(a)\]
\end{lemma}
\begin{proof}
The limit equalling $f(a)$ means that, by definition, for any arbitrarily small deleted neighborhood of $f(a)$, denoted $U_{f(a)} \setminus f(a)$, its preimage will be an open neighborhood of $a$, which itself will contain an open set. 
\end{proof}

This also means that we can use the Cauchy limit definition to defined continuity of a function at a point. That is, for any sequence $\{a_n\}$ of point in codomain $E$ which converges to point $a$, the function $f$ is continuous at $a$ if the corresponding sequence $\{f(a_n)\}$ converges to $f(a)$.

\begin{theorem}
This means that the continuous functions commute with the operation of passing to the limit at a point. 
\[\lim_{x \rightarrow a} f(x) = f\Big( \lim_{x \rightarrow a} x \Big)\]
\end{theorem}

\begin{lemma}[Properties of Continuous Functions]
Let $f: \mathbb{R}^n \longrightarrow \mathbb{R}^m, \; g: \mathbb{R}^m \longrightarrow \mathbb{R}^p$ with $c \in \mathbb{R}$. 
\begin{enumerate}
    \item $f$ continuous at $x_0 \implies$ $c f$ continous at $x_0$. 
    \item $f, g$ continuous at $x_0 \implies f + g$ continuous at $x_0$. 
    \item Let $m = 1$. $f, g$ continuous at $x_0 \implies f g$ continuous at $x_0$. 
    \item $f$ continuous at $x_0$ and $f(x) \neq 0 \forall x \in \mathbb{R}^n \implies 1 / f$ continuous at $x_0$. 
    \item If $f(x) = \big( f_1(x), f_2(x), ..., f_n(x) \big)$ coordinate-wise, then 
\[ f \text{ continuous at } x_0 \iff f_1, f_2, ..., f_m \text{ continuous  at } x_0\]
    \item $f$ continuous at $x_0$ and $g$ continuous at $y_0 = f(x_0) \implies g \circ f$ continuous at $x_0$. 
\end{enumerate}
\end{lemma}
\begin{proof}
This is an immediate result of the equivalence of a function being continuous at point $a$ and its limit at point $a$ existing. 
\end{proof}

\subsection{Points of Discontinuity}
\begin{definition}[Discontinuity]
If the function $f: E \longrightarrow \mathbb{R}$ is not continuous at a point of $E$, then this point is called a \textit{point of discontinuity}, or simply a \textit{discontinuity} of $f$. 

That is, $a$ is a point of discontinuity of $f$ if for some neighborhood $V(f(a))$ of $f(a)$, there exists no neighborhood of $a$ whose image under the mapping $f$ is contained in $V(f(a))$. 
There are three types of discontinuities: 
\begin{enumerate}
    \item A \textit{removable discontinuity} is characterized by the fact that the limit $\lim_{x \rightarrow a} f(x) = A$ exists, but $A \neq f(a)$. \begin{center}
        \includegraphics[scale=0.28]{Removable_Discontinuity.PNG}
    \end{center}
    This means that we can modify $f$ and define a new function $\Tilde{f}: E \longrightarrow \mathbb{R}$ as
    \[\Tilde{f}(x) = \begin{cases}
    f(x), & x \in E \setminus a \\
    A, & x = a
    \end{cases}\]
    which would be continuous on $E$. 
    \item A \textit{discontinuity of first kind}, also known as a jump/step discontinuity, is characterized by both the left and right-hand limits 
    \[\lim_{x \rightarrow a-0} f(x) \text{ and } \lim_{x \rightarrow a+0} f(x)\]
    existing, but at least one of them is not equal to the value $f(a)$ that the function assumes at $a$. 
    \begin{center}
        \includegraphics[scale=0.28]{Discontinuity_First.PNG}
    \end{center}
    \item A \textit{discontinuity of second kind}, also known as an essential discontinuity, is characterized by at least one of the two limits 
    \[\lim_{x \rightarrow a-0} f(x) \text{ and } \lim_{x \rightarrow a+0} f(x)\]
    not existing. 
    \begin{center}
        \includegraphics[scale=0.27]{Discontinuity_Second.PNG}
    \end{center}
\end{enumerate}
Note that strictly speaking, a removable discontinuity is really a discontinuity of first kind, but in this context we distinguish them. 
\end{definition}

\begin{example}[Dirichlet Function]
The Dirichlet function, defined
\[\mathcal{D}(x) = \begin{cases}
1, & \text{ if } x \in \mathbb{Q} \\
0, & \text{ if } x \in \mathbb{R} \setminus \mathbb{Q} 
\end{cases}\]
is discontinuous at every point, and obviously all of its discontinuities are of second kind, since in every interval there are both rational and irrational numbers and therefore there exists no limit at any point $a \in \mathbb{R}$. 

More specifically, given any point $a \in \mathbb{R}$, assume that $a$ is rational. We can set $\epsilon = 0.1$-neighborhood around the value $1$, but no matter how small we let $\delta$, the interval $(a - \delta, a + \delta)$ will contain both rationals and irrationals, meaning that it will map to $\{0,1\}$ always, which is not fully contained in $(0.9, 1.1)$.  
\end{example}

Here is a slightly more interesting example. 

\begin{example}[Riemann Function]
Let the Riemann function $\mathcal{R}$ be defined
\[\mathcal{R}(x) = \begin{cases}
\frac{1}{n}, & \text{ if } x = \frac{m}{n} \in \mathbb{Q}, \text{ where gcd}(m, n) = 1 \\
0, & \text{ if } x \in \mathbb{R} \setminus \mathbb{Q}
\end{cases}\]
We first note that for any point $a \in \mathbb{R}$, any bounded neighborhood $U(a)$ of it, and any number $N \in \mathbb{N}$, the neighborhood $U(a)$ contains only a finite number of rational numbers $\mathbb{m}{n}$, where $n < N$. By shrinking the neighborhood, we can assume that the denominators of all rational numbers in the neighborhood are larger than $N$. We can visualize why this is by seeing that rational numbers with larger denominators have smaller "gaps" between them. 
\begin{center}
    \includegraphics[scale=0.27]{Rationals_Spread_Apart.PNG}
\end{center}
Thus, at any point $x \in U(a) \setminus a$, we have 
\[\big| \mathcal{R}(x) \big| < \frac{1}{N}\]
and therefore
\[\lim_{x \rightarrow a} \mathcal{R} (x) = 0\]
at any point $a \in \mathbb{R} \setminus \mathbb{Q}$. Hence, the Riemann function is continuous at any irrational number. 
\end{example}

\subsection{Properties of Continuous Functions}

\begin{theorem}[Local Properties of Continuous Functions]
Let $f: E \longrightarrow \mathbb{R}$ be a function that is continuous at the point $a \in E$. Then, 
\begin{enumerate}
    \item $f$ is bounded in some neighborhood $U(a)$. 
    \item If $f(a) \neq 0$, then in some neighborhood $U(a)$ all the values of the function have the same sign as $f(a)$. 
    \item If the function $g: U(a) \subset E \longrightarrow \mathbb{R}$ is defined in some neighborhood of $a$ and is continuous at $a$, then the following functions 
    \begin{align*}
        & (f + g) (x) \\
        & (f \cdot g) (x) \\
        & \bigg( \frac{f}{g} \bigg) \big( x \big) \text{ where } g(a) \neq 0
    \end{align*}
    are also defined in $U(a)$ and continuous at $a$. 
    \item If the function $g: Y \longrightarrow \mathbb{R}$ is continuous at a point $b \in Y$ and $f$ is such that $f: E \longrightarrow Y$, $f(a) = b$, and $f$ is continuous at $a$, then the composite function 
    \[g \circ f: E \longrightarrow \mathbb{R}\]
    is defined on $E$ and continuous at $a$. 
    \begin{center}
        \includegraphics[scale=0.3]{Composition_Function_Continuous.PNG}
    \end{center}
    This is easy to see because given the open neighborhood of $g(b)$, we know for a fact that $U_\delta (a)$ maps completely into $U_\epsilon (b)$, and that $U_\epsilon (b)$ maps completely into $U_\kappa (g(b))$ and so the composition of these mappings must mean that $U_\delta (a)$ maps completely into $U_\kappa (g(b))$. 
\end{enumerate}
\end{theorem}

\begin{example}
An algebraic polynomial 
\[P(x) = a_0 x^n + a_1 x^{n-1} + a_2 x^{n-2} + \ldots + a_{n-1} x + a_n\]
is a continuous function on $\mathbb{R}$. Since $f(x) = x$ and $f(x) = c$ are continuous functions, by induction on $x$, we can multiply them together to find that $f(x) = x^n$ is continuous, which implies that $a x^n$ is continuous, which implies that the sums of these functions are also continuous. 
\end{example}

Unlike local properties, the global property of a function is a property involving the entire domain of definition of the function. 

\begin{theorem}[Intermediate Value Theorem]
If a function that is continuous on a closed interval assumes values with different signs at the endpoints of the interval, then there is a point in the interval where it assumes the value $0$. 
\begin{center}
    \includegraphics[scale=0.3]{IVT.PNG}
\end{center}
\end{theorem}
\begin{proof}

\end{proof}

This following proof provides a very simple algorithm for finding the zero of the equation $f(x) = 0$ on an interval whose endpoints has values with opposite signs. 
Note that the colloquial description of the intermediate value theorem, that is is impossible to pass continuously from positive to negative values without assuming the value $0$ along the way), assumes more than they state. That is, this theorem is actually dependent on the domain of definition: that is is a closed interval, or more generally, that it is \textit{connected}. 

\begin{corollary}
If a function $f$ is continuous on an open interval and assumes values $f(a) = A, f(b) = B$, then for any number $C \in (A, B)$, there is a point $c$ between $a$ and $b$ such that $f(c) = C$. 
\begin{center}
    \includegraphics[scale=0.3]{Corollary_of_IVT.PNG}
\end{center}
\end{corollary}

\begin{theorem}[Weierstrass Maximum-Value Theorem]
A function that is continuous on a closed interval is bounded in that interval, with a maximum and minimum. 
\end{theorem}

\subsubsection{Uniform Continuity}
Roughly speaking, a function $f$ is uniformly continuous if it is possible to guarantee that $f(x)$ and $f(y)$ be as close to each other as we please by requiring only that $x$ and $y$ be sufficiently close to each other. 

\begin{definition}[Uniform Continuity]
A function $f: E \longrightarrow \mathbb{R}$ is \textit{uniformly continuous} on a set $E \subset \mathbb{R}$ if for every $\epsilon > 0$, there exists $\delta > 0$ such that 
\[\big| f(x_1) - f(x_2)\big| < \epsilon\]
for all points $x_1, x_2 \in E$ such that $|x_1 - x_2| < \delta$. 

Intuitively, uniform continuity says that given any two points $x, y$ in the domain where their distance is arbitrarily small ($\delta$ apart), we can guarantee that the distance between $f(x), f(y)$ is at maximum some arbitrarily small $\epsilon$. 

The following visual shows the radical function $f(x) = \sqrt{x}$ defined on $\mathbb{R}^+$. We can see that it satisfies uniform continuity because the graph does not escape the top and/or bottom of the $\epsilon \times \delta$ window, no matter where the box is located on the graph. More strictly speaking, no matter what we set the $\epsilon$ (how long the box is), uniform continuity says that we can choose a sufficient $\delta$ (width of the box) such that the graph does not escape the top/bottom of the window no matter where the window is. 
\begin{center}
    \includegraphics[scale=0.28]{Uniform_Continuity_Radical.PNG}
\end{center}
We can clearly see that the function $f(x) = 1/x$ is not uniformly continuous, since the graph escapes the $\epsilon \times \delta$ window at some point (marked in red). More strictly speaking, given any length $\epsilon$ of the window, we cannot create a thin-enough $\delta$ box that will contain the graph, since as $x \rightarrow 1$, the function becomes unbounded. 
\begin{center}
    \includegraphics[scale=0.3]{Uniform_Continuity_Rational.PNG}
\end{center}
That is, arbitrarily thin boxes don't help when the slope is arbitrarily steep. 
\end{definition}

To compare uniform continuity with regular continuity, we can adapt this alternate (yet equivalent interpretation): Let there exist function $f: E \longrightarrow \mathbb{R}$. Given any $\epsilon>0$, we can choose a $\delta>0$ such that given any point $x \in E$ and $f(x)$, as long as a second point $y$ is $\delta$ away from $x$, then $f(y)$ is $\epsilon$ away from $f(x)$. This visualization would lead to there being a $2\epsilon \times 2\delta$ window around point $x$. 
\begin{center}
    \includegraphics[scale=0.3]{Double_Epsilon_Delta_Uniform_Continuity.PNG}
\end{center}
Uniform continuity means that the box above does not change dimensions no matter where the point is (hence, the name uniform). Therefore, given a certain $\epsilon > 0$, the way we choose $\delta$ is only dependent on $\epsilon$, and so it must be a function of $\epsilon$: 
\[\delta = \delta(\epsilon)\]
However, in continuity, there just has to exist \textbf{some} $\delta$-neighborhood of $x$ such that its image is contained in the $\epsilon$-neighborhood of $f(x)$. There are no restrictions on the dimensions of this box; it just has to exist. 
\begin{center}
    \includegraphics[scale=0.28]{Regular_Continuity_Box_Visual.PNG}
\end{center}

\begin{lemma}
If $f$ is uniformly continuous on the set $E$, it is continuous at each point of that set. However, the converse is not generally true. 
\end{lemma}

\begin{theorem}[Cantor's Theorem on Uniform Continuity]
A function that is continuous on a closed interval is uniformly continuous on that interval. 
\end{theorem}


\begin{example}
Let $f: \mathbb{R} \longrightarrow \mathbb{R}, \; f(x) = 3x+7$. Then $f$ is uniformly continuous. Choose $\epsilon > 0$. Let $\delta = \epsilon / 3$. Choose $x, y \in \mathbb{R}$ and assume $|x-y| < \delta$. Then, 
\[ | f(x) - f(y) | = | 3x + 7 - 3 y - 7 | = 3 |x-y| < 3 \delta = \epsilon \qed\]
\end{example}

\begin{example}
Let $f: (0, 4) \subset \mathbb{R} \longrightarrow \mathbb{R}, \; f(x) = x^2$. Then $f$ is uniformly continuous on $(0, 4)$. Choose $\epsilon > 0$. Let $\delta = \epsilon / 8$. Choose $x, y \in (0, 4)$ and assume $|x-y| < \delta$. Then, 
\[ |f(x) - f(y)| = |x^2 - y^2| = (x+y) |x-y| < (4+4) |x-y| = 8\delta = \epsilon \qed\]
\end{example}

In both examples, the function satisfied an inequality of form 
\[ |f(x_1) - f(x_2)| \leq M |x_1 - x_2|\]
this is called the Lipshitz inequality. 

\subsubsection{Lipshitz Continuity}
Lipshitz continuity is a strong form of uniform continuity for functions. Intuitively, a Lipshitz continuous function is limited in how fast it can change (by the Lipshitz constant). 

\begin{definition}[Lipshitz Continuous Function]
Given $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$, $f$ is \textit{Lipshitz continuous} if there exists a positive real constant $M$ such that for all real $x, y \in E$, 
\[\big| f(x) - f(y) \big| \leq M \big| x - y \big|\]
The corresponding $M$ is called the \textit{Lipshitz constant}, and the smallest constant $M$ satisfying this inequality is called the \textit{best Lipshitz constant}. 

Note that Lipshitz continuity pops up as a very natural extension of uniform continuity. The inequality above just means that given an $\epsilon$, we can choose a $\delta$ such that a linear multiple of $\delta$ is always greater than $\epsilon$. This means that Lipshitz continuity is just uniform continuity such that the $\delta$ function is linear:  
\[\delta = \delta(\epsilon) = \frac{1}{M} \epsilon\]
\begin{center}
    \includegraphics[scale=0.3]{Lipshitz_Continuity.jpg}
\end{center}
\end{definition}

Another way to interpret uniform continuity is by seeing that the derivative of $f$ is bounded by the slope $M$. 
\begin{center}
    \includegraphics[scale=0.3]{Lipshitz_Continuity_Slope_Bound.PNG}
\end{center}
This slope bound implies that for every pair of points on the graph of this function, the absolute value of the slope of the line connecting them is not greater than $M'$. The smallest $M'$ is the best Lipshitz constant. 

\begin{definition}[Bi-Lipshitz Continuity]
A function $f: E \subset \mathbb{R}$ is \textit{Bi-Lipshitz continuous} if there exists constant $M\geq 1$ such that for all real $x, y \in E$, 
\[ \frac{1}{M} |x - y| \leq |f(x) - f(y)| \leq M |x - y|\]
A visual of this map is shown, where the function $f$ must always land in the shaded green area. 
\begin{center}
    \includegraphics[scale=0.3]{BiLipshitz_Map.PNG}
\end{center}
It immediately follows that for $x \neq y$, $ |f(x) - f(y)|$ cannot equal $0$, which means that a bilipshitz map is injective. A bilipshitz map is really just Lipshitz map with its inverse also being Lipshitz. 
\end{definition}

\begin{proposition}
A bilipshitz map $f$ is a homeomorphism onto its image. 
\end{proposition}

\subsubsection{Inverse Function Theorem}

We begin by introducing this intuitive lemma. 
\begin{lemma}
A continuous mapping $f: E \longrightarrow \mathbb{R}$ of a closed interval $E = [a,b]$ into $\mathbb{R}$ is injective if and only if the function $f$ is strictly monotonic on $[a,b]$. 

Furthermore, every strictly monotonic function $f: X \subset \mathbb{R} \longrightarrow \mathbb{R}$ (for arbitrary $X$) has an inverse 
\[f^{-1}: f(X) \subset \mathbb{R} \longrightarrow \mathbb{R}\]
with the same kind of monotonicity on $f(X)$ that $f$ has on $X$. 
\end{lemma}

\begin{lemma}[Criterion for Continuity of a Monotonic Function]
A monotonic function $f: E \longrightarrow \mathbb{R}$ defined on a closed interval $E = [a,b]$ is continuous if and only if its set of values $f(E)$ is the closed interval with endpoints $f(a)$ and $f(b)$. 

Note that both conditions imply that there are no points of discontinuities in the graph of $f$. 
\end{lemma}


\begin{theorem}[Inverse Function Theorem]
A function $f: X \longrightarrow \mathbb{R}$ that is strictly monotonic on a set $X \subset \mathbb{R}$ has an inverse $f^{-1}: Y \longrightarrow \mathbb{R}$ defined on the set $Y = f(X)$ of values of $f$. The function $f^{-1}: Y \longrightarrow \mathbb{R}$ is monotonic and has the same type of monotonicity on $Y$ that $f$ has on $X$. 
\begin{center}
    \includegraphics[scale=0.33]{Inverse_Function_Theorem_Analysis.PNG}
\end{center}
If in addition, $X$ is a closed interval $[a,b]$ and $f$ is continuous on $X$, then the set $Y = f(X)$ is the closed interval with endpoints $f(a)$ and $f(b)$ and the function $f^{-1}: Y \longrightarrow \mathbb{R}$ is continuous on it.
\end{theorem}

\begin{example}
The function $f(x) = \sin{x}$ is increasing and continuous on the closed interval $\big[ -\frac{\pi}{2}, \frac{\pi}{2} \big]$. Hence, the restriction to the closed interval $\big[ -\frac{\pi}{2}, \frac{\pi}{2} \big]$ has an inverse $x = f^{-1}(y)$, which is denoted by 
\[x = \arcsin{y}\]
This function is defined on the closed interval $\big[- \sin\big(-\frac{\pi}{2}\big), \sin\big(-\frac{\pi}{2}\big) \big] = [-1,1]$ and increases continuously from $-\frac{\pi}{2}$ to $\frac{\pi}{2}$. 
\begin{center}
    \includegraphics[scale=0.3]{Inverse_Function_Theorem_Sin.PNG}
\end{center}
\end{example}

\section{Differential Calculus}
\subsection{Functions Differentiable at a Point}
\begin{definition}[Differentiable Function]
A function $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$ is \textit{differentiable} at a given point $x$ (that is a limit point of $E$) if there exists a linear function $h \mapsto df(x) h$ (called the \textit{differential of $f$}) and an infinitesimal $\alpha (x;h) = o(h)$ as $h \rightarrow 0$, such that
\[f(x + h) - f(x) = df(x) (h) + \alpha (x; h)\]
Note that $x$ is fixed; what we are really interested here is the $h$ value. Furthermore, 
\begin{enumerate}
    \item $\Delta x(h) \equiv (x + h) - x = h$ is called the \textit{increment of the argument}
    \item $\Delta f(x;h) \equiv f(x + h) - f(x)$ is called the \textit{increment of the function} 
\end{enumerate}
They are often denoted (inappropriately) by the symbols $\Delta x$ and $\Delta f(x)$ representing functions of $h$. The differential and the infinitesimal can be visualized below. 
\begin{center}
    \includegraphics[scale=0.3]{Differential_Diagram.PNG}
\end{center}
\end{definition}

\begin{definition}[Derivative]
Given function $f: E \subset \mathbb{R} \longrightarrow \mathbb{R}$, the number
\[f^\prime (x) = \lim_{h \rightarrow 0} \frac{f(x+h) - f(x)}{h}\]
is called the \textit{derivative} of the function $f$ at $x$. It can be visualized as the sequence of the slopes of the secant lines converging onto the slope of the black tangent line as shown. 
\begin{center}
    \includegraphics[scale=0.27]{Tangent_Lines_Converging.PNG}
\end{center}
This equality can also be written in the equivalent form: 
\[\frac{f(x+h) - f(x)}{h} = f^\prime (x) + \alpha (h)\]
where $\alpha$ is infinitesimal as $h \rightarrow 0$. This also also equivalent to:
\[f(x+h) - f(x) = f^\prime (x) h + o (h)\]
where the error term $o(h) \rightarrow 0$ as $h \rightarrow 0$. 
\end{definition}

Note that we have defined the differentiability of a function at a point and the existence of its derivative at a point completely separately. But it turns out that the existence of this arbitrary number $f^\prime (x)$ we call the "derivative," defined
\[f^\prime (x) = \lim_{h \rightarrow 0} \frac{f(x + h) - f(x)}{h}\]
actually has an equivalent form of 
\[f(x + h) - f(x) = f^\prime (x) h + o(h)\]
But since $f^\prime(x)$ is in $\mathbb{R}$, the function $h \mapsto f^\prime (x) h$ is linear and $o(h)$ is infinitesimal, so it is in the form 
\[f(x + h) - f(x) = df (x) (h) + \alpha(x; h)\]
which, by definition, means that it is differentiable! Therefore, we have determined the equivalence between the differentiability of a function at a point and the existence of its derivative at the same point. Furthermore, this function $h \mapsto f^\prime (x) h$ is precisely the differential of $f$, meaning that
\[df (x) (h) = f^\prime (x) h\]
Furthermore, 
\[\Delta f(x; h) - df(x)(h) = \alpha (x; h)\]
and $\alpha(x;h) = o (h)$ as $h \rightarrow 0$, or in other words, the difference between the increment of the function and the value of the function $df(x)$ in $h$ is an infinitesimal of higher order than the first in $h$. For this reason, we say that the differential is the \textit{principal linear part of the increment of the function}. 

In particular, if $f(x) \equiv x$, then we have $f^\prime (x) \equiv 1$ and 
\[dx (h) = 1 \cdot h = h\]
Substituting this equality into $df(x) (h) = f^\prime (x) h$, we get
\[df (x) (h) = f^\prime (x) \,dx (h)\]
or without the input parameter $h$, 
\[df(x) = f^\prime (x) \,dx\]
Note that this is an equality between two functions of $h$. From this, we obtain the familiar \textit{Leibniz notation} of the derivative: 
\[\frac{df (x) (h)}{dx(h)} = f^\prime (x) \iff \frac{df(x)}{dx} = f^\prime (x)\]
That is, the function $\frac{df(x)}{dx}$, which is the ratio of the functions $df(x)$ and $dx$, is constant and equals $f^\prime (x)$. 

\subsection{Tangent Line: Geometric Meaning of the Derivative, Differential}
Let us try to construct successive approximations to an arbitrary function $f: E \longrightarrow \mathbb{R}$ at a given limit point $x_0$. That is, we find a function $g$ such that
\[f = g + o(g)\]
Depending on what $g$ is, we can construct better approximations of $f$. 

\subsubsection{Constant Approximation}
The 0th order approximation is when $g$ is a constant. That is, $g \equiv c_0$ for some $c_0 \in \mathbb{R}$. This means
\[f(x) = c_0 + o(c_0) = c_0 + o(1) \text{ as } x \rightarrow x_0\]
More precisely, we want this difference $f(x) - c_0$ to be $o(1)$ as $x \rightarrow x_0$, which means that it is simply infinitesimal. Visualizing this, we can see that given a constant approximation (labeled in blue) to a function at $x_0$, its error term (labeled in green) is in fact, infinitesimal. All this boils down to the fact that 
\[\lim_{x \rightarrow x_0} f(x) = c_0\]
If the function is continuous at $x_0$, then 
\[\lim_{x \rightarrow x_0} f(x) = f(x_0)\]
and naturally $c_0 = f(x_0)$. Both the continuous (left) and noncontinuous case (right) is shown, but in most cases, we will assume continuity. 
\begin{center}
    \includegraphics[scale=0.3]{Constant_Approximation_Continuous_Noncontinuous_case.PNG}
\end{center}

\subsubsection{Linear Approximation}
The 1st order approximation is a linear function that approximates $f$ as
\[f(x) = c_0 + c_1(x - x_0) + o(x - x_0) \text{ as } x \rightarrow x_0\]
Following the previous logic, assuming $f$ continuous means that $c_0 = f(x_0)$. Furthermore, as $x \rightarrow x_0$
\begin{align*}
    f(x) = c_0 + c_1(x - x_0) + o(x - x_0) & \implies c_1 = \frac{f(x) - c_0 - o(x - x_0)}{x - x_0} \\
    & \implies c_1 = \frac{f(x) - c_0}{x - x_0} - \frac{o(x - x_0)}{x - x_0}\\
    & \implies c_1 = \frac{f(x) - c_0}{x - x_0} - o(1) \\
    & \implies c_1 = \lim_{x \rightarrow x_0} \frac{f(x) - c_0}{x - x_0} = f^\prime (x_0)
\end{align*}
But this just means that $f^\prime (x_0) = c_1$, Note that before, we have proved the equivalence of the existence of a derivative at $x_0$ with differentiability at $x_0$ (which itself means that there exists a linear approximation $df(x)(h)$ that is a function of $h$). Here, we have created a linear approximation with respect to $x = x_0 + h$, rather than $h$ (shifted the function). 

Therefore, the function 
\[\alpha (x) = f(x_0) + f^\prime (x_0) (x - x_0)\]
provides the best linear approximation to the function $f$ in a neighborhod of $x_0$ in the sense that for any other function $\beta(x)$ of the form 
\[\beta(x) = c_0 + c_1 (x - x_0)\]
we have $f(x) - \beta(x) \neq o(x - x_0)$ as $x \rightarrow x_0$. The graph of the function $\alpha$ is the straight line
\[y - f(x_0) = f^\prime (x_0) (x - x_0)\]

This leads to the definition of our familiar tangent line. 

\begin{definition}[Tangent Line]
If a function $f: E \longrightarrow \mathbb{R}$ is differentiable at a point $x_0 \in E$, the line defined by
\[y - f(x_0) = f^\prime (x_0) (x - x_0)\]
is called the \textit{tangent} to the graph of $f$ at the point $(x_0, f(x_0))$. 
\end{definition}

\subsubsection{Higher Order Approximations}
We can continue this pattern to get a quadratic approximation of $f$ in the form
\[f(x) = c_0 + c_1 (x - x_0) + c_2 (x - x_0)^2 + o\big((x - x_0)^2 \big) \text{ as } x \rightarrow x_0\]
As we have done in the previous subsection, we can derive (assuming continuity of $f$) $c_0 = f(x_0), c_1 = f^\prime (x_0)$. To derive what $c_2$ should be, we see that the equation above implies
\[c_2 = \frac{f(x) - c_0 - c_1 (x - x_0) - o\big((x - x_0)^2 \big)}{(x - x_0)^2} = \frac{f(x) - c_0 - c_1 (x - x_0)}{(x - x_0)^2} - o(1)\]
which means
\[c_2 = \lim_{x \rightarrow x_0} \frac{f(x) - c_0 - c_1 (x - x_0)}{(x - x_0)^2}\]
Extending this, if we are seeking a polynomial $P_n(x_0; x) = c_0 + c_1 (x - x_0) + \ldots + c_n (x - x_0)^n$ such that
\[f(x) = c_0 + c_1 (x - x_0) + \ldots + c_n (x - x_0)^n + o\big((x - x_0)^n\big) \text{ as } x \rightarrow x_0\]
we would find 
\begin{align*}
    c_0 & = \lim_{x \rightarrow x_0} f(x) \\
    c_1 & = \lim_{x \rightarrow x_0} \frac{f(x) - c_0}{x - x_0} \\
    c_2 & = \lim_{x \rightarrow x_0} \frac{f(x) - c_0 - c_1 (x - x_0)}{(x - x_0)^2} \\
    \ldots & = \ldots \\
    c_n & = \lim_{x \rightarrow x_0} \frac{f(x) - (c_0 + \ldots + c_{n-1}(x - x_0)^{n-1})}{(x - x_0)^n}
\end{align*}

We formalize the order of these approximations by analyzing their error bound. 

\begin{definition}[nth Order Contact]
If $f, g: E \longrightarrow \mathbb{R}$ are continuous at point $x_0$ and $(f - g) (x) = o\big( (x - x_0)^n \big)$ as $x \rightarrow x_0$, then we say that $f$ and $g$ have \textit{$n$th order contact at $x_0$}, or more precisely, \textit{contact of order at least $n$}. 

The following visual shows approximations $g$ of an arbitrary function $f$ that have $0$th (left), $1$st (middle), and $2$nd (right) order contact at $x_0$. 
\begin{center}
    \includegraphics[scale=0.3]{nth_order_contact.PNG}
\end{center}
\end{definition}

\subsubsection{The Real Tangent Space}

\begin{definition}[Tangent Space]
Given function $f: E \longrightarrow \mathbb{R}$ and a point $x_0 \in E$, the increment of the argument $h = x - x_0$ can be regarded as a vector attached to the point $x_0$ and defining the transition from $x_0$ to $x_0 + h$. $h$ is called a \textit{tangent vector}, and the set of all such vectors as $T_{x_0} \mathbb{R}$. Similarly, we denote $T_{y_0} \mathbb{R}$ the set of all displacement vectors from the point $y_0$ along the $y$-axis. 
\begin{center}
    \includegraphics[scale=0.3]{Tangent_Space_1_dimensional_in_R.PNG}
\end{center}
Then, we can see that the differential is a mapping
\[df(x_0): T_{x_0} \mathbb{R} \longrightarrow T_{f(x_0)} \mathbb{R}\]
Note that that there are two functions to pay attention to here: 
\begin{enumerate}
    \item The true increment of $f$, defined $h \mapsto f(x_0 + h) - f(x_0) = \Delta f(x_0; h)$ (labeled in green). 
    \item The differential $h \mapsto f^\prime (x_0) h = df(x_0) (h)$, which gives the increment of the tangent to the graph for increment $h$ in the argument (labeled in red). 
\end{enumerate}
\end{definition}

\begin{example}
Let $f(x) = \sin{x}$. Then we will show that $f^\prime (x) = \cos{x}$. 
\begin{align*}
    \lim_{h \rightarrow 0} \frac{\sin{(x+h)} - \sin(x)}{h} & = \lim_{h \rightarrow 0} \frac{2 \sin \big( \frac{h}{2} \big) \cos \big( x + \frac{h}{2} \big)}{h} \\
    & = \lim_{h \rightarrow 0} \cos \Big( x + \frac{h}{2} \Big) \cdot \lim_{h\rightarrow 0} \frac{\sin\big( \frac{h}{2}\big)}{\big(\frac{h}{2}\big)} = \cos(x)
\end{align*}
Here, we have used the theorem on the limit of a product, the continuity of the function $\cos(x)$, the equivalence $\sin{t} \sim t$ as $t \rightarrow 0$, and the theorem on the limit of a composite function. 
\end{example}

\begin{example}
We will show that $\cos^\prime (x) = - \sin(x)$. 
\begin{align*}
    \lim_{h\rightarrow 0} \frac{\cos(x+h) - \cos(x)}{h} & = \lim_{h \rightarrow 0} \frac{-2 \sin \big(\frac{h}{2}\big) \, \sin \big( x + \frac{h}{2}\big)}{h} \\
    & = - \lim_{h\rightarrow 0} \sin \Big( x + \frac{h}{2} \Big) \cdot \lim_{h\rightarrow0} \frac{\sin\big(\frac{h}{2} \big)}{\big( \frac{h}{2} \big)} = -\sin(x)
\end{align*}
\end{example}

\subsection{Rules of Differentiation over $\mathbb{R}$}
\subsubsection{Basic Properties; Derivatives of Composite, Inverse Functions}
\begin{theorem}[Arithmetic Properties of Differentiation over $\mathbb{R}$]
If functions $f, g: E \longrightarrow \mathbb{R}$ are differentiable at a point $x \in E$, then 
\begin{enumerate}
    \item their sum is differentiable at $x$, and 
    \[d(f+g) (x) = df(x) + dg(x) \iff (f+g)^\prime (x) = (f^\prime + g^\prime) (x)\]
    \item their product is differentiable at $x$, and 
    \[d (f \cdot g) (x) = g(x) df(x) + f(x) dg(x) \iff (f \cdot g)^\prime (x) = f^\prime (x) \cdot g(x) + f(x) \cdot g^\prime (x)\]
    \item their quotient is differentiable at $x$ if $g(x) \neq 0$, and 
    \[d \Big( \frac{f}{g} \Big) (x) =  \frac{g(x) df(x) - f(x) dg(x)}{g^2 (x)} \iff \bigg(\frac{f}{g}\bigg)^\prime (x) = \frac{f^\prime (x) g(x) - f(x) g^\prime (x)}{g^2 (x)}\]
\end{enumerate}
It is clear that $c\cdot df(x) = d (cf)(x)$, it is clear that the derivative is a linear operator from the space of all functions differentiable at $x_0$ the space of all functions. 
\end{theorem}
\begin{proof}
Since $f$ and $g$ are differentiable at $x$, there exists the differential $df(x)(h) = f^\prime (x) h$ and $dg(x) = g^\prime (x) h$ where
\begin{align*}
    f(x + h) & = f(x) + df(x)(h) + o(h) = f(x) + f^\prime (x) h + o(h) \\
    g(x + h) & = g(x) + dg(x)(h) + o(h) = g(x) + g^\prime (x) h + o(h) 
\end{align*}
From this relation, we can clearly see that a certain property of the differential automatically implies the same property of the derivative. (Remember that $f^\prime (x)$ and $g^\prime(x)$ are not functions! They are scalars defined on fixed point $x$.) 
\begin{enumerate}
    \item Even though this derivation may be a bit long, every step is included to minimize ambiguity. 
    \begin{align*}
        (f + g)(x + h) - (f + g)(x) & = \big( f(x + h) + g(x + h)\big) - \big( f(x) + g(x)\big) \\
        & = \big( f(x + h) - f(x)\big) + \big(g(x + h) - g(x) \big) \\
        & = \big( df(x)(h) + o(h)\big) + \big( dg(x)(h) + o(h)\big) \\
        & = \big(f^\prime (x) h + o(h)\big) + \big( g^\prime (x) (h) + o(h)\big) \\
        & = \big(f^\prime(x) + g^\prime (x)\big) h + o(h) \\
        & = (f^\prime + g^\prime)(x)(h) + o(h) \\
        & = d (f + g)(x) h + o(h)
    \end{align*}
    \item For the product rule, we have
    \begin{align*}
        (f \cdot g) (x + h) & - (f \cdot g)(x) = f(x+h)g(x+h) - f(x) g(x) \\
        & = \big(f(x) + df(x) (h) + o(h)\big)\big(g(x) + dg(x)(h) + o(h)\big) - f(x) g(x) \\
        & = \big(f(x) + f^\prime (x) h + o(h)\big)\big(g(x) + g^\prime (x) h + o(h)\big) - f(x) g(x)
    \end{align*}
    Expanding this gives 
    \begin{multline*}
        \big(f^\prime (x) g(x) + f(x) g^\prime(x)\big) h + \big(f(x) + g(x)\big) o(h) + \\ f^\prime (x) g^\prime (x) h^2 + \big(f^\prime (x) + g^\prime (x) \big) h o(h) + \big(o(h)\big)^2
    \end{multline*}
    but note that since $f(x), g(x), f^\prime(x), g^\prime (x)$ are constants, we see that 
    \begin{enumerate}
        \item $\big(f(x) + g(x)\big) o(h) = o(h)$ because 
        \[\lim_{h \rightarrow 0} \frac{\big(f(x) + g(x)\big) o(h)}{h} = \big(f(x) + g(x)\big) \lim_{h \rightarrow 0} \frac{o(h)}{h} = 0\]
        \item $f^\prime(x) g^\prime (x) h^2 = o(h)$ since
        \[\lim_{h \rightarrow 0} \frac{f^\prime(x) g^\prime (x) h^2}{h} = f^\prime(x) g^\prime (x) \lim_{h \rightarrow 0}  h = 0\]
        \item $\big(f^\prime(x) + g^\prime(x)\big) h o(h) = o(h)$ because 
        \[\lim_{h \rightarrow 0} \frac{\big(f^\prime(x) + g^\prime(x)\big) h o(h)}{h} = \big(f^\prime(x) + g^\prime(x)\big) \lim_{h \rightarrow 0} o(h) = 0\]
        In fact, this term is of $o(h^2)$. 
        \item We can see that $(o(h))^2 = o(h)$ since 
        \[\lim_{h \rightarrow 0} \frac{(o(h))^2}{h} = \lim_{h \rightarrow 0} \frac{o(h)}{h} \cdot \lim_{h \rightarrow 0} o(h) = 0 \cdot 0 = 0\]
        In fact, $(o(h))^2 = o(h^2)$. 
    \end{enumerate}
    Therefore, the above simplifies to 
    \[(f \cdot g)(x + h) - (f \cdot g) (x) = \big(f^\prime(x) g(x) + f(x) g^\prime (x)\big) h + o(h)\]
    But this means that the differential (best approximation) $d(f \cdot g) (x)$ must be 
    \[(f \cdot g)^\prime (x) (h) = (f \cdot g)^\prime (x) h = \big(f^\prime(x) g(x) + f(x) g^\prime (x)\big) h\]
    \item Since the function $g(x) \neq 0$ at point $x$, then by continuity we can assume that there exists a neighborhood $U(x)$ where the image of that neighborhood does not vanish. That is, we can guarantee that $g(x + h) \neq 0$ for sufficiently small values of $h$. We assume $h$ is small in the following computations. 
    \begin{align*}
        \bigg(\frac{f}{g}\bigg) (x + h) - \bigg( \frac{f}{g}\bigg) (x) & = \frac{f(x + h)}{g(x + h)} - \frac{f(x)}{g(x)} \\
        & = \frac{1}{g(x)g(x + h)} \big( f(x + h) g(x) - f(x) g(x + h)\big) \\
        & = \bigg(\frac{1}{g^2(x)} + o(1)\bigg) \Big( \big(f(x) + f^\prime(x) h + o(h)\big) g(x) \\
        & \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;- f(x) \big( g(x) + g^\prime(x) h + o(h)\big)\Big) \\
        & = \bigg(\frac{1}{g^2(x)} + o(1)\bigg) \Big(\big(f^\prime(x) g(x) - f(x) g^\prime(x)\big) h + o(h)\Big) \\
        & = \frac{f^\prime(x) g(x) - f(x) g^\prime(x)}{g^2 (x)} h + o(h)
    \end{align*}
    Note that here we have used the continuity of $g$ at the point $x$ and the fact that $g(x) \neq 0$ to deduce that
    \[\lim_{h \rightarrow 0} \frac{1}{g(x) g(x + h)} = \frac{1}{g^2(x)} \iff \frac{1}{g(x) + g(x + h)} = \frac{1}{g^2(x)} + o(1)\]
    where $o(1)$ is infinitesimal as $h \rightarrow 0$. 
\end{enumerate}
\end{proof}

\begin{theorem}[Chain Rule for Composite Functions over $\mathbb{R}$]
Let there be functions $f: E_1 \subset \mathbb{R} \longrightarrow E_2 \subset \mathbb{R}$ is differentiable at a point $x \in E_1$ and the function $g: E_2 \subset \mathbb{R} \longrightarrow \mathbb{R}$ is differentiable at point $y = f(x) \in E_2$, with respective differentials 
\begin{align*}
    df(x)& : T_x \mathbb{R} \longrightarrow T_y \mathbb{R} \\
    dg(y)& : T_y\mathbb{R} \longrightarrow T_{g(y)} \mathbb{R}
\end{align*}
Then the composite function $g \circ f: E_1 \longrightarrow \mathbb{R}$ is differentiable at $x$, and $d(g \circ f)(x): T_x \mathbb{R} \longrightarrow T_{g \circ f(x)} \mathbb{R}$ is
\[d(g \circ f)(x) = d g(y) \circ d f(x) \iff (g \circ f)^\prime (x) = g^\prime \big( f(x) \big) \circ f^\prime (x)\]
\end{theorem}
\begin{proof}
We will denote the increment of the argument with the variables $h$ and $t$. Then, by differentiability of $f$ and $g$, we have
\begin{align*}
    f(x + h) - f(x) & = f^\prime (x) h + o(h) \text{ as } h \rightarrow 0 \\
    g(y + t) - g(y) & = g^\prime(y) t + o(t) \text{ as } t \rightarrow 0
\end{align*}
Since the function $o(t)$ can be represented as $o(t) = \gamma(t) t$, where $\gamma = o(1)$ and hence is infinitesimal as $t \rightarrow 0$, meaning that we can assume $\gamma(0) = 0$ (since $o(t)$ is defined for $t = 0$). 

We can think of the displacement of $x$ as like a chain reaction: As$x \mapsto x + h$, $f(x) \mapsto f(x + h)$, which we could interpret as $y \mapsto y + t$ and hence means that $g(y) \mapsto g(y + t)$. So, setting $f(x) = y$ and $f(x + h) = y + t$, by differentiability and hence continuity of $f$ at point $x$, we can conclude that $t \rightarrow 0$ as $h \rightarrow 0$. So, we have
\[\gamma\big(f(x+h) - f(x)\big) = \gamma\big( (y+t) - y\big) = \gamma(t) = \alpha(h) \rightarrow 0 \text{ as } h \rightarrow 0\]
Thus, we get 
\begin{align*}
    o(t) = \gamma(t) t & = \gamma\big( f(x + h) - f(x)\big)\big( f(x + h) - f(x)\big) \\
    & = \alpha(h) \big(f^\prime(x) h + o(h)\big) \\
    & = \alpha(h) f^\prime(x) h + \alpha(h) o(h) \\
    & = o(h) + o(h) = o(h) \text{ as } h \rightarrow 0 \\
    (g \circ f)(x + h) - (g \circ f)(x) & = g\big(f(x + h)\big) - g\big(f(x)\big) \\
    & = g (y + t) - g(y) \\
    & = g^\prime (y) t + o(t) \\
    & = g^\prime \Big(f(x)\big) \big(f(x + h) - f(x)\big) + o\big( f(x + h) - f(x)\big) \\
    & = g^\prime \big(f(x)\big) \big(f^\prime (x) h + o(h)\big) + o\big( f(x + h)\big) - f(x)\big) \\
    & = g^\prime\big( f(x) \big) \big( f^\prime (x) h\big) + g^\prime \big( f(x)\big) \big(o(h)\big) + o\big(f(x + h) - f(x)\big) 
\end{align*}
Since $g^\prime\big(f(x)\big) \big( o(h)\big)$ is really just a constant multiplied by a function that is $o(h)$, it is $o(h)$. $o\big( f(x + h) - f(x) \big)$. As for $o\big(f(x + h) - f(x)\big)$, we see that since $f(x + h) - f(x) = t$, a function that is $o\big(f(x + h) - f(x)\big)$ becomes infinitesimal compared to $t$ as $t \rightarrow 0$. As already stated before, we have
\[o\big(f(x + h) - f(x) \big) = o(h) \text{ as } h \rightarrow 0\]
and thus, we proved that
\begin{align*}
    (g \circ f)(x + h) - (g \circ f)(x) & = g^\prime (y) f^\prime (x) h + o(h) \\
    & = \big(dg(y) \circ df(x)\big) (h) + o(h)
\end{align*}
\end{proof}

\begin{theorem}[Differentiation of Inverse Functions over $\mathbb{R}$]
Let $E_1, E_2 \subset \mathbb{R}$, and $f: E_1 \longrightarrow E_2$ and $f^{-1}: E_2 \longrightarrow E_1$ be mutually inverse and continuous at points $x_0 \in E_1$ and $f(x_0) = y_0 \in E_2$. If $f$ is differentiable at $x_0$ and $f^\prime(x_0) \neq 0$, then $f^{-1}$ also differentiable at the point $y_0$, and 
\[\big(f^{-1}\big)^{-1} (y_0) = \big(f^\prime (x_0)\big)^{-1} \iff df^{-1} (y_0) = \big(df(x_0)\big)^{-1}\]
\begin{center}
    \includegraphics[scale=0.3]{Real_Analysis_Differentiation_Inverse_Functions.PNG}
\end{center}
Note that if we knew in advance that $f^{-1}$ was differentiable at $y_0$ (which is a stronger hypothesis), we can find immediately by the identity 
\[(f^{-1} \circ f) (x) = x\]  
and the theorem on the differentiation of a composite function that
\[(f^{-1})^\prime (y_0) \cdot f^\prime (x_0) = 1\]
\end{theorem}

Note that if the hypothesis was satisfied, but $f^\prime (x_0) = 0$, then $f^{-1}$ would not be differentiable since it would have an undefined differential. 
\begin{center}
    \includegraphics[scale=0.3]{Inverse_Function_Differentiation_Derivative_Zero_problem.PNG}
\end{center}
\subsubsection{Higher-Order Derivatives}

\begin{definition}[Global Derivative Function]
If function $f: E \longrightarrow \mathbb{R}$ is differentiable at every point $x \in E$, then a new function $f^\prime: E \longrightarrow \mathbb{R}$, whose value at a point $x \in E$ equals the derivative $f^\prime(x)$ of the function $f$ at the point. 
\end{definition}

\begin{definition}[Second, Nth Derivative]
This function $f^\prime$ may itself have a derivative $(f^\prime)^\prime : E \longrightarrow \mathbb{R}$, called the \textit{second derivative} of the original function $f$, denoted 
\[f^{\prime\prime} (x), \;\;\; \frac{d^2 f(x)}{dx^2}\]
By induction, if the derivative $f^{(n-1)} (x)$ of order $n-1$ of $f$ has been defined, then the \textit{derivative of order $n$} is defined by the formula
\[f^{(n)} (x) \equiv \big(f^{(n-1)}\big)^\prime (x)\]
The set of function $f: E \longrightarrow \mathbb{R}$ having continuous derivatives up to order $n$ inclusive is denoted $C^{n} (E, \mathbb{R})$. 
\end{definition}

\begin{lemma}[Leibniz' Formula]
Let $u(x)$ and $v(x)$ be functions having derivatives up to order $n$ inclusive on a common set $E$. Then, 
\[(uv)^{(n)} = \sum_{m = 0}^n {n\choose m} u^{(n-m)} v^{(m)}\]
This means that given a polynomial $P_n (x) = c_0 + c_1 (x - x_0) + \ldots + c_n (x - x_0)^n$, then 
\begin{align*}
    P_n(x_0) & = 0 \\
    P_n^\prime (x_0) & = 1! c_1 \\
    P_n^{\prime\prime} (x_0) & = 2! c_2 \\
    \ldots & = \ldots \\
    P_n^{(n)} (x_0) & = n! c_n \\
    P_n^{(k)} (x_0) & = 0 \text{ for } k > n
\end{align*}
and thus the polynomial $P_n (x)$ can be written as
\[P_n (x) = P_n^{(0)} (x_0) + \frac{1}{1!} P_n^{(1)} (x_0) (x-x_0) + \frac{1}{2!} P_n^{(2)} (x_0) (x-x_0)^2 + \ldots + \frac{1}{n!} P_n^{(n)} (x_0) (x-x_0)^n\]
\end{lemma}

\subsection{Theorems of Differential Calculus}
\subsubsection{Fermant's Lemma, Rolle's Theorem}

\begin{definition}[Local Extrema]
A point $x_0 \in E \subset \mathbb{R}$ is called a \textit{local maximum} (resp. \textit{local minimum}) and the value of a function $f: E \longrightarrow \mathbb{R}$ at that point a \textit{local maximum value} (resp. \textit{local minimum value}) if there exists a neighborhood $U_E (x_0)$ of $x_0$ in $E$ such that at any point $x \in U_E (x_0)$ we have 
\[f(x) \leq f(x_0), \big( \text{resp. } f(x) \geq f(x_0) \big)\]
If this is a strict inequality
\[f(x) < f(x_0), \big( \text{resp. } f(x) > f(x_0) \big)\]
then $x_0$ is called a \textit{strict local maximum} (resp. \textit{strict local minimum}). 
\end{definition}

\begin{definition}[Interior Extrema]
An extremum $x_0 \in E$ of the function $f: E \longrightarrow \mathbb{R}$ is called an \textit{interior extremum} if $x_0$ is not on the boundary of $E$, or more rigorously, $x_0$ is a limit point of both sets $E_- = \{x \in E \;|\; x < x_0\}$ and $E_+ = \{ x\in E\;|\; x > x_0\}$. For example, the graphs below are interior extrema at $x_0, x_0^*$. 
\begin{center}
    \includegraphics[scale=0.3]{Interior_Extrema.PNG}
\end{center}
But the following graphs show extrema (at $x_0$) that are not interior extrema. 
\begin{center}
    \includegraphics[scale=0.3]{Non_Interior_Extrema.PNG}
\end{center}
\end{definition}

\begin{lemma}[Fermant]
If a function $f: E \longrightarrow \mathbb{R}$ is differentiable at an interior extrememum $x_0 \in E$, then its derivative at $x_0$ is $0$. That is, 
\[f^\prime (x_0) = 0\]
Thus, this lemma gives a necessary condition for an interior extremum of a differentiable function. But for non-iterior extrema, it is generally not true that $f^\prime(x_0) = 0$ and so the converse does not hold (labeled in green). 
\begin{center}
    \includegraphics[scale=0.3]{Fermant_Condition_for_Extrema.PNG}
\end{center}
\end{lemma}
\begin{proof}
By definition of differentiability at $x_0$ we get
\begin{align*}
    f(x_0 + h) - f(x_0) & = f^\prime (x_0) h + o(h) \\
    & = f^\prime(x_0) h + \alpha (x_0; h) h \\
    & = \big(f^\prime (x_0) + \alpha(x_0; h)\big) h
\end{align*}
where we know that $o(h)$ can be written as $o(1) h$ for some infinitesimal $o(1)$ as $h \rightarrow 0$. If $f^\prime (x_0) \neq 0$, then for $h$ sufficiently close to $0$ the quantity $f^\prime(x_0) + \alpha(x_0; h)$ would have the same sign as $f^\prime (x_0)$, since $\alpha(x_0; h) \rightarrow 0$ as $h \rightarrow 0$. But the value of $h$ can be both positive or negative, given that $x_0$ is an interior extremum. This contradiction must imply that $f^\prime (x_0) = 0$. 
\end{proof}

Geometrically, Fermant's lemma is obvious, since it asserts that at an extremum of a differentiable function, the tangent to its graph is horizontal. Physically, this lemma means that in motion along a line the velocity must be zero at the instant then the direction reverses. 

\begin{theorem}[Rolle's Theorem]
If a function $f: [a, b] \longrightarrow \mathbb{R}$ is continuous on a closed interval $[a,b]$ and differentiable on the open interval $(a, b)$ and $f(a) = f(b)$, then there exists a point $\zeta \in (a, b)$ such that $f^\prime (\zeta) = 0$. 
\begin{center}
    \includegraphics[scale=0.3]{Analysis_Rolles_Theorem.PNG}
\end{center}
\end{theorem}

\subsubsection{Mean Value Theorem, Cauchy's Finite-Increment Theorem}

The following theorem is extremely useful in studying numerical valued functions. 

\begin{theorem}[Mean Value Theorem]
If a function $f: [a,b] \longrightarrow \mathbb{R}$ is continuous on a closed interval $[a,b]$ and differentiable on the open interval $(a, b)$, there exists a point $\zeta \in (a, b)$ such that 
\[f^\prime (\zeta) = \frac{f(b) - f(a)}{b - a} \iff f(b) - f(a) = f^\prime (\zeta) (b-a)\]
Geometrically, this means that there exists a tangent line somewhere at $\zeta \in (a, b)$ that is parallel the secant line connecting the two points $\big(a, f(a)\big)$ and $\big( b, f(b)\big)$. 
\begin{center}
    \includegraphics[scale=0.3]{Analysis_Mean_Value_Theorem_Diagram.PNG}
\end{center}
\end{theorem}

Some remarks: 
\begin{enumerate}
    \item Physically, if $x$ is interpreted as time and $f(b) - f(a)$ as the amount of displacement over the time $b-a$ of a particle moving along the line, this theorem says that the velocity $f^\prime (x)$ of the particle at some time $\zeta \in (a, b)$ is such that if the particle had moved with constant velocity $f^\prime (\zeta)$ over the whole time interval, it would have been displaced by the same amount $f(b) - f(a)$. We call $f^\prime (\zeta)$ the \textit{average velocity} over the time interval $[a, b]$. 
    \item Note that the Mean Value Theorem is important in that it connects the increment of a function over a finite interval with the derivative of the function on that interval. Up to now, we have characterized only the local (infinitesimal) increment of a function in terms of the derivative or differential at a given point. MVT connects the increment of a function over a \textit{finite} interval with the derivative of the function. 
\end{enumerate}

The MVT actually leads to multiple useful corollaries. 

\begin{corollary}[Derivative of a Monotonic Function]
If the derivative of a function is nonnegative (resp. positive) at every point of an open interval, then the function is nondecreasing (resp. increasing) on that interval. 
\end{corollary}
\begin{proof}
If $x_1 < x_2$ are two points of the interval, then the MVT
\[f(x_2) - f(x_1) = f^\prime (\zeta) (x_2 - x_1)\]
shows that the sign of the left hand side must equal that of the right. 
\end{proof}

\begin{corollary}[Derivative of a Constant Function]
A function that is continuous on a closed interval $[a,b]$ is constant on it if and only if its derivative equals $0$ at every point of the interval $[a,b]$ or the open interval $(a, b)$. 

Therefore, if the derivatives $f_1^\prime (x)$ and $f_2^\prime (x)$ of two functions $f_1 (x)$ and $f_2 (x)$ are equal on some interval (that is, $f_1^\prime (x) = f_2^\prime (x)$ on the interval), then the difference
\[(f_1 - f_2) (x) = f_1 (x) - f_2 (x)\]
is constant. 
\end{corollary}
\begin{proof}
Given constant function $f$, the MVT equation 
\[0 = f(x_2) - f(x_1) = f^\prime (\zeta) (x_2 - x_1)\]
implies that $f^\prime (\zeta) = 0$ for all $x_1, x_2 \in E$. It follows that by the arithmetic properties of the derivative, given two functions $f_1, f_2$ with the same derivative on an interval, the derivative of their difference $(f_1 - f_2)^\prime = 0$, and therefore must be constant on that interval. 
\end{proof}

The following proposition is a useful generalization of Lagrange's theorem. 
\begin{theorem}[Cauchy's Finite-Increment Theorem]
Let $x = x(t)$ and $y = y(t)$ be functions that are continuous on a closed interval $[\alpha, \beta]$ and differentiable on the open interval $(\alpha, \beta)$. Then, there exists a point $\tau \in [\alpha, \beta]$ such that
\[x^\prime (\tau) \big( y(\beta) - y (\alpha)\big) = y^\prime (\tau) \big( x(\beta) - x(\alpha)\big)\]
If in addition $x^\prime (t) \neq 0$ for each $t \in (\alpha, \beta)$, then $x(\alpha) \neq x(\beta)$ and we have the equality 
\[\frac{y(\beta) - y(\alpha)}{x(\beta) - x(\alpha)} = \frac{y^\prime (\tau)}{x^\prime (\tau)}\]
\end{theorem}

\subsubsection{Taylor's Formula}
From the following results one may deduce that the more derivatives of two functions coincide (including the derivative of the $0$th order) at a point, the better these functions approximate each other in a neighborhood of that point. Using Leibniz's rule, approximations up to a certain degree at a point can be expressed as a polynomial 
\[P_n (x_0; x) = P_n (x_0) + \frac{P_n^\prime (x_0)}{1!} (x-x_0) + ... + \frac{P_n^{(n)} (x_0)}{n!} (x-x_0)^n\]
where each coefficient of the polynomial 

\begin{definition}[Taylor Polynomial]
If a function $f:E \longrightarrow \mathbb{R}$ has derivatives of all orders $n \in \mathbb{N}$ at a point $x_0$, the unique series
\[P_n (x_0; x) = f(x_0) + \frac{f^\prime (x_0)}{1!} (x-x_0) + ... + \frac{f^{(n)} (x_0)}{n!} (x-x_0)^n\]
is the \textit{Taylor polynomial of order $n$ of $f(x)$ at $x_0$}. We can see that the derivatives of $f$ and $P_n$ coincide up to order $n$. 
\end{definition}

\begin{definition}[Analytic Functions]
We cannot assume that the Taylor series of an infinitely differentiable function converges to the function $f$ within a neighborhood $U(x_0)$, nor can we assume that it converges at all! These types of "nice" functions that have a Taylor approximation within the neighborhood of $x_0$ are called \textit{analytic functions} and can be written in the form 
\[f(x) =  f(x_0) + \frac{f^\prime (x_0)}{1!} (x-x_0) + ... + \frac{f^{(n)} (x_0)}{n!} (x-x_0)^n + r_n (x_0; x)\]
where $r$ is called the \textit{remainder term}. 
\end{definition}

\begin{example}[Infinitely Differentiable, Non-Analytic Function]
A example of a non-analytic function is
\[f(x) = \begin{cases}
e^{-1/x^2} & \text{ if } x \neq 0 \\
0 & \text{ if } x = 0
\end{cases}\]
which looks like
\begin{center}
    \includegraphics[scale=0.25]{Infinitely_Differentiable_Non_Analytic_Function.PNG}
\end{center}
One can verify that the derivative $f^{(k)} (0) = 0$ for all $k$ and hence the Taylor series is identically equal to $0$, while $f(x) \neq 0$ if $x \neq 0$. 
\end{example}

The relationship between these different conditions is nicely summarized in the figure. 
\begin{center}
\begin{tikzpicture}
    \draw (-7.5,0) rectangle (7.5, 4);
    \draw[fill=lightgray] (-6.5, 0.5) rectangle (6.5, 3);
    \draw[fill=white] (-5.5, 1) rectangle (5.5, 2);
    \node[above] at (0, 1) {Taylor series converges to $f$ at $x_0 \iff f$ is analytic};
    \node[above] at (0, 2) {Taylor series converges at $x_0$};
    \node[above] at (0, 3) {$f$ infinitely differentiable at $x_0 \iff $ Taylor series of $f$ exists at $x_0$};
\end{tikzpicture}
\end{center}

The following lemma proves why Taylor Polynomials are considered a "good" approximations to analytic functions. 

\begin{lemma}[Infinitesimality of Functions with Vanishing Derivative up to Order $n$]
Given a function $\varphi: E \longrightarrow \mathbb{R}$ defined on a closed interval $E$ with endpoint $x_0$, let its derivatives vanish up to order $n$ at $x_0$. That is
\[\varphi(x_0) = \varphi^\prime (x_0) = \ldots = \varphi^{(n)} (x_0) = 0\]
Then, $\varphi = o\big((x - x_0)^n\big)$ as $x \rightarrow x_0$. 
\end{lemma}
\begin{proof}
We prove by induction. For $n = 1$, the definition of differentiability states that 
\[\varphi(x) = \varphi^(x_0) + \varphi^\prime (x - x_0) + o(x - x_0) \text{ as } x \rightarrow x_0\]
and so we have proved that 
\[\varphi(x_0) = \varphi^\prime (x_0) = 0 \implies \varphi(x) = o(x - x_0) \text{ as } x \rightarrow x_0\]
Now, suppose this assertion has been proved for order $n = k - 1 \geq 1$. That is, we have shown that 
\[\varphi(x_0) = \ldots = \varphi^{(k-1)}(x_0) = 0 \implies \varphi= o\big((x - x_0)^{k-1}\big) \text{ as } x \rightarrow x_0\]
Then we must show that this is valid for order $n = k \geq 2$. Assume that 
\[\varphi(x_0) = \varphi^\prime (x_0) = \ldots = \varphi^{(k)} (x_0) = 0\]
We can see that this is equivalent to
\[(\varphi^\prime)^\prime (x_0) = (\varphi^\prime)^{(2)} (x_0) = \ldots = (\varphi^\prime)^{(k-1)} = 0\]
and therefore by the induction assumption, we have
\[\varphi^\prime = o\big( (x - x_0)^{k-1}\big) \text{ as } x \rightarrow x_0\]
which means that we can put it in form 
\[\varphi(x) = \alpha (x) (x - x_0)^{k-1} \text{ so that } \lim_{x \rightarrow x_0} \varphi(x) = \lim_{x \rightarrow x_0} \alpha(x) = 0 \]

From the mean value theorem and substituting what we have above, we get 
\begin{align*}
    \varphi(x) = \varphi(x) - \varphi(x_0) & = \varphi^\prime(\zeta) (x - x_0) \\
    & = \varphi (\zeta) (\zeta - x_0)^{k-1} (x - x_0)
\end{align*}
where $\zeta \in (x_0, x)$. However, this implies that $|\zeta - x_0| < |x - x_0|$, and thus, as $x \rightarrow x_0$, $\zeta \rightarrow x_0$, which then makes $\alpha(\zeta) \rightarrow 0$. Since
\[|\varphi (x)| \leq |\alpha(\zeta)| |x - x_0|^{k-1} |x - x_0| = |\alpha(\zeta)| |x - x_0|^k\]
This means that $\varphi(x)$ is bounded by function $|\alpha(\zeta)| |x - x_0|^k$, which is $o\big((x-x_0)^k\big)$, and so 
\[\varphi = o\big( (x - x_0)^k \big) \text{ as } x \rightarrow x_0\]
By induction, this works for all orders $n$. 
\end{proof}

\begin{theorem}[Peano's Form of the Remainder]
Given analytic function $f: E \longrightarrow \mathbb{R}$, a point $x_0 \in E$, and its $n$th order Taylor polynomial $P_n (x_0; x)$ around $x_0$, $P_n$ is a "good" approximation of $f$ in the fact that its error term is $o\big((x - x_0)^n\big)$. That is, 
\[f(x) = P_n (x_0; x) + o\big((x - x_0)^n \big) \text{ as } x \rightarrow x_0\]
This equation where $r_n (x; x_0) = o\big((x - x_0)^n\big)$ is called the \textit{Peano's form of the remainder}. 
\end{theorem}
\begin{proof}
Since the Taylor polynomial $P_n (x_0; x)$ is constructed from the requirement that its derivatives up to order $n$ inclusive must coincide with the corresponding derivatives of $f$ at $x_0$, it follows that
\[r_n (x_0; x_0) \equiv f^{(k)} (x_0) - P_n^{(k)} (x_0; x_0) = 0 \text{ for } k = 0, 1, \ldots, n\]
Using the previous lemma, a this means that $r_n (x; x_0) = o\big((x - x_0)^n\big)$ as $x \rightarrow x_0$. 
\end{proof}

\begin{theorem}[Lagrange Form of the Remainder]
If $f: E \longrightarrow \mathbb{R}$ has derivatives of order $n+1$ on the open interval with endpoints $x_0$ and $x$, then 
\[f(x) = f(x_0) + \frac{f^\prime (x_0)}{1!} (x - x_0) + \ldots + \frac{f^{(n)}(x_0)}{n!} (x - x_0)^n + r_n (x; x_0)\]
where 
\[r_n (x; x_0) = \frac{f^{(n+1)} (\zeta)}{(n+1)!} (x - x_0)^{n+1}\]
This form is called \textit{Taylor's formula with the Lagrange form of the remainder}. Furthermore, this form says that if $f^{(n+1)} (x)$ is bounded in a neighborhood of $x_0$, it also implies the formula
\[f(x) = f(x_0) + \frac{f^\prime (x_0)}{1!} (x - x_0) + \ldots + \frac{f^{(n)} (x_0)}{n!} (x - x_0)^n + O\big( (x - x_0)^{n+1} \big)\]
Therefore, we can use this boundedness of $f^{(n+1)}$ to find the maximum error bound 
\[|r_n (x; x_0)|\]
of $P_n (x; x_0)$. 
\end{theorem}
\begin{proof}
It is a direct result from the lemma. This is actually a generalization of the mean value theorem but for higher orders. 
\end{proof}

\begin{corollary}[Table of Asymptotic Formulas for Elementary Functions]
We write the Maclaurin series (Taylor series around $x = 0$) for elementary functions. Note that these error terms are $O(x^{n+1})$ (bounded compared to $x^{n+1}$) and $o(x^n)$ (infinitesimal compared to $x^n$). 
\begin{align*}
    e^x & = 1 + \frac{1}{1!} x + \frac{1}{2!} x^2 + \ldots + \frac{1}{n!} x^n + O(x^{n+1}) \\
    \cos{x} & = 1 - \frac{1}{2!} x^2 + \frac{1}{4!}x^4 - \ldots + \frac{(-1)^n}{(2n)!} x^{2n} + O(x^{2n+2}) \\
    \sin{x} & = x - \frac{1}{3!} x^3 + \frac{1}{5!}x^5 - \ldots + \frac{(-1)^n}{(2n+1)!} x^{2n+1} + O(x^{2n+3}) \\
    \cosh{x} & = 1 + \frac{1}{2!} x^2 + \frac{1}{4!} x^4 + \ldots + \frac{1}{(2n)!} x^{2n} + O(x^{2n+2}) \\
    \sinh{x} & = x + \frac{1}{3!} x^3 + \frac{1}{5!} x^5 + \ldots + \frac{1}{(2n+1)!} x^{2n+1} + O(x^{2n+3}) \\
    \ln{(1+x)} & = x - \frac{1}{2}x^2 + \frac{1}{3} x^3 - \ldots + \frac{(-1)^n}{n} x^n + O(x^{n+1}) \\
    (1 + x)^\alpha & = 1 + \frac{\alpha}{1!} x + \frac{\alpha(\alpha-1)}{2!} x^2 + \ldots + \frac{\alpha (\alpha-1) \ldots (\alpha - n + 1)}{n!} x^n + O(x^{n+1})
\end{align*}
\end{corollary}

\subsection{The Study of Functions using Differential Calculus}

\subsubsection{Conditions for Monotonicity of Functions}
We can now connect the concepts of derivatives and monotonicity. 

\begin{theorem}[Derivative $\implies$ Monotonicity]
Given function $f: E \longrightarrow \mathbb{R}$ that is differentiable on an open interval $(a, b) = E$, 
\begin{align*}
    f^\prime (x) > 0 & \implies f \text{ is increasing} \\
    f^\prime (x) \geq 0 & \iff f \text{ is nondecreasing} \\
    f^\prime (x) \equiv 0 & \iff f \text{ is constant} \\
    f^\prime (x) \leq 0 & \iff \text{ is nonincreasing} \\
    f^\prime (x) < 0 & \implies f \text{ is decreasing} 
\end{align*}
Note that if $f$ is strictly increasing (resp. decreasing), we cannot determine that $f^\prime(x) \geq 0$ (resp. $f^\prime (x) \leq 0$). For example, take the function $f(x) = x^3$, which is strictly increasing, but has derivative $f^\prime (0) = 0$ at $x = 0$. 
\begin{center}
    \includegraphics[scale=0.3]{Monotonicity_Counterexample_x3.PNG}
\end{center}
It is clearly strictly increasing within a neighborhood $U(0)$, so we can see that
\begin{align*}
    f \text{ is increasing} & \implies f^\prime (x) \geq 0 \\
    f \text{ is decreasing} & \implies f^\prime (x) \leq 0
\end{align*}
\end{theorem}


\subsubsection{Conditions for Extrema of Functions}
Similarly, we can connect the concepts of extrema and derivatives. 

\begin{theorem}[First Derivative Test]
Let function $f: E \longrightarrow \mathbb{R}$ be defined in a neighborhood $U(x_0)$ of point $x_0$, which is continuous at $x_0$ and differentiable in $\mathring{U}(x_0)$, a deleted neighborhood of $x_0$. (Note that this is broader hypothesis than just assuming that $f$ be differentiable at $x_0$.) Let
\[\mathring{U}^- (x_0) \equiv \{x \in U(x_0) \;|\; x < x_0\}, \;\; \mathring{U}^+ (x_0) \equiv \{x \in U(x_0) \;|\; x > x_0\}\]
That is, $\mathring{U}^- (x_0)$ is the left portion of $\mathring{U}(x_0)$ and $\mathring{U}^+ (x_0)$ is the right portion of $\mathring{U}(x_0)$. Then, 
\begin{enumerate}
    \item $(x_0, f(x_0))$ is strict local minimum if $f^\prime(x) < 0$ in $\mathring{U}^- (x_0)$ and $f^\prime (x) > 0$ in $\mathring{U}^+ (x_0)$. 
    \begin{center}
        \includegraphics[scale=0.3]{Strict_Local_minimum.PNG}
    \end{center}
    \item $(x_0, f(x_0))$ is strict local maximum if $f^\prime(x) > 0$ in $\mathring{U}^- (x_0)$ and $f^\prime (x) < 0$ in $\mathring{U}^+ (x_0)$. 
    \begin{center}
        \includegraphics[scale=0.3]{Strict_Local_Maximum.PNG}
    \end{center}
    \item $(x_0, f(x_0))$ has no extremum at $x_0$ if $f^\prime (x) > 0$ in both $\mathring{U}^- (x_0), \mathring{U}^+ (x_0)$, or if $f^\prime(x)< 0$ in both $\mathring{U}^- (x_0), \mathring{U}^+ (x_0)$. 
    \begin{center}
        \includegraphics[scale=0.28]{No_Extremum.PNG}
    \end{center}
\end{enumerate}
\end{theorem}

Note that if there is a discontinuity at a point $x_0$, then this theorem does not apply. For example, $(x_0, f(x_0))$ in the graph below is a local minimum, even though the derivatives to the left of $x_0$ are positive and those to the right of $x_0$ are negative (within neighborhood $U(x_0)$). Similarly, $(x_0, g(x_0))$ is a local maximum, even though the derivative to the left and to the right of $x_0$ are both positive. 
\begin{center}
    \includegraphics[scale=0.3]{Theorem_not_apply_if_Discontinuity.PNG}
\end{center}

\begin{proposition}[2nd, $n$th Derivative Test]
Let function $f: E \longrightarrow \mathbb{R}$ be defined on a neighborhood $U(x_0)$ of $x_0$ has derivatives of order up to $n$ inclusive at $x_0$. If its derivatives up to the $(n-1)$th order vanishes 
\[f^\prime (x_0) = f^{\prime\prime} (x_0) ... = f^{(n-1)} (x_0) = 0\]
but the $n$th derivative at $x_0$ does \textbf{not} vanish
\[f^{(n)} (x_0) \neq 0\]
then 
\begin{enumerate}
    \item $n$ is odd $\implies$ there is no local extremum at $x_0$ 
    \item $n$ is even $\implies$ there is a local extremum at $x_0$
    \begin{enumerate}
        \item $f^{(n)} (x_0) > 0 \implies$ it is a strict local minimum
        \item $f^{(n)} (x_0) < 0 \implies$ it is a strict local maximum
    \end{enumerate}
\end{enumerate}
\end{proposition}

\subsubsection{Important Algebraic Inequalities}

We also introduce various inequalities that may be useful for producing future results. The following lemmas can be proved with elementary algebra. 

\begin{lemma}[Young's Inequalities]
If $a>0$ and $b>0$, and the numbers $p$ and $p$ are such that $p \neq 0, 1$ and $q \neq 0, 1$, and $\frac{1}{p} + \frac{1}{q} = 1$, then 
\begin{align*}
    a^{\frac{1}{p}} b^{\frac{1}{q}} \leq \frac{1}{p} a + \frac{1}{q} b \text{  if } p > 1 \\
    a^{\frac{1}{p}} b^{\frac{1}{q}} \geq \frac{1}{p} a + \frac{1}{q} b \text{  if } p < 1
\end{align*}
and equality holds in both cases if and only if $a = b$. 
\end{lemma}

\begin{lemma}[Holder's Inequalities]
Let $x_i \geq 0, y_i \geq 0$ for $i = 1, 2, ..., n$, and let $\frac{1}{p} + \frac{1}{q} = 1$. Then, 
\begin{align*}
    &\sum_{i=1}^n x_i y_i \leq \bigg( \sum_{i=1} x_i^p \bigg)^{\frac{1}{p}} \, \bigg( \sum_{i=1} y_i^q \bigg)^{\frac{1}{q}} \text{  for } p > 1 \\
    &\sum_{i=1}^n x_i y_i \geq \bigg( \sum_{i=1} x_i^p \bigg)^{\frac{1}{p}} \, \bigg( \sum_{i=1} y_i^q \bigg)^{\frac{1}{q}} \text{  for } p < 1, p \neq 0
\end{align*}
\end{lemma}

\begin{lemma}[Minkowski's Inequalities]
Let $x_i \geq 0, y_i \geq 0$ for $i = 1, 2, ... ,n$. Then, 
\begin{align*}
    \bigg( \sum_{i=1}^n (x_i + y_i)^p \bigg)^{\frac{1}{p}} & \leq \bigg( \sum_{i=1}^n x_i^p \bigg)^\frac{1}{p} + \bigg( \sum_{i=1}^n y_i^p \bigg)^{\frac{1}{p}} \text{  when } p > 1 \\
    \bigg( \sum_{i=1}^n (x_i + y_i)^p \bigg)^{\frac{1}{p}} & \geq \bigg( \sum_{i=1}^n x_i^p \bigg)^\frac{1}{p} + \bigg( \sum_{i=1}^n y_i^p \bigg)^{\frac{1}{p}} \text{  when } p < 1, p \neq 0
\end{align*}
\end{lemma}

\subsubsection{Conditions for a Function to be Convex}
\begin{definition}[Convex, Concave Functions]
A function $f: (a, b) \longrightarrow \mathbb{R}$ defined on an open interval $(a, b) \subset \mathbb{R}$ is \textit{convex} if the inequality
\[f( \alpha_1 x_1 + \alpha_2 x_2) \leq \alpha_1 f(x_1) + \alpha_2 f(x_2)\]
holds and \textit{concave}, or \textit{convex upward}, if the inequality 
\[f( \alpha_1 x_1 + \alpha_2 x_2) \geq \alpha_1 f(x_1) + \alpha_2 f(x_2)\]
holds for all pairs of points $x_1, x_2 \in (a, b)$ and any numbers $\alpha_1, \alpha_2 \geq 0$ such that $\alpha_1 + \alpha_2 = 1$. If this inequality is strict whenever $x_1 \neq x_2$ and $\alpha_1 \alpha_2 \neq 0$, the function is said to be \textit{strictly convex} and \textit{strictly concave}, respectively. 

Visually, this just means that given any two points $a, b$, the graph of a convex function (left) in $(a, b)$ always lies underneath the secant line formed by the two points and the graph of a concave function (right) in $(a, b)$ lies over the secant line formed by the two points. 
\begin{center}
    \includegraphics[scale=0.3]{Convex_Concave_Functions_Secant.PNG}
\end{center}
However, this is only a visual aid. In reality, it is actually not only the secant line formed by the two endpoints, but every pairs of points within that interval. For example, even though the secant line $l$ formed by the endpoints $a, b$ is above the whole graph in $(a, b)$, $f$ is not convex over $(a, b)$ since the secant line formed by points $\alpha, \beta$ do not lie completely underneath $f$. 
\begin{center}
    \includegraphics[scale=0.3]{Multiple_Secant_Lines_Convex_Clarification.PNG}
\end{center}
\end{definition}

The following is also another equivalent condition for a function to be convex over $(a, b)$. 

\begin{proposition}
A function $f: (a, b) \longrightarrow \mathbb{R}$ that is differentiable on the open interval $(a, b)$ is convex on $(a, b)$ if and only if its graph contains no points below any tangent drawn to it.
\begin{center}
    \includegraphics[scale=0.3]{Convex_Function_Over_Tangent_Line.PNG}
\end{center}
\end{proposition}

\begin{theorem}[2nd Derivatives of Convex Functions]
Given a function $f: (a, b) \longrightarrow \mathbb{R}$ that is differentiable in its domain, 
\begin{enumerate}
    \item $f$ is convex $\iff f^\prime$ is nondecreasing on $(a, b) \iff f^{\prime\prime} \geq 0$ on $(a, b)$ 
    \item $f$ is strictly convex $\iff f^\prime$ is increasing on $(a, b) \iff f^{\prime\prime} > 0$ on $(a, b)$ 
    \item $f$ is concave $\iff f^\prime$ is nonincreasing on $(a, b) \iff f^{\prime\prime} \leq 0$ on $(a, b)$ 
    \item $f$ is strictly concave $\iff f^\prime$ is decreasing on $(a, b) \iff f^{\prime\prime} < 0$ on $(a, b)$ 
\end{enumerate}
\end{theorem}

\begin{definition}[Inflection Point]
Let $f: E \longrightarrow \mathbb{R}$ be a function defined and differentiable on a neighborhood $U(x_0)$. If the function is convex downward (resp. upward) on the set $\mathring{U}^- (x_0) = \{x \in U(x_0) \;|\; x < x_0\}$ and convex upward (resp. downward) on $\mathring{U}^+ (x_0) = \{x \in U(x_0)\;|\; x > x_0\}$, then the point 
\[\big( x_0, f(x_0) \big)\]
is called a \textit{inflection point of the graph}. 
\begin{center}
    \includegraphics[scale=0.3]{Inflection_Point_Analysis.PNG}
\end{center}
\end{definition}

\begin{proposition}[Jensen's Inequality]
If $f: (a, b) \longrightarrow \mathbb{R}$ is a convex function, $x_1, ..., x_n$ are points of $(a, b)$, and $\alpha_1, ..., \alpha_n$ are nonnegative numbers such that $\alpha_1 + ... + \alpha_n = 1$, then 
\[f(\alpha_1 x_1 + ... + \alpha_n x_n) \leq \alpha_1 f(x_1) + ... + \alpha_n f(x_n)\]
\end{proposition}

\subsubsection{L'Hopital's Rule}

\begin{theorem}[L'Hopital's Rule]
Let $c$ be an extended real number (i.e. $c \in \mathbb{R} \cup \{+\infty, -\infty\}$ and let $(a, b)$ be an open interval containing $c$ (for a two-sided limit) or an open interval with endpoint $c$ (for a one-sided limit, or a limit at infinity if $c$ is infinite). Assume that $f$ and $g$ are assumed to be differentiable on $(a, b) \setminus c$, and additionally $g^\prime (x) \neq 0$ on $(a, b) \setminus c$. If either 
\[\lim_{x \rightarrow c} f(x) = \lim_{x \rightarrow c} g(x) = 0 \text{ or } \lim_{x \rightarrow c} |f(x)| = \lim_{x \rightarrow c} |g(x)| = \infty\]
then 
\[\lim_{x \rightarrow c} \frac{f(x)}{g(x)} = \lim_{x \rightarrow c} \frac{f^\prime (x)}{g^\prime (x)}\]
L'Hopital's rule can be stated colloquially, but not quite accurately, as follows: \textit{The limit of a ratio of functions equals the limit of the ratio of their derivatives if their derivatives exist.}
\end{theorem}

\begin{example}
Let $f(x) = \sin{x}$ and $g(x) = -0.5x$. Then, the function 
\[h(x) = \frac{f(x)}{g(x)} = \frac{\sin{x}}{-0.5x}\]
is clearly undefined at $x = 0$. 
\begin{center}
    \includegraphics[scale=0.3]{LHopital_Example_1.PNG}
\end{center}
However, we can solve the limit using L'Hopital's rule to get
\[\lim_{x \rightarrow 0} \frac{\sin{x}}{-0.5x} = \lim_{x \rightarrow 0} \frac{\cos{x}}{-0.5} = -2\]
Therefore, $h: \mathbb{R} \setminus 0 \longrightarrow \mathbb{R}$ can be completed to continuous function on all of $\mathbb{R}$ by defining the extension: 
\[H(x) \equiv \begin{cases}
h(x), & x \neq 0 \\
-2, & x = 0
\end{cases}\]
\begin{center}
    \includegraphics[scale=0.3]{LHopital_Example_2.PNG}
\end{center}
\end{example}

\subsection{Complex Analysis: An Introduction}
Just as the equation $x^2 = 2$ has no solutions in the domain $\mathbb{Q}$ of rational numbers, the equation $x^2 = -1$ has no solutions in the domain $\mathbb{R}$ of real numbers. Just as we adjoin the symbol $\sqrt{2}$ as a solution of $x^2 = 2$ and connect it with rational numbers to get new numbers of the form 
\[r_1 + r_2 \sqrt{2}, \;\;\; r_1, r_2 \in \mathbb{Q}\]
we introduce the symbol $i$ as a solution of $x^2 = -1$ and attach this number to real numbers. 

One feature of this enlargement of the field $\mathbb{R}$ of real numbers into the resulting field $\mathbb{C}$ of complex numbers, every algebraic equation with real or complex coefficients now has a solution. 

\subsubsection{Algebraic Extension of Field $\mathbb{R}$}
We introduce the number $i$, called the \textit{imaginary unit}, such that $i^2 = -1$. We may multiply real numbers $y$ to $i$ to get $yi$, and we can add real numbers to such numbers, to get numbers of the form 
\[x + yi, \;\;\; x, y \in \mathbb{R}\]
We then define all objects of the form $x + iy$ as the \textit{complex numbers}, with addition defined
\[(x_1 + i y_1) + (x_2 + i y_2) \equiv (x_1 + x_2) + i (y_1 + y_2)\]
and multiplication defined
\[(x_1 + i y_1) \cdot (x_2 + i y_2) \equiv (x_1 x_2 - y_1 y_2) + i (x_1 y_2 + x_2 y_1)\]
As expected, this makes $+$ and $\cdot$ commutative operations. Furthermore, two complex numbers $z = x_1 + i y_1$ and $w = x_2 + i y_2$ are equal if and only if $x_1 = x_2$ and $y_1 = y_2$. 

One nontrivial property of field $\mathbb{C}$ is that every element $z \in \mathbb{C}$ has a multiplicative inverse $z^{-1}$. To find this, we must define the following. 

\begin{definition}[Complex Conjugate]
Given complex number $z = x + i y$, its \textit{complex conjugate} is 
\[\overline{z} = \overline{x + iy} = x - iy\]
Note that 
\[z \cdot \overline{z} = x^2 + y^2 \neq 0 \text{ iff } z \neq 0\]
\end{definition}

Thus, given $z$, 
\[z^{-1} = \frac{1}{z \cdot \overline{z}} \cdot \overline{z} \iff (x + yi)^{-1} = \frac{x}{x^2 + y^2} - i \frac{y}{x^2 + y^2}\]

\subsubsection{Geometric Interpretation of $\mathbb{C}$}
Once the algebraic operations $+$ and $\cdot$ has been introduced, the symbol $i$ is no longer needed. That is, we can define a new set $\mathbb{R}^2 = \mathbb{R} \times \mathbb{R}$ with the operations $+_\mathbb{R}, \cdot_\mathbb{R} : \mathbb{R}^2 \times \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ defined
\begin{align*}
    (x_1, y_1) +_\mathbb{R} (x_2, y_2) & \equiv (x_1 + x_2, y_1 + y_2) \\
    (x_1, y_1) \cdot_\mathbb{R} (x_2, y_2) & \equiv (x_1 x_2 - y_1 y_2, x_1 y_2 + x_2 y_1)
\end{align*}
We can check that this new set $(\mathbb{R}^2, +_\mathbb{R}, \cdot_{\mathbb{R}})$ is isomorphic to $(\mathbb{C}, +, \cdot)$ as fields, and therefore one can identify complex numbers with vectors $z = (x, y)$ of the plane $\mathbb{R}^2$, where $x = \text{Re}\,z$ is called the \textit{real part} and $y = \text{Im}\,z$ is called the \textit{imaginary part}. 

\begin{definition}[Norm, Metric of $\mathbb{C}$]
Moreover, the isomorphism
\[\gamma: \mathbb{C} \longrightarrow \mathbb{R}^2, \;\; \gamma(x + yi) = (x, y)\]
induces additional structures on $\mathbb{C}$, such as the norm and metric. 
\begin{enumerate}
    \item The norm of $z = x + iy \in \mathbb{C}$ is defined as the norm of $\gamma(z) = (x, y) \in \mathbb{R}^2$. That is, 
    \[|z| = |x + yi| = |(x, y)| = \sqrt{x^2 + y^2}\]
    Or more simply, 
    \[|z| = z \cdot \overline{z}\]
    \item The metric of two complex numbers $z_1, z_2 \in \mathbb{C}$ is defined
    \[|z_1 - z_2| = |(x_1, y_1) - (x_2, y_2)| = |(x_1 - x_2, y_1 - y_2)| = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}\]
    Or more simply, 
    \[|z_1 - z_2| = (z_1 - z_2) \cdot \overline{(z_1 - z_2)}\]
\end{enumerate}
\end{definition}

\begin{definition}[Polar Coordinates of $\mathbb{C}$]
Given the basis transformation of polar coordinates $(r, \varphi) \mapsto p(r, \varphi) = (x, y)$ where 
\[p\begin{pmatrix} r \\ \varphi \end{pmatrix} = \begin{pmatrix}
r \cos{\varphi} \\ r \sin{\varphi} 
\end{pmatrix} = \begin{pmatrix} x \\ y \end{pmatrix}\]
the isomorphism $\mathbb{C} \simeq \mathbb{R}^2$ induces a similar polar transformation in $\mathbb{C}$
\[\rho = \gamma^{-1} \circ p \circ \gamma: \mathbb{C}_{(r, \theta)} \longrightarrow \mathbb{C}_{(x, y)}, \;\;\rho(r + \theta i) = r \cos{\theta} + r \sin{\theta} i = x + y i\]
as shown in the commutative diagram. 
\[\begin{tikzcd}
    \mathbb{C}_{(r, \theta)} \arrow{d}{\gamma} \arrow{r}{\rho} & \mathbb{C}_{(x, y)} \arrow{d}{\gamma} \\
    \mathbb{R}^2_{(r, \theta)} \arrow{r}{p} & \mathbb{R}^2_{(x, y)}
  \end{tikzcd}\]
Therefore, we can write 
\[z = r ( \cos{\varphi} + i \sin{\varphi})\]
where $r = |z|$ is called the \textit{magnitude} of $z$, and $\varphi = \text{Arg}\,z$ is called the \textit{argument} of $z$. 
\end{definition}

\begin{lemma}[Multiplication of Complex Numbers in Polar Form]
It turns out that multiplication is a lot easier in polar coordinates than in rectangular ones: 
\begin{align*}
    z_1 \cdot z_2 & = (r_1 \cos{\varphi_1} + i r_1 \sin{\varphi_1})(r_2 \cos{\varphi_2} + i r_2 \sin{\varphi_2}) \\
    & = \ldots \\
    & = r_1 r_2 \big(\cos{(\varphi_1 + \varphi_2)} + i \sin{(\varphi_1 + \varphi_2)}
\end{align*}
\begin{center}
    \includegraphics[scale=0.3]{Multiplication_Complex_Polar_Form.jpg}
\end{center}
\end{lemma}

\begin{theorem}[De Moivre's Formula]
By induction using the previous lemma, we get 
\[z = r ( \cos{\varphi} + i \sin{\varphi}) \implies z^n = r^n (\cos{n\varphi} + i \sin{n \varphi})\]
\end{theorem}

\begin{corollary}[Roots of Unity]
The $n$ complex solutions of the equation 
\[z^n = a\]
where $a = \rho (\cos{\psi} + i \sin{\psi})$ is 
\[z_k = \sqrt[n]{\rho} \bigg( \cos\Big(\frac{\psi + 2\pi k}{n} \Big) + i \sin\Big(\frac{\psi + 2\pi k}{n}\Big) \bigg), \;\;\;\;\; k = 0, 1, 2, \ldots, n-1\]
Moreover, if $a = 1$, then the $n$ complex solutions are called the \textit{$n$th roots of unity}, defined
\[z_k = \cos\Big(\frac{2\pi k}{n}\Big) + i \sin\Big(\frac{2\pi k}{n}\Big), \;\;\;\;\; k = 0, 1, 2, \ldots, n-1\]
which shows that the $n$th roots of unity are at the vertices of a regular $n$-sided polygon inscribed in the unit circle, with one vertex at $1$, within the complex plane. The $5$th and $6$th roots of unity are shown below. 
\begin{center}
    \includegraphics[scale=0.27]{5th_6th_Roots_of_Unity.PNG}
\end{center}
\end{corollary}

Finally, we can visualize certain transformations in $\mathbb{C}$. For a fixed $b \in \mathbb{C}$, the sum $z + b$ cam be interpreted as the mapping of $\mathbb{C}$ onto itself given by the formula 
\[z \mapsto z + b\]
This mapping is a translation of the plane by the vector $b$. 
\begin{center}
    \includegraphics[scale=0.25]{Translation_in_Complex_Plane.jpg}
\end{center}
Visualizing multiplication is a bit harder. Given a 
\[a = |a| (\cos{\varphi} + i \sin{\varphi}) \neq 0\]
the product $az$ can be interpreted as the mapping of $\mathbb{C}$ onto itself given by the formula
\[z \mapsto az\]
which is the composition of a dilation by a factor of $|a|$ and a rotation through the angle $\varphi \in \text{Arg}\,a$. 
\begin{center}
    \includegraphics[scale=0.3]{Multiplication_in_Complex_Plane.jpg}
\end{center}

\subsubsection{Sequences and Series in $\mathbb{C}$}
Our previous construction of a metric within $\mathbb{C}$ enables to define the $\epsilon$-neighborhood of a number $z_0 \in \mathbb{C}$ as the set
\[U_\epsilon (z_0) \equiv \{z \in \mathbb{C}\;|\; |z - z_0| < \epsilon\}\]
which can be visualized as an open disk of radius $\epsilon$ in $\mathbb{R}^2$ centered at point $(x_0, y_0)$ if $z_0 = x_0 + i y_0$. 
\begin{center}
    \includegraphics[scale=0.25]{Epsilon_Neighborhood_in_C.jpg}
\end{center}

\begin{definition}[Convergence of a Sequence in $\mathbb{C}$]
A sequence $\{z_n\}$ of complex numbers \textit{converges} to $z_0 \in \mathbb{C}$ if and only if 
\[\lim_{n \rightarrow \infty} |z_n - z_0| = 0\]
It is clear from the inequality
\[\max\{|x_n - x_0|, |y_n - y_0|\} \leq |z_n - z_0| \leq |x_n - x_0| + |y_n - y_0|\]
that a sequence of complex numbers converges if and only if the sequences of its real and imaginary parts of the terms of the sequence both converge. That is, 
\[\{z_n\} \text{ converges} \iff \{\text{Re}\,z\} \text{ and } \{\text{Im}\,z\} \text{ converges}\]
\end{definition}

\begin{lemma}[Convergence of Cauchy Sequences over $\mathbb{C}$]
A sequence of complex numbers $\{z_n\}$ is called a \textit{Cauchy sequence} if for every $\epsilon>0$ there exists an index $N \in \mathbb{N}$ such that
\[|z_n - z_m|<\epsilon \text{ for all } n, m > N\]
It is also clear that 
\[\{z_n\} \text{ is Cauchy} \iff \{\text{Re}\,z\} \text{ and } \{\text{Im}\,z\} \text{ is Cauchy}\]
and using the Cauchy criterion for sequences of real numbers, we can easily see that a sequence of complex numbers converges if and only if it is a Cauchy sequence. 
\end{lemma}

\begin{lemma}[Convergence of Cauchy Series over $\mathbb{C}$]
Interpreting the sum of a series of complex numbers
\[z_1 + z_2 + \ldots + z_n + \ldots\]
as the limit of the sequence its partial sums $\{s_n\}$, where $s_n = z_1 + \ldots z_n$ as $n \rightarrow \infty$, we can see that the series converges if and only if for every $\epsilon > 0$ there exists a $N \in \mathbb{N}$ such that 
\[|z_m + \ldots + z_n| < \epsilon\]
for any natural numbers $n \geq m > N$. 
\end{lemma}

\begin{definition}[Absolute Convergence of $\mathbb{C}$]
A series $z_1 + \ldots + z_n + \ldots$ of complex numbers is \textit{absolutely convergent} if the series
\[|z_1| + |z_2| + \ldots + |z_n| + \ldots\]
converges. Clearly, is a series converges absolutely, then it converges due to the inequality
\[|z_m + \ldots + z_n| \leq |z_m| + \ldots + |z_n|\]
\end{definition}

\begin{example}
The following complex series converges because they converges absolutely. That is, 
\begin{align*}
    1 + \frac{1}{1!}|z| + \frac{1}{2!}|z^2| + \ldots \text{ converges } \forall \; \mathbb{C} & \implies 1 + \frac{1}{1!}z + \frac{1}{2!}z^2 + \ldots \text{ converges } \forall \; \mathbb{C} \\
    |z| + \frac{1}{3!}|z|^3 + \frac{1}{5!}|z|^5 + \ldots \text{ converges } \forall \; \mathbb{C}  & \implies z - \frac{1}{3!} z^3 + \frac{1}{5!}z^5 + \ldots \text{ converges } \forall \; \mathbb{C} \\
    1 + \frac{1}{2!}|z|^2 + \frac{1}{4!} |z|^4 + \ldots \text{ converges }  \forall \; \mathbb{C} & \implies 1 - \frac{1}{2!}z^2 + \frac{1}{4!} z^4 - \ldots \text{ converges }  \forall \; \mathbb{C} 
\end{align*}
\end{example}

\begin{definition}[Complex Power Series]
Series of the form 
\[\sum_{n=0}^\infty c_n (z - z_0)^n = c_0 + c_1 (z - z_0) + \ldots + c_n (z - z_0) + \ldots\]
are called \textit{complex power series}, or \textit{power series over $\mathbb{C}$}. 
\end{definition}

But a power series is quite useless unless we know the domain in which is converges (again, note that it is not always guaranteed to converge onto the function $f$ if its power series expansion does converge at all). To develop more sophisticated tests of convergence of a complex power series, we introduce the complex analogue of the root test for real power series. 

\begin{theorem}[Cauchy-Hadamard Theorem]
The complex power series 
\[c_0 + c_1 (z - z_0) + \ldots + c_n (z - z_0) + \ldots\]
converges inside the disk $|z - z_0| < R$ with center at $z_0$ and radius given by the formula
\[R = \frac{1}{\varlimsup_{n \rightarrow \infty} \sqrt[n]{|c_n|}} = \frac{1}{\lim_{n \rightarrow \infty} \sup{\sqrt[n]{|c_n|}}}\]
Where $\varlimsup$ denotes the superior limit. Furthermore, 
\begin{enumerate}
    \item the power series diverges at any point exterior to the disk. 
    \item the power series converges absolutely at any point interior to the disk. 
    \item the power series is indeterminate at any point on the boundary of the disk. 
\end{enumerate}
Note that in the degenerate case when $R = 0$, the series converges only at the point $z = z_0$. 
\end{theorem}

\begin{corollary}[Abel's First Theorem on Power Series]
If the power series 
\[c_0 + c_1 (z - z_0) + \ldots + c_n (z - z_0) + \ldots\]
converges at some value $z^*$, then it converges absolutely for any value of $z$ satisfying
\[|z - z_0| < |z^* - z_0|\]
The values of $z$ satisfying the inequality above can be intuitively visualized as the following region. 
\begin{center}
    \includegraphics[scale=0.3]{Abels_First_Theorem.PNG}
\end{center}
\end{corollary}

\begin{theorem}[Product of Absolutely Convergent Series]
Let $a_1 + a_2 + \ldots$ and $b_1 + b_2 + \ldots$ be an absolutely convergent series such that
\[\sum_{i=1}^\infty a_i = A \text{ and } \sum_{j=1}^\infty b_j = B\]
Then, the Cauchy product of the two series 
\[\bigg( \sum_{i=1}^\infty a_i \bigg) \cdot \bigg( \sum_{j=1}^\infty b_j \bigg) = \sum_{k=0}^\infty c_k = A B, \text{ where } c_k = \sum_{l=0}^k a_l b_{k-l}\]

$a_1 b_1 + a_2 b_2 + \ldots$ is absolutely convergent and 
\[\sum_{i = 1}^\infty a_i b_i = A B\]
\end{theorem}
\begin{proof}
To be done. 
\end{proof}

\begin{example}[Convergence of the Cauchy Product of Absolutely Convergent Complex Series]
The two series 
\[\sum_{n = 0}^\infty \frac{1}{n!} a^n \text{ and } \sum_{m = 0}^\infty \frac{1}{m!} b^m\]
converges absolutely. Therefore, we can see that their Cauchy product can be nicely represented by grouping together all monomials of the form $a^n b^m$ having the same total degree $m + n = k$. 
\[\bigg( \sum_{n = 0}^\infty \frac{1}{n!} a^n \bigg) \cdot \bigg( \sum_{m = 0}^\infty \frac{1}{m!} b^m \bigg) = \sum_{k=0}^\infty \bigg(\sum_{n+m=k} \frac{1}{n!} a^n \frac{1}{m!} b^m \bigg)\]
But we can simplify 
\[\sum_{m + n = k} \frac{1}{n! m!} a^n b^m = \frac{1}{k!} \sum_{n=0}^k \frac{k!}{n! (k-n)!} a^n b^{k-n} = \frac{1}{k!} (a + b)^k\]
and therefore we find that 
\[\bigg( \sum_{n = 0}^\infty \frac{1}{n!} a^n \bigg) \cdot \bigg( \sum_{m = 0}^\infty \frac{1}{m!} b^m \bigg) = \sum_{k=0}^\infty \frac{1}{k!} (a + b)^k\]
\end{example}

\subsubsection{Euler's Formula}

\begin{definition}[Complex Taylor Expansions of Transcendental Functions]
Since we have determined absolute convergence, and therefore convergence, of all these series in all of $\mathbb{C}$, it is natural to extend the definitions of 
\[\exp, \cos, \sin: \mathbb{R} \longrightarrow \mathbb{R}\]
to the complex field 
\[\exp, \cos, \sin: \mathbb{C} \longrightarrow \mathbb{C}\]
by defining them as 
\begin{align*}
    e^z & \equiv 1 + \frac{1}{1!}z + \frac{1}{2!} z^2 + \frac{1}{3!} z^3 + \ldots \\
    \cos{z} & \equiv 1 - \frac{1}{2!} z^2 + \frac{1}{4!} z^4 - \frac{1}{6!} z^6 + \ldots \\
    \sin{z} & \equiv z - \frac{1}{3!} z^3 + \frac{1}{5!} z^5 - \frac{1}{7!} z^7 + \ldots
\end{align*}
Notice that even in the complex field, $\cos{z}$ is an even function and $\sin{z}$ is an odd function. 
\begin{align*}
    \cos(-z) & = \cos(z) \\
    \sin(-z) & = -\sin(z)
\end{align*}
\end{definition}

In fact, the last example in the previous subsection just proves the following. 

\begin{lemma}[Exponential Map as a Group Homomorphism]
The exponential map $\exp: \mathbb{C} \longrightarrow \mathbb{C}\setminus \{0\}$ satisfies the following
\[\exp(z_1 + z_2) = \exp(z_1) \cdot \exp (z_2)\]
That is, $\exp$ is a group homomorphism from $(\mathbb{C}, +)$ to $(\mathbb{C} \setminus \{0\}, \cdot)$. 
\end{lemma}

\begin{definition}[Euler's Formula]
By making the substitution $z = yi$ in the series expansion of $e^z$ (where $y$ is an arbitrary complex number), we get 
\begin{align*}
    e^{iy} & = 1 + \frac{1}{1!} (iy) + \frac{1}{2!}(iy)^2 + \frac{1}{3!} (iy)^3 + \frac{1}{4!} (iy)^4 + \ldots \\
    & = \bigg(1 - \frac{1}{2} y^2 + \frac{1}{4!} y^4 - \ldots \bigg) + i \bigg(\frac{1}{1!} y - \frac{1}{3!} y^3 + \frac{1}{5!} y^5 - \ldots \bigg)
\end{align*}
which brings us the identity
\[e^{iy} = \cos{y} + i \sin{y}\]
\end{definition}

Since $\cos$ is even and $\sin$ is odd, we can add the two identities
\begin{align*}
    e^{iz} & = \cos{z} + i \sin{z} \\
    e^{-iz} & = \cos{z} - i \sin{z} 
\end{align*}
to get 
\begin{align*}
    \cos{z} & = \frac{1}{2}\big( e^{iz} + e^{-iz} \big) \\
    \sin{z} & = \frac{1}{2i} \big( e^{iz} - e^{-iz} \big)
\end{align*}
This gives us a very elegant connection between these three transcendental functions. 

\begin{definition}[Hyperbolic Functions]
Likewise, the following series are convergent (since they are absolutely convergent) and therefore we can define the extension of $\cosh$ and $\sinh$ into the complex field as 
\begin{align*}
    \cosh{z} & \equiv 1 + \frac{1}{2!} z^2 + \frac{1}{4!} z^4 + \frac{1}{6!} z^6 + \ldots \\
    \sinh{z} & \equiv z + \frac{1}{3!} z^3 + \frac{1}{5!} z^5 + \frac{1}{7!} z^7 + \ldots 
\end{align*}
The following identities immediately follow
\begin{align*}
    \cosh{z} & = \frac{1}{2} \big( e^z + e^{-z} \big) \\
    \sinh{z} & = \frac{1}{2} \big( e^{z} - e^{-z}\big) 
\end{align*}
\end{definition}

\begin{lemma}[Trigonometric, Hyperbolic Identities over $\mathbb{C}$]
Common identities, which are exactly the same as their real analogues, are listed. 
\begin{enumerate}
    \item $\cos^2{z} + \sin^2 {z} = 1$
    \item $\cosh^2{z} - \sinh^2{z} = 1$ 
    \item $e^{i(z_1 + z_2)} = (\cos{z_1} \cos{z_2} - \sin{z_1} \sin{z_2}) + i (\sin{z_1} \cos{z_2} + \cos{z_1} \sin{z_2})$
    \item $\cos{(z_1 + z_2)} = \cos{z_1} \cos{z_2} - \sin{z_1} \sin{z_2}$
    \item $\sin{(z_1 + z_2)} = \sin{z_1} \cos{z_2} + \cos{z_1} \sin{z_2}$
    \item $\cosh{z} = \cos{iz}$ 
    \item $\sinh{z} = -i \sin{iz}$
\end{enumerate}
\end{lemma}

However, to obtain even such geometrically obvious facts as the equality
\[\sin{\pi} = 0 \text{ or } \cos{z + 2\pi} = \cos{z}\]
from the power series definitions of $\cos$ and $\sin$ is extremely difficult. What the properties actually do is present the remarkable unity of these seemingly different trigonometric and hyperbolic functions, which would have been impossible to detect without going into the domain of complex numbers. 

If we just take the following identities
\begin{align*}
    \cos{x} & = \cos{(x + 2 \pi)} \\
    \sin{x} & = \sin{(x + 2\pi)} \\
    \cos{0} & = 1 \\
    \sin{0} & = 0
\end{align*}
then we get the following identity. 

\begin{theorem}[Euler's Identity]
The following relation is true. 
\[e^{i\pi} + 1 = 0\]
which immediately implies 
\[\exp(z + 2\pi i) = \exp{z}\]
That is, the exponential function is a periodic function on $\mathbb{C}$ with the purely imaginary period $T = 2 \pi i$. 
\end{theorem}

\begin{corollary}[Trigonometric Notation of Complex Number]
With Euler's formula and the periodic relation of $\exp{z}$, the trigonometric form of a complex number can be presented as
\[z = r(\cos{\varphi} + i \sin{\varphi}) = r e^{i \varphi}\]
We can rewrite DeMoivre's formula as
\[z^n = r^n e^{n \varphi i}\]
\end{corollary}

\subsubsection{Visualizing Complex Functions}

\subsubsection{Continuity, Differentiability, Analyticity of Complex Functions}
The definitions of continuity and differentiability are the same, just under a different field. 

\begin{definition}[Limit of a Complex Function]
The function $f: E \subset \mathbb{C} \longrightarrow \mathbb{C}$ tends to $A \in \mathbb{C}$ as $z \rightarrow a$, or that
\[\lim_{z \rightarrow a} f(z) = A\]
if for every $\epsilon > 0$ there exists a $\delta > 0$ such that
\[0<|z - a|<\delta \implies |f(z) - A|<\epsilon\]
Note that we set $0<|z - a|$ to ensure that $z \neq a$. 

Therefore, in other words, for any arbitrarily small $\epsilon>0$, we can find a $\delta > 0$ such that the image of the deleted $\delta$-neighborhood of $a$, denoted $\mathring{U}_\delta (a)$), is completely within the $\epsilon$-neighborhood $U_\epsilon (A)$. 
\begin{center}
    \includegraphics[scale=0.3]{Limit_of_Complex_Function.PNG}
\end{center}
\end{definition}

\begin{definition}[Continuity of a Complex Function]
A function $f: E \subset \mathbb{C} \longrightarrow \mathbb{C}$ is \textit{continuous} at a point $z_0 \in E$ if for any neighborhood $U(f(z_0))$ there exists a neighborhood $U(z_0)$ such that its image is contained in $U(f(z_0))$. In short, 
\[\lim_{z \longrightarrow z_0} f(z) = f(z_0)\]
\begin{center}
    \includegraphics[scale=0.3]{Continuity_of_Complex_Function.PNG}
\end{center}
\end{definition}

\begin{definition}[Differentiability of a Complex Function]
The \textit{derivative} of a function $f: E \subset \mathbb{C} \longrightarrow \mathbb{C}$ is defined
\[f^\prime (z_0) = \lim_{z \rightarrow z_0} \frac{f(z) - f(z_0)}{z - z_0}\]
if this limit exists. $f$ \textit{differentiable} at $x_0$ means that a differential function 
\[df(z_0): T_{z_0} \mathbb{C} \longrightarrow T_{f(z_0)} \mathbb{C}, \;\;\; h \mapsto df(z_0)(h)\]
exists such that
\[f(z) = f(z_0) + df(z_0)(h) + o(h)\]
where $h = z - z_0$ is the increment of the argument. Just like the real case, it turns out that $df(z_0)(h) = f^\prime (z_0) h$, and 
\[f(z) - f(z_0) = f^\prime(z_0) (z - z_0) + o(z - z_0)\]
which elegantly weaves together the two concepts of differentiability and the derivative. 

Visualizing this, we can see that for whatever function $f: \mathbb{C} \longrightarrow \mathbb{C}$ there is a linear function that transforms the entire space as such at $z_0$ (along with a given point $z_0 \in \mathbb{C}$), 
\begin{center}
    \includegraphics[scale=0.3]{Differential_of_Complex_Valued_Function.PNG}
\end{center}
The differential $df(z_0)$ at the point $z_0$ is a linear mapping that "best" approximates $f$, with an error of $o(h) = o(z - z_0)$. 
\end{definition}

\begin{lemma}[Arithmetic Properties of Differentiation over $\mathbb{C}$]
If functions $f, g: E \subset \mathbb{C} \longrightarrow \mathbb{C}$ are differentiable at a point $z \in E$, then 
\begin{enumerate}
    \item their sum is differentiable at $z$, and 
    \[d(f + g)(z) = df(z) + dg(z) \iff (f + g)^\prime (z) = (f^\prime + g^\prime)(z)\]
    \item their product is differentiable at $z$, and 
    \[d(f \cdot g) (z) = g(z) df(z) + f(z) dg(z) \iff (f \cdot g)^\prime (z) = f^\prime (z) g(z) + f(z) \cdot g^\prime (z)\]
    \item their quotient is differentiable at $z$ if $g(z) \neq 0$, and 
    \[d \bigg( \frac{f}{g}\bigg) (z) = \frac{g(z) df(z) - f(z) dg(z)}{g^2 (z)} \iff \bigg(\frac{f}{g}\bigg)^\prime (z) = \frac{f^\prime (z) g(z) - f(z) g^\prime (z)}{g^2 (z)}\]
\end{enumerate}
Just like the real case, the operation of taking the derivative is a linear operator. 
\end{lemma}

\begin{lemma}[Chain Rule for Composite Functions over $\mathbb{C}$]
Let there be functions $f: E_1 \subset \mathbb{C} \longrightarrow \mathbb{C}$ differentiable at point $z \in E_1$ and $g: E_2 \subset \mathbb{C} \longrightarrow \mathbb{C}$ differentiable at point $w = f(z) \in E_2$, with respective differentials 
\begin{align*}
    df(z) & : T_z \mathbb{C} \longrightarrow T_w \mathbb{C} \\
    dg(w) & : T_w \mathbb{C} \longrightarrow T_{g(w)} \mathbb{C}
\end{align*}
Then, the composite function $g \circ f: E_1 \longrightarrow \mathbb{C}$ is differentiable at $z$, and $d(g \circ f)(z): T_z \mathbb{C} \longrightarrow T_{g \circ f(z)} \mathbb{C}$ is
\[d(g \circ f) (z) = dg(w) \circ df(z) \iff (g \circ f)^\prime (z) = g^\prime \big(f(z)\big) \circ f^\prime (z)\]
\end{lemma}

\subsubsection{Power Series Representation of a Function}
\begin{definition}[Holomorphic Function]
If function $f: E \subset \mathbb{C} \longrightarrow \mathbb{C}$ is (complex) differentiable at a point $z_0 \in E$, then $f$ is said to be \textit{holomorphic at $z_0$}. 
\end{definition}

We recall the diagram that summarizes the conditions of differetiability and analyticity of a function $f$ over the field $\mathbb{R}$. 
\begin{center}
\begin{tikzpicture}
    \draw (-7.5,0) rectangle (7.5, 4);
    \draw[fill=lightgray] (-6.5, 0.5) rectangle (6.5, 3);
    \draw[fill=white] (-5.5, 1) rectangle (5.5, 2);
    \node[above] at (0, 1) {Taylor series converges to $f$ at $x_0 \iff f$ is analytic};
    \node[above] at (0, 2) {Taylor series converges at $x_0$};
    \node[above] at (0, 3) {$f$ infinitely differentiable at $x_0 \iff $ Taylor series of $f$ exists at $x_0$};
\end{tikzpicture}
\end{center}
In the theory of functions of a complex variable we actually have a remarkable theorem that does not have an analogue for functions over $\mathbb{R}$. 

\begin{theorem}[Analyticity of Differentiable Functions over $\mathbb{C}$]
If a function $f: E \subset \mathbb{C} \longrightarrow \mathbb{C}$ is differentiable in a neighborhood of a point $z_0 \in E$, then it is analytic at that point. In other words, 
\[f \text{ is holomorphic at } z_0 \implies f \text{ is analytic at } z_0\]
This means that the conditions in the diagram above all are equivalent! Visually, 
\begin{center}
\begin{tikzpicture}
    \draw (-6.5,1) rectangle (6.5, 5); 
    \node[above] at (0,4) {$f$ is differentiable at $z_0 \iff f$ is holomorphic at $z_0$};
    \node at (0,3.8) {$\Updownarrow$};
    \node at (0,2.8) {$\Updownarrow$};
    \node at (0,1.8) {$\Updownarrow$};
    \node[above] at (0, 1) {Taylor series converges to $f$ at $z_0 \iff f$ is analytic};
    \node[above] at (0, 2) {Taylor series converges at $z_0$};
    \node[above] at (0, 3) {$f$ infinitely differentiable at $z_0 \iff $ Taylor series of $f$ exists at $z_0$};
\end{tikzpicture}
\end{center}
This is certainly an amazing fact, since it then follows from the theorem that if a function $f(z)$ has one derivative $f^\prime (z)$ in a neighborhood of a point, it also has derivatives of all orders in that neighborhood. 
\end{theorem}

\subsubsection{Algebraic Closedness of the Field $\mathbb{C}$}

\begin{definition}[Algebraically Closed Field]
A field $\mathbb{F}$ is \textit{algebraically closed} if every nonconstant polynomial in $\mathbb{F}[x]$ (the polynomial ring with coefficients in $\mathbb{F}$) has a root in $\mathbb{F}$. 
\end{definition}

\begin{theorem}[Fundamental Theorem of Algebra]
$\mathbb{C}$ is algebraically closed. That is, every polynomial 
\[P(z) \equiv c_0 + c_1 z + c_2 z^2 + \ldots + c_n z^n\]
of degree $n\geq 1$ with complex coefficients $c_i \in \mathbb{C}$ ($i = 0, 1, \ldots, n$) has a root in $\mathbb{C}$. This immediately implies that every polynomial $P(z)$ admits a representation (unique up to the order of the factors) in the form 
\[P(z) = c_n (z - z_1) (z - z_2) \ldots (z - z_n)\]
where $z_1, \ldots, z_n \in \mathbb{C}$ not necessarily all distinct. 
\end{theorem}

We can also prove the interesting property about zeroes of polynomials in $\mathbb{R}[x]$. 

\begin{corollary}[Complex Conjugate Roots of Real Polynomials]
Given a polynomial with real coefficients
\[P(z) \equiv a_0 + a_1 z + a_2 z^2 + \ldots + a_n z^n\]
$P$, as we know, does not always have real roots (e.g. $P(x) = x^2 + 1$). However, we state that
\[\text{if } P(z_0) = 0, \text{ then } P(\overline{z}_0) = 0\]
Therefore, every polynomial $P$ with real coefficients can be expanded as a product of linear and quadratic polynomial with real coefficients. 
\end{corollary}
\begin{proof}
We can see from the properties of complex numbers that
\begin{align*}
    \overline{(z_1 + z_2)} & = \overline{z_1} + \overline{z_2} \\
    \overline{(z_1 \cdot z_2)} & = \overline{(r_1 e^{i \varphi_1} \cdot r_2 e^{i \varphi_2})} \\
    & = \overline{r_1 r_2 e^{i(\varphi_1 + \varphi_2)}} = r_1 r_2 e^{-i(\varphi_1 + \varphi_2)} \\
    & = r_1 e^{-i\varphi_1} \cdot r_2 e^{-i \varphi_2} = \overline{z}_1 \cdot \overline{z}_2
\end{align*}
Thus, if $P(z_0) = 0$, then 
\[0 = \overline{P(z_0)} = \overline{a_0 + \ldots + a_n z_0^n} = \overline{a}_0 + \ldots + \overline{a}_n \overline{z}_0^n  = a_0 + \ldots + a_n \overline{z}_0^n = P(\overline{z}_0)\]
and thus $P(\overline{z}_0) = 0$. 
\end{proof}

\subsection{Primitives}
\begin{definition}[Primitive]
A function $F(x)$ is a \textit{primitive} of a function $f(x)$ on an interval if $F$ is differentiable on the interval and satisfies the equation 
\[F^\prime (x) = f(x)\]
or equivalently, if their respective differentials satisfy
\[d F(x) = f(x) \,dx\]
\end{definition}

\begin{lemma}
If $F_1(x)$ and $F_2 (x)$ are two primitives of $f(x)$ on the same interval, then the difference $(F_1 - F_2)(x)$ is constant on that interval. 
\end{lemma}

\begin{example}
Both 
\[F_1(x) \equiv \arctan{x} \text{ and } F_2(x) \equiv \arccot{\frac{1}{x}}\]
are primitives of $f(x) = \frac{1}{1 + x^2}$. Indeed, we can see by direct calculation that in the domain $\mathbb{R} \setminus 0$, 
\[F_1 (x) - F_2 (x) = \arctan{x} - \arccot{\frac{1}{x}} = \begin{cases}
0, & x > 0 \\
-\pi, & x < 0
\end{cases}\]
which is supported by the lemma. 
\end{example}

Notice how given a function $f(x)$, the operation of finding its differential, denoted with $d$, gives us a new function of $h$, called the differential 
\[df(x)(h)\]
Similarly, the operation of finding a primitive of function $f(x)$, denoted with the symbol $\int$, gives us a new function. 

\begin{definition}[Indefinite Integration]
The operation of finding a primitive of a certain function $f(x)$ is called \textit{indefinite integration}, and the mathematical notation 
\[\int f(x) \,dx\]
is called the \textit{indefinite integral of $f(x)$} on a given interval ($f$ called the \textit{integrand} and $f(x)\,dx$ called the \textit{differential form}). 
\begin{enumerate}
    \item It immediately follows from the lemma that if $F(x)$ is any particular primitive of $f(x)$ on the interval, then on that interval 
    \[\int f(x) \,dx = F(x) + C\]
    \item If $F^\prime (x) = f(x)$ (that is, $F$ is a primitive of $f$ on some interval), then we have
    \[d \int f(x)\,dx = d F(x) = F^\prime (x) \,dx \]
    \item It also follows that 
    \[\int d F(x) = \int F^\prime (x)\,dx = F(x) + C\]
\end{enumerate}
\end{definition}

\begin{theorem}[Basic Methods of Indefinite Integration]
The definition of the indefinite integral has three basic properties that can be used to solve indefinite integrals. 
\begin{enumerate}
    \item Linearity of the indefinite integral.
    \[\int \big( \alpha u(x) + \beta v(x)\big) \, dx = \alpha \int u(x)\,dx + \beta \int v(x)\,dx + C\]
    \item Integration by parts. 
    \[\int (u v)^\prime \,dx = \int u^\prime (x) v(x) \,dx + \int u(x) v^\prime (x) \,dx + C\]
    \item Change of Variable, or $U$-substitution. Given that $F^\prime (x) = f(x)$ on an interval $I_x$ and $\varphi: I_t \longrightarrow I_x$ is a $C^1$ mapping of interval $I_t$ into $I_x$, then
    \[\int (f \circ \varphi) (t) \varphi^\prime (t) \,dt = (F \circ \varphi)(t) + C\]
\end{enumerate}
\end{theorem}


\section{Integration}

\subsection{Construction of the Riemann Integral}
We shall first define the integral using the familiar notation of Riemann sums. 

\begin{definition}[Partitions with Distinguished Points]
A \textit{partition} $P$ of a closed interval $[a, b]$, $a < b$, is a finite system of points $x_0, \ldots, x_n$ of the interval such that
\[a = x_0 < x_1 < x_2 < \ldots < x_n = b\]
The intervals $[x_{i-1}, x_i]$, $i = 1, 2, \ldots, n$, are called the \textit{intervals} of the partition $P$. The largest of the lengths of the intervals of the partition $P$, denoted $\lambda(P)$, is called the \textit{mesh} of the partition. 

A \textit{partition with distinguished points} $(P, \xi)$ on the closed interval $[a, b]$ is a partition $P$ of $[a,b]$ along with the set of $n$ points 
\[\xi_1 \in [x_0, x_1], \xi_2 \in [x_1, x_2], \ldots, \xi_n \in [x_{n-1}, x_n]\]
The $n$-tuple of $\xi_i$'s is denoted by the single letter $\xi$
\[\xi = (\xi_1, \xi_2, \ldots, \xi_n)\]
\end{definition}

This naturally leads to the following construction. 

\begin{definition}[Riemann Sums]
If a function $f$ is defined on a closed interval $[a, b]$ and $(P, \xi)$ is a partition with distinguished points on this closed interval, the sum
\[\sigma(f; P, \xi) \equiv \sum_{i=1}^n f(\xi_i)\, \Delta x_i, \text{ where } \Delta x_i = x_i - x_{i-1},\]
is the \textit{Riemann sum} of the function $f$ corresponding to the partition $(P, \xi)$ with distinguished points on $[a, b]$. 
\begin{center}
    \includegraphics[scale=0.25]{Riemann_Sum_with_Partitions_Points.PNG}
\end{center}
Thus, when a function $f$ is fixed, the Riemann sum $\sigma (f; P, \xi)$ is a mapping that takes in a partition with distinguished points $p = (P, \xi)$ on the closed interval $[a, b]$ and outputs a number representing the total area of the Riemann sums. That is, for a fixed $f$ and some input $p = (P, \xi)$, we can define the function 
\[\Phi: \mathcal{P} \longrightarrow \mathbb{R}, \;\;\; \Phi(p) \equiv \sigma(f; p) \equiv \sigma(f; (P, \xi))\]
that takes in a partition with distinguished points on $[a,b]$ and outputs the corresponding Riemann sum for that fixed $f$. 
\end{definition}

\begin{definition}[Riemann Integral]
The number $\int_a^b f(x)\,dx$ is the \textit{Riemann integral} of the function $f$ on the closed interval $[a, b]$ if for every $\epsilon>0$ there exists a $\delta>0$ such that
\[\Bigg| \int_a^b f(x)\,dx - \sum_{i=1}^n f(\xi_i) \Delta x_i \Bigg| < \epsilon\]
for any partition $(P, \xi)$ with distinguished points on $[a, b]$ whose mesh $\lambda(P)$ is less than $\delta$. We can view this as a limit where $n \rightarrow \infty$, but there is a problem since we can increase the partition within different subsets of $[a,b]$, leading to multiple values of convergence. 
\begin{center}
    \includegraphics[scale=0.28]{Riemann_Integral_Converging_onto_2_Numbers.PNG}
\end{center}
Rather, we can set the mesh $\lambda(P)$ to approach $0$, which would take care of the problems. We can visualize this by imagining the lengths of the rectangles converging "uniformly."
\begin{center}
    \includegraphics[scale=0.28]{Riemann_Integral_Limit_Mesh_goes_to_0.PNG}
\end{center}
Therefore, we can culminate by defining the Riemann integral of $f(x)$ over $[a,b]$ as 
\[\int_a^b f(x)\,dx \equiv \lim_{\lambda(P) \rightarrow 0} \sum_{i=1}^n f(\xi_i) \lambda x_i\]
\end{definition}

\subsubsection{Conditions for Integrability}

\begin{definition}[Riemann Integrable Functions]
A function $f$ is \textit{Riemann integrable} on the closed interval $[a, b]$ if 
\[\int_a^b f(x)\,dx \equiv \lim_{\lambda(P) \rightarrow 0} \sum_{i=1}^n f(\xi_i) \lambda x_i\]
is defined, i.e. if the limit of the right-hand side of Riemann sums exists as $\lambda(P) \rightarrow 0$ (that is, the Riemann integral of $f$ is defined). 

Furthermore, the set of Riemann-integrable functions on a closed interval $[a, b]$ is denoted $\mathcal{R}[a,b]$. 
\end{definition}

Remember that the Riemann integral, as complicated as the formula is, is still a limit of a function. That means that we can apply the Cauchy criterion to it to determine convergence. 

\begin{lemma}[Cauchy Criterion on Existence of Riemann Integral]
Given a function $f$, the integral of $f$ over $[a, b]$, defined
\[\int_a^b f(x)\,dx \equiv \lim_{\lambda(P) \rightarrow 0} \sum_{i=1}^n f(\xi_i) \lambda x_i\]
exists if and only if for every $\epsilon>0$, there exists a $\delta>0$ such that 
\[\big| \sigma(f; P^\prime, \xi^\prime) - \sigma(f; P^{\prime\prime}, \xi^{\prime\prime} \big| < \epsilon\]
or, what is the same, 
\[\Bigg| \sum_{i=1}^{n^\prime} f(\xi_i^\prime) \Delta x_i^\prime - \sum_{i=1}^{n^{\prime\prime}} f^(\xi_i^{\prime\prime}) \Delta x_i^{\prime\prime} \Bigg| < \epsilon\]
for any partitions $(P^\prime, \xi^\prime)$ and $(P^{\prime\prime}, \xi^{\prime\prime})$ with distinguished points on the interval $[a, b]$ with
\[\lambda(P^\prime), \lambda(P^{\prime\prime}) < \delta\]
In words, this means that for any $\epsilon>0$ that we choose, there always exists a $\delta>0$ such that \textbf{any} two Riemann sums with mesh size \textbf{both} smaller than $\delta$ will have an error difference of less than $\epsilon$. \begin{center}
    \includegraphics[scale=0.3]{Cauchy_Criterion_of_Riemann_Integral.jpg}
\end{center}
\end{lemma}

\begin{theorem}[Necessary Condition for Integrability]
A necessary condition for $f$ defined on a closed interval $[a, b]$ to be Riemann integrable on $[a, b]$ is that $f$ be bounded on $[a, b]$. That is, 
\[f \in \mathcal{R}[a, b] \implies f \text{ is bounded on } [a, b]\]
We can clearly see the necessity of $f$ being bounded by looking at the contrapositive of the following statement. 
\end{theorem}

\begin{theorem}[Refinement]
Given a partition $P$ on interval $[a, b]$, recall that we have points $x_0, \ldots, x_n$ such that
\[a = x_0 < x_1 < \ldots < x_n = b\]
Here we introduce new notation: 
\begin{enumerate}
    \item $\Delta_i$ denotes the interval $[x_{i-1}, x_i]$
    \item $\Delta x_i$ denotes the difference $x_i - x_{i-1}$, i.e. the length of $\Delta_i$
\end{enumerate}
If a partition $\Tilde{P}$ of the closed interval $[a, b]$ is obtained from the partition $P$ by the addition of new points to $P$, we call $\Tilde{P}$ a \textit{refinement} of $P$. 

When a refinement $\Tilde{P}$ of a partition $P$ is constructed, some (perhaps all) of the closed intervals $\Delta_i = [x_{i-1}, x_i]$ of the partition $P$ themselves undergo partitioning. 
\[x_{i-1} = x_{i0} < x_{i1} < \ldots < x_{in_i} = x_i\]
In that connection, it will be useful to label to points of $\Tilde{P}$ by double indices, where in the notation $x_{ij}$ the first index $i$ means that 
\[x_{ij} \in \Delta_i = [x_{i-1}, x_i]\]
and the second index $j$ is the ordinal number of the point on the closed interval $\Delta_i = [x_{i-1}, x_i]$. Therefore, it is natural to set the notations
\begin{enumerate}
    \item $\Delta_{ij} = [x_{i j-1}, x_{ij}]$
    \item $\Delta x_{ij} = x_{ij} - x_{ij-1}$
\end{enumerate}
This means that 
\[\Delta x_i = \Delta x_{i1} + \Delta x_{i2} + \ldots + \Delta x_{in_i}\]
which can be visualized below
\begin{center}
    \includegraphics[scale=0.3]{Refinement_Definition_Analysis.PNG}
\end{center}
\end{theorem}

\begin{example}[Union of Partitions as a Refinement]
For some interval $[a, b]$, given partitions $P^\prime$ ($a = x_0 < \ldots < x_n = b$) and $P^{\prime\prime}$ ($a = y_0 < \ldots < y_n = b$), the union of the two partitions $\Tilde{P} = P^\prime \cup P^{\prime\prime}$ is a refinement of both $P^\prime$ and $P^{\prime\prime}$. 
\begin{center}
    \includegraphics[scale=0.3]{Refinement_as_Union_of_Partitions.PNG}
\end{center}
\end{example}

Recall that $\omega(f; E)$ denotes the oscillation of the function $f$ on the set $E$; that is, 
\[\omega(f; E) \equiv \sup_{x^\prime, x^{\prime\prime} \in E} \big| f(x^\prime) - f(x^{\prime\prime})\big|\]
In particular, $\omega(f; \Delta_i)$ is the oscillation of $f$ on the closed interval $\Delta_i$. 

\begin{theorem}[Sufficient Condition for Integrability]
Let $f$ be a bounded on a closed interval $[a, b]$ such that for every $\epsilon > 0$ there exists a number $\delta>0$ such that
\[\sum_{i=1}^n \omega(f; \Delta_i) \Delta x_i < \epsilon\]
for any partition $P$ of $[a, b]$ with mesh $\lambda(P) < \delta$. This is equivalent to saying that
\[\lim_{\lambda(P) \rightarrow 0} \sum_{i = 1}^n \omega (f; \Delta_i) \, \Delta x_i = 0\]
Then, $f$ is integrable. We can visualize
\[\sum_{i=1}^n \omega(f; \Delta_i) \Delta x_i\]
as the following sum of rectangles below. 
\begin{center}
    \includegraphics[scale=0.3]{Sufficient_Condition_for_Integrability.PNG}
\end{center}
What the theorem states, visually, is that as we make all the rectangles smaller and smaller (by putting a limit on the mesh $\lambda(P)<\delta$), we can make the sum of all these rectangles also arbitrarily small. 
\end{theorem}

\begin{corollary}[Integrability of Continuous Functions]
Every continuous function on a closed interval is integrable on that closed interval. That is, 
\[f \in C[a, b] \implies f \in \mathcal{R}[a, b]\]
\end{corollary}

We can actually make a stronger claim. 

\begin{corollary}[Integrability of Discontinuous Functions]
If a bounded function $f$ on a closed interval $[a, b]$ is continuous everywhere except at a finite set of points, then $f \in \mathcal{R}[a, b]$. 
\end{corollary}

\begin{corollary}[Integrability of Monotonic Functions]
A bounded monotonic function on a closed interval is integrable on that interval. 
\begin{center}
    \includegraphics[scale=0.3]{Integrability_of_Monotonic_Function.PNG}
\end{center}
\end{corollary}

\begin{definition}[Upper, Lower Riemann Sums]
Let $f: [a, b] \longrightarrow \mathbb{R}$ be a real-valued function that is defined and bounded on the closed interval $[a, b]$, and let $P$ be a partition of $[a, b]$, and let $\Delta_i$ ($i = 1, 2, \ldots, n$) be the intervals of the partition $P$. Let 
\begin{align*}
    m_i &= \inf_{x \in \Delta_i} f(x) \\
    M_i &= \sup_{x \in \Delta_i} f(x)
\end{align*}
be the infimum and supremum of $f$ over $\Delta x_i$. Then, the sums
\begin{align*}
    s(f; P) & \equiv \sum_{i = 1}^n m_i \, \Delta x_i \\
    S(f; P) & \equiv \sum_{i=1}^n M_i \, \Delta x_i
\end{align*}
are respectively called the \textit{lower} and \textit{upper Riemann sums} of the function $f$ on the interval $[a, b]$ corresponding to the partition $P$ of that interval. 

Given an arbitrary partition $(P, \xi)$ with distinguished points on $[a, b]$, it is clear that
\[s(f; P) = \inf_{\xi} \sigma(f; P, \xi) \leq \sigma(f; P, \xi) \leq \sup_{\xi} \sigma(f; P, \xi) = S(f; P)\]
\end{definition}

\begin{theorem}
A bounded real-valued function $f: [a, b] \longrightarrow \mathbb{R}$ is Riemann integrable on $[a, b]$ if and only if the following limits exist and are equal to each other. 
\[\underline{I} \equiv \lim_{\lambda(P) \rightarrow 0} s(f; P) = \lim_{\lambda(P) \rightarrow 0} S(f; P) \equiv \overline{I}\]
When the relation is true, then the integral is this common value. 
\[\int_a^b f(x) \,dx = \underline{I} = \overline{I}\]
\end{theorem}

Note that this condition of the upper and lower Riemann sums converging to the same value and the condition that 
\[\lim_{\lambda(P) \rightarrow 0} \sum_{i = 1}^n \omega (f; \Delta_i) \, \Delta x_i = 0\]
are the same. For we can see that the rectangles visualized from the equation above are the exact same rectangles formed by $S(f; P) - s(f; P)$! 
\begin{center}
    \includegraphics[scale=0.3]{Equivalent_Conditions_for_Integrability.PNG}
\end{center}

\subsubsection{The Vector Space of Riemann Integrable Functions}

\begin{theorem}[The Vector Space of Integrable Functions]
The set of Riemann integrable functions $\mathcal{R}[a, b]$ over closed interval $[a, b]$ is a vector space. That is, given $f, g \in \mathcal{R}[a, b]$ and $\alpha \in \mathbb{R}$, then
\begin{enumerate}
    \item $(f + g) \in \mathcal{R}[a, b]$ 
    \item $(\alpha f) \in \mathcal{R}[a, b]$
\end{enumerate}
Furthermore, 
\begin{enumerate}
    \item $|f| \in \mathcal{R}[a, b]$
    \item The restriction of $f$ in any $[c, d] \subset [a, b]$, denoted $f \big|_{[c,d]}$, is in $\mathcal{R}[c,d]$
    \item $(f \cdot g) \in \mathcal{R}[a, b]$
\end{enumerate}
\end{theorem}
\begin{proof}

\end{proof}

\subsubsection{Lebesgue's Criterion for Riemann Integrability}
We give Lebesgue's version of an intrinsic description of a Riemann integrable function. 

\begin{definition}[Measure]
A set $E \subset \mathbb{R}$ has \textit{(Lebesgue) measure zero} if for every number $\epsilon > 0$ there exists a covering of the set $E$ be an at most countable system $\{I_k\}$ of intervals, the sum of whose lengths 
\[\sum_{k=1}^\infty |I_k| \leq \epsilon\]
This means that the above series summing up the lengths of the intervals is an absolutely convergent series. 
\end{definition}

\begin{lemma}
We can deduce measures of basic sets. 
\begin{enumerate}
    \item A finite number of points are sets of measure zero. 
    \item The union of a finite or countable number of sets of measure zero is a set of measure zero. \item A subset of a set of measure zero is itself a set of measure zero. 
    \item A closed interval $[a, b]$ with $a<b$ is not a set of measure zero. 
\end{enumerate}
\end{lemma}

\begin{definition}
If a property holds at all points of a set $X$ except possible the points of a set of measure zero, we say that this property holds \textit{almost everywhere on $X$} or \textit{at almost every point of $X$}. 
\end{definition}

Now, we can state Lebesgue's criterion for integrability, which nicely summarizes what we have so far. 

\begin{theorem}[Lebesgue's Criterion for Integrability]
A function defined on a closed interval is Riemann integrable on that interval if and only if it is bounded and continuous at almost every point. 
\end{theorem}

\begin{example}[Non-Integrability of the Dirichlet Function]
The Dirichlet function
\[\mathcal{D}(x) \equiv \begin{cases}
1, & \text{ for } x \in \mathbb{Q} \\
0, & \text{ for } x \in \mathbb{R} \setminus \mathbb{Q}
\end{cases}\]
on the interval $[0,1]$ is not integrable on that interval. We state two different reasons why. 
\begin{enumerate}
    \item For any partition $P$ of $[0,1]$ we can find in each interval $\Delta_i$ both a rational point $\xi^\prime_i$ and an irrational point $\xi_i^{\prime\prime}$. Then, we can see that the lower and upper Riemann sums do not necessarily converge to each other since
    \[\sigma(f; P, \xi^\prime) = \sum_{i=1}^n 1 \cdot \Delta x_i = 1 \text{ while } \sigma(f;P, \xi^{\prime\prime}) = \sum_{i=1}^n 0 \cdot \Delta x_i = 0\]
    as $\lambda(P) \rightarrow 0$. 
    \item From the point of view of the Lebesgue criterion the nonintegrability of the Dirichlet function is obvious since $\mathcal{D}(x)$ is discontinuous at every point of $[0, 1]$, which is not a set of measure zero. 
\end{enumerate}
\end{example}

Notice that by the Lebesgue criterion, integrability is a weaker condition than continuity. That is, 
\[f \text{ continuous } \implies f \text{ Riemann integrable}\]
but not necessarily the other way around. It turns out that this has consequences when determining the composition of functions. 

\begin{proposition}[Integrable + Continuous Composition]
Let $f: I_1 = [a, b] \longrightarrow\mathbb{R}$ be a function that is integrable on $[a, b]$, with Im$\,f = [c, d] = I_2$. Define a continuous (remember, continuity is stronger than integrability) function $g: [c, d] \longrightarrow \mathbb{R}$. Then the composition
\[g \circ f: [a, b] \longrightarrow \mathbb{R}\]
is clearly defined and continuous at all the points of $[a, b]$ where $f$ is continuous. But since $f$ is integrable, the union of all the discontinuities in $[a, b]$ must have measure zero, and so it follows that since $[a, b]$ is the same  
\[g \circ f \in \mathcal{R}[a, b]\]
Therefore, we can found out that 
\[f \text{ integrable and } g \text{ continuous} \implies g \circ f \text{ integrable}\]
as visualized in the commutative diagram below. 
\[
  \begin{tikzcd}
    I_1 \arrow[r, "f"] \arrow[rr, bend left, "g \circ f"] & I_2 \arrow[r, "g"] & \mathbb{R}
  \end{tikzcd}
\]
However, contrary to intuition, 
\[f \text{ integrable and } g \text{ integrable} \centernot\implies g \circ f \text{ integrable}\]
\end{proposition}

We present a counterexample. 
\begin{example}
Consider the functions
\[|sgn|(x) \equiv \begin{cases}
1 & x \neq 0 \\
0 & x = 0
\end{cases}\]
and the Riemann function 
\[\mathcal{R}(x) \equiv \begin{cases}
\frac{1}{n} & x = \frac{m}{n} \in \mathbb{Q}, \gcd(m, n) = 1 \\
0 & x \in \mathbb{R} \setminus \mathbb{Q}
\end{cases}\]
We can see that $\mathcal{R}$ is continuous at all irrational points and discontinuous at all rational points except $0$, meaning that it is integrable ($\mathbb{Q}$ has measure zero). Then, the composition of these two functions is precisely the Dirichlet function
\[\mathcal{D}(x) = |sgn| \circ \mathcal{R}\]
which is not integrable. 
\end{example}

\subsection{Basic Properties of the Integral}

One of the most basic properties of the integral is that it is a linear map. 
\begin{lemma}[Linearity of the Integral]
Given closed interval $[a, b] \subset \mathbb{R}$, the Riemann integration function 
\[\int_a^b: \mathcal{R}[a, b] \longrightarrow \mathbb{R}\]
is a linear functional living within the dual space $\mathbb{R}^* [a, b]$. That is, given $f, g \in \mathcal{R}[a, b]$, a linear combination of them $\alpha f + \beta g$ is also integrable on $[a,b]$, and 
\[\int_a^b (\alpha f + \beta g)(x)\,dx = \alpha \int_a^b f(x)\,dx + \beta \int_a^b g(x)\,dx\]
\end{lemma}
\begin{proof}
It is clear from basic algebraic transformation that the Riemann sums for the integral expressions on both sides are equal. 
\[\sum_{i=1}^n (\alpha f + \beta g) (\xi_i) \Delta x_i = \alpha \sum_{i=1}^n f(\xi_i) \Delta x_i + \beta \sum_{i=1}^n g(\xi_i) \Delta x_i\]
Taking the limit as $\lambda(P) \rightarrow 0$ on both sides leads to the respective Riemann integrals. 
\end{proof}


The next property of the Riemann integral is its additive property \textit{on the interval of integration}. Note that the value of the integral 
\[\int_a^b f(x) \,dx \equiv \lim_{\lambda(P) \rightarrow 0} \sigma(f; P, \xi)\]
depends on both the integrand and the closed interval over which the integral is taken. 

\begin{lemma}[Properties of the Interval of Integration]
If $a < b < c$ and $f \in \mathcal{R}[a, c]$, then $f \big|_{[a,b]} \in \mathcal{R}[a, b]$, $f \big|_{[b,c]} \in \mathcal{R}[b, c]$, and the following equality holds 
\[\int_a^c f(x)\,dx = \int_a^b f(x)\, dx + \int_b^c f(x)\,dx\]
From these we set
\[\int_a^b f(x)\,dx \equiv - \int_b^a f(x)\,dx\]
and 
\[\int_a^a f(x)\,dx \equiv 0\]
\end{lemma}

\begin{theorem}[Symmetry of the Riemann Integral]
Let $a, b, c \in \mathbb{R}$ and let $f$ be integrable over the largest closed interval having two of these points as endpoints. Then, the restriction of $f$ to each of the other closed intervals is also integrable over those intervals and the following equality holds. 
\[\int_a^b f(x)\,dx + \int_b^c f(x)\,dx + \int_c^a f(x)\,dx = 0\]
This property can be abstractified to those of additive interval functions, which will be shown soon. 
\end{theorem}

We finally end with an important property of the integral which, as seen later, allows us to define inner products on function spaces. 
\begin{theorem}
If $a \leq b$ and $f \in \mathcal{R}[a, b]$, then $|f| \in \mathcal{R}[a, b]$, and 
\[\Bigg| \int_a^b f(x)\,dx \Bigg| \leq \int_a^b |f|(x)\,dx\]
\end{theorem}

\subsubsection{Mean Value Theorem of the Integral}

\begin{lemma}[Monotonicity of the Integral]
If $a \leq b, f_1, f_2 \in \mathcal{R}[a, b]$, and $f_1 (x) \leq f_2 (x)$ for every $x \in [a, b]$, then
\[\int_a^b f_1 (x)\,dx \leq \int_a^b f_2 (x)\,dx\]
\begin{center}
    \includegraphics[scale=0.27]{Monotonicity_of_Integral.PNG}
\end{center}
This immediately implies that given constants $m, M$ such that $m \leq f(x) \leq M$ at each $x \in [a, b]$, we have
\[m \cdot (b - a) \leq \int_a^b f(x)\,dx \leq M \cdot (b-a)\]
This is very easily visualized below. 
\begin{center}
    \includegraphics[scale=0.27]{Monotonicity_of_Intergral_2.PNG}
\end{center}
In particular, if $0 \leq f(x)$ on $[a, b]$, then
\[0 \leq \int_a^b f(x)\,dx\]
\end{lemma}

\begin{theorem}[Mean Value Theorem of the Integral]
Given $f \in \mathcal{R}[a, b]$, with 
\[m = \inf_{x \in [a, b]} f(x) \text{ and } M = \sup_{x \in [a, b]} f(x)\]
then there exists a number $\mu \in [m, M]$ such that
\[\int_a^b f(x)\,dx = \mu \cdot (b - a)\]
Furthermore, if $f \in C[a, b]$ (that is, continuous on $[a, b]$), it immediately follows by the intermediate value theorem that there exists a point $\xi \in [a, b]$ such that
\[\int_a^b f(x)\,dx = f(\xi) (b - a)\]
\begin{center}
    \includegraphics[scale=0.27]{Mean_Plus_Intermediate_Value_Theorem_Integral.PNG}
\end{center}
\end{theorem}

Due to the length of the proof, we ask the reader to take it for granted the following theorem. 

\begin{theorem}[Bonnet's Formula]
If $f, g \in \mathcal{R}[a, b]$ and $g$ is a monotonic function on $[a, b]$, then there exists a point $\xi \in [a, b]$ such that
\[\int_a^b (f \cdot g) (x)\,dx = g(a) \int_a^\xi f(x)\,dx + g(b) \int_\xi^b f(x)\,dx\]
\end{theorem}

\subsection{Connections between Integrals, Primitives, Derivatives}
\begin{definition}[Integral with Variable Upper Limit]
Let $f \in \mathcal{R}[a, b]$, and let us choose an $x \in [a, b]$ in order to construct the function
\[F(x) \equiv \int_a^x f(t)\,dt\]
which is called an \textit{integral with variable upper limit}. Note that since $[a, x] \subset [a, b]$, it follows that $f \big|_{[a,x]} \in \mathcal{R}[a, x]$ and therefore the function $x \mapsto F(x)$ is unambiguously defined for $x \in [a, b]$. 
\begin{center}
    \includegraphics[scale=0.27]{Integral_with_Variable_Upper_Limit.PNG}
\end{center}
Furthermore, $F(x)$ is continuous on $[a, b]$. Since $f$ is integrable on $[a, b]$, it is bounded by a constant $C$ such that
\[|f(t)| \leq C \text{ on } [a, b]\]
It follows from the additive properties of the integral and boundedness theorem that 
\[|F(x + h) - F(x)| \leq C|h|\]
if $x, x + h \in [a, b]$, as visualized. This means that for any $\delta$-neighborhood of $F(x)$, we can find an arbitrary small $h$ such that the $C|h|$-neighborhood of $F(x)$ is completely contained in the $\delta$-neighborhood. But by the inequality above, this means that there exists an $\epsilon = h$-neighborhood of $x$ such that its entire image is contained within the $C|h|$-neighborhood, which itself is contained within the $\delta$-neighborhood. This shows that $F$ is continuous. 
\end{definition}

\begin{theorem}[First Fundamental Theorem of Calculus]
Let $f \in \mathcal{R}[a, b]$ be continuous at point $x \in [a, b]$ (resp. continuous on closed interval $[a, b]$). Let $F$ be the function, defined for all $x \in [a, b]$ by 
\[F(x) \equiv \int_a^x f(t)\,dt\]
Then, $f$ is continuous and differentiable at $x$ (resp. uniformly continuous on $[a, b]$ and differentiable on $(a, b)$), 
\[F^\prime (x) = f(x)\]
at $x$ (resp. for all $x \in [a, b]$). This is an amazing fact, because visually, it tells us that the rate at which the integral $F$ is increasing at $x$ (represented by the increasing area under the curve of $f$) is equal to the value of $f$ at the point $x$ itself! 
\begin{center}
    \includegraphics[scale=0.32]{First_Fundamental_Theorem_Analysis.jpg}
\end{center}
\end{theorem}
\begin{proof}
Let $x, x + h \in [a, b]$, and let us estimate the difference $F(x+h) - F(x)$. It follows from the continuity of $f$ at $x$ that $f(t) = f(x) + \Delta(t)$, where $\Delta(t) \rightarrow 0$ as $t \rightarrow x$. If point $x$ is held fixed, the function 
\[\Delta(t) = f(t) - f(x)\]
is integrable on $[a, b]$, being the difference of the integrable function $t \mapsto f(t)$ and the constant $f(x)$. Let us denote
\[M(h) \equiv \sup_{t \in [x, x+h]} |\Delta(t)|\]
which means that $M(h)$ is the largest difference between $f(x)$ and $f(t)$ in the interval $[x, x+h]$. 
\begin{center}
    \includegraphics[scale=0.3]{Proof_First_Fundamental_Theorem_Analysis.jpg}
\end{center}
Clearly $M(h) \rightarrow 0$ as $h \rightarrow 0$. We can now find
\begin{align*}
    F(x + h) - F(x) & = \int_a^{x+h} f(t)\,dt - \int_a^x f(t)\,dt \\
    & = \int_x^{x+h} f(t)\,dt \\
    & = \int_x^{x+h} \big( f(x) + \Delta(t)\big)\,dt \\
    & = \int_x^{x+h} f(x)\,dt + \int_x^{x+h} \Delta(t)\,dt \\
    & = f(x) h + \alpha(h) h
\end{align*}
where we have set 
\[\int_x^{x+h} \Delta(t)\,dt = \alpha(h) h\]
where $\alpha$ is infinitesimal as $h \rightarrow 0$, since 
\[\Bigg| \int_x^{x+h} \Delta(t)\,dt \Bigg| \leq \Bigg| \int_x^{x+h} |\Delta(t)|\,dt \Bigg| \leq \Bigg| \int_x^{x+h} M(h)\,dt \Bigg| = M(h) |h| = \alpha(h)|h|\]
Therefore, we have shown that if the function $f$ is continuous at a point $x \in [a, b]$, then for displacements $h$ from $x$ such that $x +h \in [a, b]$, the following equality holds.
\[F(x + h) - F(x) = f(x) h + \alpha(h) h\]
where $\alpha(h) \rightarrow 0$ as $h \rightarrow 0$, and by definition, this means that $F(x)$ is differentaible on $[a, b]$ at the point $x \in [a, b]$ and that $F^\prime(x) = f(x)$. 
\end{proof}

\begin{corollary}
Every bounded function $f: [a, b] \longrightarrow \mathbb{R}$ on the closed interval $[a, b]$ and has only a finite number of points of discontinuity has a primitive, and every primitive of $f$ on $[a, b]$ has the form 
\[\mathcal{F}(x) \equiv \int_a^x f(t)\,dt + c\]
where $c$ is a constant. 
\end{corollary}

\begin{theorem}[Second Fundamental Theorem of Calculus]
Let $f$ be a real-valued function on a closed interval $[a, b]$ with $\mathcal{F}$ any primitive of $f$ on $[a, b]$. If $f$ is Riemann-integrable (i.e. $f$ bounded with finite points of Lebesgue measure zero) on $[a, b]$, then 
\[\int_a^b f(x)\,dx  = \mathcal{F} \big|_a^b \equiv \mathcal{F}(b) - \mathcal{F}(a)\]
\begin{center}
    \includegraphics[scale=0.3]{Second_Fundamental_Theorem_Analysis.PNG}
\end{center}
\end{theorem}
\begin{proof}
We already know that a bounded function on a closed interval having a finite number of discontinuities is integrable, and by the corollary, we are guaranteed an existence of a primitive $\mathcal{F}(x)$ of the function $f$ on $[a, b]$ with the form 
\[\mathcal{F} (x) \equiv \int_a^x f(t)\,dt + c\]
Setting $x = a$, we find that $c = \mathcal{F}(a)$, and so 
\[\mathcal{F}(x) \equiv \int_a^x f(t)\,dt + \mathcal{F}(a)\]
Evaluating $\mathcal{F}$ at $x = b$ gives
\[\int_a^b f(t)\,dt = \mathcal{F}(b) - \mathcal{F}(a)\]
\end{proof}

\subsubsection{Integration by Parts and Taylor's Formula}
\begin{theorem}[Definite Integration by Parts]
If the functions $u(x)$ and $v(x)$ are continuously differentiable on a closed interval with endpoints $a$ and $b$, then
\[\int_a^b (u \cdot v^\prime)(x)\,dx = (u \cdot v)\big|^b_a - \int_a^b (v \cdot u^\prime)(x)\,dx\]
which is customarily written in the form as
\[\int_a^b u\,dv = u \cdot v \big|_a^b - \int_a^b v\,du\]
\end{theorem}
\begin{proof}
By the product rule of differentiation, we have
\[(u \cdot v)^\prime (x) = (u^\prime \cdot v)(x) + (u \cdot v^\prime) (x)\]
where by hypothesis, $u^\prime \cdot v, u \cdot v^\prime$ are continuous and hence integrable on $[a, b]$. Using the linearity of the integral and the 2nd fundamental theorem of calculus, we get
\[(u \cdot v) (x) \big|^b_a = \int_a^b (u^\prime \cdot v)(x)\,dx + \int_a^b (u \cdot v^\prime) (x)\,dx\]
\end{proof}

\begin{theorem}[Integral Form of the Remainder]
If $f: E \longrightarrow \mathbb{R}$ has continuous derivatives up to order $n$ on the closed interval $[a, x]$, then Taylor's formula holds
\[f(x) = f(a) + \frac{f^\prime (a)}{1!} (x - a) + \ldots + \frac{f^{(n-1)}(a)}{(n-1)!} (x - a)^{n-1} + r_{n-1}(a; x)\]
where 
\[r_{n-1} (a;x) = \frac{1}{(n-1)!} \int_a^x f^{(n)} (t) (x - t)^{n-1} \,dt\]
This form is called \textit{Taylor's formula with the integral form of the remainder}. 
\end{theorem}
\begin{proof}
Using the 2nd fundamental theorem and the definite integration by parts formula, we can carry out the following chain of transformations, assuming continuity and differentiability when needed. 
\begin{align*}
    f(x) - f(a) & = \int_a^x f^\prime (t) \,dt \\
    & = - \int_a^x f^\prime(t) (x - t)^\prime \,dt \\
    & = -f^\prime (t) (x - t)\big|_a^x + \int_a^x f^{\prime\prime} (t) (x - t) \,dt \\
    & = f^\prime (a) (x - a) - \frac{1}{2} \int_a^x f^{\prime\prime} (t) \big( (x - t)^2\big)^\prime \,dt \\
    & = f^\prime (x - a) - \frac{1}{2} f^{\prime\prime} (t) (x - t)^2 \big|_a^x + \frac{1}{2} \int_a^x f^{\prime\prime\prime} (t) (x - t)^2\,dt \\
    & = f^\prime(a) (x - a) + \frac{1}{2} f^{\prime\prime} (a) (x - a)^2 - \frac{1}{2 \cdot 3} \int_a^x f^{\prime\prime\prime} (t) \big((x - t)^3\big)^\prime\,dt \\
    & = \ldots \\
    & = f^\prime (a) (x - a) + \ldots + \frac{1}{(n-1)!} f^{(n-1)} (a)(x - a)^{n-1} + r_{n-1}(a;x)
\end{align*}
where $r_{n-1}(a;x)$ is given by the integral formula mentioned. 
\end{proof}

\subsubsection{Change of Variables in Integration}
We now show and prove the method what we call "u-substitution" for definite integration. 

\begin{theorem}[Change of Variable]
If $\varphi: [\alpha, \beta] \longrightarrow [a, b]$ is a continuously differentiable mapping such that $\varphi(\alpha) = a$ and $\varphi(\beta) = b$, then for any continuous function $f(x)$ on $[a, b]$ the function $f\big(\varphi(t)\big) \varphi^\prime (t)$ is continuous on the closed interval $[\alpha, \beta]$ and 
\[\int_a^b f(x)\,dx = \int_\alpha^\beta f\big(\varphi(t)\big) \varphi^\prime(t)\,dt\]
\begin{center}
    \includegraphics[scale=0.3]{Change_of_Variable_Analysis_Integral.jpg}
\end{center}
\end{theorem}
\begin{proof}
We prove a slightly weaker form of the theorem with the additional hypothesis that $\varphi$ is strictly monotonic. 
\end{proof}

\subsubsection{Additive Interval Functions and the Integral}
In this section we take a step back and construct the integral in a more abstract sense, using the concepts of an additive interval function. 

\begin{definition}[Additive Interval Function]
An \textit{additive (oriented) interval function} is a function 
\[(\alpha, \beta) \mapsto I(\alpha, \beta) \in \mathbb{R}\]
that assigns a number $I(\alpha, \beta)$ to each ordered pair of points $(\alpha, \beta)$ of a fixed closed interval $[a, b]$ in such a way that the following equality holds for any triple of points $\alpha, \beta, \gamma \in [a, b]$. 
\[I(\alpha, \gamma) = I(\alpha, \beta) + I(\beta, \gamma)\]
Notice that the integral holds this property, shown in the theorem on the symmetric property of the integral. It follows that all additive interval functions are anticommutative: 
\[I(\alpha, \beta) + I(\beta, \alpha) = 0\]
which immediately results in
\[I(\alpha, \alpha) = 0\]
\end{definition}

\begin{lemma}[Generating Functions of Additive Interval Functions]
For any function $x \mapsto \mathcal{F}(x)$ that maps points on the interval $[a, b]$ to $\mathbb{R}$, we set
\[\mathcal{F}(x) \equiv I(a, x)\]
and by additivity we have
\[I(\alpha, \beta) = I(\alpha, \beta) - I(a, \alpha) = \mathcal{F}(\beta) - \mathcal{F}(\alpha)\]
and thus, every additive oriented interval function has the form 
\[I(\alpha, \beta) = \mathcal{F}(\beta) - \mathcal{F}(\alpha)\]
By constructing $I$ in this manner, we say that \textit{the function $\mathcal{F}$ generates the additive function $I$}. 
\end{lemma}

\begin{example}
If $f \in \mathcal{R}[a, b]$, the function $\mathcal{F} = \int_a^x f(t)\,dt$ generates the additive function
\[I(\alpha, \beta) = \mathcal{F}(\beta) - \mathcal{F}(\alpha) = \int_a^\beta f(t)\,dt - \int_a^\alpha f(t)\,dt = \int_\alpha^\beta f(t)\,dt\]
\end{example}

We conclude by stating a sufficient condition for an additive interval function to be generated by an integral. 
\begin{theorem}
Suppose the additive function $I(\alpha, \beta)$ defined for points $\alpha, \beta \in [a, b]$ has the property that, for some known function $f \in \mathcal{R}[a, b]$, 
\[\inf_{x \in [\alpha, \beta]} f(x) (\beta - \alpha) \leq I(\alpha, \beta) \leq \sup_{x \in [\alpha, \beta]} f(x) (\beta - \alpha)\]
holds for any closed interval $[\alpha, \beta] \subset [a, b]$ ($\alpha \leq \beta$). Then, the additive function $I$ must be the definite integral
\[I(a, b) = \int_a^b f(x)\,dx\]
\end{theorem}

This theorem is extremely useful. It says that if we have any abstract additive interval function $I(\alpha, \beta)$ that satisfies the properties above, then it \textbf{must} be generated by an integral with variable upper limit, meaning that (by the previous example) $I$ itself must be a definite integral! 

\subsubsection{Arc Length}
When modeling systems in physics, one of the most fundamental tools we use are path functions that models the movement of a particle in $\mathbb{R}^3$. 

\begin{definition}[Path]
A \textit{path} in $\mathbb{R}^3$ is a continuous mapping $r: [a, b] \subset \mathbb{R} \longrightarrow \mathbb{R}^3$ defined
\[t \mapsto \big(x(t), y(t), z(t)\big)\]
of an interval of the real line into $\mathbb{R}^3$ defined by the (continuous) scalar functions $x, y, z$. The endpoints 
\[A = \big(x(a), y(a), z(a)\big) \text{ and } B = \big(x(b), y(b), z(b)\big)\]
in $\mathbb{R}^3$ are called the \textit{initial point} and \textit{terminal point} of the path. Furthermore, a path is \textit{closed} if its initial and terminal points coincide. 
\end{definition}

\begin{definition}[Support]
If $\Gamma: I \longrightarrow \mathbb{R}^3$ is a path, the image $\Gamma(I) \subset \mathbb{R}^3$ is called the \textit{support} of the path. 
\end{definition}

\begin{definition}[Simple Paths]
A path $\Gamma: I \longrightarrow \mathbb{R}^3$ that is injective is called a \textit{simple path}, or a \textit{paramaterized curve}, and its support is called a \textit{curve} in $\mathbb{R}^3$. 

A closed path $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ is called a \textit{simple closed path/curve} if the path $\Gamma: [a, b) \longrightarrow \mathbb{R}^3$ is simple. 
\end{definition}

\begin{definition}[Smooth Paths]
A path $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ is $C^k$ smooth if the functions $x(t), y(t), z(t)$ are $C^k$ smooth. $\Gamma$ is \textit{piecewise smooth} if the closed interval $[a, b]$ can be partitioned into a finite number of closed intervals on each of which the corresponding restriction of $\Gamma$ is smooth. 
\end{definition}

Now, we are ready to construct the length of a smooth path $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$. Our initial ideas about the length $l[a, b]$ of the path traversed during the time interval $\alpha \leq t \leq \beta$ are as follows: 
\begin{enumerate}
    \item If $\alpha < \beta < \gamma$, then $l$ is an additive interval function.
    \[l[\alpha, \gamma] = l[\alpha, \beta] + l[\beta, \gamma]\]
    \item If $v(t) = \big( x^\prime (t), y^\prime (t), z^\prime (t)\big)$ is the velocity of the point at time $t$, then 
    \[\int_{x \in [\alpha, \beta]} |v(t)| (\beta - \alpha) \leq l[\alpha, \beta] \leq \sup_{x \in [\alpha, \beta]} |v(t)| (\beta - \alpha)\]
\end{enumerate}
Thus, if the functions $x, y, z$ are continuously differentiable on $[a, b]$, this is sufficient condition (by the theorem in the previous subsection) that the additive function $l$ is an integral.

\begin{definition}[Arc Length Integral]
The length of a smooth path $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ is defined by 
\[l[a, b] \equiv \int_a^b |\Gamma^\prime (t)|\,dt \equiv \int_a^b \sqrt{x^{\prime 2} (t) + y^{\prime 2} (t) + z^{\prime 2} (t)}\, dt\]
We can visualize this by partitioning the interval $[a, b]$ into the intervals $\Delta_i$, each with point $\xi_i \in \Delta_i$. This would partition the path to $\Gamma(\Delta_i)$, each with points $\Gamma(\xi_i)$, and at each point $\Gamma(\xi_i)$, we can imagine the velocity vector of the curve. By taking the magnitude of this vector $\Gamma^\prime (\xi_i)$, we multiply it by the length of the interval $\Delta x_i$ to get one rectangle, creating an approximation for one partition of the path. 
\begin{center}
    \includegraphics[scale=0.32]{Arc_Length_Integral.PNG}
\end{center}
An immediate result of this formula is the formula for the length of a graph of a function $f: [a, b] \longrightarrow \mathbb{R}$ in $\mathbb{R}^2$, by looking at the paramaterization $t \mapsto \Gamma(t) = \big(t, f(t)\big)$. 
\[l[a,b] \equiv \int_a^b \sqrt{1 + (f^\prime (t))^2}\,dt\]
\end{definition}

The question on the effect of paramaterization on the integral now arises. 

\begin{definition}[Admissible Change of Parameter]
The path $\Tilde{\Gamma}: [\alpha, \beta] \longrightarrow \mathbb{R}^3$ is obtained from $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ by an \textit{admissible change of parameter} if there exists a smooth mapping 
\[T: [\alpha, \beta] \longrightarrow [a, b]\]
such that $T(\alpha) = a, T(\beta) = b$, $T^\prime (\tau) > 0$ (that is, the reparamaterization $T$ is monotonic) on $[\alpha, \beta]$, and 
\[\Tilde{\Gamma} = \Gamma \circ T\]
The series of mappings can be represented with the following commutative diagram, where $I_{\alpha, \beta} = [\alpha, \beta] \subset \mathbb{R}$ and $I_{a, b} = [a, b] \subset \mathbb{R}$. 
\[
  \begin{tikzcd}
    I_{\alpha, \beta} \arrow{r}{T} \arrow{rd}{\Tilde{\Gamma}}& I_{a, b} \arrow{d}{\Gamma}\\
     & \mathbb{R}^3
  \end{tikzcd}
\]
or with the more detailed visual below (Note that the points are labeled $0, 1, 2, 3, 4, 5$ do not represent numerical values, but rather the order in which the points are paramaterized. We can see from this ordering that $T$ is monotonic.)
\begin{center}
    \includegraphics[scale=0.3]{Admissible_Change_of_Parameter.jpg}
\end{center}
\end{definition}

\begin{theorem}[Invariance of Arclength Integral under Admissible Change of Parameters]
If a smooth path $\Tilde{\Gamma}: [\alpha, \beta] \longrightarrow \mathbb{R}^3$ is obtained from a smooth path $\Gamma: [a, b] \longrightarrow \mathbb{R}^3$ by an admissible change of parameter, then the lengths of the two paths are equal. That is, a
\[\int_a^b |\Gamma^\prime (t) |\,dt = \int_\alpha^\beta |\Tilde{\Gamma}^\prime (t)|\,dt \equiv \int_\alpha^\beta |(\Gamma \circ T)^\prime (t)|\,dt\]
\end{theorem}


\subsection{Improper Integrals}
Due to some limitations of the Riemann integral, we cannot integrate over "singularities" where either the interval or the function is unbounded. We develop the tools of improper integration to deal with this problem; there are two types of improper integrals. 

\begin{definition}[Improper Integral of Unbounded Interval]
Suppose the function $x \mapsto f(x)$ is defined on the interval $[a, +\infty)$ and is integrable on every closed interval $[a, b]$ contained in that interval. Then, we call the following term
\[\int_a^{+\infty} f(x)\,dx \equiv \lim_{b \rightarrow + \infty} \int_a^b f(x)\,dx\]
the \textit{improper Riemann integral of $f$ over the interval $[a, +\infty)$} and 
\[\int_{-\infty}^b f(x)\,dx \equiv \lim_{a \rightarrow -\infty} \int_a^b f(x)\,dx \]
the \textit{improper Riemann integral of $f$ over the interval $(-\infty, b]$}.If the limit exists, then we say that the integral \textit{converges} and \textit{diverges} otherwise. 
\end{definition}

\begin{definition}[Improper Integral of Unbounded Function]
Suppose the function $x \mapsto f(x)$ is defined on the interval $[a, B)$ and integrable on any closed interval $[a, b] \subset [a, B)$. Then, we call the following term
\[\int_a^B f(x)\,dx \equiv \lim_{b \rightarrow B^-} \int_a^b f(x)\,dx\]
the \textit{improper Riemann integral of $f$ over interval $[a, B)$} and
\[\int_A^b f(x)\,dx \equiv \lim_{a \rightarrow A^+} \int_a^b f(x)\,dx\]
the \textit{improper Riemann integral of $f$ over interval $(A,b]$}.
\end{definition}

For cohesiveness, we can combine these two definitions of improper integrals into the following one. 

\begin{definition}[Improper Integrals]
Let $[a, \omega)$ be a finite or infinite interval and $x \mapsto f(x)$ a function defined on that interval and integrable over every closed interval $[a, b] \subset [a, \omega)$. Then, by definition
\[\int_a^\omega f(x)\,dx \equiv \lim_{b \rightarrow \omega} \int_a^b f(x)\,dx\]
if this limit exists as $b \rightarrow \omega, b \in [a, \omega)$. Similarly, given the finite or infinite interval $(\omega, b]$ with $f$ integrable over every closed interval $[a, b] \subset (\omega, b]$, we have
\[\int_\omega^b f(x)\,dx \equiv \lim_{a \rightarrow \omega} \int_a^b f(x)\,dx\]
Note that if $\omega \in \mathbb{R}$ and $f \in \mathcal{R}[a, \omega]$, the improper integral is equivalent to the regular Riemann integral. 
\[\int_a^\omega f(x) = \lim_{b\rightarrow \omega} \int_a^b f(x)\,dx\]
\end{definition}

\begin{lemma}[Properties of the Improper Integral]
Suppose $f, g$ are functions defined on interval $[a, \omega)$ (without loss of generality, we let $\omega$ be the upper limit of integration) and integrable on every closed interval $[a, b] \subset [a, \omega)$. Suppose the improper integrals 
\[\int_a^\omega f(x)\,dx \text{ and } \int_a^\omega g(x)\,dx\]
are well-defined. 
\begin{enumerate}
    \item For any $\lambda_1, \lambda_2 \in \mathbb{R}$ the function $(\lambda_1 f + \lambda_2 g)(x)$ is integrable in the improper sense on $[a, \omega)$ and
    \[\int_a^\omega (\lambda_1 f + \lambda_2 g)(x)\,dx = \lambda_1 \int_a^\omega f(x)\,dx + \lambda_2 \int_a^\omega g(x)\,dx\]
    \item For any $c \in [a, \omega)$, 
    \[\int_a^\omega f(x)\,dx = \int_a^c f(x)\,dx + \int_c^\omega f(x)\,dx\]
    \item If $\varphi: [\alpha, \gamma) \longrightarrow [a, \omega)$ is a smooth strictly monotonic mapping with $\varphi(\alpha) = a$ and $\varphi(\beta) \rightarrow \omega$ as $\beta \rightarrow \gamma^-$, then the improper integral of the function $t \mapsto (f \circ \varphi)(t) \varphi^\prime (t)$ over $[\alpha, \gamma)$ exists and 
    \[\int_a^\omega f(x)\,dx = \int_\alpha^\gamma (f \circ \varphi)(t) \varphi^\prime (t)\,dt\]
\end{enumerate}
\end{lemma}

\subsubsection{Convergence of an Improper Integral}
Note that by definition, an improper integral 
\[\int_a^\omega f(x)\,dx \equiv \lim_{b \rightarrow \omega} \int_a^b f(x) \,dx\]
is a limit of the function 
\[\mathcal{F}(b) \equiv \int_a^b f(x)\,dx\]
as $b \rightarrow \omega$. This means that we can use the Cauchy criterion to determine the convergence of this limit, and hence, existence of this improper integral. 

\begin{theorem}[Cauchy Criterion for Convergence of an Improper Integral]
If the function $x \mapsto f(x)$ is defined on the interval $[a, \omega)$ and integrable on every closed interval $[a, b] \subset [a, \omega)$, then the integral 
\[\int_a^\omega f(x)\,dx\]
converges if and only if for every $\epsilon > 0$ there exists $B \in [a, \omega)$ such that the relation
\[\Bigg| \int_{b_1}^{b_2} f(x)\,dx \bigg| < \epsilon\]
holds for any $b_1, b_2 \in [a, \omega)$ satisfying $B < b_1$ and $B < b_2$. 
\end{theorem}
\begin{proof}
We have
\[\int_{b_1}^{b_2} f(x)\,dx = \int_a^{b_2} f(x)\,dx - \int_a^{b_1} f(x)\,dx = \mathcal{F}(b_2) - \mathcal{F}(b_1)\]
and therefore the condition is simply the Cauchy criterion for the existence of a limit for the function $\mathcal{F}(b)$ as $b \rightarrow \omega$. 
\end{proof}

\begin{definition}[Absolute Convergence of an Improper Integral]
The improper integral 
\[\int_a^\omega f(x)\,dx\]
\textit{converges absolutely} if the integral
\[\int_a^\omega |f|(x)\,dx\]
converges. Clearly, the inequality
\[\Bigg| \int_{b_1}^{b_2} f(x)\,dx \Bigg| \leq \Bigg| \int_{b_1}^{b_2} |f|(x)\,dx \Bigg|\]
implies that if an improper integral converges absolutely, then it converges. 
\end{definition}

This study of absolute convergence reduces to the study of convergence of integrals of nonnegative functions. The following lemma is useful in determining convergence of such functions. 

\begin{lemma}
Let there be a function $f$ defined on interval $[a, \omega)$ that is also integrable over every closed interval $[a, b] \subset [a, \omega)$. If $f(x) \geq 0$ on $[a, \omega)$, then the improper integral 
\[\int_a^\omega f(x)\,dx\]
exists if and only if the function 
\[\mathcal{F}(b) \equiv \int_a^b f(x)\,dx\]
is bounded on $[a, \omega)$. 
\end{lemma}
\begin{proof}
It is clear that 
\[\int_a^\omega f(x)\,dx = \lim_{b \rightarrow \omega} \mathcal{F}(b)\]
If $f(x)\geq 0$, then the function $\mathcal{F}(b)$ is nondecreasing on $[a, \omega)$ and therefore has a limit as $b \rightarrow \omega$ only if it is bounded (since every monotonically increasing sequence that is bounded always converges). 
\end{proof}

This leads to the familiar integral test for convergence of a series. 

\begin{theorem}[Integral Test for Convergence of a Series]
If the function $x \mapsto f(x)$ is defined on the interval $[1, +\infty)$, nonnegative, nonincreasing, and integrable on each closed interval $[1, b] \subset [1, +\infty)$, then the series 
\[\sum_{n=1}^\infty f(n) = f(1) + f(2) + \ldots\]
and the integral 
\[\int_a^{+\infty} f(x)\,dx\]
either both converge or both diverge. 
\end{theorem}

We can use the comparison test analogue to determine convergence of improper integrals. 

\begin{theorem}[Comparison Test for Convergence of Improper Integrals]
Suppose the functions $f(x), g(x)$ are defined on the interval $[a, \omega)$ and integrable on any closed interval $[a, b] \subset [a, \omega)$. If 
\[0 \leq f(x) \leq g(x)\]
on $[a, \omega)$, then 
\[\int_a^\omega g(x)\,dx \text{ converges} \implies \int_a^\omega f(x)\,dx \text{ converges}\]
and the inequality 
\[\int_a^\omega f(x)\,dx \leq \int_a^\omega g(x)\,dx\]
holds. Also, 
\[\int_a^\omega f(x)\,dx \text{ diverges} \implies \int_a^\omega g(x)\,dx \text{ diverges}\]
\end{theorem}
\subsubsection{Improper Integrals with Multiple Singularities}

\begin{definition}[Improper Integral with Both Limits as Singularities]
Given singularities $\omega_1, \omega_2$, the improper integral is defined
\[\int_{\omega_1}^{\omega_2} f(x)\,dx \equiv \int_{\omega_1}^c f(x)\,dx + \int_c^{\omega_2} f(x)\,dx\]
where $c$ is an arbitrary point in $(\omega_1, \omega_2)$. 
\end{definition}

\begin{example}[Gaussian Integral]
The integral 
\[\int_{-\infty}^{+\infty} e^{-x^2}\,dx = \sqrt{\pi}\]
\end{example}

\chapter{Probability}
An abstract introduction to probability and its applications. 

\section{Probability Spaces}
In order to define a probability space, we must revisit a concept in algebra. 

\begin{definition}
A \textbf{$\sigma$-algebra} (or a \textbf{$\sigma$-field}) on a set $X$ is a collection $\Sigma$ of subsets fo $X$ that includes $X$ itself, is closed under complement, and is closed under countable unions. 

This definition implies that $\emptyset \in X$, and $\Sigma$ is closed under countable intersections. Furthermore, a $\sigma$-algebra is a type of algebra of sets. 
\end{definition}

\begin{example}
Given any set $X$, $2^X$ is a $\sigma$-algebra. 
\end{example}

\begin{example}
A $\sigma$-algebra $\mathcal{F} \subseteq 2^{\Omega}$ corresponds to a finite or countable partition $\Omega = B_1 \cup B_2 \cup \ldots$, with the general form of an event $A \in \mathcal{F}$ being 
\[A = B_{k_1} \cup B_{k_2} \cup \ldots \]
\end{example}

\begin{definition}
A \textbf{measure} on a set is a systematic way to assign a number, intuitively interpreted as its "size," to some subsets of that set, called \textbf{measurable sets}. That is, let $X$ be a set and $\Sigma$ be a $\sigma$-algebra over $X$. A function $\mu: \Sigma \longrightarrow \mathbb{R} \cup \{\infty, -\infty\}$ is called a measure if it satisfies the following properties: 
\begin{enumerate}
    \item Non-negativity: For all $E \in \Sigma$, we have $\mu (E) \geq 0$. 
    \item Null empty set: $\mu (\emptyset) = 0$
    \item Countable additivity: For all countable collections $\{E_k\}_{k=1}^\infty$ of pairwise disjoint sets in $\Sigma$, 
    \[\mu \bigg( \bigsqcup_{k=1}^\infty E_k \bigg) = \sum_{k=1}^\infty \mu (E_k)\]
\end{enumerate}
If at least one set $E$ has finite measure, then the requirement that $\mu (\empty) = 0$ is met automatically. Indeed, by countable additivity, 
\[\mu(E) = \mu(E \cup \emptyset) = \mu(E) + \mu(\emptyset) \implies \mu(\emptyset) = 0\]
\end{definition}

\subsubsection{Lebesgue Measure}
A popular measure and one that is a generalization of our natural notions of length, area, and volume is the \textit{Lebesgue measure}. To properly introduce the motivation for this measure, we recognize the need to measure the "size" of a set in $\mathbb{R}$. For intervals $I = (a, b)$, we can simply use the length $l$ defined as 
\[l(I) \equiv b - a, \;\;\; \text{ where } a \leq b\]
However, if we are measuring the set of, say, all irrational numbers in $\mathbb{R}$, this notion of length fails us. Therefore, we must extend this concept of length/size of an interval to arbitrary sets. Given a set $E$ of real numbers, let $\lambda(E)$ represent its Lebesgue measure, which should have properties: 
\begin{enumerate}
    \item If $I$ is an interval, then $\lambda(I)$ should naturally be $l(I)$. 
    \item If $A \subset B$, then $\lambda (A) \leq \lambda(B)$. 
    \item Given $A \subset \mathbb{R}$ and $x_0 \in \mathbb{R}$, define $A + x_0 \equiv \{x + x_0\,|\, x \in A\}$, the translation of $A$. Then $\lambda (A + x_0) = \lambda (A)$, since translation should not change the measure. 
    \item If $A, B$ are disjoint sets, then $\lambda(A \cup B) = \lambda(A) + \lambda(B)$. That is, if $\{A_i\}_{i \in \mathbb{N}}$ is a sequence of disjoint sets, then 
    \[\lambda \bigg( \bigcup_{i=1}^\infty A_i\bigg) = \sum_{i=1}^\infty \lambda(A_i)\]
\end{enumerate}
However, it is a fact that it is \textit{not} possible to define a measure that satisfies all of these properties for all subsets of real numbers. The difficulty lies in property $4$, which is essential to guarantee the linearity of the Lebesgue integral. In other words, some sets will not have a Lebesgue measure, that is, are not Lebesgue measurable. 

\begin{definition}
Let $E \subseteq \mathbb{R}$. The \textbf{Lebesgue outer measure} of $E$, denoted by $\lambda^* (E)$, is defined
\[\lambda^*(E) \equiv \inf \bigg\{ \sum_k l(I_k)\,|\,\{I_k\} \text{ is a sequence of open intervals with } E \subseteq \bigcup_k I_k \bigg\}\]
In other words, $\cup_{k} I_k$ is a cover of $E$. Clearly, $0 \leq \lambda^* (E) \leq \infty$.
\end{definition}

\begin{lemma}[Properties of the Lebesgue Outer Measure]
$\lambda^*$ has the following properties: 
\begin{enumerate}
    \item If $A \subseteq B$, then $\lambda^* (A) \leq \lambda^*(B)$. 
    \item $\lambda^* (\emptyset) = 0$. 
    \item If $A$ is a countable set, then $\lambda^* (A) = 0$. 
    \item Lebesgue outer measure is invariant under translation. That is, for each $x_0 \in \mathbb{R}$, $\lambda^* (E + x_0) = \lambda^* (E)$. 
    \item Lebesgue outer measure is countably subadditive. That is, given a sequence of sets $\{E_i\}$, 
    \[\lambda^* \bigg( \bigcup_i E_i \bigg) \leq \sum_i \lambda^* (E)\]
    \item For any interval $I$, $\lambda^* (I) = l(I)$.
\end{enumerate}
\end{lemma}

With this definition, every set has a Lebesgue outer measure and satisfies the properties 1-3 mentioned before. However, it is not guaranteed to satisfy property 4, as there exists two disjoint sets $A, B$ for which $\lambda^* (A \cup B) \neq \lambda^* (A) + \lambda^* (B)$. However, we will focus our attention on a collection of sets, known as measurable sets, for which property 4 holds. 

\begin{definition}
Let set $E \subseteq \mathbb{R}$ be \textbf{Lebesgue measurable} if for each set $A \subseteq \mathbb{R}$, it satisfies the \textit{Caratheodory criterion}, which requires that
\[\lambda^* (A) = \lambda^* (A \cap E) + \lambda^* (A \cap E^C)\]
where $E^C = \mathbb{R} \setminus E$. If $E$ is a Lebesgue measurable set, then the Lebesgue measure of $E$, denoted $\lambda(E)$ is defined to be its outer Lebesgue measure $\lambda^* (E)$. 

The \textbf{Lebesgue $\sigma$-algebra} is the collection of all sets $E$ which satisfy the Caratheodory criterion. As stated before, for any set in the Lebesgue $\sigma$-algebra, its Lebesgue measure is given by 
\[\lambda (E) \equiv \lambda^* (E)\]
\end{definition}

The intuition that characterises the Lebesgue outer measure can be seen as the \textit{total length of interval sets which fit $E$ most tightly and do not overlap}. Whether this outer measure translates to the Lebesgue measure proper depends on an additional condition. 

This condition is tested by taking subsets $A$ of the real numbers using $E$ as an instrument to split $A$ into two partitions: the part of $A$ which intersects with $E$ and the remaining part of $A$ which is not in $E$. These partitions of $A$ are subject to the outer measure. If for all possible such subsets $A$ of the real numbers, the partition of $A$ cut part by $E$ have outer measures whose sum is the outer measure of $A$, then the outer Lebesgue measure of $E$ gives its Lebesgue measure.

This condition means that the set $E$ must not have some curious properties which causes a discrepancy in the measure of another set when $E$ is used as a "mask" to "clip" that set. 

\begin{theorem}
There exists sets that are not Lebesgue measurable. 
\end{theorem}

\begin{example}
A \textbf{Vitali set} is a subset $V$ of the interval $[0,1]$ of $\mathbb{R}$ such that, for each real number $r$, there is exactly one number $v \in V$ such that $v=r$ is a rational number. It is known that a Vitali set is non-measurable. 
\end{example}

\begin{lemma}[Measurable sets]
The collection of measurable sets has the following properties: 
\begin{enumerate}
    \item $\emptyset$ and $\mathbb{R}$ are measurable. 
    \item If $E$ is measurable, then so is $E^C$. 
    \item If $\lambda^* (E) = 0$, then $E$ is measurable. 
\end{enumerate}
\end{lemma}

\begin{lemma}
Every open set and every closed set are measurable. 
\end{lemma}

\begin{definition}[Measurable vs Measure Spaces]
The pair $(X, \Sigma)$ ($X$ a set with $\Sigma$ its $\sigma$-algebra) is called a \textit{measurable space}, the members of $\Sigma$ are called measurable sets. Note that no measure is needed for measurable spaces. 

The triple $(X, \Sigma, \mu)$ is called a \textbf{measure space}. Unlike a measurable space, a measure space requires a measure function $\mu$. 
\end{definition}

\begin{definition}[Probability Space]
A \textbf{probability space} is a measure space such that the measure of the space is equal to $1$. More specifically, it is a triple $(\Omega, \mathcal{F}, P)$ consisting of: 
\begin{enumerate}
    \item The \textbf{sample space} $\Omega$ is the set of all possible outcomes, where an \textbf{outxome} is the result of a single execution of the model. 
    \item The \textbf{event space} $F \subseteq 2^{\Omega}$, which is a $\sigma$-algebra and the set of subsets of $\Omega$. Each element of $\mathcal{F}$ is called an \textbf{event}, with each event being a set of outcomes in the sample space. Note that since $\mathcal{F}$ is a $\sigma$-algebra, 
    \begin{enumerate}
        \item $\mathcal{F}$ contains the sample space: $\Omega \in \mathcal{F}$
        \item $\mathcal{F}$ is closed under complements: $A \in \mathcal{F} \implies (\Omega \setminus A) \in \mathcal{F}$
        \item $\mathcal{F}$ is closed under countable unions and countable intersections
        \[A_1, \ldots \in \mathcal{F} \implies \bigcup_{i=1}^\infty A_i \in \mathcal{F}, \bigcap_{i=1}^\infty A_i \in \mathcal{F}\]
    \end{enumerate}
    An event is considered to have \textit{happened} during an experiment when the outcome of the model is an element of the event. Since the same outcome may be a member of many events, it is possible for many events to have happened given a single outcome. 
    \item The probability measure $P: \mathcal{F} \longrightarrow [0,1]$ is a function returning an event's probability, such that
    \begin{enumerate}
        \item $P$ is countably additive. That is, if $\{A_i\}_{i=1}^\infty$ is a countable collection of pairwise disjoint sets, then 
        \[P \bigg( \bigcup_{i=1}^\infty A_i \bigg) = \sum_{i=1}^\infty P(A_i)\]
        \item The measure of the entire sample space equals $1$
        \[P(\Omega) = 1\]
    \end{enumerate}
\end{enumerate}
Note that not every subset of the sample space $\Omega$ must necessarily be considered an event: some of the subsets are simply not of interest, and others cannot be measured. This is not so obvious in a case like a coin toss. In a different example, one could consider javelin throw lengths, where the events typically are intervals like "between $60$ and $65$ meters" and unions of such intervals, but not sets like the "irrational numbers between $60$ and $65$ meters".
\end{definition}

Using countable additivity, we can see that given two events $A, B \in \mathcal{F}$, 
\[A \subset B \implies \mathbb{P}(A) \leq \mathbb{P}(B)\]
Intuitively, this means that if the cases in $B$ contains all the cases in $A$, the probability of a case being in $B$ is at least that of a case being in $A$. 

\subsection{Discrete Case}
Discrete probability theory needs only at most countable sample spaces $\Omega$. Probabilities can be ascribed to points of $\Omega$ by the probability mass function $p: \Omega \longrightarrow [0,1]$ such that
\[\sum_{\omega \in \Omega} p(\omega) = 1\]
All subsets of $\Omega$ can be treated as events, making $\mathcal{F} = 2^{\Omega}$. The probability measure takes the simple form 
\[P(A) = \sum_{\omega \in A} p(\omega) \text{ for all } A \subseteq \Omega\]
The greatest $\sigma$-algebra $F = 2^{\Omega}$ describes the complete information. The cases $p(\omega) = 0$ is permitted by the definition, but rarely used since such $\omega$ can safely be excluded from the sample space. 

\begin{example}
Consider the flip of a fair coin with outcomes either hands or tails. Then, $\Omega = \{H, T\}$. The $\sigma$-algebra $F = 2^{\Omega}$ contains $2^2 = 4$ events: 
\begin{align*}
    \{\} &= \text{Neither heads nor tails} \\
    \{H\} &= \text{Heads} \\
    \{T\} &= \text{Tails} \\
    \{H, T\} &= \text{Either heads or tails}
\end{align*}
That is, $\mathcal{F} = \{\{\}, \{H\}, \{T\}, \{H, T\}\}$. Our probability measure $P$ is defined
\[P(f) = \begin{cases}
0 & f = \{\} \\
0.5 & f = \{H\} \\
0.5 & f = \{T\} \\
1 & f = \{H, T\}
\end{cases}\]
\end{example}

\begin{example}
A fair coin is tossed 3 times, creating 8 possible outcomes. 
\[\Omega = \{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\}\]
The complete information is described by the $\sigma$-algebra $\mathcal{F} = 2^{\Omega} = 2^8 = 256$ events, where each of the events is a subset of $\Omega$. 

Alice knows the outcome of the second toss only. Thus, her incomplete information is described by the partition 
\[\Omega = A_1 \sqcup A_2 = \{HHH, HHT, THH, THT\} \sqcup \{HTH, HTT, TTH, TTT\}\]
and the corresponding $\sigma$-algebra is 
\[\mathcal{F}_{Alice} = \{\emptyset, A_1, A_2, \Sigma\}\]
Bryan knows only the total number of tails, so his partition contains 4 parts: 
\begin{align*}
    \Omega & = B_0 \sqcup B_1 \sqcup B_2 \sqcup B_3 \\
    & = \{HHH\} \sqcup \{HHT, HTH, TTH\} \sqcup \{TTH, THT, HTT\} \sqcup \{TTT\}
\end{align*}
When we calculate Bryan's event space, we have
\begin{align*}
    \mathcal{F}_{Bryan} & = \big\{\emptyset, \{HHH\}, \{HHT\}, \{HTH\}, \{THH\}, \{HHT, HTH\}, \{HHT, THH\}, \\
    & \;\;\;\;\{TTH, THT\}, \{TTH\}, \{THT\}, \{HTT\}, \{TTH, THT\},\{TTH, HTT\}, \\
    & \;\;\;\;\{THT, HTT\}, \{TTT\}, \Omega \big\} 
\end{align*}
Note that the event space of Bryan (and Alice) is not merely just $2^{\Omega}$ since we have some predetermined knowledge of the outcome space $\Omega$. Therefore, we can partition it into 4 cases and construct the event space by putting only the events that are subsets of each partition. For example, it wouldn't make sense to have an event 
\[\{HHH, TTT\}\]
since the events $\{HHH\}$ and $\{TTT\}$ are in completely different outcome spaces (given the number of tails). That is, if we knew that 3 tails were thrown, the event $\{HHH, TTT\}$ wouldn't make any sense. However, the event $\Omega$ or $\emptyset$ is viable since they describe the case of whether the coin was tossed at all or not. 
Furthermore, $\mathcal{F}_{Alice}$ and $\mathcal{F}_{Bryan}$ are incomparable. That is, $\mathcal{F}_{Alice} \not\subseteq \mathcal{F}_{Bryan}$ and $\mathcal{F}_{Bryan} \not\subseteq \mathcal{F}_{Alice}$, even though both are subalgebras of $2^{\Omega}$. 
\end{example}

\begin{example}
If $100$ voters are to be drawn randomly from among all voters in California and asked whom they will vote for governor, then the set of all sequences of $100$ Californian voters would be the sample space $\Omega$. We assume that sampling without replacement is used: only sequences of $100$ different voters are allowed. For simplicity an ordered sample is considered, that is a sequence $\{Alice, Bryan\}$ is different from $\{Bryan, Alice\}$. We also take for granted that each potential voter knows exactly his/her future choice, that is he/she doesnt choose randomly.

Alice knows only whether or not Arnold Schwarzenegger has received at least $60$ votes. Her incomplete information is described by the $\sigma$-algebra $\mathcal{F}_{Alice}$ that contains:
\begin{enumerate}
    \item the set of all sequences in $\Omega$ where at least $60$ people vote for Schwarzenegger
    \item the set of all sequences where fewer than $60$ vote for Schwarzenegger
    \item the whole sample space $\Omega$
    \item the empty set $\emptyset$
\end{enumerate}
Bryan knows the exact number of voters who are going to vote for Schwarzenegger. His incomplete information is described by the corresponding partition $\Omega = B_0 \sqcup B_1 \ldots B_{100}$ and the $\sigma$-algebra $\mathcal{F}_{Bryan}$ consists of $2^{101}$ events. 

In this case Alices $\sigma$-algebra is a subset of Bryans: $\mathcal{F}_{Alice} \subset \mathcal{F}_{Bryan}$. Bryans $\sigma$-algebra is in turn a subset of the much larger "complete information" $\sigma$-algebra $2^{\Omega}$ consisting of $2^{n(n-1)\ldots (n-99)}$ events, where $n$ is the number of all potential voters in California. 
\end{example}

\subsection{General and Non-Atomic Cases}

\begin{definition}
Let $\Omega$ be uncountable. If for some $\omega \in \Omega$, $p(\omega) \neq 0$, then $\omega$ is called an \textbf{atom}. 
\end{definition}

Now, given a general (discrete or continuous, or a combination of both) distribution, the set of all the atoms are an at most countable (maybe empty) set whose probability is the sum of probabilities of all atoms (by countable additivity). That is, given $\omega_1, \ldots$ atoms, 
\[P \bigg( \bigsqcup_{i=1}^\infty \omega_i\bigg) = \sum_{i=1}^\infty P(\omega_i)\]
If this sum is equal to $1$ then all other points can be safely excluded from the sample space $\Omega$, returning us to the discrete case. 

Otherwise, if the sum of probabilities of all atoms is between $0$ and $1$, then the probability space decomposes into a discrete, atomic (possibly empty) part and a non-atomic, continuous part. 

We now move on to describe the non-atomic case. If $p(\omega) = 0$ for all $\omega \in \Omega$, then $\Omega$ must be uncountable since otherwise $P(\Omega) = 1$ could not be satisfied and then equation 
\[P(A) = \sum_{\omega \in A} p(\omega) \text{ for all } A \subseteq \Omega\]
fails: the probability of a set is not necessarily the sum over the probabilities of its elements, as summation is only defined for countable numbers of elements. 


\begin{definition}
A \textbf{Borel set} is any set in a topological space that can be formed from open sets (or equivalently, from closed sets) through the operations of countable union, countable intersection, and relative complement ($B \setminus A \equiv \{x \in B\;|\; x \not\in A\}$. 

For a topological space $X$, the collection of all Borel sets on $X$ forms a $\sigma$-algebra, known as a Borel algebra. The Borel algebra on $X$ is the smallest $\sigma$-algebra containing all open sets (or equivalently, all closed sets). 
\end{definition}

\begin{definition}
The \textbf{Lebesgue measure} is the standard way of assigning a measure to subsets of $n$-dimensional Euclidean space. For $n = 1, 2, 3$, it coincides with the standard measure of length, area, or volume. 
\end{definition}

\begin{example}
A number between $0$ and $1$ is chosen at random uniformly. Here, $\Omega = [0,1]$, $\mathcal{F}$ is the $\sigma$-algebra of Borel sets on $\Omega$, and $P$ is the Lebesgue measure on $[0,1]$. In this case, the open intervals of the form $(a, b)$, where $0<a<b<1$, could be taken as generator sets. Each such set can be ascribed the probability of $P((a, b)) = b-a$, which generates the Lebesgue measure on $[0,1]$ and the Borel $\sigma$-algebra on $\Omega$. 
\end{example}

We mention a counting technique in combinatorics that may help in computing probabilities. 

\begin{lemma}[Inclusion-Exclusion Principle]
Let $A, B \in \mathcal{F}$. That is, they are two (not necessarily disjoint) sets of events in $\Omega$. Then, 
\[|A \cup B| = |A| + |B| - |A \cap B|\]
More generally, for finite sets $A_1, \ldots, A_n$, we have 
\[\bigg| \bigcup_{i=1}^n A_i \bigg| = \sum_{i=1}^n |A_i| - \sum_{1 \leq i \leq j \leq n} |A_i \cap A_j| + \sum_{1 \leq i \leq j \leq k \leq n} |A_i \cap A_j \cap A_k| - \ldots - (-1)^{n-1} |A_1 \cap \ldots \cap A_n |\]
Combined with the countable additivity of the function $P$, this leads to
\[\mathbb{P} \bigg(\bigcup_{i=1}^n A_i \bigg) = \sum_{i=1}^n \mathbb{P}(A_i) - \sum_{1 \leq i \leq j \leq n} \mathbb{P}(A_i \cap A_j) - (-1)^{n-1} \mathbb{P}(A_1 \cap \ldots \cap A_n )\]
\end{lemma}

\subsection{Conditional Probability}
This definition of a probability space that we have constructed gives rise to the natural concept of \textbf{conditional probability}.

\begin{definition}
If $A \subset \Omega$ and $B \subset \Omega$ are two events (that is, $A, B \in \mathcal{F}$) and $\mathbb{P}(A) > 0$, then the conditional probability of $B$ given $A$ is defined  
\[\mathbb{P}(B|A) \equiv \frac{\mathbb{P}(B \cap A)}{\mathbb{P}(A)}\]
This is interpreted as the measure of the probability of an event occurring, given that another event (by assumption, assertion, or evidence) has already occurred. Note that if $P(B) = 0$, then by definition, $P(A\,|\,B)$ is undefined. 
\end{definition}

Note that for any event $B$ such that $P(B) > 0$, the function $Q$ defined by 
\[Q(A) \equiv P(A\,|\,B)\]
for all events $A$ is itself a probability measure. 

\begin{lemma}[Partition Rule]
Suppose $A_1, A_2, ..., A_n$ is a partition of $\Omega$. Then, 
\[\{B \cap A_k\}_{k=1}^n\]
is a partition of $B$, and 
\[\mathbb{P}(B) = \sum_{k=1}^n \mathbb{P} (B|A_k)\, \mathbb{P}(A_k)\]
This is also called the \textit{Law of Total Probability}. 
\end{lemma}

\section{Random Variables}
Before we go any further, we must introduce what random variables are. We will do so in full generality. 

\begin{definition}
A \textit{measurable function} is a function between the underlying sets of two measurable spaces $(X, \Sigma_1)$ and $(Y, \Sigma_2)$ (equipped with their respective $\sigma$-algebras) that preserves the structure of the spaces: the preimage of any measurable set is measurable. 

Notice that this is analogous to the definition that a continuous function between topological spaces preserves the topological structure: the preimage of any open set is open. 
\end{definition}

\begin{definition}
A \textit{random variable} is a measurable function 
\[X: (\Omega, \mathcal{F}, P) \longrightarrow E\]
from a set of possible outcomes $\Omega$ to a measurable space $E$. The probability that $X$ takes on a value in a measurable set $S \subseteq E$ is written as 
\[P(X \in S) \equiv P( \{\omega \in \Omega \,|\, X (\omega) \in S\})\]
\end{definition}


\subsection{Independence and Bayes' Formula}
\begin{definition}[Independence]
Events $A$ and $B$ are said to be \textit{independent} if and only if 
\[\mathbb{P}(A \cap B) = \mathbb{P}(A)\, \mathbb{P}(B)\]
Using conditional probability, this is equivalent to the condition that both 
\[\mathbb{P}(B|A) = \mathbb{P}(B) \text{ and } \mathbb{P}(A|B) = \mathbb{P}(A)\]
holds. Generally, a collection of events $A_1, A_2, ..., A_n$ is independent if and only if 
\[\mathbb{P} \bigg( \bigcup_{k \in J} A_k \bigg) = \prod_{k\in J} \mathbb{P}(A_k)\]
holds for any subset of indices $J \subset \{1, 2, ..., n\}$. 
\end{definition}

Note that pairwise independence does not imply independence of the entire collection. 

\begin{theorem}[Bayes' Formula]
For any events $B, C \subset \Omega$, 
\[\mathbb{P}(B|C) = \frac{\mathbb{P}(C|B)\, \mathbb{P}(B)}{\mathbb{P}(C)}\]
If $B_1,..., B_n$ forms a partition of $\Omega$, and $C$ is some other event, then 
\[\mathbb{P}(B_k|C) = \frac{\mathbb{P}(C|B_k) \, \mathbb{P}(B_k)}{\sum_{l=1}^n \mathbb{P}(C|B_l) \, \mathbb{P}(B_l)}\]
The probabilities $\mathbb{P}(B_k)$ are called \textit{prior probabilities}. 
\end{theorem}

Bayes' formula is extremely useful in a variety of fields, such as medical diagnosis and criminal identification.

\section{Distributions of Random Variables}
The whole concept of distributions assumes that $\Omega$ is an ordered set. In statistical terms, elements of $\Omega$ are assumed to be \textit{quantitative}, not \textit{categorical}. In this context, we will assume that $\Omega \subset \mathbb{R}$. 

\begin{definition}
A \textit{random variable} $X = X(\omega)$ is a function on the outcome space
\[X: \Omega \longrightarrow \mathbb{R}\]
\end{definition}

The random variable can be interpreted as a bar (for discrete) or smooth (for continuous) graph in the 2-dimensional space $\Omega \times \mathbb{R}$. 

\begin{definition}
The \textit{cumulative distribution function} (CDF) of a random variable $X$ is the function 
\[F(x) = \mathbb{P}(X \leq x), \; x \in \mathbb{R}\]
This is well-defined for both discrete distributions and probability density functions. It is clear from the formula that 
\[\lim_{x \rightarrow \infty} F(x) = 1 \text{ and } \lim_{x \rightarrow -\infty} F(x) = 0\]
The relationship between the distribution and the CDF is 
\[F^\prime (x) = f(x)\]
assuming that $f$ is continuous at $x$. 
\end{definition}

\subsection{Discrete Random Variables}
\begin{definition}
A discrete random variable is a random variable which takes only countably many values; that is, $\im(X)$ is countable. The \textit{distribution} of a discrete random variable refers to the assignment of probabilities. 
\[\mathbb{P} (X = x) = \mathbb{P}(\{\omega \subset \Omega \; | \; X (\omega) = x \})\]
for all of the possible values $x$ in the (countable) image of $X$. Any discrete probability distribution must satisfy  
\[\mathbb{P} (X = x) \geq 0 \text{ and } \sum_x \mathbb{P}(X = x) = 1\]
Note that the random variable is not the same as the distribution of that random variable! Two different random variables can have the same distribution. 
\end{definition}

\begin{definition}[Bernoulli]
A \textit{Bernoulli(p)} distribution, having parameter $p \in [0,1]$ and range $\{0, 1\}$ is defined as 
\[\mathbb{P}(X = 1) = p, \;\; \mathbb{P}(X = 0) = 1-p\]
The most common example is when we are flipping a $p$-coin, with $1$ representing a heads and $0$ representing tails. The Bernoulli distribution is also denoted with the \textit{indicator function}
\[\mathbb{I}_A\]
where $A$ is the outcome of success. 
\end{definition}

\begin{definition}[Binomial]
A \textit{Binomial(n, p)} distribution has range $\{0, 1, 2, ..., n\}$ and is defined by 
\[\mathbb{P}(X = k) = {n \choose k} \, p^k \, (1-p)^{n-k}, \; k = 0, 1, 2, ..., n\]
A common example is $X$ being the number of heads occurring in a sequence of $n$ independent tosses of a $p$-coin. 
\end{definition}

\begin{proposition}
While we haven't defined sums of distributions yet, we will state this fact early on. The distribution Binomial$(n, p)$ is equivalent to the sum of $n$ Bernoulli distributions. That is, if $X \sim$ Binomial$(n, p)$, then 
\[X = \sum_{n} \mathbb{I}_p \]
where $\mathbb{I}_p$ is an indicator function with probability of success $p$. 
\end{proposition}

\begin{definition}[Geometric]
A \textit{Geometric(p)} distribution has range $\{1, 2, 3, ...\}$ and is defined by
\[\mathbb{P}(X = k) = (1-p)^{k-1} \, p, \; k = 1, 2, 3, ...\]
It is equivalent to say that $X$ is the number of independent trials needed until success (having probability $p$) occurs. 
\end{definition}

\begin{definition}[Hypergeometric]
A \textit{Hypergeometric(n, G, N)} distribution is defined by 
\[\mathbb{P}(X = g) = \frac{{G \choose g} {{N-G} \choose {n-g}}}{{N \choose n}}\]
A common example is with marbles. Let there be an urn with $N$ total marbles, $G$ of which are green. Then, $X$ is the number of green balls appearing in a sample size of $n$, drawn without replacement. 
\end{definition}

\begin{definition}[Poisson]
A \textit{Poisson($\lambda$)} distribution is a discrete distribution defined by 
\[\mathbb{P}(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}, \; k = 0, 1, 2, 3, ...\]
\begin{center}
    \includegraphics[scale=0.15]{Poisson_Distribution_Model.png}
\end{center}
It's CDF is: 
\begin{center}
    \includegraphics[scale=0.15]{Poisson_Distribution_Model_2.png}
\end{center}
\end{definition}

\begin{definition}[Negative Binomial Distribution]
The negative binomial distribution, denoted NB$(r, p)$ is defined as
\[\mathbb{P}(X = x) \equiv {{k+r-1} \choose k} \, (1-p)^r \, p^k\]
It can be interpreted as the distribution that models the number of successes in a sequence of iid Bernoulli-$p$ trials before a specified number $r$ failures occurs. 
\begin{center}
    \includegraphics[scale=0.5]{Negative_Binomial_Distribution_Model.png}
\end{center}

\end{definition}

\subsection{Continuous Random Variables}
\begin{definition}
A real valued random variable $X$ is \textit{continuously distributed with density $f(x)$} if, for all $a < b$
\[\mathbb{P}(a \leq x \leq b) = \int_a^b f(x) \, dx\]
This continuous distribution is also called the \textit{probability density function} (PDF). Clearly, it must satisfy
\[f(x) \geq 0 \; \forall x \in \Omega \text{ and } \int_{\Omega} f(x)\, dx = \int_{-\infty}^\infty f(x) \, dx = 1\]
\end{definition}

\begin{definition}[Uniform]
A \textit{Uniform($a, b$)} distribution is defined 
\[f(x) = \begin{cases}
\frac{1}{|b-a|} & x \in [a, b] \\
0 & x \not\in [a,b]
\end{cases}\]
The CDF is defined
\[F(x) = \begin{cases}
0 & x < a \\
\frac{x-a}{b-a} & x \in [a, b] \\
1 & x > b
\end{cases}\]
\end{definition}

To introduce the CDF of the Normal distribution, we must first define the error function. 

\begin{definition}
The \textit{error function} is defined
\[erf (z) \equiv \frac{2}{\sqrt{\pi}} \int_0^z e^{-t^2} \, dt\]
This function is encountered when integrating the normal distribution. 
\end{definition}

\begin{definition}[Normal]
A \textit{Normal($\mu$, $\sigma^2$)} distribution is defined
\[f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}, \; x \in \mathbb{R}\]
\begin{center}
    \includegraphics[scale=0.15]{Normal_Distribution_Model.png}
\end{center}
It is worthwhile to remember the standardized normal distribution Normal($0$, $1$).
\[f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}, \; x \in \mathbb{R}\]
It's CDF is computed with usual integration, but for the sake of consistency, we provide a formula. 
\[F(x) = \frac{1}{2} \bigg(1 + erf\Big(\frac{x-\mu}{\sigma \sqrt{2}}\Big) \bigg)\]
\begin{center}
    \includegraphics[scale=0.15]{Normal_Distribution_Model_2.png}
\end{center}
\end{definition}

\begin{definition}[Exponential]
A \textit{Exponential($\lambda$)} distribution is defined
\[f(x) = \begin{cases}
\lambda e^{-\lambda x} & x \geq 0 \\
0 & x < 0
\end{cases}\]
\begin{center}
    \includegraphics[scale=0.15]{Exponential_Distribution_Model.png}
\end{center}
The CDF is defined
\[F(x) = 1 - e^{-\lambda x}\]
\begin{center}
    \includegraphics[scale=0.15]{Exponential_Distribution_Model_2.png}
\end{center}
Notice the similarity between an exponential distribution (continuous) and a geometric distribution (discrete). 
\end{definition}

\begin{definition}[Gamma Function]
The \textit{Gamma function} is a commonly used function used extension of the factorial function to the complex numbers. It can be interpreted as a solution to the problem: \textit{Find a smooth curve that connects the points $(x, y)$ given by $y = (x-1)!$ at the positive integer values for $x$.} That is, for any positive integer $x$, 
\[\Gamma(x) \equiv (x-1)!\]
The extension of this for complex numbers with a positive real part is defined with an improper convergent integral: 
\[\Gamma(z) \equiv \int_{0}^\infty x^{z-1} e^{-x}\, dx, \;\;\;\;\; \text{Re}(z) > 0\]
The gamma function is then defined as the analytic continuation of the integral function to the rest of the complex numbers. 
\end{definition}

\begin{definition}[Gamma]
A \textit{Gamma($n$, $\lambda$)}, or with different notational parameters, Gamma($n$, $\theta = 1/\lambda$) distribution for natural numbers $n$ is defined 
\[f(x) = \frac{\lambda^n x^{n-1}}{(n-1)!} e^{-\lambda x} = \frac{x^{n-1}}{\theta^n (n-1)!} e^{-x/\theta}, \;\;\; x \geq 0\]
but the general case for all $n \in \mathbb{R}$ results in the factorial being replaced by the Gamma function: 
\[f(x) = \frac{\lambda^n x^{n-1}}{\Gamma(n)} e^{-\lambda x} = \frac{x^{n-1}}{\theta^n \Gamma(n)} e^{-x/\theta}\;\;\; x \geq 0\]
\begin{center}
    \includegraphics[scale=0.15]{Gamma_Distribution_Model.png}
\end{center}
Note that Gamma(1, $\lambda$) is precisely the exponential density Exp($\lambda$). Its CDF is: 
\begin{center}
    \includegraphics[scale=0.15]{Gamma_Distribution_Model_2.png}
\end{center}
\end{definition}

\begin{definition}[Beta Distribution]
A \textit{Beta($\alpha$, $\beta$)} distribution for positive real numbers $\alpha, \beta$ is defined
\[f(x) \equiv \frac{x^{\alpha-1} \,(1-x)^{\beta-1}}{B(\alpha, \beta)}, \text{ where } B(\alpha, \beta) \equiv \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}\]
and $\Gamma$ is the Gamma function. 
\begin{center}
    \includegraphics[scale=0.4]{Beta_Distribution_Model.png}
\end{center}
Its CDF is
\begin{center}
    \includegraphics[scale=0.4]{Beta_Distribution_Model_2.png}
\end{center}
The generalization of the Beta distribution to multiple variables is called the \textit{Dirichlet distribution}. 
\end{definition}

\section{Expectation, Variance} 
\begin{definition}
The expectation of a discrete random variable $X: \Omega \longrightarrow \mathbb{R}$ is 
\[\mathbb{E}(X) = \sum_{x \in \im(X)} x \, \mathbb{P}(X = x)\]
where the sum is over the countable set of all possible values of $X$, assuming that the sum converges absolutely. 
\end{definition}

\begin{definition}
The expectation of a continuous random variable $X$ with density $f(x)$ is the integral 
\[\int_\mathbb{R} x \, f(x) \, dx\]
assuming that the integral converges absolutely. 
\end{definition}

It is possible that the expectation is infinite or not well-defined. In any case, the expectation is a property of the distribution. If two random variables have the same distribution, then $\mathbb{E}(X) = \mathbb{E}(Y)$. We now state some properties of expectation. 

\begin{proposition}
Expectation is a linear operator from the space of all discrete distributions to $\mathbb{R}$. That is, for any constants $\alpha, \beta \in \mathbb{R}$ and random variables $X, Y$ on $\Omega$, 
    \[\mathbb{E}(\alpha X + \beta Y) = \alpha \mathbb{E}(X) + \beta \mathbb{E}(Y)\] 
\end{proposition}
\begin{proof}
Let $V_X, V_Y \subset \mathbb{R}$ denote the ranges of $X$ and $Y$, respectively. That is, 
\[V_X \equiv \{x \in \mathbb{R} \; | \; \mathbb{P}(X =x) >0\}, \; V_Y \equiv \{y \in \mathbb{R} \; | \; \mathbb{P}(Y =y) > 0\}\]
Now, let $V_{X+Y}$ be the range of $X+Y$, explicitly defined
\[V_{X+Y} \equiv \{x+y \; | \; x \in V_X, y \in V_Y\}\]
Note that $V_X, V_Y$, and $V_{X+Y}$ are all countable sets. Then, we can define $\mathbb{E}(X+Y)$ through the joint distribution of $X$ and $Y$, and get
\begin{align*}
    \mathbb{E}(X+Y) & = \sum_{(x,y) \in V_{X+Y}} (x+y) \mathbb{P} (X=x, Y=y) \\
    & = \sum_{x \in V_X} \sum_{y \in V_Y} (x+y) \mathbb{P} (X=x, Y=y) \\
    & = \sum_{x \in V_X} x \sum_{y \in V_Y} \mathbb{P} (X=x, Y=y) + \sum_{y \in V_Y} y \sum_{x \in V_X} \mathbb{P} (X=x, Y=y) \\
    & = \sum_{x \in V_X} x \mathbb{P}(X=x) + \sum_{y \in V_Y} \mathbb{P}(Y=y) \\
    & = \mathbb{E}(X) + \mathbb{E}(Y)
\end{align*}
Proving linearity for scalar multiples is trivial, and will not be shown here. 
\end{proof}

\begin{theorem}[Expectations of functions]
Given a function $g: \mathbb{R} \longrightarrow \mathbb{R}$, 
\[\mathbb{E} \big( g(X) \big) = \sum_x g(x) \, \mathbb{P}(X = x)\]
in the discrete case. If $X$ has density $f$, then 
\[\mathbb{E} \big( g(X) \big) = \int_\mathbb{R} g(x) \, f(x) \, dx\]
For multivariate functions $g: \mathbb{R} \times \mathbb{R} \longrightarrow \mathbb{R}$ in joint distributions, we have
\[\mathbb{E}\big( g(X, Y) \big) = \sum_{x, y} g(x, y) \, \mathbb{P} (X=x, Y=y)\]
\end{theorem}

\begin{proposition}[Expectation of Independent Events]
If $X$ and $Y$ are independent random variables, 
\[\mathbb{E}(XY) = \mathbb{E}(X) \, \mathbb{E}(Y)\]
\end{proposition}

\begin{theorem}[Tail Sum Formula]
If a discrete random variable $X$ takes values in the non-negative integers $\{0, 1, 2, 3, ...\}$, then 
\[\mathbb{E}(X) = \sum_{k=1}^\infty \mathbb{P}(X \geq k)\]
In any case (continuous or discrete), if $X$ is a non-negative random variable, then 
\[\mathbb{E}(X) = \int_0^\infty \mathbb{P}(X > x) \, dx = \int_0^\infty 1 - F(x) \, dx\]
where $F$ is the CDF of $X$. 
\end{theorem}
\begin{proof}
Suppose that $X$ takes values in $\{0, 1, 2, 3, ...\}$. Then, 
\begin{align*}
    \mathbb{E}(X) & = \sum_{k \geq 1} k \, \mathbb{P}(X=k) \\
    & = \sum_{k\geq 1} \sum_{j=1}^k \mathbb{P}(X = k) \\
    & = \sum_{k \geq 1} \sum_{j=1}^k \mathbb{I}_{j \leq k} \, \mathbb{P}(X=k) \\
    & = \sum_{j=1}^\infty \sum_{k \geq 1} \mathbb{I}_{j \leq k} \, \mathbb{P}(X =k) \\
    & = \sum_{j=1}^\infty \sum_{k \geq j} \mathbb{P}(X=k) \\
    & = \sum_{j=1}^\infty \mathbb{P}(X \geq j)
\end{align*}
\end{proof}

We can actually use linear algebra to optimize approximation problems. That is, assuming that $\mathbb{E}(X^2)$ is finite, the value of $a\in \mathbb{R}$ which minimizes the function 
\[L(a) = \mathbb{E} \big( (X - a)^2 \big)\]
is $a = \mathbb{E}(X)$. 

\begin{definition}[Variance]
If $\mu = \mathbb{E}(X)$ is the mean of a random variable $X$, then the \textit{variance} of $X$ is 
\[\Var(X) = \mathbb{E} \big( (X - \mu)^2 \big) = \mathbb{E}(X^2) - \mathbb{E}(X)^2\]
$\Var(X)$ is always nonnegative, but it may be infinite, even if $\mathbb{E}(X)$ is finite. 
\end{definition}

\begin{definition}
The \textit{standard deviation} of random variable $X$ is defined 
\[\std(X)\equiv \sqrt{\Var(X)}\]
\end{definition}

\begin{proposition}
Variance has the following properties. Given $\alpha \in \mathbb{R}$ and $c \in \mathbb{R}$,
\[\Var(\alpha X) = \alpha^2 \Var(X), \; \std(\alpha X) = |\alpha| \std(X)\]
Furthermore, variance is invariant under shifts in distributions. 
\[\Var(X) = \Var(X + c)\]
\end{proposition}

\begin{definition}
The $m$th \textit{moment} of $X$ is defined as $\mathbb{E}(X^m)$. 
\end{definition}

We now introduce the process of \textit{standardization} of a distribution. That is, if $X$ is a random variable with mean $\mu = \mathbb{E}(X)$ and variance $\sigma^2 = \Var(X)$, then the random variable 
\[Y = \frac{X - \mu}{\sigma}\]
has mean $\mathbb{E}(Y) = 0$ and variance $\Var(Y) = 1$. 

\begin{theorem}[Markov's Inequality]
If $X$ is a non-negative random variable and $x >0$, then 
\[\mathbb{P}(X \geq x) \leq \frac{1}{x} \mathbb{E}(X)\]
\end{theorem}
\begin{proof}
Given that $X$ can take values $0 \leq x_1 \leq x_2 \leq ... \leq x_j = x \leq ... \leq x_n$. Then, we have
\[\mathbb{E}(X) = \sum_{i=1}^n x_i \, \mathbb{P}(X=x_i) \geq \sum_{i=j}^n x_i \, \mathbb{P}(X=x_i) \geq \sum_{i=j}^n x \, \mathbb{P}(X=x_i)\]
and we are done. 
\end{proof}

\begin{corollary}[Markov's Inequality, 2nd Form]
\[\mathbb{P}\big( X \geq s \, \mathbb{E}(X) \big) \leq \frac{1}{s} \]
\end{corollary}
\begin{proof}
Let $x = s \mathbb{E}(X)$ in Markov's inequality to get this second form of Markov's inequality. 
\end{proof}

\begin{corollary}
For any $m > 0$ and $\alpha > 0$,  
\[\mathbb{P} \big(|X| > \alpha \big) \leq \frac{1}{\alpha^m} \mathbb{E} \big( |X|^m \big)\]
\end{corollary}

\begin{theorem}[Chebyshev Inequality]
For distribution $X$, if $\mathbb{E}(X) = \mu$ and $\Var(X) = \sigma^2$, then for all $\alpha > 0$, 
\[\mathbb{P} \big( |X - \mu| > \alpha \sigma \big) \leq \frac{1}{\sigma^2}\]
Equivalently, we can write 
\[\mathbb{P} \big( |X - \mathbb{E}(X)| > \alpha \big) \leq \frac{\Var(X)}{\sigma^2}\]
\end{theorem}

\begin{theorem}[Weak Law of Large Numbers]
Let $X_1, X_2, ..., X_n$ be a sequence of independent and identically distributed (iid) random variables, with mean $\mu= \mathbb{E}(X_k)$ and with finite variance. Then, for any $\epsilon > 0$, 
\[\lim_{n \rightarrow \infty} \mathbb{P} \bigg( \bigg| \Big( \frac{1}{n} \sum_{k=1}^n X_k \big) - \mu \bigg| > \epsilon \bigg) = 0\]
\end{theorem}

\begin{lemma}[Borel-Cantelli Lemma]
If $\{A_n\}_{n \in J}$ is any sequence of events such that 
\[\sum_{k=1}^\infty \mathbb{P}(A_n) < \infty\]
then, 
\[\mathbb{P} \bigg( \bigcap_{j \geq 1} \bigcup_{k \geq j} A_k \bigg) = 0\]
The event $\bigcap_{j \geq 1} \bigcup_{k \geq j} A_k$ means that $A_n$ occurs "infinitely often" as $n \rightarrow \infty$. 
\end{lemma}

\begin{theorem}[Strong Law of Large Numbers]
Let $X_1, X_2, X_3, ...$ be a sequence of independent, identically distributed (iid) random variables, with mean $\mu = \mathbb{E}(X_k)$ and with finite variance. Then, 
\[\mathbb{P} \bigg( \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{k=1}^n X_k = \mu \bigg) = 1\]
\end{theorem}

\section{Sums of Independent Distributions}
\begin{definition}[Convolutions of Discrete Variables]
If $X$ and $Y$ are independent discrete random variables, then the distribution of their sum $Z = X + Y$ is defined
\[\mathbb{P}(X + Y = z) = \sum_{y} \mathbb{P}(X = z-y) \, \mathbb{P}(Y=y)\]
\end{definition}

\begin{definition}[Convolutions of Densities]
If $X$ and $Y$ have densities and are independent, then the density for their sum $Z = X + Y$ is defined
\[f_Z (z) = \int_\mathbb{R} f_X(z - y) \, f_Y (y) \, dy\]
$f_Z$ is called the \textit{convolution} of the functions $f_X$ and $f_Y$. 
\end{definition}

\begin{theorem}[Sums of Discrete Variables]
Assume that $X$ and $Y$ are independent. 
\begin{enumerate}
    \item $X \sim$ Binomial$(n, p)$, $Y \sim$ Binomial$(m, p)$ $\implies X + Y \sim$ Binomial$(n + m, p)$. 
    \item $X \sim$ Poisson$(\lambda)$, $Y \sim$ Poisson$(\gamma)$ $\implies X + Y \sim$ Poisson$(\lambda + \gamma)$. 
    \item If $X_1, ..., X_n$ are Geometric$(p)$, then $X_1 + ... + X_n$ is NB$(n, p)$. 
\end{enumerate}
\end{theorem}

\begin{theorem}[Sums of Densities]
Assume that $X$ and $Y$ are independent. 
\begin{enumerate}
    \item $X \sim$ Normal$(\mu_1, \sigma_1^2)$, $Y \sim$ Normal$(\mu_2, \sigma_2^2)$ $\implies X + Y \sim$ Normal $(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$. 
    \item If $X_1, X_2, ..., X_n$ are Exponential$(\lambda)$, then $X_1 + ... + X_n \sim$ Gamma$(n, \lambda)$.
    \item $X \sim$ Gamma$(n, \lambda)$, $Y \sim$ Gamma$(m, \lambda)$ $\implies X + Y \sim$ Gamma$(n + m, \lambda)$. 
    \item $X \sim$ Gamma $(n, \lambda)$, $Y \sim$ Exponential $(\lambda)$ $\implies X + Y \sim$ Gamma$(n+1, \lambda)$. 
\end{enumerate}
\end{theorem}

\begin{theorem}
Let $X_1, X_2, ..., X_n$ be any random variables (discrete or continuous). Then, 
\[\mathbb{E}\Big(\sum_i X_i\Big) = \sum_i \mathbb{E}(X_i)\]
and if the $X_i$'s have finite variance, then 
\[\Var \Big( \sum_i X_i \Big) = \sum_i \Var(X_i)\]
\end{theorem}



\begin{theorem}[Central Limit Theorem]
Let $X_1, X_2, X_3, ...$ be a sequence of iid random variable, with mean $\mu = \mathbb{E}(X_k)$ and with variance $\Var(X_k) = \sigma^2 > 0$. Then, for any $a < b$, 
\[\lim_{n \rightarrow \infty} \mathbb{P} \bigg( a < \frac{1}{\sigma \sqrt{n}} \bigg( \Big( \sum_{k=1}^n X_k \Big) - n \mu \bigg) < b \bigg) = \int_a^b \frac{1}{\sqrt{2\pi}} e^{-\frac{y^2}{2}}\, dy\]
\end{theorem}
Roughly speaking, the law of large numbers says that 
\[\Big( \frac{1}{n} \sum_{k=1}^n X_k \Big) - \mu \approx 0\]
while the CLT involves renormalization. 
\[\sqrt{n} \bigg( \Big( \frac{1}{n} \sum_{k=1}^n X_k \Big) \bigg) \approx N(0, \sigma^2)\]
where $\approx$ means that the distributions are close when $n$ is large. The central limit theorem is essential when performing \textit{Normal approximation} described as such: If a random variable $Y$ is a sum of many iid random variables having certain mean and variance, then the distribution of $Y$ may be close to that of a normal random variable having the same mean and variance as $Y$. Since many random variables have this structure, we can use the CLT to approximate the distribution of a sum of independent random variables (e.g. the binomial distribution as a sum of $n$ Bernoulli distributions). 

\section{Covariance, Correlation}
\begin{definition}
The \textit{covariance} of two real-valued random variables $X$ and $Y$ is defined
\begin{align*}
    \Cov(X, Y) & \equiv \mathbb{E}\big( (X - \mu_X) (Y - \mu_Y)\big) \\
    & = \mathbb{E}(X Y) - \mathbb{E}(X) \mathbb{E}(Y) 
\end{align*}
where $\mu_X$ and $\mu_Y$ are the means of $X$ and $Y$. Note that covariance can be positive, negative, or zero. It obviously follows from the definition that covariance is symmetric. 
\[\Cov(X, Y) = \Cov(Y, X)\]
Furthermore, covariance is bilinear with respect to its arguments.
\[\Cov \bigg( \sum_{i=1}^n \alpha_i X_i , \sum_{j=1}^m \beta_j Y_j \bigg) = \sum_{i=1}^n \sum_{j=1}^m \alpha_i \beta_j \Cov(X_i, Y_j)\]
\end{definition}

\begin{definition}
Given random variables $X$ and $Y$, $X$ and $Y$ are \textit{uncorrelated} if and only if 
\[\Cov(X, Y) = 0\]
\end{definition}

\begin{lemma}
$X$ and $Y$ independent $\implies$ $X$ and $Y$ uncorrelated. However, $\Cov(X, Y) = 0 \not\implies X$ and $Y$ independent. 
\end{lemma}
\begin{proof}
$X, Y$ independent $\implies \mathbb{E}(XY) = \mathbb{E}(X) \mathbb{E}(Y) \implies \mathbb{E}(XY) - \mathbb{E}(X) \mathbb{E}(Y) = \Cov(X, Y) = 0$. 
\end{proof}

\begin{theorem}
Let us have random variables $X_1, X_2, ..., X_n$ all with finite variance (not necessarily independent). Then, 
\[\Var \Big( \sum_i X_i \Big) = \sum_{i=1}^n \Var(X_i) + 2 \sum_{i < k} \Cov(X_i, X_k)\]
\end{theorem}

Notice that this is a generalization of the previous theorem where we've assumed that the $X_i$'s are independent. However, it turns out that independence is too strong of a condition for the formula
\[\Var \Big( \sum_i X_i \Big) = \sum_i \Var(X_i)\]
to hold. Rather, we have the following corollary. 

\begin{corollary}
Let $X_1, X_2, ..., X_n$ be random variables with finite variance. If all the $X_1, X_2,..., X_n$ are pairwise uncorrelated, then 
\[\Var \Big( \sum_i X_i \Big) = \sum_i \Var(X_i)\]
\end{corollary}

\begin{proposition}
If $X$ and $Y$ are two random variables with finite variance, then the magnitude of their covariance is bounded by the following inequality. 
\[|\Cov(X,Y)| \leq \sqrt{\Var(X) \, \Var(Y)} = \std(X) \, \std(Y)\]
\end{proposition}

\begin{definition}
The \textit{correlation} of two random variables is the normalized covariance. That is, 
\[\Corr(X, Y) \equiv \frac{\Cov(X, Y)}{\std(X) \, \std(Y)}\]
By definition, this implies that $-1 \leq \Corr(X, Y) \leq 1$. When $\Corr(X, Y) > 0$ (which also means that $\Cov(X, Y) > 0$), it is said that $X$ and $Y$ are \textit{positively correlated}, and when $\Corr(X, Y) < 0$ (which also means that $\Cov(X, Y) < 0$), it is said that they are \textit{negatively correlated}. 
\end{definition}

\begin{proposition}
$\Corr(X,Y) = \pm 1$ indicates a linear relationship between $X$ and $Y$. 
\begin{enumerate}
    \item Let $\Corr(X, Y) = 1$. Then, there exists a $m>0$ and $b \in \mathbb{R}$ such that $Y = m X + b$. 
    \item Let $\Corr(X, Y) = -1$. Then, there exists a $m<0$ and $b \in \mathbb{R}$ such tat $Y = m X + b$. 
\end{enumerate}
This implies that $\Corr(X, Y) = \pm 1$ indicates that the joint distribution of $(X, Y)$ is concentrated on a line in $\mathbb{R}^2$. 
\end{proposition}

\section{Joint, Marginal, Conditional Distributions}
\subsection{Discrete Case}
\begin{definition}
The \textit{joint distribution} is two random variables $X: \Omega \longrightarrow \mathbb{R}$ and $Y: \Omega \longrightarrow \mathbb{R}$ is the distribution in $\Omega \times \Omega \subset \mathbb{R}^2$ of the pair $(X, Y)$. It is the assignment of probabilities 
\[\mathbb{P}(X = A, Y = B)\]
for any intervals $A, B \subset \Omega$. It can also be seen as the 2-dimensional surface in $\Omega \times \Omega \times \mathbb{R}$ sufficing the equality above for all rectangles $A \times B \subset \Omega \times \Omega$. 
\end{definition}

\begin{definition}
The \textit{discrete joint distribution} of discrete random variables $X$ and $Y$ is the assignment of probabilities 
\[\mathbb{P}(X = x, Y = y)\]
for all $x, y$ in the countable set $\Omega$. It can be visualized as the set of distinct points in the form
\[\big(x, y, \mathbb{P}(X = x, Y = y) \big) \in \Omega \times \Omega \times \mathbb{R}\]
\end{definition}

\begin{definition}
The \textit{discrete marginal distributions} of $X$ and $Y$ may be recovered from the joint distribution by 
\[\mathbb{P}(X=x) = \sum_{x \in \im(Y)} \mathbb{P}(X =x, Y=y), \;\;\; \mathbb{P}(Y=y) = \sum_{x \in \im(X)} \mathbb{P}(X=x, Y=y)\]
We can visualize the marginal distribution of $X$ and $Y$ as the distributions on the "margins" of the box $\Omega \times \Omega \subset \mathbb{R} \times \mathbb{R}$. This is essentially the partition rule. We can also write this relation using conditioning
\[\mathbb{P}(X = x) = \sum_{y \in \im(Y)} \mathbb{P}(X=x \, | \, Y=y) \, \mathbb{P}(Y = y)\]
\end{definition}

\begin{definition}
For given $y \in \im(Y)$, the function 
\[x \mapsto \mathbb{P}(X = x \, | \, Y = y) = \frac{\mathbb{P}(X=x, Y=y)}{\mathbb{P}(Y=y)} = \frac{\mathbb{P}(X=x, Y=y)}{\sum_{r \in \im(X)} \mathbb{P}(X=r, Y=y)}\]
defines the \textit{conditional distribution} of $X$, given $Y = y$. 

Note that the marginal distributions of $X$ and $Y$ are not enough to determine their joint distribution. However, if we have both the marginal and conditional distributions, then the joint distribution of $X$ and $Y$ can be obtained with the formula 
\[\mathbb{P}(X = x, Y = y) = \mathbb{P}(X = x \,|\, Y = y) \, \mathbb{P}(Y=y) \;\; \forall x, y\]
\end{definition}

Both intuitively and from the formula above, we can see that if $X$ and $Y$ are independent, then the conditional distribution of $X$ given $Y=y$ is equal to the marginal distribution of $X$. 

\begin{proposition}
For a multivariate function $g: \mathbb{R}^2 \longrightarrow \mathbb{R}$, the expectation $\mathbb{E} \big( g(X, Y) \big)$ is 
\[\mathbb{E} \big( g(X, Y)\big) = \sum{(x, y)} g(x, y) \, \mathbb{P}(X=x, Y=y)\]
\end{proposition}

It is often useful to calculate expectation by conditioning. For example, suppose $g$ is a function of $x$. Then, 
\begin{align*}
    \mathbb{E}\big(g(X)\big) & = \sum_{y \in \im(Y)} \sum_{x \in \im(X)} g(x) \, \mathbb{P}(X = x, Y = y) \\
    & = \sum_{y \in \im(Y)} \sum_{x \in \im(X)} g(x) \, \mathbb{P}(X = x \, | \, Y = y) \, \mathbb{P}(Y=y) \\
    & = \sum_{y \in \im(Y)} \bigg( \sum_{x \in \im(X)} g(x) \, \mathbb{P}(X = x \, | \, Y = y)  \bigg) \, \mathbb{P}(Y = y) \\
    & = \sum_{y \in \im(Y)} \mathbb{E}\big( g(X) \, | \, Y = y \big) \, \mathbb{P}(Y=y)
\end{align*}
Therefore, $\mathbb{E}\big( g(X)\big)$ is dependent on the expectations $\mathbb{E} \big( g(X) \, | \, Y = y\big)$, which denotes expectation with respect to the conditional distribution $x \mapsto \mathbb{P}(X = x \, | \, Y = y)$ given $Y = y$.

\begin{definition}
The quantity
\[h(y) \equiv \mathbb{E} \big( g(X) \, | \, Y=y\big) = \sum_{x \in \im(X)} g(x) \, \mathbb{P}(X = x \, | \, Y = y)\]
is the \textit{conditional expectation} of $g(X)$, given $Y = y$. Note that this is really just a function of $y$. 
\end{definition}

\begin{definition}
If we define this as a random variable 
\[h(Y) \equiv \mathbb{E} \big( g(X) \,|\,Y\big)\]
we can calculate, using the derivation of $\mathbb{E}\big(g(X)\big)$ above, to get
\begin{align*}
    \mathbb{E}\big(g(X)\big) & = \sum_{y \in \im(Y)} \mathbb{E} \big( g(X) \, | \, Y = y\big) \, \mathbb{P}(Y = y) \\
    & = \sum_{y \in \im(Y)} h(y) \, \mathbb{P}(Y = y) \\
    & = \mathbb{E}\big(h(Y)\big) \\
    & = \mathbb{E} \big( \mathbb{E}(g(X) \, | \, Y ) \big) 
\end{align*}
This formula is called the \textit{Tower rule}, used to calculate the \textit{total expectation} out of conditional expectations. 
\end{definition}

\subsection{Continuous Case}
\begin{definition}
The \textit{continuous joint distribution} of continuous random variables $X$ and $Y$ is the joint density $f(x, y)$ satisfying
\[\mathbb{P}(X \in A, Y \in B) = \iint_{A \times B} f(x, y)\, dx\,dy\]
for all intervals $A, B \subset \Omega \subset \mathbb{R}$.
\end{definition}

\begin{definition}
Given joint density $f(x, y)$, the \textit{continuous marginal densities} are obtained by 
\[f_X (x) = \int_\mathbb{R} f(x, y) \, dy,  \;\;\; f_Y (y) = \int_\mathbb{R} f(x, y) \, dx\]
We can also write this using conditioning 
\[f_X (x) \equiv \int_\mathbb{R} f_X (x \, | \, Y = y) \, f_Y (y) \, dy\]
\end{definition}

\begin{definition}
For a given $Y = y$, the function 
\[x \mapsto f_X (x \, | \, Y = y) = \frac{f(x, y)}{f_Y (y)} = \frac{f(x, y)}{\int_\mathbb{R} f(r, y) \, dr}\]
is the \textit{conditional density} for $X$ given $Y = y$. 

Similarly to the discrete case, if we have both the conditional and marginal densities, we can find the joint density with the formula
\[f(x, y) = f_X (x \, | \, Y = y) \, f_Y (y)\]
\end{definition}

Again, we can define expectations for multivariate functions as
\[\mathbb{E}\big( g(X, Y) \big) = \int_{\mathbb{R}^2} g(x, y) \, f(x, y) \, dx\,dy\]

It is often useful to calculate expectation by conditioning. For example, suppose $g$ is a function of $x$. Then, 
\begin{align*}
    \mathbb{E}\big(g(X)\big) & = \int_\mathbb{R} \int_\mathbb{R} g(x) \, f(x, y) \, dx\,dy \\
    & = \int_\mathbb{R} \int_\mathbb{R} g(x) \, f_X (x \, | \, Y = y) \, f_Y (y) \,dx \,dy\\
    & = \int_\mathbb{R} \bigg( \int_\mathbb{R} g(x) \, f_X (x \, |\, Y =y) \, dx \bigg) f_Y (y) \, dy \\
    & = \int_\mathbb{R} \mathbb{E}\big( g(X) \,|\, Y = y\big) \, f_Y(y) \, dy
\end{align*}
Therefore, $\mathbb{E}\big( g(X)\big)$ is dependent on the expectations $\mathbb{E} \big( g(X) \, | \, Y = y\big)$, which denotes expectation with respect to the conditional distribution $x \mapsto f_X (x\,|\,Y = y)$, given $Y = y$. 

\begin{definition}
The quantity
\[h(y) \equiv \mathbb{E} \big( g(X) \, | \, Y=y\big) = \int_\mathbb{R} g(x) \, f_X (x\,|\, Y=y) \, dx\]
is the \textit{conditional expectation} of $g(X)$, given $Y = y$. Note that this is really just a function of $y$. 
\end{definition}

\begin{definition}
If we define this as a random variable 
\[h(Y) \equiv \mathbb{E} \big( g(X) \,|\,Y\big)\]
we can calculate, using the derivation of $\mathbb{E}\big(g(X)\big)$ above, to get
\begin{align*}
    \mathbb{E}\big(g(X)\big) & = \int_\mathbb{R} \mathbb{E} \big( g(X) \, | \, Y = y \big) \, f_Y (y) \, dy \\
    & = \int_\mathbb{R} h(y) \, f_Y (y) \, dy  \\
    & = \mathbb{E}\big(h(Y)\big) \\
    & = \mathbb{E} \big( \mathbb{E}(g(X) \, | \, Y ) \big) 
\end{align*}
\end{definition}

We now generalize the concept of independence from specific events to general distributions. 
\begin{definition}
Random discrete variables $X$ and $Y$ are \textit{independent} if 
\[\mathbb{P}(X \in A, Y \in B) = \mathbb{P}(X \in A) \, \mathbb{P}(Y \in B)\]
holds for any intervals $A, B \subset \mathbb{R}$. Equivalently, 
\[\mathbb{P}(X \leq x, Y \leq y) = \mathbb{P}(X \leq x) \, \mathbb{P}(Y \leq y)\]
Similarly, if continuous random variables $X$ and $Y$ have a joint density, then they are independent if and only if 
\[f(x, y) = f_X (x) \, f_Y (y)\]
for all $x, y \in \Omega \subset \mathbb{R}$. 
\end{definition}

\subsubsection{Alternative Interpretations of Conditional Probabilities}
Suppose $A$ is some event. Then we can define
\[\mathbb{P}(A) = \int_\mathbb{R} \mathbb{P}(A \,|\, Y = y) \, f_Y (y) \, dy\]
Then, the conditional probability $\mathbb{P}(A\,|\,Y=y)$ can also be viewed as a conditional expectation
\[\mathbb{P}(A\,|\,Y = y) = \mathbb{E} \big( \mathbb{I}_A \,|\, Y =y \big)\]
Alternatively, it may also be viewed as a limit
\[\mathbb{P}(A\,|\,Y = y) = \lim_{\epsilon \rightarrow 0} \frac{\mathbb{P}\big(A, Y \in (y - \epsilon, y + \epsilon)\big)}{\mathbb{P}\big(Y \in (y-\epsilon, y+\epsilon)\big)}\]
We can also interpret CDF of densities as 
\[\mathbb{P}(X \leq x) = \int_\mathbb{R} \mathbb{P}(X \leq x \,|\, Y = y) \, f_Y (y) \, dy\]

\section{Multivariate Gaussian Distribution}
A vector-valued random variable $X = (X_1 \ldots X_n)^T$ is said to have a \textbf{multivariate Gaussian distribution} with mean $\mu \in \mathbb{R}^n$ and covariance matrix $\Sigma$ (in the space of symmetric positive definite $n\times n$ matrices) if its probability density function is
\[p(x;\mu, \Sigma) = \frac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} \exp\bigg( -\frac{1}{2} (x-\mu)^T \Sigma^{-1} (x - \mu)\bigg)\]
We write this as $X \sim \mathcal{N}(\mu, \Sigma)$. 

Note some of the similarities between univariate and multivariate Gaussians. First, like $-\frac{1}{2\sigma^2} (x - \mu)^2$ the exponent
\[-\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu)\] 
is a quadratic, negative-definite form in the vector variable $x$. The coefficient term is just a normalizing constant, and if we integrate the entire distribution, it would be $1$. 
\[\frac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} \int_{\mathbb{R}^n} \exp\bigg( -\frac{1}{2} (x- \mu)^T \Sigma^{-1} (x-\mu)\bigg) dx -= 1\]

\subsubsection{Covariance Matrix}
Recall that for a pair of random variables $X, Y$, their covariance is defined as
\[\Cov(X, Y) = \mathbb{E}(XY) - \mathbb{E}(X) \mathbb{E}(Y)\]

\begin{definition}
In the multivariate case, the covariance matrix $\Sigma$ is the $n \times n$ matrix whose $(i, j)$th entry is $\Cov(X_i, X_j)$. That is, for any random vector $X$ with mean $\mu$ and covariance matrix $\Sigma$, 
\[\Sigma = \mathbb{E}\big( (X - \mu) (X - \mu)^T \big) = \mathbb{E}(X X^T) - \mu \mu^T\]
\end{definition}
Note that visually, $\Sigma$ will determine how much the Gaussian distribution is "stretched" on one way or another. 

If $\Sigma = I_n$ (the $n \times n$ identity matrix), then we could visualize the Gaussian distribution as being perfectly symmetric. However, if we scale the distribution up to a certain constant (below shown $\Sigma = I$, $\Sigma = 0.61 I$, $\Sigma = 2 I$), we get
\begin{center}
    \includegraphics[scale=0.65]{Gaussian_Distribution.png}
\end{center}

It is true that the $n$ axes of the $(n-1)$-dimensional isocontour ellipsoid formed by an $n$-dimensional Gaussian distribution are precisely the eigenvectors of $\Sigma$ multiplied by their eigenvalues. But since we are talking about $\Sigma$'s that are symmetric and positive definite, in the $2$ dimensional case, we deal with matrices $\Sigma$ of form (up to constant scaling): 
\[\Sigma = \begin{pmatrix}
1 & \alpha \\ \alpha & 1
\end{pmatrix}\]
which has eigenvectors $(1\; 1)$ (with eigenvalue $1+\alpha$) and $(-1\;1)$ (with eigenvalue $1-\alpha$). Therefore, in the 2 dimensional case, we would be looking at Gaussian distributions that are either circular ($\Sigma = \sigma I$), ellipses angled at $45^O$ (when $\alpha > 0$ in case above), or ellipses angled at $-45^O$ (when $\alpha < 0$). The visuals are analogous for higher dimensional distributions. 

Obviously, the "peak" of the distribution will be $\mu$. 

\section{Order Statistics}
Let $X_1, X_2, ..., X_n$ be a finite collection of independent, identically distributed random variables. Suppose that they are continuously distributed with density $f$ and CDF $F$. 

\begin{definition}
Define the random variable $X_{(k)}$ to be the $k$th ranked value, called the \textit{$k$th order statistic}. This means that 
\[X_{(1)} = \min\{X_1, X_2, ..., X_n\}, \;\; X_{(n)} = \max\{X_1, X_2, ..., X_n\}\]
and in general, for any $k \in \{1, 2, ..., n\}$, 
\[X_{(k)} = X_j \text{ if } \sum_{l=1}^n \mathbb{I}_{X_l < X_j} = k - 1\]
which means that exactly $k-1$ of the values of $X_l$ are less than $X_j$. Since $F$ is continuous, 
\[X_{(1)} < X_{(2)} < ... < X_{(n)}\]
holds with probability $1$. This leads us to define the random variable $X_{(k)}$ representing the $k$th order statistic.
\[f_{(k)} (y) = \begin{cases} 
n \, {{n-1} \choose {k-1}} y^{k-1} (1-y)^{n-k} & y \in (0, 1) \\
0 & y \not\in (0,1)
\end{cases}\]
That is, $X_{(k)}$ has the Beta$(k, n-k_1)$ distribution. 
\end{definition}

\subsection{Poisson Arrival Process}
A \textit{Poisson Arrival Process} with rate $\lambda > 0$ on the interval $[0, \infty)$ is a model for the occurence of some events which may have at any time. We can interpret the process as a collection of random points in $[0, \infty)$ which are the times at which the arrivals occur. 

\textbf{Interpretation 1} Set $T_0 = 0$. The arrival times are random variables $0 < T_1 < T_2 < T_3 < ...$ such that the inter-arrival waiting times
\[W_k = T_k - T_{k-1}, \;\;\; k \geq 0\]
have the property that $\{W_k\}_{k=1}^\infty$ are independent Exp$(\lambda)$ random variables. 
\\
\\
\textbf{Interpretation 2} For any interval $I \subset [0, \infty)$, let
\[N_I \equiv \text{ number of arrivals that occur in interval } I\]
Then, $N_I \sim$ Poisson$(\lambda |I|)$, and for any collection of disjoint intervals $I_1, I_2, ..., I_n$, the random variables 
\[\{N_{I_k}\}_{k=1}^n\]
are independent. 

\begin{theorem}
These two interpretations of the arrival process are equivalent. 
\end{theorem}
\begin{proof}
In the 2nd interpretation, the statement $N_I \sim$ Poisson$(\lambda |I|)$ means that 
\[\mathbb{P}(N_I = m) = e^{-\lambda |I|} \frac{(\lambda |I|)^m}{m!}, \;\;\; m = 0, 1, 2, 3, ...\]
where $|I|$ is the length of interval $I$. From the first perspective, notice that 
\[T_k = W_1 + W_2 + ... + W_k\]
so that the $k$th arrival time $T_k$ is a sum of $k$ independent Exp$(\lambda)$ random variables. Thus, 
\[T_k \sim \text{Gamma}(k, \lambda)\]
and therefore has density
\[ \lambda e^{-\lambda t} \frac{(\lambda t)^{k-1}}{(k-1)!}, \;\;\; t>0\]
Note that the arrival times $T_i$ are not independent of each other, but the wait times $W_i$ are indeed independent. 
\end{proof}

We can slightly modify this to create a Poisson arrival process over some finite time horizon $[0, L]$. Again, you can do this two ways: 
\begin{enumerate}
    \item Starting with independent Exp$(\lambda)$ random variables $W_1, W_2, ...$, we define
    \[T_k = \sum_{i=1}^k W_i\]
    Once you have $T_k > L$, stop. 
    \item We let $N \sim$ Poisson$(\lambda L)$, since we are only working in finite interval $L$. Given $N = n$, let $U_1, U_2, ..., U_n \sim$ Uniform$([0, L])$. These define the arrival times, and let us order them to get
    \[T_k = U_{(k)}, \;\; k = 1, 2, ..., N\]
    where $U_{(k)}$ is the $k$th ordered point, with $T_1 = \min(U_1, ..., U_N)$. 
\end{enumerate}

\begin{lemma}[Memoryless Property]
The Exp$(\lambda)$ distribution has the property that for all $t, s \geq 0$, 
\[\mathbb{P}(W > t + s \; | \; W > t) = \mathbb{P}(W > s)\]
which is called the \textit{memoryless property}. We can interpret this in the following way. Let $W$ be the time you have to wait for the first arrival. Given that you already waited $t$ units of time, the probability that you have the wait $s$ additional units of time is just the probability that you wait at least $s$ from the beginning. That is, knowing that $t$ units of time have elapsed does not affect the distribution of the remaining waiting time. 
\end{lemma}

\begin{theorem}
Let $W$ be a continuously distributed random variable. Then $W \sim$ Exp$(\lambda)$ for some $\lambda > 0$ if and only if $W$ satisfies the memoryless property. 
\end{theorem}

\section{Markov Chains}
\subsection{Discrete Time Chains}
\begin{definition}
A \textit{Markov chain} is a sequence of random variables $\{X_n\}_{n=0}^\infty$, which take values in some set $\mathcal{S}$, called the \textit{state space} satisfying the \textit{Markov property}. Since we are working with discrete time chains, we will assume that $\mathbb{S}$ is a countable (and in most cases, finite). Thus, the $X_n$ will all be discrete random variables. We can also think of $X_n$ as a discrete "time" index; that is, $X_n$ is the state of the system at time $n$. Therefore, the sequence of random variables models a system evolving in a random way. 
\end{definition}

\begin{definition}
A sequence of random variables $\{X_i\}$ satisfies the \textit{Markov property} if 
\[\mathbb{P}(X_{n+1} = y \; | \; X_n = x_n, X_{n-1} = x_{n-1}, ..., X_0 = x_0\} = \mathbb{P}(X_{n+1} = y \; | \; X_n = x_n\}\]
holds for any choice oc states $y, x_n, x_{n-1}, ..., x_0 \in \mathcal{S}$ and for any $n \geq 1$. 
\end{definition}
Colloquially, given that one is at state $X_n = x_n$, knowing all the previous states does not help in predicting $X_{n+1}$. Knowing only the current state is relevant in predicting the next one. We can model this entire system using a matrix. 

\begin{definition}
Assuming that the chain is \textit{time-homogeneous}, the \textit{transition probability matrix} $P$ has elements $P_{x y}$ defined
\[P_{x y} = P(x, y) = \mathbb{P}(X_1 = y \,|\, X_0 = x) = \mathbb{P}(X_{n+1} = y \,|\, X_n = x)\]
which is the probability of moving from state $x$ to state $y$ in one step. The time homogeneous condition refers to the last equality; that is, the one-step transition probabilities don't change with the time index $n$. Note that if $\mathcal{S}$ is finite, then $P$ is a $|S| \times |S|$ matrix, and if $\mathcal{S}$ is countably infinite, then $P$ is an infinite-dimensional matrix. The axioms of probability imply that $A^T$ is an entry-wise nonnegative stochastic matrix.
\end{definition}

\begin{example}[Random Walks]
A \textit{random walk} on the integers $\mathcal{S} = \mathbb{Z}$ where a point has equal probability of moving right or left can be modeled with the probability function. 
\[P(x, y) = \mathbb{P}(X_{n+1} = y \, | \, X_n = x) = \begin{cases}
\frac{1}{2} & y = x + 1 \\
\frac{1}{2} & y = x - 1\\
0 & otherwise
\end{cases}\]
This can be generalized to multiple dimensional random walks on graphs with probability function 
\[P(x, y) = \frac{1}{\text{deg}(x)}\]
where deg$(x)$ is the number of adjacent nodes to node $x$. In this way, the point hops randomly from node to node, and if the graph is connected, then the walker can visit any vertex in the graph. 
\end{example}

\begin{example}[Discrete Moran Model]
Consider a population of size $N$. Each individual is one of two types (say, red or blue). At each time step, the system evolves in the following way: First, one of the individuals is chosen uniformly at random to be eliminated from the population; and another individual is chosen uniformly at random to produce one offspring identical to itself. These two choices are made independently. So, if a red individual is chosen to reproduce, and a blue one is chosen for elimination, then the total number of red particles increases by one and the number of blue particles decreases by one. If a red is chosen for reproduction and a red is chosen for elimination, then there is no net change in the number of reds and blues. Let $X_n$ be the number of red individuals at time $n$. The transition matrix for this chain is
\[P_{i j} = \begin{cases}
\frac{i}{N} \bigg(\frac{N-i}{N} \bigg) & j=i-1, i \neq 0 \\
\bigg(\frac{N-i}{N} \bigg) \frac{i}{N} & j=i+1, i \neq N \\
1 - 2 \bigg(\frac{N-i}{N} \bigg) \frac{i}{N} & j = i \\
0 & \text{otherwise}
\end{cases}\]
Note that the states $X_n = 0$ and $X_n = N$ are absorbing states, which represents a phenomenon called \textit{fixation}. 
\end{example}

\begin{definition}
A certain state $F$ in the state space $\mathcal{S}$ of a Markov chain is called an \textit{absorbing state} if
\[\mathbb{P}(X_{n+1} = F \; | \; X_n = F) = 1 \iff \mathbb{P}(X_{n+1} \neq F \; | \; X_n = F) = 0\]
\end{definition}

\begin{theorem}
Let there exist a time homogeneous Markov chain with transition probability matrix $P$. Given a probability distribution $\nu_n$ (a row vector) representing the a state of a system at time $t=n$, the probability distribution of which state the system will be at when $t=n+1$ can be calculated by 
\[\nu_{n+1} = \nu_n P\]
The probability distribution of the state of the system at $t=n+k$ can be calculated by summing up all of the possible probabilities that lead to each state at $t=n+k$. It is calculated equivalently as matrix multiplication: 
\[\nu_{n+k} = \nu_n P^k\]
\end{theorem}

\begin{definition}
The distribution $\nu$ of a Markov chain at time $t=0$ is called the \textit{initial distribution} for the chain. That is, $\nu$ is the initial distribution if 
\[\mathbb{P}(X_0 = x) = \nu(x)\]
\end{definition}

\begin{definition}
An \textit{invariant distribution}, or \textit{stationary distribution}, is a probability distribution $\pi$ such that 
\[\pi P = \pi\]
This means that 
\[\pi P^k = \pi\]
for all $k \in \mathbb{N}$. We can equivalently call $\pi$ the left eigenvector of matrix $P$ with eigenvalue $1$. If $\pi$ is an invariant distribution for the chain, and $X_0 \sim \pi$, then the distribution of $X_n$ does not change with $n$; it is invariant. Note that this does not mean that $X_n$ is constant; rather, it means that the distribution of $X_n$ is not changing. 
\end{definition}

\begin{example}
Let us have a two node system with nodes labeled $L$ and $R$. That is, $\mathcal{S} = \{L, R\}$. Consider a chain on this state space with transition probability matrix. 
\[P = \begin{pmatrix}
1-a & a \\ b & 1-b 
\end{pmatrix}\]
which can be visualized in the following diagram below.
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
                    thick,main node/.style={circle,draw}]
    \node[main node] (R) {R};
    \node[main node] (L) [left of=R] {L};
    \path[every node/.style={font=\sffamily\small}]
    (L) edge [loop left] node {1-a} (L)
        edge [bend left] node {a} (R)
    (R) edge [loop right] node {1-b} (R)
        edge [bend left] node {b} (L);
\end{tikzpicture}
\end{center}

Then, the stationary distribution is 
\[\pi = \Big( \frac{b}{a+b}, \frac{a}{a+b} \Big)\]
Notice that if $a = b = 0$, then this definition is ill-defined, and any probability distribution is invariant since $P = I_2$, the identity matrix. 
\end{example}

\begin{definition}
A state $x \in \mathcal{S}$ is \textit{recurrent} if
\[\mathbb{P}(X_n = n \text{ for some } n \geq 1 \, | \, X_0 = x\} = 1\]
That is, if the initial state is $x$, the chain has probability $1$ of returning to $x$ at some later time. If a state is not recurrent, then the state is said to be \textit{transient}. That is, if $x$ is transient, there is some positive probability that the chain will never return to $x$. 
\end{definition}

\begin{definition}
Two states $x, y \in \mathcal{S}$ are said to \textit{communicate}, denoted $x \leftrightarrow y$, if there are positive integers $n$ and $m$ such that 
\[P^{(n)} (x, y) > 0 \text{ and } P^{(m)} (y, x) > 0\]
That is, there is some positive probability that the chain can go from $x$ to $y$ and from $y$ to $x$ in some number of steps. 
\end{definition}

\begin{definition}
If all pairs $x, y \in \mathcal{S}$ communicate, then the chain is said to be \textit{irreducible}. If there exists a pair of states that do not communicate, then the chain is said to be \textit{reducible}. 
\end{definition}

Note that the notion of communication is an equivalence relation between states. That is, it satisfies the properties. 
\begin{enumerate}
    \item $x \leftrightarrow x$.
    \item $x \leftrightarrow y \implies y \leftrightarrow x$.
    \item $x \leftrightarrow y, y \leftrightarrow z \implies x \leftrightarrow z$.
\end{enumerate}
This relation partitions the state space $\mathcal{S}$ uniquely into transient states and irreducible sub-chains
\[\mathcal{S} = T \cup C_1 \cup C_2 \cup ...\]
More specifically, $T$ is the set of all transient states, and the sets $C_k$ are \textit{closed communication classes}, meaning that
\begin{enumerate}
    \item For all $x, y \in C_k$, $x \leftrightarrow y$. 
    \item $P(x, z) = 0$ whenever $x \in C_k$ but $z \not\in C_k$. 
\end{enumerate}
Note that for all $x, y \not\in T$, $x$ and $y$ communicate if and only if $x$ and $y$ are in the same class $C_k$. Moreover, once the chain reaches one of the sets $C_k$, it cannot leave $C_k$. 

\begin{definition}
For any state $x \in \mathcal{S}$, the \textit{period} of $x$ is defined to be
\[d(x) \equiv \gcd \{n \geq 1 \; | \; P^{(n)} (x, x) > 0\}\]
\end{definition}

\begin{theorem}
It follows that if two states $x$ and $y$ communicate, then they must have the same period: $d(x) = d(y)$. It naturally follows that if the chain is irreducible, then all states must have the same period, and we can define the period of the chain to be $d(x)$ for any $x$ we choose.
\end{theorem}

\begin{definition}
If an irreducible chain has period $1$, the chain is said to be \textit{aperiodic}. Otherwise, the chain is \textit{periodic} with period $d > 1$. 
\end{definition}

\begin{theorem}
Suppose $|\mathcal{S}| < \infty$. If the chain is irreducible, then there always exists a unique stationary distribution $\pi$. If the chain is also aperiodic, then for any initial distribution $\nu$, 
\[\lim_{k \rightarrow \infty} \nu P^k = \pi \]
Hence
\[\lim_{k \rightarrow \infty} P^{(k)}(x, y) = \pi(y)\]
for all $x, y \in \mathcal{S}$. Furthermore, for any function $F: \mathcal{S} \longrightarrow \mathbb{R}$, the limit
\[\lim_{N \rightarrow \infty} \frac{1}{N} \sum_{n=1}^N F(X_n) = \sum_{x \in \mathcal{S}} F(x)\, \pi(x) = \mathbb{E} \big( F(x) \big)\]
holds with probability $1$. In particular, the limit does not depend on the initial distribution. 
\end{theorem}
\begin{proof}
The Frobenius Extension to Perron's theorem (Linear Algebra, Theorem 7.31) combined with its applications to stochastic matrices (Linear Algebra, Theorem 7.30) proves this statement. 
\end{proof}

\begin{definition}
For each $x \in \mathcal{S}$, define the \textit{first visit} to $x$ by 
\[T_x \equiv \min\{ n \geq 1 \; | \; X_n = x\}\]
This $T_x$ is an integer-valued random variable. We say $T_x = + \infty$ if $X_n$ never reaches $x$. Then, we define the \textit{mean return time} to $x$ by 
\[\mu_x \equiv \mathbb{E}\big( T_x \, | \, X_0 = x)\]
If $x$ is transient, then $\mu_x = + \infty$, since there is positive probability that $T_x = + \infty$. 
\end{definition}

\begin{definition}
It is possible that $x$ is recurrent while $\mu_x = +\infty$. If this is the case, then $x$ is said to be \textit{null-recurrent}. If $x$ is recurrent and $\mu_x < \infty$, then $x$ is said to be \textit{positive recurrent}. 
\end{definition}

\begin{theorem}
An irreducible chain has a stationary probability distribution $\pi$ if and only if all states are positive recurrent. If a chain is irreducible and all states are positive recurrent, then 
\[\pi(x) = \frac{1}{\mu_x}\]
for all $x \in \mathcal{S}$. $\pi$ is also unique. 
\end{theorem}

\subsubsection{Exit Probabilities}
Suppose a chain is finite and irreducible. Let $a, b \in \mathcal{S}$ be given states, and let us define $h(x)$ to be the probability of hitting $b$ before $a$, given that we start from $x$. 
\[h(x) \equiv \mathbb{P} (X_n \text{ reaches } b \text{ before } a \, | \, X_0 = x)\]
Clearly, $h(b) = 1$ and $h(a) = 0$. By conditioning on the first jump out of $x$, we also have 
\begin{align*}
    h(x) & = \mathbb{P}(X_n \text{ reaches } b \text{ before } a \, | \, X_0 = x) \\
    & = \sum_{y} \mathbb{P}(X_n \text{ reaches } b \text{ before } a \, | \, X_1 = y, X_0 = x) \, \mathbb{P}(X_1 = y \,|\,X_0 = x) \\
    & = \sum_y \mathbb{P}(X_n \text{ reaches } b \text{ before } a \, | \,X_1 = y, X_0 = x) \, P(x, y) \\
    & = \sum_y \mathbb{P}(X_n \text{ reaches } b \text{ before } a \, | \,X_1 = y) \, P(x, y) \\
    & = \sum_y h(y) \, P(x, y) 
\end{align*}
The sum is over all $y \in \mathcal{S}$ for which $P(x, y) \neq 0$. This gives us a linear system of equations to solve for $h$
\begin{align*}
    & h(x) = \sum_y P(x, y) h(y) \,\, \forall x \in \mathcal{S} \setminus \{a, b\}, \\
    & h(b) = 1, \\
    & h(a) = 0
\end{align*}

\subsubsection{Exit Prize}
Let $B \subset \mathcal{S}$ be some subset of the state space, and let $g: B \longrightarrow \mathbb{R}$ be some function. Consider the function 
\[h(x) = \mathbb{E}\big( g(X_\tau) \, |\, X_0 = x \big)\]
where $\tau = \min\{ n\geq 0 \,|\, X_n \in B\}$ is the first time that the chain reaches some state in the set $B$ (this time is random). We can interpret $g(y)$ as a "prize" that is awarded if the chain first reaches $B$ at state $y$, which means that $h(x)$ is the expected prize, given that $X_0 = x$. If $x \in B$, then $\tau = 0 \implies h(x) = g(x)$. But if $x \not\in B$, then by the same argument as shown in exit probabilities, it is true that $h$ satisfies the linear system of equations
\begin{align*}
    & h(x) = \sum_g P(x, y)\,h(y), \;\; \forall x \in \mathcal{S} \setminus B, \\
    & h(x) = g(x), \;\; x \in B 
\end{align*}
Note that Exit probability system is a special case of the Exit prize system. In the former, we have defined $B = \{a, b\}$ and $g$ defined by $g(a) = 0, g(b) = 1$. 

\subsubsection{Occupation Times, Absorbing States}
Suppose that a chain on a finite $\mathcal{S}$ is irreducible. Let $B \subset \mathcal{S}$ be some subset of states and let $A = \mathcal{S} \setminus B$ be the other states. Then for $x \in A$, we wish to know how many steps the chain will take before reaching a state in the set $B$. We define 
\[\tau_B = \min\{n \geq 0 \,|\, X_n \in B\}\]
which represents the first time that $X$ is in $B$, an integer valued random variable. We wish to compute
\[h(x) = \mathbb{E}(\tau_B \,|\, X_0 = x)\]
Clearly, $h(y) = 0$ for all $y \in B$. For $x \in A$, it takes at least one step to reach $B \implies h(x) \geq 1$ for $x \in A$. We condition on the first step from $x$. This leads to the system \begin{align*}
    h(x) = 1 + \sum_{y \in \mathcal{S}} P(x, y) \, \mathbb{E}(\tau_B \,|\, X_1 = y), & \forall x \in A = \mathcal{S} \setminus B
\end{align*}
Since the chain is time-homogeneous, this means that
\begin{align*}
    h(x) = 1 + \sum_{y \in \mathcal{S}} P(x, y) \, h(y), & \forall x \in A 
\end{align*}
Since $h(y) = 0$ for all $y \in B$, we now have
\begin{align*}
    h(x) = 1 + \sum_{y \in A} P(x, y) \, h(y), & \forall x \in A 
\end{align*}
To solve this system, let us define $M$ as the $|A| \times |A|$ submatrix of $P$ obtained by keeping only the entries $P(x, y)$ with $x, y \in A$. So, the system can be written as
\begin{align*}
    h(x) = 1 + \sum_{y \in A} M(x, y) \, h(y), & \forall x \in A
\end{align*}
We can solve this system of equations through the equivalent matrix equation
\[(I - M) h = 1\]
where $1 = (1, 1, ..., 1)^T$ is the column vector consisting of all $1$'s. The solution vector is therefore
\[h = (I - M)^{-1} 1\]
So, for a particular $x \in A$, 
\[h(x) = \sum_{y \in A} (I - M)^{-1} (x, y)\]
\\

Alternatively, we can slightly modify the chain to chain $\Tilde{X}_n$ by replacing the transition probability matrix $P$ with another one defined as 
\[\Tilde{P}(x, y) = \begin{cases}
P(x, y) & x \in A, y \in \mathcal{S} \\
1 & x = y \in B \\
0 & \text{else}
\end{cases}\]
This modification means that all transitions from state in $A$ to any other state are preserved and the only transitions from a state $x \in B$ are self loops. In particular, all transitions from states $x \in B$ to states $y \in A$ are removed. Therefore, under this modified transition matrix, the states in $B$ are absorbing states. The tail sum formula implies that
\[\mathbb{E}(\tau_B \,|\, X_0 = x) = \sum_{k=0}^\infty \mathbb{P}(\tau_B > k \,|\, X_0 = x)\]
Notice that since the chain $X_n$ and $\Tilde{X}_n$ have the same transition rules before hitting a state $B$, we have 
\[P^{(k)} (x, y) = \Tilde{P}^{(k)} = M^{(k)}(x, y)\]
where $M$ is the $|A| \times |A|$ submatrix defined previously. Therefore, putting this all together, we have
\begin{align*}
    \mathbb{E}(\tau_B \,|\, X_0 = x) & = \sum_{k=0}^\infty \mathbb{P}(\tau_B > k \,|\, X_0 = x) \\
    & = \sum_{k=0}^\infty \mathbb{P}(\Tilde{X}_k \in A \,|\, X_0 = x) \\
    & = \sum_{k=0}^\infty \sum_{y \in A} \Tilde{P}^{(k)} (x, y) \\
    & = \sum_{k=0}^\infty \sum_{y \in A} M^{(k)} (x, y) \\
    & = \sum_{y \in A} \bigg( \sum_{k=0}^\infty M^{(k)} \bigg) (x, y) 
\end{align*}
Using a theorem from linear algebra, we can show that if all the eigenvalues of a $d \times d$ matrix $M$ have modulus strictly less than $1$, then $I-M$ is invertible and
\[\sum_{k=0}^\infty M^{(k)} = (I - M)^{-1}\]
where $I$ is the $d \times d$ identity matrix. If $M$ is the $|A| \times |A|$ submatrix described above, one can show that $M$ has his property and that $I - M$ is invertible. Hence, 
\[\mathbb{E}(\tau_B \,|\, X_0 = x) = \sum_{y \in A} \bigg( \sum_{k=0}^\infty M^{(k)} \bigg) (x, y) = \sum_{y \in A} (I-M)^{-1} (x, y)\]
which refers to the $(x, y)$ entry of the matrix $(I - M)^{-1}$. This is indeed consistent with our previous derivation of the formula for $h(x)$, the expected number of steps before the state reaches $B$. 

\subsection{Markov Chain Monte Carlo Algorithms}
In statistics, Markov chain Monte Carlo (MCMC) methods comprise of a class of algorithms for sampling from a probability distribution by constructing a Markov chain that has the desired distribution as its equilibrium distribution. That way, by recording samples from the chain, one may get better approximations of the actual distribution. 

Let there exist a state space $\mathcal{S}$ with some probability distribution $\pi(x)$ for every $x \in \mathcal{S}$. Clearly, 
\[\sum_{x \in \mathcal{S}} \pi(x) = 1\]
but the problem is that we do not know that $\pi$ is. We do know, however, another function $f$ that is directly proportional to $\pi$. 
\[\pi(x) = \frac{f(x)}{c}, \text{ where } c = \sum_{x \in \mathcal{S}} f(x)\]
is the normalizing constant. It is often the case that $c$ is unknown and the state space $\mathcal{S}$ is so large that computing $c$ directly is expensive. Therefore, we construct Markov chains that can provide approximations to $\pi$. 

\subsubsection{Metropolis-Hastings Algorithm}
This algorithm is useful because it does not require knowledge of the normalizing constant $c$. The algorithm only requires evaluations of 
\[\frac{\pi(x)}{\pi(y)} = \frac{f(x)}{f(y)}\]
We first have the state space $\mathcal{S}$ consisting of all the possible states. We now construct (any) probability transition matrix $q$ for a Markov chain on $\mathcal{S}$. Note that $q$ is a $|\mathcal{S}| \times |\mathcal{S}|$ matrix and $q^T$ is a stochastic matrix. This matrix is constructed by the user and is completely well-defined and known. We start off with any initial state $x_0 \in \mathcal{S}$ and iterate the following 2-steps to construct a Markov chain. 
\begin{enumerate}
    \item Given a state $X_n = x$, we generate a new state $X_{n+1}$ by first proposing a new state $y \in \mathcal{S}$ with probability $q(x, y)$ (determined from the matrix $q$). 
    \item With this chosen state $y$, we decide whether to accept to reject the proposal. With probability 
    \[\min \bigg( 1, \frac{\pi(y) \,  q(y, x)}{\pi(x) \, q(x, y)} \bigg)\]
    we accept the proposal and set $X_{n+1} = y$. Otherwise, the proposal is rejected and the new state is the same $X_{n+1} = x$. 
\end{enumerate}
Note that there are two levels of randomness here: which state the new state $y$ will be and whether to accept this state to be the next one or not. If step two did not exist (i.e. the probability of accepting the proposal is always $1$), then this would just be a regular Markov chain represented by the matrix $q$. But the addition of step 2 means that while $q$ is used in constructing the discrete chain $X_n$, it is \textit{not} the transition probability matrix of $X_n$. 

There is also a lot of flexibility on choosing $q$, although the performance of the algorithm (speed of convergence of the distribution of $X_n$ to the stationary distribution) will depend on the choice.

\begin{proposition}
For the chain defined by the Metropolis-Hastings algorithm, the distribution $\pi$ is stationary. 
\end{proposition}
\begin{proof}
Let us write in shorthand 
\[\alpha(x, y) = \frac{\pi(y)\, q(y, x)}{\pi(x)\, q(x, y)}\]
First, observe that if $x \neq y$, the transition probability for the chain defined by the algorithm is just
\[P(x, y) = q(x, y)\, \min\{1, \alpha(x, y)\}\]
Next, we claim that for all $x, y \in \mathcal{S}$, 
\[\pi(x) P(x, y) = \pi(y) \, P(y, x) \]
This condition is called \textit{detailed balance}. Assuming that $\alpha(x, y) \leq 1$, it is true that
\[\pi(x) P(x, y) = \pi(x) q(x, y) \frac{\pi(y) q(y, x)}{\pi(x) q(x, y)} = \pi(y) q(y, x)\]
In this case, we also have $\alpha(y, x) = 1 / \alpha(x, y) \leq 1$. So, 
\[\pi(y) P(y, x) = \pi(y) q(y, x) \]
and we have proved what we had claimed. Now, summing over $x$,
\[\sum_x \pi(x) P(x, y) = \sum_x \pi(y) P(y, x) = \pi(y) \sum_x P(y, x) = \pi(y)\]
since $P^T$ is stochastic. 
\end{proof}

\subsubsection{Gibb's Sampling}
Let $\mathcal{A} = \{a_1, ..., a_k\}$ be some finite set. Suppose that the state space 
\[\mathcal{S} = \mathcal{A} \times ... \times \mathcal{A} = \mathcal{A}^M\]
for some $M \in \mathbb{N}$. The following algorithm generates a Markov chain on $\mathcal{S}$ with stationary distribution
\[\pi(x) = \frac{f(x_1, x_2, ..., x_M)}{c}, \;\; x = (x_1, x_2, ..., x_M) \in \mathcal{S} \]
where $c >0$ is a normalizing constant. Note that $|\mathcal{S}| = k^M$, so computing $c$ may be expensive when $M$ is large. The current state of the chain is denoted 
\[X_n = (X_n^1, X_n^2, ..., X_n^M)\]
We think of $X_n$ as having $M$ components, each component taking values in $\mathcal{A}$. We start off with any initial state $X_0 = (X_0^1, X_0^2, ..., X_0^M)$ and construct a Markov chain by iterating the following two steps. 
\begin{enumerate}
    \item Given $X_n = (X_n^1, X_n^2, ..., X_n^M)$, we generate the next state $X_{n+1}$ by picking a component index $i \in \{1, ..., M\}$ uniformly at random. 
    \item With this chosen, well-defined $i$, we choose a random $Y^i \in \mathcal{A}$ according to the distribution
    \[\mathbb{P}(Y^i = a) = \frac{f\big(X_n^1 ,..., X_n^{i-1}, a, X_n^{i+1}, ..., X_n^M\big)}{\sum_{j=1}^k f\big(X_n^1 ,..., X_n^{i-1}, a_j, X_n^{i+1}, ..., X_n^M\big)}, \;\; a \in \{a_1, ..., a_k\}\]
    \item Then, set $X_{n+1} = \big(X_n^1, ..., X_n^{i-1}, Y^i, X_n^{i+1}, ..., X_n^M\big)$. 
\end{enumerate}
Note that at each step, only one component of $X_n$ is updated. Observe that the distribution above is also equal to 
\[\mathbb{P}(Y^i = a) = \frac{\pi\big(X_n^1 ,..., X_n^{i-1}, a, X_n^{i+1}, ..., X_n^M\big)}{\sum_{j=1}^k \pi \big(X_n^1 ,..., X_n^{i-1}, a_j, X_n^{i+1}, ..., X_n^M\big)}\]
which is the marginal distribution of the $i$th component, given the values of the other components. 

\begin{proposition}
For the chain defined by this algorithm, the distribution $\pi$ is stationary. 
\end{proposition}
\begin{proof}
We verify that the detailed balance condition holds. It is also helpful to note that $P(x, y) \neq 0$ if and only if $x$ and $y$ differ in one coordinate. 
\end{proof}

\subsection{Continuous Time Markov Chains}
As the name suggests, in a continuous time Markov chain $X_t$, the time parameter is continuous ($t \geq 0$). As before, the system jumps randomly between states in $\mathcal{S}$, but now the jumps may occur at any time and they occur randomly. This implies that there are \textit{two} sources of randomness:
\begin{enumerate}
    \item \textit{where} the system jumps and 
    \item \textit{when} the system jumps
\end{enumerate}

\begin{definition}
The Markov property in the continuous time case says that for any $s, t \geq 0$ and $y \in \mathcal{S}$, 
\[\mathbb{P}(X_{t + s} = y \, | \, X_t) = \mathbb{P}(X_{t+s} = y \, | \, X_r \; \forall 0 \leq r \leq t)\]
Colloquially, the conditional distribution of $X_{t+s}$ given the history up to time $t$ is the same as the conditional distribution of $X_{t+s}$ given only $X_t$. Thus, if we know the current state at $t$, knowing information about the past doesn't help us better predict the future state $X_{t+s}$. 
\\

In order for the Markov property to hold, the times between jumps must be exponentially distributed random variables because it is the only density that has the memoryless property. This fact has already been stated in a theorem when covering Poisson arrival processes. This is what makes Exp$(\lambda)$ so important for continuous time Markov chains. 
\end{definition}

\begin{lemma}
Let $T_1, T_2, ..., T_n$ be independent exponential random variables with rates $\lambda_1, \lambda_2, ..., \lambda_n$, respectively. Then the random variable $T \equiv \min\{T_1, T_2, ..., T_n\}$ is
\[T \sim \text{Exp}\Big(\sum_{i=1}^n T_i\Big)\]
Moreover, 
\[\mathbb{P}(T_k = \min\{T_1, ..., T_n\}) = \frac{\lambda_k}{\lambda_1 + ... + \lambda_n}\]
\end{lemma}

We can interpret the lemma above by imagining that we have $n$ alarm clocks all set simultaneously, which will ring independently at random times. Suppose that clock $k$ will ring after $T_k$ units of time have expired, where $T_k$ is a random variable distributed as Exp$(\lambda_k)$. Then, $T = \min\{T_1, ..., T_n\}$ is the time at which the first ring occurs. 

\begin{example}
The simplest and the most important continuous time Markov chains is the Poisson arrival process. The process really has a single parameter $\lambda >0$ (the rate of process) by definition and is integer valued. At each jump time, the process increases by $1$, and the time between jumps are independent, distributed as Exp$(\lambda)$. 

Notice that when $\lambda$ is large, the arrivals occur more frequently than when $\lambda$ is small, because the expected time between arrivals is $1/\lambda$. The second way we can interpret it is to choose an interval of time $t$ and let $X_t$ be the number of jumps that have occurred up to time $t$. It is a fact that $X_t$ is a integer-valued, Poisson$(\lambda t)$ distribution. That is, 
\[\mathbb{P}(X_t = k) = e^{-\lambda t} \frac{(\lambda t)^k}{k!}, \; k = 0, 1, 2, ...\]
In particular, $\mathbb{E}(X_t) = \lambda t$ and $\Var(X_t) = \lambda t$. 
\end{example}

\subsection{Branching Processes}
\begin{definition}
A \textit{branching process} is a type of Markov chain modeling a population in which each individual produces a random number of children (possibly $0$) and dies. The state space is $\mathcal{S} = \{0, 1, 2, 3, ...\}$. Furthermore, there is a discrete-time version and a continuous time version of the chain. In the discrete case, the state is $Z_n$, the size of the population at time $n = 0, 1, 2, ...$, and in the continuous case, the state is $Z_t$ for $t \geq 0$. 
\end{definition}

\subsubsection{Discrete-time Branching Process}
In the discrete case, all of the $Z_n$ individuals in the current generation branch at the same time and immediately die. The branching is independent and distributed according to the \textit{offspring distribution} $\{p_k\}_{k=0}^\infty$. Specifically, if $Z_n = m$, then 
\[Z_{n+1} = Y_1^n + Y_2^n + ... + Y_m^n\]
where $Y_i^n$ represents the number of offspring the $i$th individual in the $n$th generation has. All of them are distributed as
\[\mathbb{P}(Y_i^n = k) = p_k, \; k = 0, 1, 2, 3, ...\]
where $p_k$ is the probability that a parent has $k$ children. Note that if $p_0 \neq 0$, then there is positive probability that $Y_i^n = 0$ for all $i$, meaning that the population can go extinct. A sample branching process up to the second generation is shown below. 
\begin{center}
\begin{tikzpicture}[scale=0.8]
    \draw[fill] (0,4) circle (0.05);
    \draw[fill] (-2,2) circle (0.05);
    \draw[fill] (0,2) circle (0.05);
    \draw[fill] (2,2) circle (0.05);
    \draw[dashed] (0,4)--(-2,2);
    \draw[dashed] (0,4)--(0,2);
    \draw[dashed] (0,4)--(2,2);
    \draw[fill] (-3,0) circle (0.05);
    \draw[fill] (-1,0) circle (0.05);
    \draw[dashed] (-2,2)--(-3,0);
    \draw[dashed] (-2,2)--(-1,0);
    \draw[dashed] (2,2)--(3,0);
    \draw[dashed] (2,2)--(1,0);
    \draw[dashed] (2,2)--(2,0);
    \draw[fill] (3,0) circle (0.05);
    \draw[fill] (2,0) circle (0.05);
    \draw[fill] (1,0) circle (0.05);
    \node at (5,4) {$Z_0 = 1$};
    \node at (5,2) {$Z_1 = 3$};
    \node at (5,0) {$Z_2 = 5$};
    \draw[->] (4.3,4)--(3.5,4);
    \draw[->] (4.3,2)--(3.5,2);
    \draw[->] (4.3,0)--(3.5,0);
    \node at (-5, 3) {$Y_1^0 = 3$};
    \node at (-5, 1.5) {$Y_1^1 = 2$};
    \node at (-5, 1) {$Y_2^1 = 0$};
    \node at (-5, 0.5) {$Y_3^1 = 3$};
\end{tikzpicture}
\end{center}

Suppose that the mean number of offspring of a single parent is finite. 
\[\mu = \mathbb{E}(Y) = \sum_{k=0}^\infty k \, \mathbb{P}(Y = k) = \sum_{k=0}^\infty k \, p_k < \infty\]
If $Y_1$ and $Y_2$ are two independent, discrete random variables, we can define their convolution and use the fact that $\mathbb{P}(Y_i = k) = p_k$ to get
\begin{align*}
    \mathbb{P}(Y_1 + Y_2 = k) & = \sum_j \mathbb{P}(Y_1 = k - j) \, \mathbb{P}(Y_2 = j) \\
    & = \sum_{j=0}^\infty p_{k-j} p_j, \;\; k = 0, 1, 2, ...
\end{align*}
This is a two-fold convolution of the sequence $\{p_k\}$ with itself, denoted
\[p_k^{*2} = \sum_{j=0}^\infty p_{k-j} \, p_j\]
Extending this, we can find the $m$-fold convolution of the sequence $\{p_j\}$ with itself, represented by the sequence $\{p_j^{*m}\}$, where $p_k^{*m}$ is the $k$th term in this sequence. This gives us
\[p_k^{*n+1} = \sum_{j=0}^\infty p_{k-j} \, p_j^{*n}\]
for all $n \in \mathbb{N}$. Using this, we can write down the transition probabilities for the Markov chain $Z_n$. 
\[\mathbb{P}(Z_{n+1} = k \, | \, Z_n = m) = \begin{cases}
0 & \text{if } m = 0 \\
p_k^{*m} & \text{if } m \geq 1, k \geq 0
\end{cases}\]
where $\mathbb{P}(Z_{n+1} = k \, | \, Z_n = m)$ represents the probability of the $n$th generation consisting of $m$ individuals producing a total of $k$ offspring for the $(n+1)$th generation. Thus, the branching process is completely determined by the distribution of $Z_0$ and the offspring distribution $\{p_k\}_{k=0}^\infty$. 

\begin{lemma}
Given this discrete-time branching process, let $\mu$ be the mean of the offspring distribution. Then, 
\[\mathbb{E}(Z_n \, | \, Z_0 = 1) = \mu^n\]
If $\mu > 1$, the mean of $Z_n$ grows exponentially, and if $\mu_1$, the mean of $Z_n$ decreases exponentially. 
\end{lemma}

\subsubsection{Continuous-time Branching Process}
A continuous time branching process $Z_t$ has very similar structure to the discrete time branching process, except that the times between branch events (for each individual) are independent exponentially distributed random variables Exp$(\lambda)$, where the parameter $\lambda> 0$ is the branching rate. It is as though each individual has an independent alarm clock which rings as a time that is Exp$(\lambda)$, independently of all other clocks. So, if there are currently $N$ individuals, then the next alarm will ring at rate $\lambda N$; that is, the time until the next ring is distributed as Exp$(\lambda N)$, since it is the minimum of $N$ independent Exp$(\lambda)$ random variables. When an individual branches (clock rings), that individual produces a random number of offspring, according to the offspring distribution $\{p_k\}$, as before. So, a continuous time branching process has the same geneological structure as the discrete time process, but the times between branch events is randomized. Consequently, whether or not the process eventually goes extinct, depends only on the offspring distribution, not on the branching rate $\lambda$. 

Let $m_1(t) = \mathbb{E}(Z_t)$ denote the expected population size at time $t$. Then, it is a fact that $m_1(t)$ satisfies the ordinary differential equation
\[\frac{d}{d t} m_1 (t) = \lambda(\mu - 1) m_1 (t)\]
where 
\[\mu = \sum_{k=1}^\infty k p_k\]
is the mean of the offspring distribution. Solving this equation reveals that 
\[m_1 (t) = e^{\lambda (\mu-1) t} m_1 (0)\]
If $\mu > 1$, the mean population size grows exponentially, and if $\mu < 1$, the mean population size decreases exponentially. 

\subsubsection{Extinction Probability, Generating Functions}
The expression for the transition probabilities of $Z_n$ (disrete case) is quite difficult to work with. Alternatively, it can be convenient to work with generating functions. 

\begin{definition}
The \textit{generating function} for the offspring distribution is the function 
\[G(s) \equiv \sum_{k=0}^\infty p_k \, s^k = \mathbb{E}(s^Y)\]
where $Y \sim \{p_k\}$ is a random variable representing the number of children produced by a given individual. Note that $G$ is a power series that simply encodes information about the offspring distribution (also a sequence) $\{p_k\}_{k=0}^\infty$. 
\end{definition}

\begin{theorem}
\begin{enumerate}
    \item The radius of convergence of $G(s)$ is at least $1$. $G(s)$ defines a continuous function on $|s| \leq 1$. 
    \item On the interval $[0,1]$, $G(s)$ is increasing and convex. If $p_0 + p_1 < 1$, then $G(s)$ is strictly convex for $s \in [0,1]$. 
    \item $G(0) = p_0$. 
    \item $G(1) = 1$. 
    \item $G^\prime(1^-) = \mu$ is the expected number of offspring of a single individual. 
\end{enumerate}
\end{theorem}
\begin{proof}
We use the fact that 
\[\sum_{k=0}^\infty p_k = 1 \text{ and } 0 \geq p_k \geq \; \forall k = 0, 1, 2, ...\]
\end{proof}

\begin{theorem}
Suppose that $Z_0 = 1$ and that $p_0 + p_1 < 1$. Then
\[\lim_{n \rightarrow \infty} \mathbb{P}(Z_n = 0) = \mathbb{P}(\text{eventual extinction}) = t\]
where $t \in [0, 1]$ is the smallest non-negative root of the equation $t = G(t)$. If $\mu \leq 1$, then $t = 1$ (clearly, since the population will exponentially decrease on average). If $\mu > 1$, there is a positive probability that the population never goes extinct. 
\end{theorem}
\begin{proof}
Let $t$ be the probability that an individual's descendent family tree goes extinct. That is, $t = \mathbb{P}(Z_n = 0$ for some $n \geq 1 \; | \; Z_0 = 1)$. To derive the equation $t = G(t)$, let us condition on the first generation, with $Y_1$ denoting the number of offspring of the single parent. 
\begin{align*}
    t & = \mathbb{P}(\text{eventual extinction} \; | \; Z_0 = 1) \\
    & = \sum_{k=0}^\infty \mathbb{P}(\text{eventual extinction} \; | \; Z_0 = 1, Y_1 = k) \, \mathbb{P}(Y_1 = k \; | \; Z_0 = 1) \\
    & = \sum_{k=0}^\infty \mathbb{P}(\text{eventual extinction} \; | \;Z_0 =1, Y_1 = k) \, p_k
\end{align*}
That is, given that there are $k$ children of the first individual, the probability that this first individual's descendent family tree will go extinct is equal to the probability that each of the $k$ children's trees go extinct. These $k$ extinction events are independent. Therefore, 
\[\mathbb{P}(\text{eventual extinction} \; | \;Z_0 = 1, Y_1 = k) = t^k\]
which implies that 
\[t = \sum_{k=0}^\infty \mathbb{P}(\text{eventual extinction} \; | \; Z_0 = 1, Y_1 = k) \, p_k = \sum_{k=0}^\infty t^k \, p_k = G(t)\]
Additionally, under the hypothesis that $p_0 + p_1 < 1$, then $G(s)$ is strictly convex on $[0,1]$. Hence if $G^\prime (1) = \mu \leq 1$, the smallest non-negative root of $t = G(t)$ must be $t=1 \implies$ extinction occurs with probability 1. On the other hand, if $G^\prime (1) = \mu > 1$, then the smallest root of $t = G(t)$ occurs in the interval $[0,1)$. 
\end{proof}

Note that this result applies to both the discrete time case and the continuous time case. In continuous-time chains, whether or not the population goes extinct does not depend on $\lambda$, the rate at which individuals give birth. The $\lambda$ affects the time at which extinction occurs (if it occurs), but it does not affect the probability that it occurs. However, the extinction probability certainly does depend on the offspring distribution. 

\begin{definition}
A random variable $X$ is a \textit{counting variable} if it takes values in $\{0, 1, 2, ...\}$. 
\end{definition}

Note that generating functions is a mapping from $X$, the set of counting variables (all assumed to be pairwise independent) to the algebra of power series over variable $s$.
\[G: X \longrightarrow F[[s]]\]

\begin{lemma}
Let $X$ and $Y$ be two independent random counting variables, with generating functions $G_X (s) = \mathbb{E}(s^X)$ and $G_Y (s) = \mathbb{E}(s^Y)$. Then, the generating function for the random variable $Z = X + Y$ is $G_Z(s) = G_X (s) G_Y (s)$. That is, the generating function mapping $G$ is a homomorphism that maps addition to multiplication. In particular, if $X$ and $Y$ are iid, then $G_Z (s) = G_X (s)^2$. 
\end{lemma}
\begin{proof}
Since $X$ and $Y$ are independent, 
\[G_Z (s) = \mathbb{E}(s^Z) = \mathbb{E}(s^{X+Y}) = \mathbb{E}(s^X s^Y) = \mathbb{E}(s^X) \mathbb{E}(s^Y) = G_X (s) G_Y (s)\]
\end{proof}

Applying this argument iteratively, we get the following lemma. 
\begin{lemma}
Let $N \geq 1$ be a fixed positive integer. Let $Y_1, Y_2, ..., Y_N$ be independent, identically distributed random counting variables with generating function $G_Y (s) = \mathbb{E}(s^Y)$. Then, the generating function for the sum $Z = Y_1 + ... + Y_n$ is 
\[G_Z (s) = G_Y (s)^N\]
\end{lemma}

Now, suppose that $N$ is not fixed, but another random variable. We wish to describe the distribution of the sum of a random number of random variables. 

\begin{lemma}
Let $Y_1, Y_2, Y_3, ...$ be a collection of independent, identically distributed random variables with generating function $G_Y (s) = \mathbb{E}(s^Y)$. Let $N$ be a random counting variable, independent of the $Y_i$. Let $N$ have generating function $G_N (s)$. Then the generating function for $Z = Y_1 + Y_2 + ... + Y_N$ is 
\[G_Z (s) = G_N \big( G_Y (s) \big)\]
\end{lemma}
\begin{proof}
Just condition on $N = k$ 
\begin{align*}
    G_Z (s) = \mathbb{E}(s^Z) & = \sum_{k=0}^\infty \mathbb{E}\big( s^Z \,|\, N=k\big) \, \mathbb{P}(N=k) \\
    & = \sum_{k=0}^\infty \mathbb{E}(s^{Y_1 + ... + Y_k} \,|\,N=k) \, \mathbb{P}(N=k) \\
    & = \sum_{k=0}^\infty G_Y (s)^k \, \mathbb{P}(N=k) \\
    & = \mathbb{E}\big( G_Y (s)^N \big) = G_N \big( G_Y (s) \big)
\end{align*}
\end{proof}

\begin{theorem}
Let $G(s)$ be the generating function for the offspring distribution $G(s) = \sum_{k=0}^\infty p_k s^k$. Suppose that $Z_0 = 1$ and let $G_n (s) = \mathbb{E}(s^{Z_n})$ be the generating function for the random variable $Z_n$. Then, 
\[G_{n+m} (s) = G_n \big(G_m (s)\big) = G_m \big( G_n (s) \big)\]
Hence, 
\[G_n (s) = G(G(G(...(G(s))...))) \;\;\;\; \text{n-fold composition}\]
\end{theorem}

\begin{example}
Suppose the offspring distribution is
\[p_k = q p^k, \;\; k \geq 0\]
for some $p \in (0, 1)$, where $q = 1-p$. Thus, the number of children from a given parent is $Y = X - 1$, where $X \sim$ Geom$(q)$. Then, $\mathbb{E}(Y) = \frac{1}{q} - 1 = \frac{p}{q}$. With some computation, this means that
\[G(s) = \frac{q}{1- p s}\]
and $t = \min \{1, \frac{q}{p}\}$. 
\end{example}

\section{Basic Statistical Concepts}
Given a \textbf{population} that we would like to observe, we would ideally calculate its \textbf{parameter} directly. In reality, this is not efficient, and thus we take a sample in order to measure its \textbf{statistic}. This statistic (also called a \textbf{estimator}) is used to estimate the parameter.

\begin{definition}
The \textbf{bias} of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. 

An estimator with zero bias is called \textbf{unbiased}. 
\end{definition}

\begin{definition}[Notation]
Listed. 
\begin{enumerate}
    \item The population mean (a parameter) is denoted $\mu$. 
    \item The standard deviation of an arbitrary distribution is denoted $\sigma$, and the variance $\sigma^2$. 
    \item The mean of a sample taken from a population is denoted $\bar{x}$. 
\end{enumerate}
\end{definition}


\subsection{Sampling Distributions}
\begin{definition}
A \textbf{sampling distribution} is the probability distribution of a given random sample-based statistic, considered as a random variable, when derived from a random sample of size $n$. It can be considered as the distribution of the statistic for all possible samples from the same population of a given sample size. 

The sampling distribution depends on the underlying distribution of the population, but it will tend towards normal for large $n$ (by the CLT). Note that a sample distribution, which is just the distribution of the sample that we have taken, is completely different from the sampling distribution. 
\end{definition}

\begin{example}
Given a population of $50,000$ students in a university, we measure their heights. The true mean of the heights, which is usually unknown, can be denoted $\mu$. If we take a sample of, say, $200$ students the mean of this sample is denoted $\bar{x}$. Furthermore, if we take another sample of $200$ students (uncorrelated to the first one), chances are the $\bar{x}$ will also be different, meaning that we can treat $\bar{x}$ as a random variable. The distribution of $\bar{x}$ is the sampling distribution, which is different from the true distribution of heights of the population. 
\end{example}

\subsubsection{Standard Deviation vs Error}
\begin{definition}[Standard Error]
The standard deviation of the sampling distribution of a statistic is called the standard error of that quantity.
\end{definition}

\begin{definition}[True, Estimated Standard Error of the Mean]
 If a sample of size $n$ are taken from a statistical population with standard deviation of $\sigma$, then the mean value calculated from the sample $\bar{x}$ will have an associated standard error on the mean $\sigma_{\bar{x}}$ given by 
\[\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}\]
However, since the standard deviation $\sigma$ of the population being sampled is seldom known, the standard error of the mean is usually estimated by replacing $\sigma$ with the sample standard deviation $\sigma_x$ instead. Note that this is an \textit{estimator} for the true standard error. 
\[\hat{\sigma_{\bar{x}}} \approx \frac{\sigma_x}{\sqrt{n}}\]
Note that the sample size $n$ must be quadrupled in order to achieve $1/2$ the measurement error. 
\end{definition}

Note that we must be able to distinguish the four terms. 
\begin{enumerate}
    \item The SD of the \textit{population}: $\sigma$
    \item The SD of the \textit{sample}: $\sigma_x$
    \item The SD of the \textit{mean} itself (i.e. the SE): $\sigma_{\bar{x}}$ 
    \item The \textit{estimator} of the SE (colloquially called the SE): $\hat{\sigma_{\bar{x}}}$
\end{enumerate}

Note that when the sample size is small, using the standard deviation of the sample $\sigma_x$ instead of the true standard deviation of the population $\sigma$ will tend to underestimate the population standard deviation, and therefore also the standard error $\hat{\sigma_{\bar{x}}}$. When $n=2$, the underestimate is about $25\%$, but for $n=6$, the underestimate is only $5\%$. 

\subsubsection{Student t-Distribution}
In many practical applications, the true value of $\sigma$ is unknown, and as a result, we need to use a distribution that takes into account that spread of possible $\sigma$'s. In the ideal case that we have a population distribution that is Gaussian with standard deviation $\sigma$, we can calculate the sampling distribution of the mean to be $\sigma/\sqrt{n}$. 

But when the true underlying population (Gaussian) distribution has unknown $\sigma$, the the resulting sampling distribution must take into account that spread of possible $\sigma$'s. 

\begin{definition}
Therefore, when estimating the mean of a normally-distributed population in situations where the population's standard deviation is unknown, the \textbf{student t-distribution} is used as the sampling distribution. 

It is slightly different from Gaussian as they have heavier tails and vary depending on the size of the sample. Small samples are somewhat more likely to underestimate the population standard deviation and have a mean that differs from the true population mean, and the student t-distribution accounts for the probability of these events with somewhat heavier tails compared to a Gaussian.
\end{definition}

But note that the t-distribution is approximated well by the Gaussian distribution when the sample size is over $100$, so for such samples one can use the latter distribution, which is much simpler. 

\subsubsection{Confidence Intervals}
The estimator is an example of a point estimation, i.e. a single value given as the estimate of a population parameter. Contrarily, an interval estimate specifies instead a range within which the parameter is estimated to lie. 

\begin{example}
In a survey of polls, a sample was taken and was found that $40\%$ of the respondents stated that they would vote for a certain party. A $99\%$ confidence interval for the proportion of the whole population having the same intention on the survey might be $30\% \sim 50\%$. From the same data, one may calculate a $90\%$ confidence interval of $37\% \sim 43\%$. 

A major factor determining the length of a confidence interval is the size of the sample used in the estimation procedure. 
\end{example}

Various interpretations of a confidence interval can be given. We will provide equivalent ones for, say a $90\%$ confidence interval. \begin{enumerate}
    \item Repeated Samples: \textit{Where this procedure to be repeated on numerous samples, the fraction of calculated confidence intervals (which would differ for each sample) that encompasses the true population parameter would tend towards $90\%$.}
    \item Single Sample: \textit{There is a $90\%$ probability that the calculated confidence interval from some future experiment encompasses the true value of the population parameter. }
\end{enumerate}


\section{Generalized Linear Models}
A statistical model can informally be thought of as a set of statistical assumptions with a certain property: that the assumption allows us to calculate the probability of any event. 

\begin{definition}
Formally, a \textbf{statistical model} is a pair $(S, \mathcal{P})$ where $S$ is the set of possible observations, i.e. the sample space, and $\mathcal{P}$ is the set of probability distributions on $S$. 

Intuitively, it is assumed that there is a "true" probability distribution induced by the process that generates the observed data. We choose $\mathcal{P}$ to represent a set (of distributions) which contains a distribution that adequately approximates the true distribution. Note that it is not required that $\mathcal{P}$ contains the true distribution, and in practice is rarely the case. 
\end{definition}

\begin{example}
Suppose that we have a group of children, with ages of the children distributed uniformly, in the population. The height of a child will be stochastically related to the age. We could formalize this relationship between age and height with a \textit{linear regression} model as such:
\[\text{height}_i = b_0 + b_1\, \text{age}_i + \epsilon_i\]
where $b_0$ is the intercept, $b_1$ is a parameter that age is multiplied by to obtain a prediction of height, $\epsilon_i$ is the error term, and $i$ identifies the child. This implies that height is predicted by age, with some error. 
\end{example}
\chapter{Number Theory}
An introductory course in number theory. Much of the material introduced in this chapter can be found in other sections, especially those about Euclidean and Integral domains which are generalizations of the integers. 

We begin by stating the well ordering principle of the natural numbers $\mathbb{N}$. 

\begin{theorem}[Well-Ordering Principle]
Every nonempty set $S$ of nonnegative integers contains a least element. That is, there exists some integer $a \in S$ such that $a \leq b$ for all $b \in S$. 
\end{theorem}

This leads to the following. 

\begin{theorem}[Archimedean Property]
If $a, b$ are any positive integers, there exists a positive integer $n$ such that $n a \geq b$. 
\end{theorem}

\subsubsection{Induction}
We provide three methods of proof. 

\begin{proposition}[Induction Principle]
Given $P(n)$, a property depending on a positive integer $n$, 
\begin{enumerate}
    \item if $P(n_0)$ is true for some positive integer $n_0$, and 
    \item if for every $k \geq n_0$, $P(k)$ true implies $P(k+1)$ true, 
\end{enumerate}
then $P(n)$ is true for all $n \geq n_0$. 
\end{proposition}

\begin{proposition}[Strong Induction Principle]
Given $P(n)$, a property depending on a positive integer $n$, 
\begin{enumerate}
    \item if $P(n_0), P(n_0 + 1), ..., P(n_0 +m)$ are true for some positive integer $n_0$ and nonnegative integer $m$, and
    \item if for every $k > n_0 + m$, $P(j)$ true for all $n_0 \leq j \leq k$ implies $P(k)$ true, 
\end{enumerate}
then $P(n)$ is true for all $n \geq n_0$. 
\end{proposition}

\begin{proposition}[Infinite Descent]
Given $P(n)$, a property depending on a positive integer $n$, assume that $P(n)$ is false for a set of integers $\mathcal{S}$. Let the smallest element of $\mathcal{S}$ be $n_0$. If $P(n_0)$ false implies $P(k)$ false, where $k < n_0$, then by contradiction, $P(n)$ is true for all $n$. 
\end{proposition}
Note that the method of infinite descent is based off of the well ordering principle. 

In some cases (especially in the Putnam exam), sometimes a creative use of induction will be requied. For example, you can first induct on a subset $\mathcal{S}$ of $\mathbb{N}$, then induct backwards (proving $P(n)$ true given $P(n+1)$ true), or use a double induction argument where you induct on two variables instead of one.

\section{Divisibility Theory and Primes}
A huge portion of number theory rests on the following theorem/algorithm. 

\begin{theorem}[Division Algorithm]
Given integers $a, b$ with $b > 0$, there exist unique integers $q, r$ satisfying
\[a = q b + r, \;\; 0 \leq r < b\]
The integers $q$ and $r$ are called the \textit{quotient} and \textit{remainder} in the division of $a$ by $b$, respectively. 
\end{theorem}
\begin{proof}
This statement can be quite obvious, but a rigorous proof requires the use of the well-ordering principle and proof by contradiction. 
\end{proof}

\begin{definition}
Let $a$ and $b$ be given integers, with at least one of them different from zero. The \textit{greatest common divisor of $a$ and $b$}, denoted by $\gcd(a, b)$, is the positive integer $d$ satisfying
\begin{enumerate}
    \item $d |a$ and $d|b$
    \item If $c|a$ and $c|b$, then $c \leq d$ 
\end{enumerate}
Note that $0$ is divisible by every number. 
\end{definition}

\begin{theorem}
Given integers $a, b$ not both of which are $0$, there exist integers $x$ and $y$ such that
\[\gcd(a, b) = a x + b y\]
\end{theorem}
\begin{proof}
Consider the set $S$ of all positive linear combinations of $a$ and $b$. Note that $S$ is nonempty and is a subset of $\mathbb{N}$. 
\[S \equiv \{ au + bv \;|\; au+bv > 0, \; u, v \in \mathbb{Z}\}\]
From the well-ordering principle, $S$ must contain a smallest element $d$. Thus, from the definition of $S$, there exist integers $x$ and $y$ for which $d = ax + by$. We claim that $d = \gcd(a, b)$. 

Using the division algorithm, we can obtain integers $q, r$ such that $a = qd + r$, where $0 \leq r < d$. Then, $r$ can be written in the form 
\begin{align*}
    r = a - qd & = a - q(ax + by) \\
    & = a(1 - qx) + b(-qy)
\end{align*}
If $r >0$, then this representation of $r$ above would simply mean that $r \in S$, contradicting the fact that $d$ is the smallest element in $S$. So, $r = 0 \implies a = qd$, which implies $d | a$. By similar reasoning, $d|b$, which makes $d$ a common divisor of $a$ and $b$. 

Now, if $c$ is an arbitrary positive common divisor of the integers $a$ and $b$, then $c | (ax+by)$; that is, $c|d$. Since $d \geq c$ for all $c$, $d = \gcd(a, b)$. 
\end{proof}

\begin{corollary}
If $a$ and $b$ are given nonzero integers, then the set
\[T \equiv \{ax + by \;|\; x, y \in \mathbb{Z}\}\]
is precisely the set of all multiples of $d = \gcd(a, b)$. 
\end{corollary}

\begin{definition}
Two integers $a$ and $b$, not both of which are zero, are said to be \textit{relatively prime} whenever $\gcd(a, b) = 1$. 
\end{definition}

\begin{theorem}
Let $a, b$ be nonzero integers. Then $a$ and $b$ are relatively prime if and only if there exist $x, y \in \mathbb{Z}$ such that
\[1 = a x + b y\]
\end{theorem}
\begin{proof}
This is a direct result of the previous corollary. 
\end{proof}

This result directly leads to an observation that may be useful in some situations. 

\begin{corollary}
If $\gcd(a, b) = d$, then $\gcd(a/d, b/d) = 1$. 
\end{corollary}
\begin{proof}
Since it is possible to find integers $x, y$ such that 
\[d = ax + by\]
Upon dividing the Diophantine equation by $d$, we obtain 
\[1 = \bigg(\frac{a}{d}\bigg) x + \bigg( \frac{b}{d} \bigg) y\]
where $a/d$ and $b/d$ are integers. Using the previous theorem, the two are relatively prime. 
\end{proof}

\subsection{The Euclidean Algorithm}
Here we introduce an algorithm that finds the greatest common divisors of two arbitrary integers. Without loss of generality, we can assume that $a, b > 0$ when finding 
\[\gcd(a, b)\]
We will need to following lemma. 

\begin{lemma}
If $a = q b + r$, then $\gcd(a, b) = \gcd(b, r)$. 
\end{lemma}
\begin{proof}
If $d = \gcd(a, b)$, then the relations $d|a$ and $d|b$ together imply that $d|(a-qb)$, or $d|r$. Thus, $d$ is a common divisor of both $b$ and $r$. On the other hand, if $c$ is an arbitrary common divisor of both $b$ and $r$, then $c|(qb+r)$, whence $c|a \implies c$ is a common divisor of both $a$ and $b$, so that $c \leq d$. So, $c \leq d$. 
\end{proof}

Using the result of this lemma, we can calculate 
\begin{align*}
    a = q_1 b + r_1, \;\;\; & 0 < r_1 < b \\
    b = q_2 r_1 + r_2 , \;\;\; & 0 < r_2 < r_1 \\
    r_1 = q_3 r_2 + r_3 , \;\;\; & 0 < r_3 < r_2 \\
    ... , \;\;\; & ... \\
    r_{n-2} = q_n r_{n-1} + r_n , \;\;\; & 0 < r_n < r_{n-1} \\
    r_{n-1} = q_{n+1} r_n + 0, \;\;\; &
\end{align*}
and find that
\[\gcd(a, b) = \gcd(b, r_1) = ... = \gcd(r_{n-1}, r_n) = \gcd(r_n, 0) = r_n\]

\begin{example}
Let us calculate $\gcd(12378, 3054)$ using the Euclidean algorithm. The appropriate calculations produces the following: 
\begin{align*}
    12378 & = 4 \cdot 3054 + 162 \\ 
    3054 & = 18 \cdot 162 + 138 \\
    162 & = 1 \cdot 138 + 24 \\
    24 & = 1 \cdot 18 + 6 \\
    18 & = 3 \cdot 6 + 0
\end{align*}
Therefore, $\gcd(12378, 3054) = 6$. To represent $6$ as a linear combination of the integers $12378$ and $3054$, we start with the second to last equation and substitute in remainders.
\begin{align*}
    6 & = 24 - 18 \\
    & = 24 - (138 - 5 \cdot 24) \\
    & = 6 \cdot 24 - 138 \\
    & = 6 (162 - 138) - 138 \\
    & = 6 \cdot 162 - 7 \cdot 138 \\
    & = 6 \cdot 162 - 7 (3054 - 18 \cdot 162) \\
    & = 132 \cdot 162 - 7 \cdot 3054 \\
    & = 132(12378 - 4 \cdot 3054) - 7 \cdot 3054 \\
    & = 132 \cdot 12378 + (-535) \cdot 3054
\end{align*}
Thus, we have 
\[\gcd(12378, 3054) = 6 = 12378 x + 3054 y\]
where $x = 132, y = -535$. 
\end{example}

\begin{proposition}[Lame]
The number of steps required in the Euclidean Algorithm is at most $5$ times the number of digits in the smaller integer. 
\end{proposition}

\begin{theorem}
For positive integers $a, b$, 
\[\gcd(a, b) \, \text{lcm}(a, b) = ab\]
\end{theorem}
\begin{proof}
Let $d = \gcd(a, b)$. This allows us to express $a= dr$ and $b = ds$ for some $r, s \in \mathbb{N}$. If 
\[m = \frac{ab}{d}\]
then $m = as = rb$, which makes $m$ a positive common multiple of both $a$ and $b$. Now, let $c$ be a positive integer that is a common multiple of $a$ and $b$, say, $c = au + bv$. Since there exist integers $x, y$ satisfying $d = ax + by$, we get
\[\frac{c}{m} = \frac{cd}{ab} = \frac{c(ax+by)}{ab} = \frac{c}{b} x + \frac{c}{a} y = vx + uy\]
This means that $m |c$ and so $m \leq c$. 
\end{proof}

The significance of the previous theorem is that it makes the calculation of the least common multiple dependent on the greatest common divisor, which can be calculated using the Euclidean algorithm. For example, 
\[\text{lcm}(3054, 12378) = \frac{3054 \cdot 12378}{6} = 6300402\]

\begin{corollary}
For any choice of positive integers $a, b$, $\text{lcm}(a, b) = ab$ if and only if $\gcd(a, b) = 1$. 
\end{corollary}

\subsection{The Diophantine Equation ax+by=c}
It is customary to call a Diophantine equation any equation in one or more variables that is to be solved in the integers. The simplest type of Diophantine equation is
\[a x+ by = c\]

\begin{theorem}
The linear Diophantine equation $ax + by = c$ has a solution if and only if $d|c$, where $d = \gcd(a, b)$. If $x_0, y_0$ is a particular solution to this equation, then the general solution can be paramaterized as
\[x = x_0 + \Big(\frac{b}{d} \Big) t, \; y = y_0 - \Big( \frac{a}{d} \Big) t, \;\;\; t \in \mathbb{Z}\]
\end{theorem}

To find a particular solution, we apply Euclidean's algorithm to the coefficients $a, b$ and work backwards to find a linear combination of $a$ and $b$ to get $\gcd(a, b)$. Then we multiply it according to the proper scalar to find the values of $x, y$. 

\begin{example}
Consider the linear Diophantine equation. 
\[172x + 20y = 1000\]
We apply Euclidean's algorithm to calculate $\gcd(172, 20)$. 
\begin{align*}
    172 & = 8 \cdot 20 + 12 \\
    20 & = 1 \cdot 12 + 8 \\
    12 & = 1 \cdot 8 + 4 \\
    8 & = 2 \cdot 4
\end{align*}
So, $\gcd(172, 20) = 4$. Since $4|1000$, a solution to this equation exists. Moreover, by working backwards, we have
\begin{align*}
    4 &  = 12 - 8 \\
    & = 12 - (20 - 12) \\
    & = 2 \cdot 12 - 20 \\
    & = 2 (172 - 8 \cdot 20) - 20 \\
    & = 2 \cdot 172 + (-17) \cdot 20
\end{align*}
By multiplying both sides of $4 = 2 \cdot 172 + (-17) \cdot 20$ by $250$, we get 
\[1000 = 500 \cdot 172 + (-4250) \cdot 20\]
So, $x = 500, y = -4250$ is one solution to the equation. All other solutions are expressed by 
\begin{align*}
    &x = 500 + \frac{20}{4} t = 500 + 5t \\
    &y = -4250 - \frac{172}{4} t = -4250 - 43t
\end{align*}
\end{example}

\begin{corollary}
If $\gcd(a, b) = 1$, and if $x_0, y_0$ is a particular solution of the linear Diophantine equation $ax + by = c$, then all solutions are given by
\[x = x_0 + bt, \;\; y = y_0 - at\]
\end{corollary}

Systems of linear equations can also be solved accordingly with a bit of modification. 

\begin{example}
To solve the system 
\[5x + 3y + \frac{1}{3}z = 100, \; x + y + z = 100\]
by eliminating one of the unknowns by substituting $z = 100 - x - y$, we are left with the equation 
\[5x + 3y + \frac{1}{3} (100-x-y) = 100 \implies 7x + 4y = 100\]
\end{example}

\subsection{The Fundamental Theorem of Arithmetic}

\begin{definition}
An integer $p > 1$ is called a \textit{prime number} if its only positive divisors are $1$ and $p$.
\end{definition}

\begin{theorem}[Fundamental Theorem of Arithmetic]
Every positive integer $n>1$ can be expressed as a product of primes. This representation is unique up to the order in which the factors occur. 
\end{theorem}

The process of putting a number into this form is called \textit{prime factorization}. 

\begin{corollary}
Any positive integer $n>1$ can be written uniquely in a \textit{canonical form}
\[n = \prod_{i=1}^r p_i^{k_i} = p_1^{k_1} p_2^{k_2}... p_r^{k_r}\]
where, for $i=1, 2, ..., r$, each $k_i$ is a positive integer and each $p_i$ is a prime, with $p_1 < p_2 < ... < p_r$. 
\end{corollary}

We now present a method of identifying whether a certain number is prime or not. 

\begin{theorem}[Sieve of Eratosthenes]
If an integer $a >1$ is not divisible by any prime $p \leq \sqrt{a}$, then $a$ is prime. 
\end{theorem}

\begin{theorem}[Euclid]
There is an infinite number of primes.
\end{theorem}
\begin{proof}
Assume that there are a fininte number of primes $p_1, ..., p_n$. Consider the number 
\[P = p_1 p_2... p_n + 1\]
Clearly, $P$ is not divisible by any of the $p_i$'s 
\end{proof}

We can actually put an upper bound on the $n$th (smallest) prime. 

\begin{theorem}
If $p_n$ is the $n$th prime number, then 
\[p_n \leq 2^{2^{n-1}}\]
\end{theorem}

However, by 1854, a much better bound was formed. 
\begin{theorem}
\[p_n \leq 2^n\]
\end{theorem}

\begin{definition}
A \textit{repunit} is an integer written (in decimal notation) as a string of $1$'s, such as $11, 111, 1111, ...$. Let $R_n$ denote the repunit with $n$ digits. Every repunit is in the form 
\[R_n = \frac{10^n - 1}{9}\]
\end{definition}

The first seven repunit primes are
\[R_2, R_{19}, R_{23}, R_{317}, R_{1031}, R_{49081}, R_{86453}\]

\subsection{The Goldbach Conjecture}
We now introduce some progress on identifying some pattern in primes. We have already established our first claim: that there are an infinite number of primes. We can claim even further. 

\begin{theorem}
The sum of the reciprocals of the primes diverges to infinity. That is, given the set of all primes $\mathbb{P} \subset \mathbb{N}$,
\[\sum_{p \in \mathbb{P}} p = \infty\]
\end{theorem}

\begin{definition}
A \textit{twin prime} is a pair of primes $(p, q)$ such that $q-p = 2$. 
\end{definition}

\begin{conjecture}[Twin Prime Conjecture]
There are an infinite number of twin primes. 
\end{conjecture}

Twin primes get much more scarce as numbers get bigger. The largest known twin prime in 2002 is 
\[33219825 \cdot 2^{169690} \pm 1\]
with 51090 digits long. 

\begin{theorem}[Brun]
The sum of the reciprocals of the twin primes converges to a sum, known as \textit{Brun's constant}. Brun's constant is approximately
\[1.902160583209\pm 0.000000000781\]
based on all twin primes less than $2 \times 10^{16}$.
\end{theorem}

\begin{theorem}[Zhang, 2014]
There are an infinite number of prime pairs differing by 246. 
\end{theorem}

We now state one of the oldest and most well-known conjectures in number theory. 

\begin{conjecture}[Goldbach Conjecture, 1742]
Every even positive integer greater than $2$ is the sum of two prime numbers. 
\end{conjecture}
The numerical data supporting the Goldbach conjecture is overwhelming, and many mathematicians believe that it is true. We provide more claims about primes. 

\begin{theorem}
There are an infinite number of primes in the form $4n + 3$. 
\end{theorem}

\begin{theorem}[Dirichlet]
If $a$ and $b$ are relatively prime positive integers, then the arithmetic progression
\[a, a + b, a + 2b, a + 3b\]
contains infinite many primes. 
\end{theorem}

For example, this theorem tells us that there are an infinite number of primes ending in $999$, such as $1999, 100999, 1000999, ...$ since they appear in the arithmetic progression $1000n + 999$, where $\gcd(1000, 999) = 1$. 

\begin{conjecture}
There exists arbitrarily long but finite arithmetic progressions consisting only of prime numbers. The longest progression found to date is the $22$ primes
\[11410337850553 + 4609098694200 n, \;\;\; 0 \leq n \leq 21\]
\end{conjecture}
The prime factorization of the common difference between the terms is 
\[2^3 \cdot 3 \cdot 5^2 \cdot 7 \cdot 11 \cdot 13 \cdot 17 \cdot 19 \cdot 23 \cdot 1033\]
which is divisible by $9699690$, the product of the primes less than $22$. This leads to the following theorem. 

\begin{theorem}
If all the $n>2$ terms of the arithmetic progression 
\[p, p+d, p+2d, ..., p + (n-1) d\]
\end{theorem}

\section{The Theory of Congruences}

\begin{definition}
Let $n$ be a fixed positive integer. Two integers $a$ and $b$ are said to be \textit{congruent modulo $n$}, denoted
\[a \equiv b \pmod{n}\]
if $n|(a-b)$; that is, if there exists an integer $k$ such that $a-b = k n$. 
\end{definition}

The following is clearly a relation within the set of integers. That is, 
\begin{enumerate}
    \item $a \equiv a \pmod{n}$
    \item $a \equiv b \pmod{n} \implies b \equiv a \pmod{n}$
    \item $a \equiv b \pmod{n}, b \equiv c \pmod{n} \implies a \equiv c \pmod{n}$
\end{enumerate} 
This furthermore partitions the integers into \textit{congruence classes}. 

\begin{theorem}
For arbitrary integers $a$ and $b$, $a \equiv b \pmod{n}$ if and only if $a$ and $b$ have the same nonnegative remainder when divided by $n$. 
\end{theorem}
\begin{proof}
Trivial.
\end{proof}

Since the integers are naturally endowed with the operations of addition and multiplication, we can conclude even further results about congruences. 

\begin{theorem}
Let $n>1$ be fixed and $a, b, c, d$ be arbitrary integers. Then 
\begin{enumerate}
    \item $a \equiv b \pmod{n}, c \equiv d \pmod{n} \implies a+c \equiv b+d \pmod{n}$
    \item $a \equiv b \pmod{n}, c \equiv d \pmod{n} \implies ac \equiv bd \pmod{n}$
    \item $a \equiv b \pmod{n} \implies a^k \equiv b^k \pmod{n}$ for any positive integer $k$
\end{enumerate}
All three can be combined to get the following. Let \[P(x) = \sum_{k=0}^m c_k x^k\] 
be a polynomial function of $x$ with integral coefficients $c_k$. If $a \equiv b \pmod{n}$, then $P(a) \equiv P(b) \pmod{n}$. 
\end{theorem}

However, note that congruences do not hold when integers are divided! Note the example 
\[2 \equiv 8 \pmod{6} \centernot\implies 1 \equiv 4 \pmod{6}\]
The following theorem must be used. 

\begin{theorem}
If $ca \equiv cb \pmod{n}$, then $a \equiv b \pmod{n/d}$, where $d = \gcd(c, n)$. 
\end{theorem}

This states that if $\gcd(c, n) = 1$, then we can divide both sides by $c$ without a change in modulus. 

\begin{corollary}
If $ca \equiv cb \pmod{n}$ and $\gcd(c, n) = 1$, then $a \equiv b \pmod{n}$. 
\end{corollary}

\begin{corollary}
If $ca \equiv cb \pmod{p}$ where $p$ is a prime number, then $a \equiv b \pmod{p}$. 
\end{corollary}

\begin{definition}
A number in the digit form 
\[\overline{a_n a_{n-1} ...a_0}\]
in \textit{base $m$} is calculated to be in the form \[\overline{a_n a_{n-1} ...a_-} = \sum_{i=0}^n a_i m^i = a_0 + a_1 m^1 + a_2 m^2 + ... + a_n m^n\]
\end{definition}

With this, we can prove requirements of divisibility of numbers by $3, 9$, and $11$. 

\begin{theorem}
Let $N = \overline{a_n a_{n-1} ...a_0}$ be the decimal (base 10) representation of a the positive integer $N$. Then 
\begin{enumerate}
    \item $3|N$ if and only if $3 \big| \sum_{i=0}^n a_i$
    \item $9|N$ if and only if $9 \big| \sum_{i=0}^n a_i$
    \item $11|N$ if and only if $11 \big| \sum_{i=0}^n (-1)^{i} a_i$
\end{enumerate}
\end{theorem}
\begin{proof}
We can see that 
\begin{align*}
    \overline{a_n a_{n-1} ...a_0} = \sum_{i=0}^n a_i 10^i & \equiv \sum_{i=0}^n a_i (1)^i \pmod{3} \\
    & \equiv \sum_{i=0}^n a_i (1)^i \pmod{9} \\
    & \equiv \sum_{i=0}^n a_i (-1)^i \pmod{11}
\end{align*}
\end{proof}

\subsection{Linear Congruences}
\begin{definition}
An equation of linear congruence is of form 
\[a x \equiv b \pmod{n}\]
where the solutions are equivalence classes of integers $[x]$. Two integers in the same equivalence class are counted as the same solution. 
\end{definition}

\begin{theorem}
The linear congruence $a x \equiv b \pmod{n}$ has a solution if and only if $d|b$, where $d = \gcd(d, n)$. If $d|b$, then it has $d$ distinct solutions of equivalence classes. 

Furthermore, if $x_0$ is a particular solution, then the $d = \gcd(a, n)$ incongruent solutions are
\[x_0, x_0 + \frac{n}{d}, x_0 + 2 \Big( \frac{n}{d} \Big), ..., x_0 + (d-1) \Big( \frac{n}{d} \Big)\]
\end{theorem}

\begin{corollary}
If $\gcd(a, n) = 1$, then the linear congruence $a x \equiv b \pmod{n}$ has a unique solution modulo $n$. 
\end{corollary}

\begin{example}
Consider the equation $18 x \equiv 30 \pmod{42}$. Since $\gcd(18,42) = 6$ and $6 |30$, there are exactly $6$ solutions that are incongruent modulo $42$. One solution is $x = 4$, so the rest of them are 
\[x \equiv 4 + \frac{42}{6} t \equiv 4 + 7t \pmod{42}, \;\; t = 0, 1, 2, 3, 4, 5\]
which is the equivalence classes
\[x \equiv 4, 11, 18, 25, 32, 39 \pmod{42}\]
\end{example}

\begin{theorem}[Chinese Remainder Theorem]
Let $n_1, n_2, ..., n_r$ be positive integers such that $\gcd(n_i, n_j) = 1$ for $i \neq j$. Then, the system of linear congruences 
\begin{align*}
    x \equiv a_1 \pmod{n_1} \\
    x \equiv a_2 \pmod{n_2} \\
    ... \\
    x \equiv a_r \pmod{n_r}
\end{align*}
has a simultaneous solution, which is unique modulo the integer $n_1 n_2 ... n_r$. 
\end{theorem}
\begin{proof}
Define the product $n = n_1 n_2 ... n_r$. For each $k = 1, 2, ..., r$, let
\[N_k = \frac{n}{n_k} = n_1 n_2 ... n_{k-1} n_{k+1} ... n_r\]
By hypothesis, all $n_i$ are relatively prime, so, $\gcd(N_k, n_k) = 1$. According to the theory of a single linear congruence, it is therefore possibly to solve the congruence $N_k x \equiv 1 \pmod{n_k}$; denote the unique solution as $x_k$. We claim that the integer 
\[\bar{x} = \sum_{i = 1}^r a_i N_i x_i\]
is a simultaneous solution of the given system. Since $N_i \equiv 0 \pmod{n_k}$ for $i \neq k$, we have
\[\bar{x} = \sum_{i=1}^r a_i N_i x_i \equiv a_k N_k x_k \pmod{n_k}\]
But since the integer $x_k$ was chosen to satisfy the congruence $N_k x \equiv 1 \pmod{n_k}$, this forces
\[\bar{x} \equiv a_k \pmod{n_k}\]
which shows that a solution exists. As for uniqueness, suppose that $x^\prime$ is any other integer satisfying the congruences. Then, 
\[\bar{x} \equiv a_k \equiv x^\prime \pmod{n_k}, \;\; k = 1, 2, ..., r\]
and so $n_k | \bar{x} - x^\prime$ for each $k$. Since $\gcd(n_i, n_j) = 1$, this implies that 
\[\Big( \prod_{i=1}^r n_i \Big) \bigg| (\bar{x} - x^\prime)\]
which implies that $\bar{x} \equiv x^\prime \pmod{n}$. 
\end{proof}

\begin{example}
Let us solve the system 
\begin{align*}
    x \equiv 2 \pmod{3} \\
    x \equiv 3 \pmod{5} \\
    x \equiv 2 \pmod{7}
\end{align*}
We have $n = 3 \cdot 5 \cdot 7$ and so
\begin{align*}
    N_1 = 35, N_2 = 21, N_3 = 15
\end{align*}
leading to the linear congruences
\begin{align*}
    35x \equiv 1 \pmod{3} \\
    21 x \equiv 1 \pmod{5} \\
    15 x \equiv 1 \pmod{7}
\end{align*}
The solutions to these equations are $x_1 = 2, x_2 = 1, x_3 = 1$, respectively. Thus, a solution of the original system is given by 
\[x = 2 \cdot 35 \cdot 2 + 3 \cdot 21 \cdot 1 + 2 \cdot 15 \cdot 1 = 233\]
Taking modulo 105, we get the unique solution $x = 233 \equiv 23 \pmod{105}$. 
\end{example}

\begin{definition}
A linear congruence equation in two variables is of the form 
\[ax + by \equiv c \pmod{n}\]
This congruence has a solution if and only if $\gcd(a, b, n) | c$. 
\end{definition}

We briefly describe the process of solving the equation when either one of $a$ or $b$ is relatively prime to $n$. Without loss of generality, let $\gcd(a, n) = 1$. Then, we can express the congruence as 
\[ax \equiv c - by \pmod{n}\]
and for each of the $n$ incongruent values of $y$, we are guaranteed a unique solution for $x$. 

\begin{example}
Given the equation 
\[7x + 4y \equiv 5 \pmod{12}\]
since $\gcd(7, 12) = 1$, we change the equation to 
\[7x \equiv 5 - 4y \pmod{12}\]
Using casework by substituting each of the 12 possible incongruent values of $y$, we can reduce the above to a linear equation in one variable. For instance, leting $y \equiv 5 \pmod{12}$ produces the equation
\[7x \equiv -15 \pmod{12} \implies -5x \equiv -15 \implies x \equiv 3 \pmod{12}\]
Therefore, $(x, y) \equiv (3, 5)$ is one out of the 12 solutions. 
\end{example}

We now shift towards solving systems of these equations. 

\begin{theorem}
The system of linear congruences
\begin{align*}
    ax + by \equiv r \pmod{n} \\
    cx + dy \equiv s \pmod{n}
\end{align*}
has a unique solution modulo $n$ whenever $\gcd(ad-bc, n) = 1$. 
\end{theorem}
\begin{proof}
Let us multiply the first congruence of the system by $d$, the second congruence by $b$, and subtract the lower result form the upper. We then get
\[(ad-bc) x \equiv dr - bs \pmod{n}\]
Since by hypothesis, $\gcd(ad-bc, n) = 1$, this ensures that the congruence 
\[(ad - bc) z \equiv 1 \pmod{n}\]
has a unique solution; call it $t$. When we multiply this to the first equation, we get 
\[x \equiv t (dr - bs) \pmod{n}\]
Similarly, we can get a value for $y$:
\[y \equiv t (as - cr) \pmod{n}\]
Since we have described an explicit formula for the solutions $x, y$, we are done. 
\end{proof}

Notice that we can interpret this system as
\[\begin{pmatrix}
a & b\\c&d
\end{pmatrix} \begin{pmatrix}
x \\ y
\end{pmatrix} \equiv \begin{pmatrix}
r \\ s
\end{pmatrix} \pmod{n}\]
For those with a bit of background in algebra, we can interpret the matrix of cofficients as a linear endomorphism of the quotient space of lattices $\mathbb{Z}^2 / \sim$, where $\sim$ is the congruence relation. 

\begin{example}
We use the formulas gotten in the previous proof to find the solutions of the system: 
\begin{align*}
    7x + 3y \equiv 10 \pmod{16} \\
    2x + 5y \equiv 9 \pmod{16} 
\end{align*}
Since $\gcd(7\cdot 5 - 2 \cdot 3, 16) = \gcd(29, 16) = 1$, a solution exists. Multiplying the first congruence by $5$, the second by $3$, and subtracting the second from the first gives the equation
\[29 x \equiv 23 \pmod{16} \implies 13 x \equiv 7 \pmod{6}\]
producing the solution $x \equiv 3 \pmod{16}$. When we eliminate the $x$ variable, we get the equation 
\[29 y \equiv 43 \pmod{16} \implies y \equiv 7 \pmod{16}\]
So, the unique solution to the system is
\[x \equiv 3 \pmod{16}, \;\; y \equiv 7 \pmod{16}\]
\end{example}

\subsection{Fermant's Little Theorem and Pseudoprimes}

\begin{theorem}[Fermant's Little Theorem]
Let $p$ be a prime and suppose that $p \not\big| \,a$. Then, 
\[a^{p-1} \equiv 1 \pmod{p}\]
\end{theorem}
\begin{proof}
We consider the first $p-1$ positive multiples of $a$. 
\[a, 2a, 3a, ..., (p-1) a\]
None of these numbers is congruent modulo $p$ to any other, nor is any congruent to zero, since if any were, then 
\[ra \equiv sa \pmod{p}, \;\; 1 \leq r < s \leq p-1\]
then $a$ could be canceled to give $r \equiv s \pmod{p}$, which is impossible. Therefore, the previous set of integers must be congruent modulo $p$ to $1, 2, 3, ..., p-1$, taken in some orer. Multiplying these congruences together gives 
\[a^{p-1} (p-1)! \equiv (p-1)! \pmod{p}\]
Since $p \not\big| \, (p-1)!$, we can divide both sides by $(p-1)!$ without changing the modulo to get
\[a^{p-1} \equiv 1 \pmod{p}\]
\end{proof}

We can state this theorem in a slightly more general way by not requiring that $p$ does not divide $a$. 

\begin{corollary}
If $p$ is prime, then $a^p \equiv a \pmod{p}$ for any integer $a$. 
\end{corollary}

Ancient Chinese mathematicians conjectured that $n$ is prime if and only if $n|(2^n - 2)$, which held true up to $340$. However, $n = 341$ provides a counterexample to this claim, but numbers $n$ that satisfy $n | (2^n - 2)$ are prime often enough to merit a name. 

\begin{definition}
A composite integer $n$ is called a \textit{pseudoprime} if $n | (2^n - 2)$. 
\end{definition}

\begin{theorem}
If $n$ is an odd pseudoprime, then 
\[M_n = 2^n -1\]
is a larger one. 
\end{theorem}

\begin{corollary}
There are an infinite number of pseudoprimes. 
\end{corollary}
\begin{proof}
The previous theorem allows us to construct an infinite sequence of increasing odd pseudoprimes. 
\end{proof}
The first four are $341, 561, 645$, and $1105$. 

\begin{definition}
More generally, a composite integer $n$ for which 
\[a^n \equiv a \pmod{n}\]
is called a \textit{pseudoprime to the base $a$}. When $a=2$, $n$ is simply said to be a pseudoprime. 
\end{definition}

\begin{proposition}
There are infinitely many pseudoprimes to any given base. 
\end{proposition}
Even though there are an infinite number of pseudoprimes, they are much rarer than regular primes. Indeed, there are only $245$ pseudoprimes and $78,498$ primes smaller than $1,000,000$.

\begin{definition}
Composite numbers $n$ that are pseudoprimes to every base $a$ are called \textit{absolute pseudoprimes}. 
\end{definition}

\begin{lemma}
$561$ is an absolute pseudoprime. 
\end{lemma}
\begin{proof}
Note that $561 = 3 \cdot 11 \cdot 17$, and notice that $\gcd(a, 561) = 1$ gives 
\[\gcd(a, 3) = \gcd(a, 11) = \gcd(a, 17) = 1\]
Using Fermant's little theorem, we get the congruences
\[a^2 \equiv 1 \pmod{3}, \; a^{10} \equiv 1 \pmod{11}, \;\; a^{16} \equiv 1 \pmod{17}\]
which implies 
\begin{align*}
    &a^{560} \equiv (a^2)^{280} \equiv 1 \pmod{3} \\
    &a^{560} \equiv (a^{10})^{56} \equiv 1 \pmod{11} \\
    &a^{560} \equiv (a^{16})^{35} \equiv 1 \pmod{17} 
\end{align*}
So, we have $a^{560} \equiv 1 \pmod{561}$, where $\gcd(a, 561) =1$. So, $a^{561} \equiv a \pmod{561}$ for all $a$. 
\end{proof}

The next absolute pseudoprimes are 
\begin{align*}
    1105 & = 5 \cdot 13 \cdot 17 \\
    2821 & = 7 \cdot 13 \cdot 31 \\
    15841 & = 7 \cdot 31 \cdot 73 \\
    ... & = ... \\
    16046641 & = 13 \cdot 37 \cdot 73 \cdot 457
\end{align*}

Now, we present a theorem that provides a means for producing absolute pseudoprimes. 

\begin{theorem}
Let $n$ be a composite square-free integer, say $p_1... p_n$, where the $p_i$ are distinct primes. If 
\[(p_i - 1) \big| (n-1) \text{ for } i = 1, 2, ..., r\]
then $n$ is an absolute pseudoprime. 
\end{theorem}
\begin{proof}
Suppose that $a$ is an integer such that $\gcd(a, n) = 1$, so that $\gcd(a, p_i) = 1$ for all $i$. Then, Fermant's theorem yields
\[p_i \big| a^{p_i - 1} - 1 \implies p_i \big| (a^n - a)\]
for all $a$ and for all $i = 1, 2, ..., r$. So, we end up with $n \big| (a^n - a)$, making $n$ an absolute pseudoprime. 
\end{proof}

There are $43$ absolute pseudoprimes less than $1,000,000$ and $105,212$ less than $10^{15}$. 

\begin{theorem}[Wilson's Theorem]
$p$ is a prime number if and only if 
\[(p-1)! \equiv -1 \pmod{p}\]
\end{theorem}
\begin{proof}
$(\rightarrow)$ We can check by hand that the cases $p=2$ and $p=3$ are evident. Take $p >3$. Suppose that $a$ is any one of the $p-1$ positive integers
\[1, 2, 3, ..., p-1\]
and consider the linear congruence $ax \equiv 1 \pmod{p}$. Since $\gcd(a, p) = 1$, there is a unique solution modulo $p$, call it $a^\prime$. So, there is a unique integer $a^\prime$, with $1 \leq a^\prime \leq p-1$ satisfying $a a^\prime \equiv 1 \pmod{p}$. 

Now, note that because $p$ is prime, $a = a^\prime$ if and only if $a = 1$ or $a = p-1$, since this would lead to the congruence $a^2 \equiv 1 \pmod{p}$. If we omit the numbers $1$ and $p-1$, we claim that the remaining $(p-3)/2$ numbers can be multiplied together to be congruent to $1$. That is, we can group the remaining integers $2, 3, ..., p-2$ into pairs $a, a^\prime$ where $a \neq a^\prime$, such that their product $a a^\prime \equiv 1 \pmod{p}$. It is a fact that 
\[2 \cdot 3 \cdot ... \cdot (p-2) \equiv 1 \pmod{p} \iff (p-2)! \equiv 1 \pmod{p}\]
We multiply by $p-1$ to obtain the congruence
\[(p-1)! \equiv p-1 \equiv -1 \pmod{p}\]
$(\leftarrow)$ The converse will not be proven here. 
\end{proof}

\begin{example}
Let us take $p=13$. Then, we get 
\[11! = (2 \cdot 7) (3 \cdot 9) (4 \cdot 10) (5 \cdot 8) (6 \cdot 11) \equiv 1 \cdot 1 \cdot 1 \cdot 1 \cdot 1 \equiv 1 \pmod{13}\]
which implies that 
\[12! \equiv 12 \equiv -1 \pmod{13}\]
\end{example}

\begin{definition}
A \textit{quadratic congruence} is a congruence of the form 
\[a x^2 + bx + c \equiv 0 \pmod{n}, \;\; a \neq 0 \pmod{n}\]
\end{definition}

An application of Wilson's theorem goes into the following claim. 

\begin{theorem}
The quadratic congruence $x^2 + 1 \equiv 0 \pmod{p}$, where $p$ is an odd prime, has a solution if and only if $p \equiv 1 \pmod{4}$. 
\end{theorem}

We finally end with a generalization of Fermant's theorem by stating Euler's theorem. 

\begin{theorem}[Euler's Theorem]
If $n \geq 1$ and $\gcd(a, n) = 1$, then 
\[a^{\varphi(n)} \equiv 1 \pmod{n}\]
\end{theorem}

Fermant's theorem is then a corollary of Euler's theorem. 

\begin{corollary}[Fermant's Little Theorem]
If $p$ is prime and $p$ does not divide $a$, then $a^{p-1} \equiv 1 \pmod{p}$. 
\end{corollary}
\begin{proof}
If $p$ is prime, then $\varphi(p) = p-1$. So, 
\[a^{p-1} \equiv a^{\varphi(p)} \equiv 1 \pmod{p}\]
\end{proof}

\subsection{Fermant-Kraitchik Factorization Method}


\section{Number Theoretic Functions}
\subsection{Sum and Number of Divisors}
\begin{definition}
A \textit{number-theoretic} (or \textit{arithmetic}) function is a function whose domain is the set of positive integers. That is, it is a function 
\[F: \mathbb{Z} \longrightarrow X\]
for arbitrary $X$ (not necessarily $\mathbb{Z}$). 
\end{definition}

Two of the most common arithmetic functions are defined below. 

\begin{definition}
Given a positive integer $n$, let $\tau(n)$ denote the number of positive divisors of $n$ and let $\sigma(n)$ denote the sum of these divisors. 

We can also interpret $\tau$ and $\sigma$ as 
\[\sum_{d|n} f(d)\]
where the subscript on the summation denotes all divisors $d$ of $n$ and $f$ is some function. For instance,
\[\sum_{d|20} f(d) = f(1) + f(2) + f(4) + f(5) + f(10) + f(20)\]
With this, $\tau$ and $\sigma$ can be expressed in the form 
\[\tau(n) = \sum_{d|n} 1, \;\;\; \sigma(n) = \sum_{d|n} d\]
\end{definition}

The following theorem provides a well known method to compute $\tau$. 

\begin{theorem}
Given a positive integer $n$, let its prime factorization be 
\[n = \prod_{i} p_i^{k_i}\]
Then, the divisors of $n$ are precisely those integers $d$ of the form 
\[d = \prod_i p_i^{a_i}, \;\; 0 \leq a_i \leq k_i \text{ for } i = 1, 2, ..., r\]
\end{theorem}

\begin{corollary}
If the prime factorization of $n$ is $n = p_1^{k_1} p_2^{k_2} ... p_r^{k_r}$, then
\begin{align*}
    \tau(n) & = \prod_i (k_i + 1) \\
    \sigma(n) & = \prod_i \frac{p_i^{k_i + 1} - 1}{p_i - 1}
\end{align*}
\end{corollary}
\begin{proof}
The evaluation for $\tau(n)$ is trivial, since each divisor can be made by "choosing" from the $k_i + 1$ choices for the exponent $a_i$. To evaluate $\sigma(n)$, consider the product 
\[\prod_i \Big( \sum_{j=0}^{k_i} p_i^j \Big) = \prod_{i} \big(1 + p_i + p_i^2 + ... + p_i^{k_i}\big)\]
and notice that each divisor of $n$ appears once and only once as a term in the expansion of this product. 
\end{proof}

\begin{proposition}
The product of the positive divisors of a positive integer $n$ is equal to $n^{\tau(n)/2}$. That is, 
\[n^{\tau(n)} = \bigg( \prod_{d|n} d \bigg)^2\]
\end{proposition}

Note that given positive integer $m, n$, 
\[\tau(m n) \neq \tau(m) \cdot \tau(n) \text{ and } \sigma(m n) = \sigma(m) \cdot \sigma(n)\]
That is, $\tau$ and $\sigma$ are not multiplicative in general! However, there is a certain circumstance when they are multiplicative. 

\begin{definition}
Within the context of number theory, a number theoretic function $f$ is said to be \textit{multiplicative} if 
\[f(m n) = f(m) f(n)\]
whenever $\gcd(m, n) = 1$. 
\end{definition}

\begin{proposition}
$\tau$ and $\sigma$ are multiplicative functions. 
\end{proposition}
\begin{proof}
Since $m$ and $n$ are coprime, the prime factorization of $m$ does not "overlap" that of $n$ in such a way that none of the exponents are the same between $m$ and $n$. 
\end{proof}

We can prove a more general results on multiplicative functions. T

\begin{lemma}
If $\gcd(m, n) = 1$, then the set of positive divisors $mn$ consists of all products $d_1 d_2$, where $d_1 | m$ and $d_2 | n$, and $\gcd(d_1, d_2) = 1$. Furthermore, these products are all distinct. 
\end{lemma}

\begin{theorem}
If $f$ is a multiplicative function and $F$ is defined by 
\[F(n) = \sum_{d|n} f(d)\]
then $F$ is also multiplicative. 
\end{theorem}
\begin{proof}
Let $m, n$ be coprime. By the previous lemma, every divisor of $mn$ can be written as $d_1 d_2$. By definition of a multiplicative function, $f(d_1d_2) = f(d_1) f(d_2)$, which implies
\begin{align*}
    F(mn) & = \sum_{d_1|m, d_2|n} f(d_1) f(d_2) \\
    & = \bigg( \sum_{d_1|m} f(d_1) \bigg) \bigg( \sum_{d_2|n} f(d_2) \bigg) \\
    & = F(m) F(n)
\end{align*}
\end{proof}

From this result, we can see that since the corresponding $f$'s in the summation representation of $\tau$ and $\sigma$ are multiplicative, the functions themselves are multiplicative. 

\subsection{The Mobius Inversion Formula}

\begin{definition}
For a positive integer $n$, we define the \textit{Mobius $\mu$-function} as 
\[\mu(n) = \begin{cases}
1 & n = 1 \\
0 & p^2 | n \text{ for some prime } p \\
(-1)^r & n = p_1 p_2 ... p_r, \text{ where } p_i \text{ are distinct primes} 
\end{cases}\]
In words, this definition states that $\mu(n) = 0$ if $n$ is not a square-free integer, whereas $\mu(n) = (-1)^r$ if $n$ is square-free with $r$ prime factors. 
\end{definition}

\begin{example}
Say $n = 30$. Then $\mu(30) = \mu(2 \cdot 3 \cdot 5) = (-1)^3 = -1$. The first few values of $\mu$ are
\[\mu(1) = 1, \; \mu(2) = -1, \; \mu(3) = -1, \; \mu(4) = 0, \; \mu(5) = -1, \; \mu(6) = (-1)^2 = 1\]
\end{example}

\begin{lemma}
$\mu$ is a multiplicative function. (Note that multiplicative only applies to arguments that are relatively prime)
\end{lemma}

What happens if we sum all of the divisors of $n$ with $\mu$ applied to it? 

\begin{theorem}
For each positive integer $n \geq 1$, 
\[\sum_{d|n} \mu(d) = \begin{cases}
1 & n = 1\\
0 & n > 1
\end{cases}\]
\end{theorem}

\begin{example}
\begin{align*}
    \sum_{d|10} \mu(d) & = \mu(1) + \mu(2) + \mu(5) + \mu(10) \\
    & = 1 + (-1) + (-1) + 1 = 0
\end{align*}
\end{example}

The significance of the Mobius function is shown in the following theorem. 

\begin{theorem}[Mobius Inversion Formula]
Let $F$ and $f$ be two number theoretic functions related by the formula
\[F(n) = \sum_{d|n} f(d)\]
Then,
\[f(n) = \sum_{d|n} \mu(d)\, F \Big(\frac{n}{d} \Big) = \sum_{d|n} \mu \Big( \frac{n}{d} \Big) \, F(d)\]
\end{theorem}

\begin{example}
Let us use $n=10$. We see that
\begin{align*}
    \sum_{d|10} \bigg( \sum_{c|(10/d)} \mu(d) \, f(c) \bigg) & = \mu(1) \big( f(1) + f(2) + f(5) + f(10)\big)  \\
    & + \mu(2) \big( f(1) + f(5)\big) + \mu(5) \big( f(1) + f(2) \big) + \mu(10) f(1) \\
    & = f(1) \big( \mu(1) + \mu(2) + \mu(5) + \mu(10)\big) \\
    & + f(2) \big(\mu(1) + \mu(5) \big) + f(5) \big( \mu(1) + \mu(2) \big) + f(10) \mu(1) \\
    & = \sum_{c|10} \bigg( \sum_{d|10/c} f(c) \mu(d) \bigg)
\end{align*}
\end{example}

\begin{lemma}
If $F$ is a multiplicative function and 
\[F(n) = \sum_{d|n} f(d)\]
then $f$ is also multiplicative. 
\end{lemma}

\subsection{The Greatest Integer Function}

\begin{definition}
For an arbitrary real number $x$, we denote as $[x]$, called the \textit{floor function}, the largest integer less than or equal to $x$. That is, $[x]$ is the unique integer satisfying
\[x-1 < [x] \leq x\]
Clearly, every real number $x$ can be written as
\[x = [x] + \theta, \;\; 0 \leq \theta < 1 \]
\end{definition}

Given an integer $n$, we now introduce a method in finding the highest power $k$ of $p$ prime such that $p^k$ divides $n!$. 

\begin{theorem}
If $n$ is a positive integer and $p$ a prime, then the highest power $k$ of $p$ that divides $n!$ is 
\[\sum_{k=1}^\infty \bigg[ \frac{n}{p^k} \bigg]\]
where the series is infinite, because $[n/p^k] = 0$ for $p^k > n$. 
\end{theorem}

\begin{example}
The greatest power of $2$ that can divide $50!$ is 
\begin{align*}
    [50/2] & + [50/2^2] + [50/ 2^3] + [50/2^4] + [50/2^5] \\
    & = 25+12+6+3+1 \\
    & = 47
\end{align*}
So, $2^{47}$ divides $50!$, but $2^{48}$ does not. 
\end{example}

\begin{lemma}
If $n$ and $r$ are positive integers with $1 \leq r < n$, then the binomial coefficient 
\[{{n}\choose{r}} = \frac{n!}{r!\, (n-r)!}\]
is also an integer. 
\end{lemma}
\begin{proof}
We prove this using the floor function. Note that for any real numbers $a, b$, we have $[a+b] \geq [a] + [b]$. In particular, for each prime factor $p$ of $r! (n-r)!$, 
\[\bigg[\frac{n}{p^k}\bigg] \geq \bigg[\frac{r}{p^k}\bigg] + \bigg[\frac{n-r}{p^k}\bigg], \;\; k = 1, 2, ...\]
Summing them over $k$, we get
\[ \sum_{k\geq 1} \bigg[\frac{n}{p^k}\bigg] \geq \sum_{k \geq 1} \bigg[\frac{r}{p^k}\bigg] + \sum_{k \geq 1} \bigg[\frac{n-r}{p^k}\bigg]\]
The left hand side gives the exponent of the highest power of the prime $p$ that divides $n!$, while the right hand side equals the highest power of this prime contained in $r! (n-r)!$. Hence, $p$ appears in the numerator at least as many times in the denominator. Since this holds true for all $p$, $r!(n-r)!$ must divide $n!$, making the binomial coefficient an integer. 
\end{proof}

\begin{corollary}
For a positive integer $r$, the product of any $r$ consecutive positive integers is divisible by $r!$. 
\end{corollary}
\begin{proof}
The product of $r$ consecutive integers, the largest of which is $n$, is 
\[n (n-1) (n-2) ... (n-r+1)\]
Now, we have 
\[n(n-1)... (n-r+1) = \bigg( \frac{n!}{r! (n-r)!} \bigg) r!\]
Since $n!/r! (n-r)!$ is an integer, $r!$ must divide the product $n(n-1)...(n-r+1)$. 
\end{proof}

We incorporate the floor function into the topic of number theoretic functions. 

\begin{theorem}
Let $f$ and $F$ be number theoretic functions such that
\[F(n) = \sum_{d|n} f(d)\]
Then, for any positive integer $N$, 
\[\sum_{n=1}^N F(n) = \sum_{k=1}^N f(k) \bigg[ \frac{N}{k} \bigg]\]
\end{theorem}

This allows us to compute $\tau$ and $\sigma$ with the following corollaries. 

\begin{corollary}
If $N$ is a positive integer, then
\[\sum_{n=1}^N \tau(n) = \sum_{n=1}^N \bigg[ \frac{N}{n} \bigg]\]
\end{corollary}

\begin{corollary}
If $N$ is a positive integer, then
\[\sum_{n=1}^N \sigma(n) = \sum_{n=1}^N n \bigg[ \frac{N}{n} \bigg]\]
\end{corollary}

\begin{example}
Consider the case when $N = 6$. Then, 
\[\sum_{n=1}^6 \tau(n) = \sum_{n=1}^6 \bigg[ \frac{6}{n} \bigg] = 6 + 3 + 2 + 1 + 1 + 1 = 14\]
We also have 
\[\sum_{n=1}^6 \sigma(n) = \sum_{n=1}^6 n \bigg[ \frac{6}{n} \bigg] = 1 \cdot 6 + 2 \cdot 3 + 3 \cdot 2 + 4 \cdot 1 + 5 \cdot 1 + 6 \cdot 1 = 33\]
\end{example}

\subsection{Euler's Totient (Phi) Function}
\begin{definition}
For $n \geq 1$, let $\varphi(n)$ denote the number of positive integers not exceeding $n$ that are relatively prime to $n$. 
\end{definition}

For example, $\varphi(30) = 8$, since there are a total of $8$ integers. Explicitly listing them out gives 
\[1, 7, 11, 13, 15, 19, 23, 29\]

Clearly, there is an upper bound for $\varphi$. That is, 
\[\varphi(n) \leq n-1\]
with equality reaching if $n$ is prime. That is, if we graph $\big(n, \varphi(n)\big)$, all points will be bounded in the lower triangular region of the first quadrant. 

\begin{theorem}
Algebraically, $\varphi(n)$ gives the order for the multiplicative group of integer modulo $n$, which is isomorphic to the multiplicative group $\mathbb{Z} / n \mathbb{Z}$. That is, 
\[\varphi(n) = \text{card} \bigg( \frac{\mathbb{Z}}{n \mathbb{Z}} \bigg)\]
\end{theorem}

\begin{lemma}
If $p$ is prime and $k>0$, then 
\[\varphi(p^k) = p^k - p^{k-1} = p^k \bigg(1 - \frac{1}{p} \bigg)\]
\end{lemma}

\begin{lemma}
$\varphi$ is a multiplicative function. 
\end{lemma}

These two leads to the following theorem that describes a method to compute $\varphi(n)$. 

\begin{theorem}
If the integer $n>1$ has the prime factorization
\[n = p_1^{k_1} p_2^{k_2} ... p_r^{k_r}\]
then
\begin{align*}
    \varphi(n) & = \big( p_1^{k_1} - p_1^{k_1 - 1} \big) \big( p_2^{k_2} - p_2^{k_2 - 1} \big) ... \big( p_r^{k_r} - p_r^{k_r - 1} \big) \\
    & = n \bigg(1 - \frac{1}{p_1} \bigg) \bigg(1 - \frac{1}{p_2} \bigg) ... \bigg( 1 - \frac{1}{p_r}\bigg) 
\end{align*}
\end{theorem}

\begin{example}
To calculate $\varphi(360)$, note that $360 = 2^3 \cdot 3^2 \cdot 5$, so 
\[\varphi(360) = 360 \bigg(1 - \frac{1}{2} \bigg) \bigg( 1 - \frac{1}{3} \bigg) \bigg(1 - \frac{1}{5} \bigg) = 96\]
\end{example}

Notice that except for $\varphi(1)$ and $\varphi(2)$, the values of $\varphi(n)$ are always even. 

\begin{theorem}
For $n>2$, $\varphi(n)$ is an even integer. 
\end{theorem}
\begin{proof}
In the case when $n$ is a power of $2$; that is, $n = 2^k$, then 
\[\varphi(n) = \varphi(2^k) = 2^k \bigg(1 - \frac{1}{2} \bigg) = 2^{k-1}\]
If $n$ is not a power of $2$, then it is divisible by an odd prime $p$. So, we can write $n = p^k m$ for some $k \geq 1$ and $m$, where $\gcd(p^k, m) = 1$. Using the multiplicative property of $\varphi$, we get 
\[\varphi(n) = \varphi(p^k) \varphi(m) = p^{k-1} (p-1) \varphi(m)\]
where $p-1$ is even, so $\varphi(n)$ is also even. 
\end{proof}

One interesting property of the totient function is that the sum of the values of $\varphi(d)$ as $d$ ranges over the positive divisors of $n$ is equal to $n$ itself. 

\begin{theorem}[Gauss]
For each positive integer $n \geq 1$, 
\[n = \sum_{d|n} \varphi(d)\]
which is the sum being added over all positive divisors of $n$. 
\end{theorem}
\begin{proof}
The integers between $1$ and $n$ can be separated into classes as follows. If $d$ is a positive divisor of $n$, we put the integer $m$ in the class $S_d$ provided that $\gcd(m, n) = d$. That is, 
\[S_d = \{m\;|\; \gcd(m, n) = d, 1 \leq m \leq n\}\]
Now, $\gcd(m, n) = d$ if and only if $\gcd(m/d, n/d) = 1$. Thus, the number of integers in the class $S_d$ is equal to the number of positive integers not exceeding $n/d$ that are relatively prime to $n/d$, which is just equal to $\varphi(n/d)$. Since each of the integers $1, 2, ..., n$ lies in exactly one class $S_d$, we get the formula
\[n = \sum_{d|n} \text{card}(S_d) = \sum_{d|n} \varphi \bigg(\frac{n}{d} \bigg)\]
But as $d$ runs through all positive divisors of $n$, so does $n/d$, implying that
\[\sum_{d|n} \varphi \bigg( \frac{n}{d} \bigg) = \sum_{d|n} \varphi (d)\]
\end{proof}

\begin{example}
Let $n=10$. Then the classes $S_d$ are 
\begin{align*}
    S_1 & = \{1, 3, 7, 9\} \\
    S_2 & = \{2, 4, 6, 8\} \\
    S_5 & = \{5\} \\
    S_{10} & = \{10\}
\end{align*}
These contain $\varphi(10) = 4, \varphi(5) = 4, \varphi(2) = 1, \varphi(1) = 1$ integers, respectively. Therefore, 
\begin{align*}
    \sum_{d|10} \varphi(d) & = \varphi(10) + \varphi(5) + \varphi(2) + \varphi(1) \\
    & = 4 + 4 + 1 + 1 = 10 
\end{align*}
\end{example}

\begin{theorem}
For $n>1$, the sum of the positive integers less than $n$ and relatively prime to $n$ is
\[\frac{1}{2} n \,\varphi(n)\]
\end{theorem}
\begin{proof}
Let $a_1, a_2, ..., a_{\varphi(n)}$ be the positive integers less than $n$ and relatively prime to $n$. Because $\gcd(a, n) = 1$ if and only if $\gcd(n-a, n) = 1$, the numbers
\[n-a_1, n-a_2, ..., n - a_{\varphi(n)}\]
are equal in some order to $a_1, a_2, ..., a_{\varphi(n)}$. Thus, 
\begin{align*}
    a_1 + a_2 + ... + a_{\varphi(n)} & = (n- a_1) + (n - a_2) + ... + (n - a_{\varphi(n)}) \\
    & = n\,\varphi(n) - (a_1 + a_2 + ... + a_{\varphi(n)}
\end{align*}
This implies that 
\[2 (\sum_{i=1}^{\varphi(n)} a_i = n\, \varphi(n)\]
\end{proof}

\begin{example}
When $n = 30$, the $\varphi(30) = 8$ integers that are less than $30$ and relatively prime to it are
\[1, 7, 11, 13, 17, 19, 23, 29\]
This is consistent with the theorem, since 
\[1+7+11+13+17+19+23+29=\frac{1}{2} \cdot 30 \cdot 8\]
Also, note the pairings: 
\[1+29=30, \; 7+23=3-, \; 11+19=30, \; 13+17=30\]
\end{example}

This final theorem provides an application of the Mobius inversion formula. 

\begin{theorem}
For any positive integer $n$, 
\[\varphi(n) = n \sum_{d|n} \frac{\mu(d)}{d}\]
\end{theorem}
\begin{proof}
We apply the inversion formula to
\[F(n) = n = \sum_{d|n} \varphi(d)\]
to get
\begin{align*}
    \varphi(n) & = \sum_{d|n} \mu(d) \,F \bigg( \frac{n}{d} \bigg) \\
    & = \sum_{d|n} \mu(d) \, \frac{n}{d}
\end{align*}
\end{proof}

\section{Primitive Roots and Indices}

With Euler's theorem, we know that $a^{\varphi(n)} \equiv 1 \pmod{n}$, whenever $\gcd(a, n) = 1$. However, there are often powers smaller than $a^{\varphi(n)}$ that are congruent to $1$ modulo $n$. 

\begin{definition}
Let $n>1$ and $\gcd(a, n) = 1$. The \textit{order of $a$ modulo $n$} is the smallest positive integer $k$ such that $a^k \equiv 1$. 
\end{definition}

\begin{example}
Consider the successive powers of $2$ modulo $7$. 
\[2^1 \equiv 2, \;\ 2^2 \equiv 4, \; 2^3 \equiv 1, \; 2^4 \equiv 2, ... \]
So, the integer $2$ has order $3$ modulo $7$. 
\end{example}

\begin{lemma}
If two integers are congruent modulo $n$, then they have the same order modulo $n$. For if $a \equiv b \pmod{n}$ and $a^k \equiv 1 \pmod{n}$, then $a^k \equiv b^k \pmod{n}$, implying that $b^k \equiv 1 \pmod{n}$. 
\end{lemma}

Also note that our definition of order modulo $n$ concerns only integers $a$ for which $\gcd(a, n) = 1$. Indeed, if $\gcd(a, n) >1$, then we see that the linear congruence $ax \equiv 1 \pmod{n}$ has no solution, meaning that the relation $a^k \equiv 1 \pmod{n}$ cannot hold. With this in mind, one can deduce the following theorem. 

\begin{theorem}
Let the integer $a$ have order $k$ modulo $n$. Then $a^h \equiv 1 \pmod{n}$ if and only if $k|h$; in particular, $k|\varphi(n)$. 
\end{theorem}

Another basic result. 

\begin{theorem}
If the integer $a$ has order $k$ modulo $n$, then $a^i \equiv a^j \pmod{n}$ if and only if $i \equiv j \pmod{k}$. 
\end{theorem}

\begin{corollary}
If $a$ has order $k$ modulo $n$, then the integers $a, a^2, a^3, ..., a^k$ are incongruent modulo $n$. 
\end{corollary}
\begin{proof}
If $a^i \equiv a^j \pmod{n}$ for $1 \leq i \leq j \leq k$, then the theorem ensures that $i \equiv j \pmod{k}$. But this is impossible unless $i = j$. 
\end{proof}

\begin{theorem}
If the integer $a$ has order $k$ modulo $n$ and $h>0$, then $a^h$ has order $k/\gcd(h, k)$ modulo $n$. 
\end{theorem}

\begin{corollary}
Let $a$ have order $k$ modulo $n$. Then $a^h$ also has order $k$ if and only if $\gcd(h, k) = 1$. 
\end{corollary}

\begin{example}
$2$ has order $12$ modulo $13$. Calculations show that the orders of $2^2$ and $2^3$ are $6$ and $4$, respectively, which is consistent with the result that
\[6 = \frac{12}{\gcd(2, 12)}, \;\; 4 = \frac{12}{\gcd(3, 12)}\]
Moreoever, the integers that also have order $12$ modulo $13$ are 
\[2^1 \equiv 2, \; 2^5 \equiv 6, \; 2^7 \equiv 11, \; 2^{11} \equiv 7 \pmod{13}\]
\end{example}

\begin{definition}
If an integer $a$ has the largest order possible, then we call it a \textit{primitive root of $n$}. That is, if $\gcd(a, n) = 1$ and $a$ is of order $\varphi(n)$ modulo $n$, then $a$ is a \textit{primitive root} of $n$. 
\end{definition}

\begin{example}
Listing out all the positive multiplies of $3$, we can see that $3$ is a primitive root of $7$ since it has an order of $\varphi(7) = 6$.  
\[3^1 \equiv 3, \; 3^2 \equiv 2, \; 3^3 \equiv 6, \; 3^4 \equiv 4, \; 3^5 \equiv 5, \; 3^6 \equiv 1\]
Another primitive root of $7$ is $5$, since it also has an order of $\varphi(7) = 6$
\[5^1 \equiv 5, \; 5^2 \equiv 4, \; 5^3 \equiv 6, \; 5^4 \equiv 2, \; 5^5 \equiv 3, \; 5^6 \equiv 1 \pmod{7}\]
However, no other primitive roots exist for $7$. Try $4$, 
\[4^1 \equiv 4, \; 4^2 \equiv 2, \; 4^3 \equiv 1 \pmod{7}\]
which has an order of $3 \neq \varphi(7)$. 
\end{example}

In fact, primitive roots exist for any prime modulus, since Euler's theorem combined with the fact that any number less than a prime is coprime with the prime itself. There are plenty of primitive roots for composite numbers, though. 

\begin{example}
$2$ is a primitive root of $9$. Note that $\varphi(9) = 6$
\[2^1 \equiv 2,\; 2^2 \equiv 4, \;2^3 \equiv 8,\; 2^4 \equiv 7, \; 2^5 \equiv 5, \; 2^6 \equiv 1\]
\end{example}

However, it is more often the case that a number is not a primitive root. 

\begin{proposition}
If the Fermant number $F_n = 2^{2^n} + 1$ with $n\geq 2$ is a prime, then $2$ is a not a primitive root of $F_n$. 
\end{proposition}
\begin{proof}
We factorize $F_{n+1} = 2^{2^{n+1}} + 1 = (2^{2^n} + 1)(2^{2^n} - 1)$, which implies that
\[2^{2^{n+1}} \equiv 1 \pmod{F_n}\]
This means that the order of $2$ modulo $F_n$ does not exceed $2^{n+1}$. But if $F_n$ is assumed to be prime, then
\[\varphi(F_n) = F_n - 1 = 2^{2^n}\]
but we can prove (by induction) that $2^{2^n} > 2^{n+1}$ whenever $n>1$. Thus, the order of $2$ modulo $F_n$ is smaller than $\varphi(F_n)$ and by definition $2$ cannot be a primitive root of $F_n$. 
\end{proof}

The following theorem is immensely useful. 

\begin{theorem}
Let $\gcd(a, n) = 1$ and let $a_1, a_2, ..., a_{\varphi(n)}$ be the positive integers less than $n$ and relatively prime to $n$. If $a$ is a primitive root of $n$, then 
\[a, a^2, ..., a^{\varphi(n)}\]
are congruent modulo $n$ to $a_1, a_2, ..., a_{\varphi(n)}$ in some order. 
\end{theorem}
\begin{proof}
Since $a$ is relatively prime to $n$ the same holds for all the powers of $a$, meaning that each $a^k$ is congruent modulo $n$ to some one of the $a_i$. But since the $\varphi(n)$ numbers in the set $\{a, a^2, ..., a^{\varphi(n)}\}$ are incongruent, these powers must represent some permutation of the integers $a_1, a_2, ..., a_{\varphi(n)}$. 
\end{proof}

\begin{corollary}
If $n$ has a primitive root, then it has exactly $\varphi \big( \varphi(n) \big)$ of them. 
\end{corollary}
\begin{proof}
Suppose that $a$ is a primitive root of $n$. By the theorem, any other primitive root of $n$ is found among the members of the set $\{a, a^2, ..., a^{\varphi(n)}\}$. But the number of powers $a^k, 1 \leq k \leq \varphi(n),$ that have order $\varphi(n)$ is equal to the number of integers $k$ for which $\gcd\big(k, \varphi(n)\big) = 1$. There are $\varphi\big( \varphi(n)\big)$ such integers. 
\end{proof}

\subsection{Primitive Roots for Primes}

\begin{theorem}[Lagrange]
If $p$ is prime and 
\[f(x) = a_n x^n + a_{n-1} x^{n-1} + ... + a_1 x + a_0, \;\; a_n \not\equiv 0 \pmod{p}\]
is a polynomial of degree $n\geq 1$ with integral coefficients, then the congruence 
\[f(x) \equiv 0 \pmod{p}\]
has at most $n$ incongruent solutions modulo $p$.
\end{theorem}

\begin{corollary}
If $p$ is a prime number and $d|(p-1)$, then the congruence 
\[x^d - 1 \equiv 0 \pmod{p}\]
has exactly $d$ solutions. 
\end{corollary}

\begin{theorem}
If $p$ is a prime number and $d|(p-1)$, then there are exactly $\varphi(d)$ incongruent integers having order $d$ modulo $p$. 
\end{theorem}

\begin{corollary}
If $p$ is prime, then there are exactly $\varphi(p-1)$ incongruent primitive roots of $p$.
\end{corollary}

\begin{definition}
Let $\chi(p)$ denote the smallest positive primitive root of the prime $p$. 
\end{definition}

The first few values of $\chi$ is 
\[\begin{array}{cccccc}
    \chi(2) = 1 & \chi(3) = 2 & \chi(5) = 2 & \chi(7) = 3 & \chi(11) = 2 & \chi(13) = 2 \\
    \chi(17) = 3 & \chi(19) = 2 & \chi(23) = 5 & \chi(29) = 2 & \chi(31) = 3 & \chi(37) = 2 \\
    \chi(41) = 6 & \chi(43) = 3 & \chi(47) = 5 & \chi(53) = 2 & \chi(59) = 2 & \chi(61) = 2 \\
    \chi(67) = 2 & \chi(71) = 7 & \chi(73) = 5 & \chi(79) = 3 & \chi(83) = 2 & \chi(89) = 3 \\
\end{array}\]

The table suggests, although not proven, that there exist an infinite number of primes $p$ for which $\chi(p) = 2$. Looking at the distribution of values more statistically, we can see that $\chi(p) \leq 19$ for all $p < 200$. Additionally, among the first 19862 odd primes up to $223051$, $\chi(p) \leq 6$ holds for about $80\%$ of these primes; $\chi(p) = 2$ about $37\%$ of the time and $\chi(p) = 3$ about $23\%$ of the time. 

\subsection{Primitive Roots for Composite Numbers}
We state a few results. 

\begin{theorem}
For $k\geq 3$, the integer $2^k$ has no primitive roots. 
\end{theorem}
\begin{proof}
We start by showing that if $a$ is an odd integer, then for $k\geq 3$ 
\[a^{2^{k-2}} \equiv 1 \pmod{2^k}\]
If $k=3$, this congruence becomes $a^2 \equiv 1 \pmod{8}$, which is true. For $k > 3$ we proceed by induction on $k$. Assume that the congruence holds for some integer $k$. Then 
\[a^{2^{k-2}} \equiv 1 \pmod{2^k} \implies a^{2^{k-2}} = 1 + b 2^k\]
where $b \in \mathbb{Z}$. Squaring both sides, we get
\begin{align*}
    a^{2^{k-1}} = \big(a^{2k-2}\big)^2 & = 1 + 2(b 2^k) + (b2^k)^2 \\
    & = 1 + 2^{k+1} (b + b^2 2^{k-1}) \\
    & \equiv 1 \pmod{2^{k+1}}
\end{align*}
meaning that the congruence holds for $n+1$ and so for all $n>3$. Now, the integers that are relatively prime to $2^k$ are precisely the odd integers, so $\varphi(2^k) = 2^{k-1}$, which is also equivalent to $2 \cdot 2^{k-2}$. So, if $a$ is an odd integer and $k\geq 3$, then by the congruence just proved, 
\[a^{\varphi(2^k)/2} \equiv 1 \pmod{2^k}\]
and consequently, there are no primitive roots of $2^k$. 
\end{proof}

\begin{theorem}
If $\gcd(m, n) = 1$, where $m>2, n>2$, then the integer $mn$ has no primitive roots. 
\end{theorem}

\begin{corollary}
The integer $n$ fails to have a primitive if either
\begin{enumerate}
    \item $n$ is divisible by two odd primes, or
    \item $n$ is of the form $2^m p_k$, where $p$ is an odd prime and $m\geq 2$. 
\end{enumerate}
\end{corollary}

This allows us to reduce our search for primitive roots to the integers $2, 4, p^k$, and $2p^k$, where $p$ is an odd prime. The following theorem says the rest. 

\begin{theorem}
An integer $n>1$ has a primitive root if and only if 
\[n = 2, 4, p^k, \text{ or } 2p^k\]
where $p$ is an odd prime. 
\end{theorem}

\subsection{The Theory of Indices}

\begin{definition}
Let $r$ be a primitive root of $n$. If $\gcd(a, n) = 1$, then the smallest positive integer $k$ such that $a \equiv r^k \pmod{n}$ is called the \textit{index of $a$ relative to $r$}, denoted by ind$_r a$. 
\end{definition}

Clearly, $1 \leq$ ind$_r a \leq \varphi(n)$, and 
\[r^{\text{ind}_r a} \equiv a \pmod{n}\]
The notation ind$_r a$ is meaningless unless $\gcd(a, n) = 1$. 

\begin{example}
The integer $2$ is a primitive root of $5$, and 
\[\begin{array}{cccc}
    2^1 \equiv 2 & 2^2 \equiv 4 & 2^3 \equiv 3 & 2^4 \equiv 1 \pmod{5}
\end{array}\]
If follows that 
\[\begin{array}{cccc}
    \text{ind}_2 1 = 4 & \text{ind}_2 2 = 1 & \text{ind}_2 3 = 3 & \text{ind}_2 4 = 2
\end{array}\]
\end{example}
Note that the way the index operation behaves is very similar to the logarithmic function. 

\begin{theorem}
If $n$ has a primitive root $r$ and ind$_r a$ denote the index of $a$ relative to $r$, then the following properties hold. 
\begin{enumerate}
    \item ind$_r (a b) \equiv$ ind$_r a + $ ind$_r b \pmod{\varphi(n)}$
    \item ind$_r a^k \equiv k$ ind$_r a \pmod{\varphi(n)}$ for $k>0$ 
    \item ind$_r 1 \equiv 0 \pmod{\varphi(n)}$, ind$_r \equiv 1 \pmod{\varphi(n)}$
\end{enumerate}
\end{theorem}

The theory of indices can be used to solve certain types of congruences. For example, the binomial congruence
\[x^k \equiv a \pmod{n}, \;\; k \geq 2\]
where $n$ is a positive integer having a primitive root and $\gcd(a, n) = 1$ is entirely equivalent to the linear congruence 
\[k \,\text{ind} \, x \equiv \text{ind} \, a \pmod{\varphi(n)}\]

\begin{theorem}
Let $n$ be an integer possessing a primitive root and let $\gcd(a, n) = 1$. Then the congruence $x^k \equiv a \pmod{n}$ has a solution if and only if 
\[a^{\varphi(n)/d} \equiv 1 \pmod{n}\]
where $d = \gcd\big(k, \varphi(n)\big)$. If it has a solution, then there are exactly $d$ solutions modulo $n$. 
\end{theorem}

\begin{corollary}
Let $p$ be a prime and let $\gcd(a, p) = 1$. Then the congruence $x^k \equiv a \pmod{p}$ has a solution if and only if 
\[a^{(p-1)/d} \equiv 1 \pmod{p}\]
where $d = \gcd(k, p-1)$. 
\end{corollary}

\section{Introduction to Cryptography}

The practice of encrypting and decrypting messages is called cryptography. Codes are called \textit{ciphers}, the information to be concealed is called \textit{plaintext}, and after transformation to a secret form, a message is called \textit{ciphertext}. 

\subsection{Common Cipher Methods}

We now describe one of the most ancient and simplest of all encryption techniques, named after the Roman emperor Julius Caesar. 

\subsubsection{Caesar Cipher}
Let us assign the English alphabet into digits from $00$ to $25$. 
\[\begin{array}{cccccccccccccc}
    A & B & C & D& E & F & G&H&I&J&K&L&M \\
    00 & 01 & 02 & 03 & 04&05&06&07&08&09&10&11&12 \\
    N&O&P&Q&R&S&T&U&V&W&X&Y&Z\\
    13&14&15&16&17&18&19&20&21&22&23&24&25
\end{array}\]
Then, if $P$ is the digital equivalent of a plaintext letter and $C$ is the digital equivalent of the corresponding ciphertext letter, then 
\[C \equiv P + d \pmod{26}\]
where $d$ is how much the alphabet "shifts."


The plaintext message CAESAR WAS GREAT can be digitized to 
\[\begin{array}{cccccccccccccc}
     02&00&04&18&00&17&22&00&18&06&17&04&00&19 
\end{array}\]
and using the congruence $C \equiv P + 3 \pmod{26}$, this becomes the ciphertext
\[\begin{array}{cccccccccccccc}
     05&03&07&21&03&20&25&03&21&09&20&07&03&22
\end{array}\]
which translates to FDHVDU ZDV JUHDW. 

To recover the plaintext, the procedure is to simply reverse the means of the congruence
\[P \equiv C - 3 \equiv C + 23 \pmod{26}\]
This cipher is extermely simple and therefore, insecure. This is an example of a \textit{monoalphabetic cipher}, an encryption scheme in which each letter of the original message is replaced by the same cipher substitute. Such cipher systems are extremely vulnerable to statistical methods of attack because they preserve the frequency (i.e. relative commonness) of individual letters. 


\subsubsection{Vigenere Cipher}
One of the simplest and most famous example of a \textit{polyalphabetic cipher} (a cipher that transformed a plaintext letter into more than one ciphertext equivalent) is the \textit{Vigenere cipher}. In this case, the standard alphabet is digitized with number $00$ to $25$, and the communicating parties agree on an easily remembered word or phrase, called the keyword. The digitized version of the keyword is arranged below the numerical plaintext of the message and added together to produce the ciphertext. 

Let the plaintext be ATTACK AT ONCE, with the keyword READY. The numerical version of READY is 17 04 00 03 24. We write the numerical plaintext on the top row and repeating sequences of the numerical version of READY below. 
\[\begin{array}{cccccccccccc}
    00&19&19&00&02&10&00&19&14&13&02&04 \\
    17&04&00&03&24&17&04&00&03&24&17&04 
\end{array}\]
When the columns are added modulo $26$, we get
\[\begin{array}{cccccccccccc}
    17&23&19&03&00&01&04&19&17&11&19&08
\end{array}\]
or, converted to letters, RXTDAB ET RLTI. 

Note that a given letter of plaintext is represented by different letters in ciphertext. The double T in the word ATTACK no longer appears as a double letter when ciphered. 

In general, any sequence of $n$ letters with numerical equivalents $b_1, b_2, ..., b_n$ ($00\leq b_i \leq 25$) can serve as the keyword. The plaintext message can be expressed as successive blocks $P_1 P_2 P_3 ... P_n$ of $n$ two-digit integers $P_i$, and then converted to ciphertext blocks $C_1 C_2 ... C_n$ by means of the congruences 
\[C_i \equiv P_i + b_i \pmod{26}, \;\; 1 \leq i \leq n\]
Decryption is carried out by simply reversing it. 
\[P_i \equiv C_i - b_i \pmod{26}, \;\; 1 \leq i \leq n\]

A weakness in the Vigenere algorithm is that once the length of the keyword has been determined, a coded message can be regarded as a number of separate monoalphabetic ciphers, each subject to straightforward frequency analysis. Then rather than using a single word that is to be repeated, people have used what is called a \textit{running key}, which is a random assignment of ciphertext letters to plaintext letters. A popular procedure for generating such keys is to use the text of a book, and the system was thought to be secure until algorithms were generated that broke those codes. 

However, a modification of using what is now called the \textit{autokey} has made it more secure. This approach makes use of the plaintext message itself in constructing the encryption key. The idea is to start the keyword with a short \textit{seed} or \textit{prime} (generally a single letter) followed by the plaintext, whose ending is truncated by the length of the seed. Conveniently, this only requires the two communicating groups to remember the one letter key. 

Assume that the message 
\[\text{ONE IF BY DAWN}\] 
is to be encrypted. Taking the letter K as the seed, the keyword becomes
\[\text{KONEIFBYDAW}\]
Now we can convert both to numerical form, obtaining the array
\[\begin{array}{ccccccccccc}
    14&13&04&08&05&01&24&03&00&22&13\\
    10&14&13&04&08&05&01&24&03&00&22
\end{array}\]
and adding them up modulo $26$ gives
\[\begin{array}{ccccccccccc}
     24&01&17&12&13&06&25&01&03&22&09
\end{array}\]
or changing back to letters, 
\[\text{YBR MN GZ BDWJ}\]

We can decipher the message by first converting it to its numerical form. Suppose that the plaintext is $P_1 P_2 ... P_n$ and the ciphertext is $C_1 C_2 ... C_n$. If $S$ indicates the seed, then the first letter of the plaintext is gotten with
\[P_1 = C_1 - S \pmod{26}\]
For the following letters, we use 
\[P_k \equiv C_k - P_{k-1} \pmod{26}, \;\; 2 \leq k \leq n\]

Doing this recovers 
\begin{align*}
    P_1 &\equiv 24 - 10 \equiv 14 \pmod{26} & \implies P_1 = O\\
    P_2 &\equiv 01-14 \equiv 13 \pmod{26} & \implies P_2 = N\\
    P_3 &\equiv 17 - 13 \equiv 04 \pmod{26} & \implies P_3 = E \\
    ...
\end{align*}

\subsubsection{Hill's Cipher}
An even better security system is to divide the plaintext message into blocks of $n$ letters (possibly filling out hte last block by adding dummy letters such as Xs), and then encrypt block by block by using a system of $n$ linear congruences in $n$ variables. In its simplest form, when $n = 2$, the procedure takes two successive letters and transforms their numerical equivalents $P_1 P_2$ into a block $C_1 C_2$ of ciphertext numbers via the pair of congruences. 
\begin{align*}
    C_1 \equiv a P_1 + b P_2 \pmod{26} \\
    C_2 \equiv c P_1 + d P_2 \pmod{26}
\end{align*}
In order to permit decipherment (that is, for the system to be solvable), the four coefficients $a, b, c, d$ must be selected so that $\gcd(ad-bc, 26) = 1$. 

For example, let us Hill encrypt the messages BUY NOW with blocks of $2$ letters through the system
\begin{align*}
    C_1 & \equiv 2 P_1 + 3 P_2 \pmod{26} \\
    C_2 & \equiv 5 P_1 + 8 P_2 \pmod{26} 
\end{align*}
The first block BU is numerically equivalent to 01 20, which is encrpyted by 
\begin{align*}
    2 (01) + 3(20) \equiv 62 \equiv 10 \pmod{26} \\
    5(01) + 8(20) \equiv 165 \equiv 09 \pmod{26}
\end{align*}
Doing this for the additional blocks YN and OW, we get the completed ciphertext
\[\begin{array}{cccccc}
    10&09&09&16&16&12
\end{array}\]
which can be expressed as KJJQQM. Deciphering the message requires solving the original system of congruences for $P_1$ and $P_2$ in terms of $C_1$ and $C_2$. After calculation, we get
\begin{align*}
    P_1 & \equiv 8 C_1 - 3 C_2 \pmod{26} \\
    P_2 & \equiv -5 C_1 + 2 C_2 \pmod{26} 
\end{align*}
For the block 10 09 of ciphertext, we calculate
\begin{align*}
    P_1 & \equiv 8 (10) - 3(09) \equiv 53 \equiv 01 \pmod{26} \\
    P_2 & \equiv -5 (10) + 2 (09) \equiv -32 \equiv 20 \pmod{26}
\end{align*}
Indeed, the block 01 20 represents BU. Doing this for the rest of the numbers returns the plaintext. 
\subsubsection{Verman Cipher}
Another way of representing the letters of the alphabet is with binary numbers. 
\[\begin{array}{ccc}
    A = 11000 & J = 11010 & S = 10100 \\
    B = 10011 & K = 11110 & T = 00001 \\
    C = 01110 & L = 11110 & U = 11100 \\
    D = 10010 & M = 00111 & V = 01111 \\
    E = 10000 & N = 00110 & W = 11001 \\
    F = 10110 & O = 00011 & X = 10111 \\
    G = 01011 & P = 01101 & Y = 10101 \\
    H = 00101 & Q = 11101 & Z = 10001 \\
    I = 01100 & R = 01010
\end{array}\]
For example, a plaintext message ACT NOW would be translated into a sequence of binary digits
\[110000111000001001100001111001\]
Then, both parties would have some type of encryption key of an arbitrary sequence of 0s and 1s with the same length as that of the numerical plaintext. For example, a random key can be generated as
\[101001011100100010001111001011\]
Then, by adding the key onto the numerical unencrypted message modulo $2$, we get the encrypted message
\[011001100100101011101111110010\]
The security of this cipher is extremely high, especially if a new key is generated after every use (called a \textit{one-time system}). 

\subsubsection{RSA Encryption}
In conventional cryptographic systems, the sender and receiver jointly have a secret \textit{key}. The sender uses the key to encrypt the plaintext to be sent, and the receiver uses the same key to decrypt the ciphertext obtained. 

\textit{Public-key cryptography} differs from conventional cryptography in that it uses two keys: encryption key and a decryption key. Although the two keys effect inverse operations and are therefore related, there is no easily computed method of deriving the decryption key from the encryption key. Thus, the encryption key can be made public without compromising the decryption key. That is, each user can encrypt messages, but only the intended recipient (whose decryption key is kept secret) can decipher them. A major advantage of a public-key cryptosystem is that it is unnecessary for senders and receivers to exchange a key in advance of their decision to communicate with each other. 

In 1977, R. Rivest, A. Shamir, and L. Adleman proposed a public key system called \textit{RSA}, named after their initials. Its security depends on the assumption that in the current state of computer technology, the factorization of composite numbers with large prime factors is prohibitively time-consuming. 

Each user of the RSA system chooses a pair of distinct primes $p$ and $q$, large enough that the factorization of their product $n = pq$, \textit{called the enciphering modulus}, is beyond all current computational capabilities. For instance, picking $p$ and $q$ with 200 digits each would produce a number $n$ with approximately 400 digits. Having selected $n$, the user then chooses a random positive integer $k$, called the \textit{enciphering exponent}, satisfying
\[\gcd\big(k, \varphi(n)\big) = 1\]
The pair $(n, k)$ (but not the factors $p, q$ of $n$) is placed in a public file as the user's personal encryption key. This allows anyone else in the communication network to encrypt and send a message to that individual. 

The encrpytion process begins with digitizing an alphabet. An example would be 
\[\begin{array}{cccc}
    A=00 & K=10 & U=20 & 1 = 30 \\
    B=01 & L=11 & V=21 & 2=31 \\
    C = 02 & M = 12 & W = 22 & 3 = 32 \\
    D = 03 & N = 13 & X = 23 & 4 = 33 \\
    E = 04 & O = 14 & Y = 24 & 5 = 34 \\
    F = 05 & P = 15 & Z = 25 & 6 = 35 \\
    G = 06 & Q = 16 & , = 26 & 7 = 36 \\
    H = 07 & R = 17 & . = 27 & 8 = 37 \\
    I = 08 & S = 18 & ? = 28 & 9 = 38 \\
    J = 09 & T = 19 & 0 = 29 & ! = 39 \\
\end{array}\]
and $99$ indicating a space between words. For example, the message
\[\text{The brown fox is quick}\]
is transformed into the numerical string
\[M = 1907049901171422139905142399081899162008021027\]
It is assumed that the plaintext number $M < n$, where $n$ is, again, the enciphering modulus. Otherwise, it would be impossible the distinguish $M$ from any larger integer congruent to it modulo $n$. When the message is too long to be handled as a single number $M<n$, then $M$ is broken up into blocks of digits $M_1, M_2, ..., M_s$ of appropriate size, and each block is encrypted separately. 

Looking up the intended recipient's encryption key $(n, k)$ in the public directory, the sender disguises the plaintext number $M$ as a ciphertext number $r$ by raising $M$ to the $k$th power and then reducing the result modulo $n$. That is, 
\[M^k \equiv r \pmod{n}\]
From this step, it is obvious why $M<n$; it is wasn't, then it would be impossible to deduce $M$ from $r$. This encrpytion method is very fast on high speed computers. Since $k$ can be any integer such that $\gcd(k, \varphi(n)) = 1$, a obvious recommended choice of $k$ is to be any prime larger than both $p$ and $q$. 

At the other end, the authorized recipient deciphers the transmitted information by first determining the integer $j$, the secret \textit{recovery exponent}, for which 
\[k j \equiv 1 \pmod{\varphi(n)}\]
Because $\gcd(k, \varphi(n)) = 1$, this linear congruence has a unique solution modulo $\varphi(n)$. In fact, the Euclidean algorithm produces $j$ as a solution $x$ to the equation 
\[kx + \varphi(n) y = 1\]
The recovery exponent can only be calculated by someone who knows both $k$ and $\varphi(n) = (p-1) (q-1)$ and hence, knows the prime factors $p$ and $q$. So, $j$ is secure from a third party. Now, by calculating $r^j$ modulo $n$ and assuming that $\gcd(n, M) = 1$ to use Euler's theorem, the recipient can see that 
\begin{align*}
    r^j \equiv (M^k)^j & \equiv M^{1 + \varphi(n) t} \\
    & \equiv M \big( M^{\varphi(n)} \big)^t \equiv M \cdot 1^t \equiv M \pmod{n}
\end{align*}

In other words, raising the ciphertext number to the $j$th power and reducing it modulo $n$ recovers the original plaintext number $M$. 

In the unlikely even that $M$ and $n$ are not coprime, we can actually prove that
\[r^j \equiv M \pmod{p} \text{ and } r^j \equiv M \pmod{q}\]
which yields the desired congruence $r^j \equiv M \pmod{n}$. Again, the major advantage to this encryption system is that it does not require the knowledge of the two primes $p$ and $q$; it only requires the product $n$. 

We work through an example with the RSA public-key algorithm. We first select two primes 
\[p = 29, \;\; q = 53\]
of an unrealistically small size for example purposes. In reality, $p$ and $q$ would be large enough to fill up a considerable portion of this page. Our enciphering modulus of $n = 29 \cdot 53 = 1537$, and $\varphi(n) = 28 \cdot 52 = 1456$. Since $\gcd(47, 1456) = 1$, we may choose $k = 47$ to be the enciphering exponent. Then, the recovery exponent, the unique integer $j$ satisfying the congruence $kj \equiv 1 \pmod{\varphi(n)}$, is $j = 31$. The encrypt the message 
\[\text{NO WAY} \implies M = 131499220024\]
Now, since $n = 1537$, we want each block to be an integer less than $1537$. Given this restriction, it seems reasonable to split $M$ into blocks of three digits each. The first block, $131$ encrypts as the ciphertext number 
\[131^{47} \equiv 0570 \pmod{1537}\]
At the other end, the authorized recipient, knowing that the recovery exponent is $j = 31$, begins to recover the plaintext number by computing 
\[570^{31} \equiv 131 \pmod{1537}\]
The total ciphertext of our message is 
\[0570 \; 1222 \; 0708 \; 1341\]

The security of the RSA system rests on what is known as the \textit{work factor}, the expected amount of computer time needed to factor the product of two large primes. Factoring is computationally more difficult than distinguishing between primes and composites, so at least up to current times, this system is secure. Even if computers get better, we can just choose larger primes. 

In 1977, the three inventors of the system submitted a ciphertext message to \textit{Scientific American} which depended on a 129-digit enciphering modulus that was the product of two primes of approximately the same length. The large number acquired the name RSA-129. Taking into account the most powerful factoring methods and fastest computers available at that time, it was estimate that at least 40 quadrillion years would be required to break down RSA-129, but with increasing computing power, it was broken after 17 years in 1994. 

\subsection{The Merkle-Hellman Knapsack Cryptosystem}
The \textit{Knapsack problem}, or the \textit{subset sum problem}, in combinatorics is as follows: Given a knapsack of volume $V$ and $n$ items of various volumes $a_1, a_2, ..., a_n$, can a subset of these items be found that will completely fill the knapsack? Slightly modified, for positive integers $a_1, a_2, ..., a_n$ and a sum $V$, solve the equation
\[V = \sum_{i} a_i x_i\]
where $x_i \in \{0, 1\}$ for $i = 1, 2, ..., n$. 

There may be no, one, or multiple solutions, but finding a solution to a randomly chosen knapsack problem is notoriously difficult. None of the known methods for attacking the problem are substantially less time-consuming than bashing through all $2^n$ possibilities for $x_1, x_2, ..., x_n$. 

\begin{example}
The knapsack problem 
\[22 = 3x_1 + 7x_2 + 9x_3 + 11x_4 + 20x_5 \]
has no solution, but the problem 
\[27 = 3x_1 + 7x_2 + 9x_3 + 11x_4 + 20x_5 \]
has two distinct solutions 
\[x_2 = x_3 = x_4 = 1, \;\; x_1 = x_5 = 0\]
and 
\[x_2 = x_5 = 1, \;\; x_1 = x_3 = x_4 = 0\]
\end{example}

However, if the sequence of integers $a_1, a_2, ..., a_n$ happens to have some special properties, then the knapsack problem becomes much easier to solve. 

\begin{definition}
A sequence $a_1, a_2, ..., a_n$ is \textit{superincreasing} when each $a_i$ is larger than the sum of all the preceding ones; that is, 
\[a_i > \sum_{j=1}^i a_j, \;\; i = 2, 3, ..., n\]
\end{definition}

A simple example of a knapsack problem with a superincreasing sequence is 
\[V = x_1 + 2x_2 + 4x_3 + ... + 2^n x_n, \;\; V < 2^{n+1}\]

Knapsack problems with superincreasing sequences are uniquely solvable if they are solvable at all. The general algorithm goes as such: Suppose that we wish to solve the Knapsack problem 
\[V = a_1 x_1 + a_2 x_2 + ... + a_n x_n\]
where $a_1, ..., a_n$ is superincreasing. Assume that $V$ can be obtained by using some subset of the sequence so that $V$ is not larger than the sum $a_1 + ... a_n$. Working from right to left in our sequence, we begin by letting $x_n = 1$. If $V \geq a_n$ and $x_n = 0$ if $V<a_n$. Then, obtain $x_{n-1}, x_{n-2}, ..., x_1$ in turn by choosing
\[x_i = \begin{cases}
1 & \text{if } V - (a_{i+1}x_{i+1} + ... + a_n x_n) \leq a_i \\
0 & \text{if } V - (a_{i+1}x_{i+1} + ... + a_n x_n) < a_i
\end{cases}\]

\begin{example}
We have the superincreasing knapsack problem
\[28 = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5\]
We start with the largest coefficient $41$. Since $41>28$, $x_5 = 0$. The next largest coefficient is $20$, with $20<28$. The sum of the preceeding coefficients is $3+5+11<28$, so that these cannot fill the knapsack. Therefore $20$ must be included in the sum and $x_4 = 1$. Knowing the values of $x_4$ and $x_5$, the problem is reduced to 
\[8 = 3x_1 + 5x_2 + 11x_3\]
Since $11 > 8$, $x_3 = 0$, meaning that $x_1 = x_2 = 1$ to sum up to $8$. Therefore, the solution is 
\[x_1 = x_2 = x_4 = 1, \;\; x_3 = x_5 = 0\]
\end{example}

A public-key encryption system is based off of this knapsack problem. A typical user of the system starts by choosing a superincreasing sequence $a_1, a_2, ..., a_n$. He or she also selects a modulus $m > 2a_n$ and a multiplier $a$, with $0 < a < m$ and $\gcd(a, m) = 1$. This ensures that the congruence 
\[ax \equiv 1 \pmod{m}\]
has a unique solution, say $x \equiv c \pmod{m}$. Finally, we form the sequence of integers $b_1, b_2, ..., b_n$, defined by 
\[b_i \equiv a a_i \pmod{m}, \;\; i = 1, 2, ..., n\]
where $0 < b_i < m$. Carrying out this last transformation generally destroys the superincreasing property of the $a_i$'s. The user keeps the original sequence $a_1, a_2, ..., a_n$ and the numbers $m$ and $a$, but publishes $b_1, b_2, ..., b_n$ in a public directory. As the reader would expect, this sequence of $b_i$'s serves as the encryption key. 

We will use the following binary representation of the alphabet. 
\[\begin{array}{ccc}
    A = 00000 & J = 01001 & S = 10010 \\
    B = 00001 & K = 01010 & T = 10011 \\
    C = 00010 & L = 01011 & U = 10100 \\
    D = 00011 & M = 01100 & V = 10101 \\
    E = 00100 & N = 01101 & W = 10110 \\
    F = 00101 & O = 01110 & X = 10111 \\
    G = 00110 & P = 01111 & Y = 11000 \\
    H = 00111 & Q = 10000 & Z = 11001 \\
    I = 01000 & R = 10001
\end{array}\]
For example, the message First Place would be converted into the numerical representation 
\[M = 00101\;0100\;10001\;10010\;10011\;01111\;01011\;00000\;00010\;00100\]
The sender then splits this string into an arbitrary number of blocks of $n$ binary digits (remember that $n$ is the length of the sequences $a_i$ and $b_i$), with the last block being filled out with $1$s at the end if necessary. The public encrypting sequence $b_1, b_2, ..., b_n$ is used to transform the given plaintext block, say 
\[x_1 x_2 x_3 ... x_n\]
into the sum 
\[S = b_1 x_1 + b_2 x_2 + ... + b_n x_n\]
and the encryption is complete for that block. We do this for the rest of the blocks to encrypt the rest of the message. Now, since because each $x_i$ is either $0$ or $1$, the problem of recreating the plaintext block from $S$ is equivalent to solving the apparently difficult knapsack problem (remember that the new sequence $b_1, b_2, ..., b_n$ is not superincreasing anymore). 

Once the authorized receiver receives this knapsack problem, he/she can change it into an easy one using the private key. Knowing $c$ and $m$, the recipient can compute 
\[S^\prime \equiv c S \pmod{m}, \;\; 0 \leq S^\prime < m\]
and by expanding, we get
\begin{align*}
    S^\prime & \equiv c b_1 x_1 + c b_2 x_2 + ... + c b_n x_n \pmod{m} \\
    & \equiv c a a_1 x_1 + c a a_2 x_2 + ... + c a a_n x_n \pmod{m}
\end{align*}
Now, $ca \equiv 1 \pmod{m}$, so the previous congruence becomes 
\[S^\prime \equiv a_1 x_1 + a_2 x_2... + a_n x_n \pmod{m}\]
But due to the conditions that $m > 2a_n > a_1 + ... + a_n$ and that $0 \leq S^\prime < m$, the congruence can be simplified to the equality 
\[S^\prime = a_1 x_1 + a_2 x_2 + ... + a_n x_n\]
Since $S^\prime$ and the superincreasing $a_i$'s are given, the solution to this superincreasing knapsack problem can be easily computed, allowing us to recover the plaintext block $x_1 x_2 ... x_n$ of $n$ of the binary digits. Doing this for all the blocks entirely decrypts the message. 

We provide an example with low-level sequences. Suppose that a typical user of this cryptosystem selects as a secret key the superincreasing sequences $3, 5, 11, 20, 41$, the modulus $85$, and the multiplier $a = 44$. Each member of the superincreasing sequence is multiplied by $44$ and reduced modulo $85$ to yield 
\begin{align*}
    44 \cdot 3 &\equiv 47 \pmod{85} \\
    44 \cdot 5 &\equiv 50 \pmod{85} \\
    44 \cdot 11 &\equiv 59 \pmod{85} \\
    44 \cdot 20 &\equiv 30 \pmod{85} \\
    44 \cdot 41 &\equiv 19 \pmod{85} 
\end{align*}
These five numbers $47, 50, 59, 30, 19$ is submitted to the public directory. Someone who wants to send a plaintext message to the user, such as 
\[\text{HELP US}\]
first converts it into the following binary digits.
\[M = 00111\;00100\;01011\;01111\;10100\;10010\]
Then, since the length of the sequence is $5$, the entire string is broken up into blocks of digits of length $5$. Using the listed public key to encrypt, the sender transforms the successive blocks into 
\begin{align*}
    108 & = 47 \cdot 0 + 50 \cdot 0 + 59 \cdot 1 + 30 \cdot 1 + 19 \cdot 1 \\
    59 & = 47 \cdot 0 + 50 \cdot 0 + 59 \cdot 1 + 30 \cdot 0 + 19 \cdot 0 \\
    99 & = 47 \cdot 0 + 50 \cdot 1 + 59 \cdot 0 + 30 \cdot 1 + 19 \cdot 1 \\
    158 & = 47 \cdot 0 + 50 \cdot 1 + 59 \cdot 1 + 30 \cdot 1 + 19 \cdot 1 \\
    106 & = 47 \cdot 1 + 50 \cdot 0 + 59 \cdot 1 + 30 \cdot 0 + 19 \cdot 0 \\
    77 & = 47 \cdot 1 + 50 \cdot 0 + 59 \cdot 0 + 30 \cdot 1 + 19 \cdot 0
\end{align*}
Therefore, the transmitted ciphertext consists of the sequence of positive integers. 
\[108\;\;\;59\;\;\;99\;\;\;158\;\;\;106\;\;\;77\]
To read the message, the legitimate receiver first solves the congruence $44x \equiv 1 \pmod{85}$ to get the value of $c$, which is $x \equiv 29 \pmod{85}$. Then, each ciphertext number is multiplied by $29$ and reduced modulo $85$ to produce a superincreasing knapsack problem. 
\begin{align*}
    29 \cdot 108 & \equiv 72 \pmod{85} \\
    29 \cdot 59 & \equiv 11 \pmod{85} \\
    29 \cdot 99 & \equiv 66 \pmod{85} \\
    29 \cdot 158 & \equiv 77 \pmod{85} \\
    29 \cdot 106 & \equiv 14 \pmod{85} \\
    29 \cdot 77 & \equiv 23 \pmod{85}
\end{align*}
which produces six corresponding knapsack problems with superincreasing sequences for each calculation. Each problem can be easily computed to get the corresponding solutions
\begin{align*}
    72 & = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5 & \implies (x_1, x_2, x_3, x_4, x_5) = (0,0,1,1,1) \\
    11 & = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5 & \implies (x_1, x_2, x_3, x_4, x_5) = (0,0,1,0,0) \\
    66 & = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5 & \implies (x_1, x_2, x_3, x_4, x_5) = (0,1,0,1,1) \\
    77 & = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5 & \implies (x_1, x_2, x_3, x_4, x_5) = (0,1,1,1,1) \\
    14 & = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5 & \implies (x_1, x_2, x_3, x_4, x_5) = (1,0,1,0,0) \\
    23 & = 3x_1 + 5x_2 + 11x_3 + 20x_4 + 41x_5& \implies (x_1, x_2, x_3, x_4, x_5) = (1,0,0,1,0) 
\end{align*}
This cryptosystem aroused a great deal of interest because it was based on a provably difficult problem. However in 1982, Shamir invented a reasonably fast algorithm for solving a knapsack problem. The weakness of the system is that the public encryption key $b_1, b_2, ..., b_n$ is too special; that is, multiplying by $a$ and reducing modulo $m$ does not completely disguise the sequence $a_1, a_2, ..., a_n$. The system can be modified by iterating the modular multiplication method with different values of $a$ and $m$ so that the public and private sequences differ by several transformations, but even this was successfully broken by $1985$. Although most variations of the Merkle-Hellman scheme have been shown to be insecure, there are a few that have resisted. 

\subsection{An Application of Primitive Roots to Cryptography}
Most modern cryptography systems rely on the presumed difficulty of solving some particular number theoretic problem within a reasonable length of time. 

\subsubsection{ElGamal Encryption}
In 1985, Taher ElGamal introduced a method of encrypting messages based on a version of the discrete logarithm problem, which is stated as follows: Find the integer $0 < x < \varphi(n)$, if it exists, that is the solution to the congruence
\[r^x \equiv y \pmod{n}\]
for given $r, y, n$. The exponent $x$ is said to be the \textit{discrete logarithm of $y$ to the base $r$, modulo $n$}. By requiring that the base $r$ be a primitive root of prime number $n$, it is guaranteed that $y$ will always have a well-defined logarithm; that is, a solution $x$ will always exist (by definition of the primitive root, and $x = \varphi(n) - 1$ when $n$ is prime, at the very least). Note that merely requiring $n$ to be prime guarantees that $x = \varphi(n)$ to be a solution by Euler's theorem, but there may exist no solutions that are less than $\varphi(n)$. The logarithm could be found by exhaustive search; that is, by calculating the successive powers of $r$ until $y \equiv r^x \pmod{n}$ is reached However, this would not be practical for large $n$. 

A typical user begins by selecting a prime number $p$ along with one of its primitive roots $r$. Then an integer $k$ with $2 \leq k \leq p-2$ is randomly chosen to serve as the secret key. Then, $a$ is calculated as such. 
\[a \equiv r^k \pmod{p}, \;\; 0 \leq a \leq p-1\]
The triple of integers $(p, r, a)$ becomes the person's public key, but the value of the exponent $k$ is not revealed. It is also impractical for an unauthorized third party to calculate $k$ since it would require them to solve a discrete logarithm problem that would be nearly impossible for large values of $a$ and $p$. 

\begin{example}
An individual begins by picking the prime $p = 113$ and its smallest primitive root $r=3$. The choice $k=37$ is then made for the integer satisfying $2 \leq 37 \leq 111$. Then $a \equiv 3^{37} \pmod{113}$ is calculated 
\[a \equiv 3^{37} \equiv 3^1 \cdot 3^4 \cdot 3^{37} \equiv 3 \cdot 81 \cdot 28 \equiv 24 \pmod{113}\]
The triple $(113, 2, 24)$ serves as the public key, while the integer $37$ becomes the secret deciphering key. 
\end{example}

Now, assume that a message is to be sent to someone who has a public key $(p, r, a)$ and also the corresponding private key $k$. We first convert the original message into a numerical equivalent with, say the standard convention that 
\[\begin{array}{cccc}
    A = 00 & B = 01 & ... & Z = 25
\end{array}\]
It is assumed that $M<p$. If $M \geq p$, then $M$ is split into successive blocks, each block containing the same number of digits (which must be even since the numerical representation all have an even number of digits). Depending on how big the prime $p$ is (which determines how big the blocks can get), it may be necessary to add extra digits (sometimes $25 = z$) to fill out the final block. Let $B$ denote the first block. Then, the sender, who is aware of the recipient's public key, arbitrarily selects an integer $2 \leq j \leq p-2$ and computes two values: 
\[C_1 \equiv r^j \pmod{p}, \;\; C_2 \equiv Ba^j \pmod{p}, \; 0 \leq C_1, C_2 \leq p-1\]
The encrypted ciphertext of the block $B$ is the pair of integers $(C_1, C_2)$. For greater security, it is possible for the choice of $j$ to be changed from block to block. The recipient of the ciphertext can then recover the block $B$ by using the secret key $k$ using the following identity. The recipient first evaluates $C_1^{p-1-k} \pmod{p}$ and then $P \equiv C_2 C_1^{p-1-k}$. Then the two values are multiplied together. 
\begin{align*}
    P \equiv C_2 C_1^{p-1-k} & \equiv (Ba^j)(r^j)^{p-1-k} \\
    & \equiv B (r^k)^j (r^{j(p-1) - jk}) \\
    & \equiv B(r^{p-1})^j \\
    & \equiv B \pmod{p}
\end{align*}
where the final congruence results from the Fermant identity $r^{p-1} \equiv 1 \pmod{p}$. Therefore, the decryption can be carried out by someone who knows the value of $k$. 

We work though an example with a reasonably small prime number for simplicity. Assume that the user wishes the deliver the message 
\[\text{SELL NOW}\]
to a receiver who has the secret key $k=15$ and public encryption key $(p, r, a) = (43, 3, 22)$, where $22 \equiv 3^{15} \pmod{43}$. The plaintext is first converted to the string of digits 
\[M = 18\;01\;11\;11\;13\;14\;22\]
To create the ciphertext, the sender selects an integer $j$ satisfying $2 \leq j \leq 41$, say $j=23$, and then calculates
\[C_1 = r^j \equiv 3^{23} \equiv 34 \pmod{43} \text{ and } a^j \equiv 22^{23} \equiv 32 \pmod{43}\]
So, the product $C_1 B \equiv 32 B \pmod{43}$ is computed for each two-digit block $B$ of $M$. Doing this for all $7$ blocks modulo $43$. 
\[\begin{array}{cccc}
    32 \cdot 18 \equiv 17 & 32 \cdot 04 \equiv 42 & 32 \cdot 11 \equiv 08 & 32 \cdot 11 \equiv 08 \\
    32 \cdot 13 \equiv 29 & 32 \cdot 14 \equiv 18 & 32 \cdot 22 \equiv 16
\end{array}\]
We get the ciphertext 
\[(34,17)\;(34,42)\;(34,08)\;(34,08)\;(34,29)\;(34,18)\;(34,16)\]
The receiver, who knows that $k = 15$, decrypts it by first calculating
\[C_1^{p-1-k} \equiv 34^{27} \equiv 39 \pmod{43}\]
Then, this is multiplied modulo $43$ to the second entry in the ciphertext pair. 
\[\begin{array}{cccc}
    39 \cdot 17 \equiv 18 & 39 \cdot 42 \equiv 04 & 39 \cdot 08 \equiv 11 & 39 \cdot 08 \equiv 11 \\
    39 \cdot 29 \equiv 13 & 39 \cdot 18 \equiv 14 & 39 \cdot 16 \equiv 22
\end{array}\]
which produces the plaintext in numerical form. 

\subsubsection{Digital Signatures}
To confirm the integrity of a message, that is to confirm that the incoming message was sent by an authorized person, the sender must provide a \textit{digital signature}. Fortunately, the ElGamal cryptosystem allows for an efficient procedure for authenticating messages. 

Consider a user (sender) of the system who has a public key $(p, r, a)$, private key $k$, and encrypted message $M$. The first step toward supplying a signature is to choose an integer $1 \leq j\leq p-1$ where $\gcd(j, p-1) = 1$. Let $B$ be the first block (and later blocks) of the ciphertext message. The user computes 
\[c \equiv r^j \pmod{p}, \; 0 \leq j \leq p-1\]
and then obtains a solution of the linear congruence
\[jd + kc \equiv B \pmod{p-1} \implies jd \equiv B-kc, \; 0 \leq d \leq p-2\]
The solution $d$ can be found using the Euclidean algorithm. The pair of integers $(c, d)$ is the required digital signature appended to the message. Note that while $c$ can be made by anyone, the integer $d$ can be created only by someone who knows the private key $k$, the random integer $j$, and the encoded message $M$. What really matters is that the sender knows $k$. 

The recipient uses the sender's public key $(p, r, a)$ to confirm the purported signature. By calculating the two values 
\[V_1 \equiv a^c c^d \pmod{p} \text{ and } V_2 \equiv r^B \pmod{p}, \;\; 0 \leq V_1, V_2 \leq p-1\]
the signature is accepted as legitimate if $V_1 = V_2$, since (if the actual value of $d$ is the solution to the linear congruence $jd + kc \equiv B \pmod{p-1}$), 
\begin{align*}
    V_1 \equiv a^c c^d & \equiv (r^k)^c (r^j)^d \\
    & \equiv r^{kc + jd} \\
    & \equiv r^B \equiv V_2 \pmod{p}
\end{align*}
In other words, this signature verifies that the sender actually has the key $k$ (which must be needed to get the proper value of $d$). Note that this does not require the receiver to know the key. 

For example, a sender having public key $(43, 3, 22)$ and private key $k=15$ wants to sign and reply to the message SELL NOW. This is carried out by first choosing an integer $0 \leq j \leq 42$ with $\gcd(j, 42) = 1$; say $j=25$. If the first block of the encoded reply is $B=13$, then the person calculates
\[c \equiv 3^{25} \equiv 5 \pmod{43}\]
and solves the congruence 
\[25 d \equiv 13 - 5 \cdot 15 \pmod{42}\]
to get $d \equiv 16 \pmod{42}$. The digital signature is therefore $(5, 16)$. On its arrival, the signature is confirmed by checking the equality of integers $V_1$ and $V_2$. 
\begin{align*}
    V_1 & \equiv 22^5 \cdot 5^{16} \equiv 39 \cdot 40 \equiv 12 \pmod{43} \\
    V_2 & \equiv 3^{13} \equiv 12 \pmod{43}
\end{align*}


\section{Perfect Numbers and Mersenne Primes}
\begin{definition}
A \textit{proper divisor} of an integer $n$ are all of its divisors except $n$ itself. 
\end{definition}

\begin{definition}
A positive integer $n$ is said to be \textit{perfect} if $n$ is equal to the sum of its proper divisors. 
\end{definition}

We can also express it in the following way. Let $\sigma(n)$ be the sum of all of its divisors. Then, a perfect number is an integer $n$ such that
\[\sigma(n) = 2n\]

\begin{example}
Some examples of proper divisors are: 
\begin{align*}
    \sigma(6) & = 1 + 2 + 3 + 6 = 2 \cdot 6 \\
    \sigma(28) & = 1 + 2 + 4+ 7+ 14+ 28 = 2 \cdot 28
\end{align*}
Let $P_k$ be the $k$th proper divisor, then 
\begin{align*}
    P_3 & = 496 \\
    P_4 & = 8128 \\
    P_5 & = 33550336 \\
    P_6 & = 8589869056 \\
    P_7 & = 137438691328 \\
    P_8 & = 2305843008139952128 \\
    P_9 & = 2658455991569831744654692615953842176
\end{align*}
\end{example}

It is not known whether there are a finite number or an infinite number of perfect numbers. We proceed to find some patterns in the form of perfect numbers. 

\begin{theorem}
If $2^k - 1$ is prime $(k > 1)$, then 
\[n = 2^{k-1} (2^k - 1)\]
is perfect and every even perfect number is of this form. 
\end{theorem}

Therefore, the problem of finding even perfect numbers is reduced to the search of all primes of the form $2^k - 1$. That is, upon finding a Mersenne prime, we just multiply it by the corresponding multiple of $2$ to get a perfect number. 

\begin{definition}
Numbers of the form 
\[M_n = 2^n - 1, \;\;\; n \geq 1\]
are called \textit{Mersenne numbers}. Mersenne numbers that are also prime are called \textit{Mersenne primes}. 
\end{definition}

\begin{lemma}
If $a^k - 1$ is prime $(a>0, k \geq 2)$, then $a = 2$ and $k$ is prime. 
\end{lemma}
\begin{proof}
Since
\[a^k - 1 = (a-1)(a^{k-1} + a^{k-2} + ... + a + 1)\]
where
\[a^{k-1} + a^{k-2} + ... + a + 1 \geq a + 1 > 1\]
the other factor of $a^k -1$ (which is assumed to be prime) must be $1$. So, $a-1 = 1 \implies a = 2$. To prove $k$ prime, assume that it is composite. Then, we can write $k = rs$, where $r, s > 1$. Then, 
\begin{align*}
    a^k - 1 & = (a^r)^s - 1 \\
    & = (a^r - 1) (a^{r(s-1)} + a^{r(s-2)} + ... + a^r + 1)
\end{align*}
where both factors are clearly greater than $1$. This violates that $a^k -1$ must be prime, so our assumption that $k$ is composite is false. 
\end{proof}

We can write the first six Mersenne primes (also perfect numbers) as 
\begin{align*}
    P_1 & = 2(2^2 -1) \\
    P_2 & = 2^2 (2^3 - 1) \\
    P_3 & = 2^4 (2^5 - 1) \\
    P_4 & = 2^6 (2^7 - 1) \\
    P_5 & = 2^{12} (2^{13} - 1) \\
    P_6 & = 2^{16} (2^{17} - 1) \\
    P_7 & = 2^{18} (2^{19} - 1) \\
    P_8 & = 2^{30} (2^{31} - 1) \\
    P_9 & = 2^{66} (2^{67} - 1) 
\end{align*}

This leads to the question of whether there are an infinite number primes of the type $2^p - 1$, where $p$ is a prime. 

\begin{conjecture}
There exists an infinite number of Mersenne primes of form
\[2^p - 1, \;\; p \text{ prime}\]
\end{conjecture}

If this conjecture is true, then this would imply that there exists an infinite number of (even) perfect numbers. We can also prove results on the digits of even perfect numbers. So far, there are a total of 51 Mersenne primes found, with the largest being
\[2^{82589933} -1\]
with $24,862,048$ digits when written in base-10. It is also the largest known prime as of November 2020. 

\begin{theorem}
An even perfect number $n$ ends in the digit $6$ or $8$. That is, 
\[n \equiv 6 \pmod{10} \text{ or } n \equiv 8 \pmod{10}\]
Even better, every even perfect number ends in $6$ or $28$. 
\end{theorem}

One property that was noticed was that substituting some Mersenne primes for $n$ in the formula $2^n - 1$ produces a higher Mersenne prime. This works for the first four Mersenne primes $3, 7, 31$, and $127$. 
\begin{align*}
    2^2 - 1 = 3 \implies 2^3 - 1 = 7 
\end{align*}

It was conjectured that if the number $M_n$ is prime, then $M_{M_n}$ is also prime, but this was shown to false when 
\[M_{M_{13}} = 2^{M_{13}} - 1 = 2^{8191} - 1\]
was shown to be composite. 

The final type of numbers is a \textit{Fermant number}. 

\begin{definition}
A \textit{Fermant number} is an integer of the form
\[F_n = 2^{2^n} + 1, \;\; n \geq 0\]
If $F_n$ is prime, then it is said to be a \textit{Fermant prime}. 
\end{definition}

The first five Fermant numbers are indeed prime, but $F_5$ was shown to be composite. 
\begin{align*}
    F_0 &= 2^{2^0} + 1 = 3 \\
    F_1 &= 2^{2^1} + 1 = 5 \\
    F_2 &= 2^{2^2} + 1 = 17 \\
    F_3 &= 2^{2^3} + 1 = 257 \\
    F_4 &= 2^{2^4} + 1 = 65537 \\
    F_5 &= 2^{2^5} + 1 = 4294967297
\end{align*}

\begin{theorem}
The Fermant number $F_5$ is divisible by $641$. 
\end{theorem}
\begin{proof}
By letting $a = 2^7$ and $b = 5$, we have 
\[1 + ab = 641\]
We can see that
\[1 + ab - b^4 = 1 + (a-b^3) b = 1 + 3b = 2^4\]
This implies that 
\begin{align*}
    F_5 = 2^{2^5} + 1 & = 2^{32} + 1 \\
    & = 2^4 a^4 + 1\\
    & = (1+ab-b^4) a^4 + 1 \\
    & = (1+ab) a^4 + (1-a^4 b^4) \\
    & = (1+ab) \big( a^4 + (1-ab)(1+a^2 b^2)\big)
\end{align*}
which gives $641 | F_5$. 
\end{proof}

It is not known whether there are an infinite number of Fermant primes, or even if there is at least one Fermant prime beyond $F_4$. But there is a useful property about Fermant numbers in that they are relatively prime to each other. 

\begin{lemma}
For distinct Fermant numbers $F_n, F_m$, where $n,m \geq 0$, 
\[\gcd(F_m, F_n) = 1\]
\end{lemma}

One final result we have is about the divisors of Fermant numbers. 

\begin{theorem}
Any prime divisor $p$ of the Fermant number $F_n = 2^{2^n} + 1$, where $n \geq 2$, is of the form
\[p = k \cdot 2^{n+2} + 1\]
\end{theorem}

\section{Certain Nonlinear Diophantine Equations}

\begin{definition}
A \textit{Pythagorean triple} is a set of three integers $x, y, z$ such that 
\[x^2 + y^2 = z^2\]
\end{definition}

\begin{theorem}
All the solutions of the Pythagorean equation
\[x^2 + y^2 = z^2\]
satisfying the conditions 
\[\gcd(x, y, z) = 1, \;\; 2 \big| x, \;\; x, y, z > 0\]
are given by the formulas 
\[x = 2st, \;\; y = s^2 - t^2, \;\; z= s^2 + t^2\]
for integers $s > t > 0$ such that $\gcd(s, t) = 1$ and $s \not\equiv t \pmod{2}$. 
\end{theorem}

\begin{corollary}
The radius of the inscribed circle of a Pythagorean triangel is always an integer. 
\end{corollary}

\subsection{Fermant's Last Theorem}
\begin{theorem}
The Diophantine equation 
\[x^4 + y^4 = z^2\]
has no solution in the positive integers $x, y, z$. 
\end{theorem}
\begin{proof}
Assume that there exists a positive solution $x_0, y_0, z_0$. Without loss of generality, suppose also that $\gcd(x_0, y_0) = 1$. Then, we express the equation as
\[(x_0^2)^2 +(y_0^2)^2 = z_0^2\]
meaning that $x_0^2, y_0^2, z_0$ must be a Pythagorean triple and must be (without loss of generality of the order of $x_0$ and $y_0$)
\begin{align*}
    & x_0^2 = 2st \\
    & y_0^2 = s^2 - t^2 \\
    & z_0 = s^2 + t^2
\end{align*}
where $s > t > 0$ are relatively prime integers and exactly one of $s$ and $t$ is even. Note that since $y_0$ is odd, $y_0^2 \equiv 1 \pmod{4}$. If $s$ is even, then 
\[1 \equiv y_0^2 = s^2 - t^2 \equiv 0 - 1 \equiv 3 \pmod{4}\]
which is an impossibility. Therefore, $s$ must be odd and so $t$ is even; denote $t = 2r$. Then, the equation $x_0^2 = 2st$ becomes $x_0^2 = 4sr$, which says that
\[\bigg(\frac{x_0}{2} \bigg)^2 = sr\]
But note that since $\gcd(s, r) = 1$ (due to $\gcd(s, t) = 1$) and $sr$ is a perfect square, this must imply that each of the integers $s$ and $r$ are both perfect squares. Denote them by $s = z_1^2, r = w_1^2$. Now, since 
\[t^2 + y_0^2 = s^2\]
and $\gcd(s, t) = 1$, it follows that $\gcd(t, y_0, s) = 1$, making them a Pythagorean triple. With $t$ even, we get
\begin{align*}
    t = 2 uv \\
    y_0 = u^2 - v^2 \\
    s = u^2 + v^2
\end{align*}
for relatively prime integers $u>v>0$. Now, the relation 
\[uv = \frac{t}{2} = r = w_1^2\]
implies that $u$ and $v$ are both squares, so denote $u = x_1^2, v = y_1^2$. When these values are substituted in the equation $s = u^2 + v^2$, we get 
\[z_1^2 = s = u^2 + v^2 = x_1^4 + y_1^4\]
and we are back at the same equation again. But now, consider the inequality
\[0<z_1 \leq z_1^2 = s \leq s^2 < s^2 + t^2 = z_0\]
Therefore, starting with one solution $x_0, y_0, z_0$, we have proved the existence of another solution $x_1, y_1, z_1$ such that $0<z_1 < z_0$. Repeating the argument, this would lead to a third solution $x_2, y_2, z_2$ and so forth, which provides an infinite decreasing sequence of positive integers
\[z_0 > z_1 > z_2 > ...\]
But since there is only a finite supply of positive integers less than $z_0$, a contradiction occurs, so no solution does exist.   
\end{proof}

An immediate result is the following corollary. 

\begin{corollary}
The equation $x^4 + y^4 = z^4$ has no solution in the positive integers.
\end{corollary}
\begin{proof}
$(x_0, y_0, z_0)$ being a positive solution implies that $(x_0, y_0, z_0^2)$ is a solution of $x^4 + y^4 = z^2$, which contradicts the previous theorem. 
\end{proof}

If $n>2$, then $n$ is either a power of $2$ or divisible by an odd prime $p$. In the first case, $n=4k$ and the Fermant equation $x^n + y^n = z^n$ can be written as 
\[(x^k)^4 + (y^k)^4 = (z^k)^4\]
which does not have a solution by the previous corollary. When $n=pk$, the Fermant equation is the same as 
\[(x^k)^p + (y^k)^p = (z^k)^p\]
So, if it could be shown that the equation $x^p + y^p = z^p$ has no solution, then, there would exist no solutions for $x^n + y^n = z^n$. After more than 300 years of effort, Fermant's conjecture turned out to be true (proved in 1995). 

\begin{theorem}[Fermant's Last Theorem]
There exist no solution to the Diophantine equation 
\[x^n + y^n = z^n\]
for all integers $n>2$. For $n=1, 2$, there is clearly an infinite number of solutions. 
\end{theorem}

\begin{theorem}[Fermant]
The Diophantine equation
\[x^4 - y^4 = z^2\]
has no solution in the positive integers $x, y, z$. 
\end{theorem}

\begin{theorem}
The area of a Pythagorean triangle can never be equal to a perfect square. 
\end{theorem}
\begin{proof}
Assume that a solution exists with side lengths $x, y$ and hypotenuse length $z$ such that $x^2 + y^2 = z^2$. Then, the area of the triangle is $\frac{1}{2} xy$ and let it be equal to $u^2$ for some $u \in \mathbb{N}$. Then, $2xy = 4u^2$, and adding/subtracting the equation into $x^2 + y^2 = z^2$, we get
\[(x+y)^2 = z^2 + 4u^2, \;\; (x-y)^2 = z^2 - 4u^2\]
When these last two equations are multiplied together, we get
\[(x^2-y^2)^2 = z^4 - 16u^4 = z^4 - (2u)^4\]
But this contradicts the fact that there exists solutions to the equation $x^4 - y^4 = z^2$, so no such $u$ can exist. 
\end{proof}

\section{Representation of Integers as Sums of Squares}
\subsection{Sums of Two Squares}
A common question is to find whether every integer can be expressed as a sum of squares, and if so, what is the minimum number of squares (including $0^2$) that one needs to express an integer? It turns out to be 4 (e.g. $7 = 2^2 + 1^2 + 1^2 + 1^2$), but we will first explore the necessary and sufficient conditions that a positive integer be representable as the sum of two squares. 

\begin{lemma}
If $m$ and $n$ are each the sum of two squares, then so it their product $mn$. 
\end{lemma}
\begin{proof}
If $m = a^2 + b^2$ and $n = c^2 + d^2$, then 
\[mn = (a^2 + b^2)(c^2 + d^2) = (ac + bd)^2 + (ad - bc)^2\]
\end{proof}

Clearly, not every prime can be written as the sum of two squares, since if this were indeed true, then by the previous lemma, every number can be written as a sum of squares (which contradicts our counterexample that $7 = 2^2 + 1^2 + 1^2 + 1^2$). 

\begin{theorem}
No prime $p$ of the form $4k + 3$ is a sum of two squares. 
\end{theorem}
\begin{proof}
$a \equiv 0, 1, 2, 3 \pmod{4}$ for all $a \in \mathbb{N} \implies a^2 \equiv 0, 1 \pmod{4}$. This means that 
\[a^2 + b^2 \equiv 0, 1, 2 \pmod{4}\]
\end{proof}

\begin{lemma}[Thue's Lemma]
Let $p$ be a prime and let $\gcd(a, p) = 1$. Then, the congruence
\[a x \equiv y \pmod{p}\]
admits a solution $x_0, y_0$, where
\[0 < |x_0| < \sqrt{p} \text{  and  } 0 < |y_0| < \sqrt{p}\]
\end{lemma}

\begin{theorem}[Fermant]
An odd prime $p$ is expressible as a sum of two squares if and only if $p \equiv 1 \pmod{4}$. 
\end{theorem}

\begin{corollary}
Any prime $p$ of the form $4k+1$ can be represented uniquely, up to order of the summands, as a sum of two squares. 
\end{corollary}

The following is a statement about representing integers as the \textit{difference} of two squares. 

\begin{theorem}
A positive integer $n$ can be represented as the difference of two squares if and only if $n$ is not of the form $4k + 2$. 
\end{theorem}
\begin{proof}
Because $a^2 \equiv 0, 1 \pmod{2}$ for integers $a$, it follows that
\[a^2 - b^2 \equiv 0, 1, 3 \pmod{4}\]
\end{proof}

\begin{corollary}
An odd prime is the difference of two successive squares. 
\end{corollary}
\begin{proof}
We can put $p$ in the form 
\[p = \bigg( \frac{p+1}{2} \bigg)^2 - \bigg( \frac{n-1}{2} \bigg)^2\]
\end{proof}

For example, 
\[11 = 6^2 - 5^2, \;\; 17 = 9^2 - 8^2, \;\; 29 = 15^2 - 14^2\]

\subsection{Sums of More Than Two Squares}
Expanding the allowed number of summands to three squares allows to broaden the amount of integers expressible as sums of squares. For example, 
\[14 = 3^2 + 2^2 + 1^2, \;\; 33 = 5^2 + 2^2 + 2^2, \;\; 67 = 7^2 + 3^2 + 3^2\]
But we can guarantee that there exists integers that are still not expressible as the sum of two squares. 

\begin{theorem}
No positive integer of the form $4^n (8m+7)$ can be represented as the sum of three squares. 
\end{theorem}
\begin{proof}
For any integer $a$, $a^2 \equiv 0, 1, 4 \pmod{8}$, which implies that
\[a^2 + b^2 + c^2 \equiv 0, 1, 2, 3, 4, 5, 6 \pmod{8}\]
for any integers $a, b, c$. So, there exist no solutions for $a^2 + b^2 + c^2 = 8m + 7$. Now, suppose that $n\geq 1$ and solutions exist to the equation
\[a^2 + b^2 + c^2 = 4^n (8m + 7)\]
Then, all three integers $a, b, c$ must be even (choosing exactly one to be even leads to an inconsistency when doing $\pmod{4}$). So, substituting, $a = 2 a_1, b = 2b_1, c= 2c_1$, we get 
\[a_1^2 + b_1^2 + c_1^2 = 4^{n-1} (8m+7)\]
We can do this until one of the $a_i, b_i$, or $c_i$ are odd or $n = 1$. In either case, this leads to a contradiction. 
\end{proof}

To prove that every number $p$ can be written as the sum of four squares, we need the following two lemmas. 

\begin{lemma}[Euler]
If the integers $m$ and $n$ are each the sum of four squares, then $m n$ is likewise representable as sums of four squares. 
\end{lemma}
\begin{proof}
A straightforward, yet tedious calculation shows this. 
\begin{align*}
    m n & = (a_1^2 + a_2^2 + a_3^2 + a_4^2) (b_1^2 + b_2^2 + b_3^2 + b_4^2) \\
    & = (a_1 b_1 + a_2 b_2 + a_3 b_3 + a_4 b_4)^2 \\
    & + (a_1 b_2 - a_2 b_1 + a_3 b_4 - a_4 b_3)^2 \\
    & + (a_1 b_3 - a_2 b_4 - a_3 b_1 + a_4 b_2)^2 \\
    & + (a_1 b_4 + a_2 b_3 - a_3 b_2 - a_4 b_1)^2
\end{align*}
\end{proof}

\begin{lemma}
If $p$ is an odd prime, then the congruence 
\[x^2 + y^2 + 1 \equiv 0 \pmod{p}\]
has a solution $x_0, y_0$ where 
\[0 \leq x_0 \leq (p-1)/2, \;\; 0 \leq y_0 \leq (p-1)/2\]
\end{lemma}

This leads to the theorem we've been waiting for. 

\begin{theorem}
Any prime $p$ can be written as the sum of four squares. 
\end{theorem}

By prime factorizing every number $n>1$ and using Euler's lemma, we get. 

\begin{corollary}[Lagrange]
Any positive integer $n$ can be written as the sum of four squares, some of which may be $0$. 
\end{corollary}

These results have a natural extension to sums of higher powers. In fact, the minimum number of $k$th powers needed to produce a representation of every natural number is denoted $g(k)$. 

\begin{theorem}
Every positive integer can be expressed as the sum of $9$ cubes. That is, $g(3) = 9$. 
\end{theorem}

However, only the numbers
\begin{align*}
    23 & = 2^3 + 2^3 + 1^3 + 1^3 + 1^3 + 1^3 + 1^3 + 1^3 + 1^3 \\
    239 & = 4^3 + 4^3 + 3^3+ 3^3 + 3^3 + 3^3 + 1^3 + 1^3 + 1^3 
\end{align*}
are the only integers that actually require as many as $9$ cubes in their representation. We can claim something even stronger.

\begin{proposition}[Linnik]
There are only a finite number of integers that require at least $8$ cubes in their represenations. 
\end{proposition}

\begin{theorem}
Every positive integer can be expressed as the sum of $53$ fourth powers. That is, $g(4) = 19$. Furthermore, $g(5) = 37$.  
\end{theorem}

For higher numbers $n$, the following result was proved. 

\begin{theorem}
For all but a finite number of integers $n \geq 6$, the following formula holds. 
\[g(k) = \bigg[ \bigg( \frac{3}{2} \bigg)^k \bigg] + 2^k - 2\]
However, there is strong evidence that this theorem holds for all $p$. 
\end{theorem}

\section{Fibonacci Numbers}

\begin{definition}
The \textit{Fibonacci sequence} is defined recursively as 
\[u_n = \begin{cases}
1 & n = 1, 2 \\
u_{n-1} + u_{n-2} & n \geq 3
\end{cases}\]
\end{definition}

The first few Fibonacci numbers are
\[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, ...\]

\begin{theorem}
In the Fibonnaci sequence, $\gcd(u_n, u_{n+1}) = 1$ for every $n\geq 1$. 
\end{theorem}
\begin{proof}
Suppose that $d >1 $ and that the integer $d$ divides both $u_n$ and $u_{n-1}$. Then, it divides $u_{n-2} = u_n - u_{n-1}$, and doing this recursively, this implies that $d | u_1$, which is false since $u_1 = 1$.
\end{proof}

\begin{proposition}
Except $u_1, u_2, u_6$, and $u_{12}$, each Fibonacci number has a "new" prime factor; that is, a prime factor that does not occur in any Fibonacci number with a smaller subscript. 
\end{proposition}

\begin{theorem}
For $m, n \geq 1$, $u_{mn}$ is divisible by $u_m$. 
\end{theorem}

\begin{theorem}
The greatest common divisor of two Fibonacci numbers is also a Fibonacci number. In fact, 
\[\gcd(u_m, u_n) = u_d, \text{ where } d = \gcd(n, m)\]
\end{theorem}


\begin{corollary}
In the Fibonacci sequence, $u_m \,|\, u_n$ if and only if $m|n$ for $n \geq m \geq 3$. 
\end{corollary}

The following theorem shows a result in expressing integers as sums of Fibonacci numbers. 

\begin{theorem}[Zeckendorf Representation]
Any positive integer $N$ can be expressed as a sum of distinct Fibonacci numbers, no two of which are consecutive. That is, 
\[N = u_{k_1} + u_{k_2} + ... + u_{k_r}\]
where $k_1 \geq 2$ and $k_{j+1} \geq k_j + 2$ for $j = 1, 2, ..., r-1$. 
\end{theorem}

Using linear algebra, the explicit representation of Fibonacci numbers is evident. 

\begin{theorem}[Binet's Formula]
For every Fibonacci number $u_n$, 
\[u_n = \frac{1}{\sqrt{5}} \Bigg( \bigg(\frac{1 + \sqrt{5}}{2} \bigg)^n - \bigg( \frac{1-\sqrt{5}}{2} \bigg)^n \Bigg) \implies u_n = \frac{\alpha^n - \beta^n}{\alpha - \beta}\]
where
\[\alpha = \frac{1 + \sqrt{5}}{2}, \; \beta = \frac{1-\sqrt{5}}{2}\]
\end{theorem}
\begin{proof}
The first formula can be found using linear algebra. 
\end{proof}

One useful application of Binet's formula is to produce new Fibonacci numbers from old ones. 

\begin{corollary}
We claim that
\[u_{n+2}^2 - u_n^2 = u_{2n+2}\]
\end{corollary}
\begin{proof}
Since $\alpha \beta = 1$, we have $(\alpha \beta)^{2k} = 1$, 
\begin{align*}
    u_{n+2}^2 - u_n^2 & = \bigg(\frac{ \alpha^{n+2} - \beta^{n+2}}{\alpha - \beta} \bigg)^2 - \bigg( \frac{\alpha^n - \beta^n}{\alpha - \beta}\bigg)^2 \\
    & = \frac{\alpha^{2(n+2)} - 2 + \beta^{2(n+2)}}{(\alpha - \beta)^2} - \frac{\alpha^{2n} - 2 + \beta^{2n}}{(\alpha - \beta)^2} \\
    & = \frac{\alpha^{2(n+2)} + \beta^{2(n+2)} - \alpha^{2n} - \beta^{2n}}{(\alpha-\beta)^2} \\
    & = \frac{(\alpha^2-\beta^2) (\alpha^{2n+2} - \beta^{2n+2})}{(\alpha-\beta)^2} \\
    & = \big( \alpha + \beta \big) \bigg( \frac{\alpha^{2n+2} - \beta^{2n+2}}{\alpha - \beta} \bigg) \\
    & = 1 \cdot u_{2n+2} = u_{2n+2}
\end{align*}
\end{proof}

Another one. 

\begin{corollary}
We claim that 
\[u_{2n+1} u_{2n-1} - 1 = u_{2n}^2\]
\end{corollary}
\begin{proof}
We calculate
\begin{align*}
    u_{2n+1} u_{2n-1} & = \bigg( \frac{\alpha^{2n+1} - \beta^{2n+1}}{\sqrt{5}}\bigg) \bigg( \frac{\alpha^{2n-1} - \beta^{2n-1}}{\sqrt{5}}\bigg) - 1 \\
    & = \frac{1}{5} \big( \alpha^{4n} + \beta^{4n} - (\alpha \beta)^{2n-1} \alpha^2 - (\alpha \beta)^{2n-1} \beta^2 - 5 \big) \\
    & = \frac{1}{5} \big( \alpha^{4n} + \beta^{4n} + (\alpha^2 + \beta^2) - 5 \big)
\end{align*}
Since $\alpha^2 + \beta^2 = 3$, we have 
\begin{align*}
    \frac{1}{5} \big( \alpha^{4n} + \beta^{4n} - 2 \big) & = \frac{1}{5} \big( \alpha^{4n} + \beta^{4n} - 2 (\alpha \beta)^{2n} \big) \\
    & = \bigg( \frac{\alpha^{2n} - \beta^{2n}}{\sqrt{5}} \bigg)^2 = u_{2n}^2
\end{align*}
\end{proof}

\begin{corollary}
Binet's formula can be modified to
\[u_n = \bigg[ \frac{\alpha^n}{\sqrt{5}} + \frac{1}{2} \bigg]\]
\end{corollary}
\begin{proof}
Since $0<|\beta|<1$, we see that 
\[|\beta^n| = |\beta|^n < 1 \text{ for } n \geq 1\]
Therefore, we have 
\begin{align*}
    \bigg| u_n - \frac{\alpha^n}{\sqrt{5}} \bigg| & = \bigg| \frac{\alpha^n - \beta^n}{\sqrt{5}} - \frac{\alpha^n}{\sqrt{5}} \bigg| \\
    & = \frac{|\beta^n|}{\sqrt{5}} < \frac{1}{\sqrt{5}} < \frac{1}{2}
\end{align*}
Therefore, we can view $u_n$ as the largest integer not exceeding $\frac{\alpha^n}{\sqrt{5}} + \frac{1}{2}$, leading to the formula 
\[u_n = \bigg[ \frac{\alpha^n}{\sqrt{5}} + \frac{1}{2} \bigg]\]
\end{proof}

We also introduce two final theorems concerning prime factors of Fibonacci numbers. 

\begin{theorem}
For any prime $p > 5$, either 
\[p\,|\,u_{p-1} \text{ or } p \,|\, u_{p+1}\]
but not both. 
\end{theorem}

\begin{theorem}
Let $p\geq 7$ be a prime for which $p \equiv 2 \pmod{5}$ of $p \equiv 4 \pmod{5}$. If $2p-1$ is also prime, then 
\[(2p-1)\,\big|\, u_p\]
\end{theorem}

\begin{example}
$u_19 = 37 \cdot 113$, where $19 \equiv 4 \pmod{5}$. $u_{37} = 73 \cdot 330929$, where $37 \equiv 2 \pmod{5}$. 
\end{example}
\section{Continued Fractions}
\begin{definition}
A \textit{partition} of a positive integer $n$ is a way of writing $n$ as a sum of positive integers, with order being irrelevant.. Let $p(n)$ denote the total number of partitions of $n$. 
\end{definition}

\begin{example}
The 
\end{example}

\begin{theorem}[Hardy-Ramanujan]
For large $n$, the partition function satisfies the relation
\[p(n) \approx \frac{e^{c\sqrt{n}}}{4n \sqrt{3}}, \;\;\; c = \pi \sqrt{\frac{2}{3}}\]
\end{theorem}

\begin{proposition}[Ramanujan]
With the partition function $p$ and any integer $n$, we have
\begin{align}
    & p(5k+4) \equiv 0 \pmod{5} \\
    & p(7k+5) \equiv 0 \pmod{7} \\
    & p(11k+6) \equiv 0 \pmod{11}
\end{align}
\end{proposition}


\begin{proposition}[Ramanujan]
The constant $\pi$ can be calculated with the infinite series.
\[\frac{1}{\pi} = \frac{\sqrt{8}}{9801} \sum_{n=0}^\infty \frac{(4n)!}{(n!)^4} \, \frac{[1103 + 26390n]}{396^{4n}}\]
Each successive term in the series adds roughly 8 more correct digits! The efficiency of this series has made it possible to calculate millions of digits of $\pi$. Another series is 
\[\frac{1}{\pi} = \sum_{n=0}^\infty {{2n}\choose{n}}^3 \; \frac{42n + 5}{2^{12n+4}}\]
\end{proposition}


\subsection{Finite Continued Fractions}

\begin{definition}
A \textit{finite continued fraction} is an expression of the form 
\[a_0 + \cfrac{1}{a_1 + \cfrac{1}{... + \cfrac{...}{a_{n-1} + \cfrac{1}{a_n}}}}\]
where $a_0, a_1, ..., a_n$ are all real numbers, all of which except possible $a_0$ are positive. The $a_k$'s are called the \textit{partial denominators} of this fraction. If the $a_k$'s are all integers, then the fraction is called a \textit{simple finite continued fraction}. 
\end{definition}

\begin{theorem}
Any rational number can be written as a finite simple continued fraction with the algorithm presented in the proof. 
\end{theorem}
\begin{proof}
Let $a/b$, where $b >0$ be an arbitrary rational number. Euclid's algorithm for finding the greatest common divisor of $a$ and $b$ gives us the equations 
\begin{align*}
    &a = b a_0 + r_1 & 0 < r_1 < b \\
    &b = r_1 a_1 + r_2 & 0 < r_2 < r_1 \\
    &r_1 = r_2 a_2 + r_3 & 0 < r_3 < r_2 \\
    &... & ... \\
    &r_{n-1} = r_{n-1} a_{n-1} + r_n & 0 < r_n < r_{n-1} \\
    &r_{n-1} = r_n a_n + 0 & 
\end{align*}
We can rewrite it in the following way. 
\begin{align*}
    \frac{a}{b} &= a_0 + \frac{r_1}{b} = a_0 + \frac{1}{\frac{b}{r_1}} \\
    \frac{b}{r_1} &= a_1 + \frac{r_2}{r_1} = a_1 + \frac{1}{\frac{r_1}{r_2}} \\
    \frac{r_1}{r_2} &= a_2 + \frac{r_3}{r_2} = a_2 + \frac{1}{\frac{r_2}{r_3}} \\
    ... & = ... \\
    \frac{r_{n-1}}{r_n} &= a_n
\end{align*}
Then by substituting the equations below to the one above it starting from the third equation, we can get
\[\frac{a}{b} = a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{\cfrac{r_2}{r_3}}}}\]
Continuing in from the bottom equation, we get
\[\frac{a}{b} = a_0 + \cfrac{1}{a_1 + \cfrac{1}{... + \cfrac{...}{a_{n-1} + \cfrac{1}{a_n}}}}\]
\end{proof}

\begin{example}
We find the representation of $19/51$ as a continued fraction. We use Euclid's algorithm to get
\begin{align*}
    51 = 2 \cdot 19 + 13 \implies \frac{51}{19} = 2 + \frac{13}{19} \\
    19 = 1 \cdot 13 + 6 \implies \frac{19}{13} = 1 + \frac{6}{13} \\
    13 = 2 \cdot 6 + 1 \implies \frac{13}{6} = 2 + \frac{1}{6} \\
    6 = 6 \cdot 1 + 0 \implies \frac{6}{6} = 1
\end{align*}
After the substitutions, we get
\begin{align*}
    \frac{19}{51} = \frac{1}{\frac{51}{9}} & = \cfrac{1}{2 + \frac{13}{19}} \\
    & = ... \\
    & = \cfrac{1}{2 + \cfrac{1}{1 + \cfrac{1}{2 + \cfrac{1}{6}}}}
\end{align*}
\end{example}

\begin{definition}
The continued fraction made from $[a_0;a_1, a_2, ... a_n]$ by cutting off the expansion after the $k$th partial denominator $a_k$ is called the \textit{$k$th convergent} of the given continued fraction and denoted by $C_k$. That is, 
\[C_k = [a_0;a_1, a_2, ..., a_k], \;\; 1 \leq k \leq n\]
\end{definition}

Much of the labor of computing convergents of a finite continued fraction can be avoided by establishing certain formulas for their numerators and denominators. 

\begin{theorem}
Given a finite continued fraction $[a_0; a_1, a_2, ..., a_n]$, let 
\begin{align*}
    &p_0 = p_0 & &q_0 = 1 \\
    &p_1 = a_1 a_0 + 1 & &q_1 = a_1 \\
    &p_k = a_k p_{k-1} + p_{k-2} & &q_k = a_k q_{k-1} + q_{k-2} 
\end{align*}
for $k = 2, 3, ..., n$. Then, the $k$th convergent of the fraction has the value 
\[C_k = \frac{p_k}{q_k}, \; k = 0, 1, ..., n\]
\end{theorem}
\begin{proof}
We can manually check that this is true for $k = 0, 1, 2$. Assume that it is true for $k=m$, where $2 \leq m$. Then, 
\[C_m = \frac{p_m}{q_m} = \frac{a_m p_{m-1} + p_{m-2}}{a_m q_{m-1} + q_{m-2}}\]
Note that the integers $p_{m-1}, q_{m-1}, p_{m-2}, q_{m-2}$ depend on the first $m-1$ partial denominators $a_1, a_2, ..., a_{m-1}$ and there are independent of the value of $a_m$. The equation above therefore remains true if we replace $a_m$ with $a_m + \frac{1}{a_{m+1}}$. 
\[\Big[a_0;a_1, a_2, ..., a_m + \frac{1}{a_{m+1}} \Big] = \frac{\Big( a_m + \frac{1}{a_{m+1}} \Big) p_{m-1} + p_{m-2}}{\Big( a_m + \frac{1}{a_{m+1}} \Big) q_{m-1} + q_{m-2}}\]
But this above $m$th convergent is really just equal to the $(m+1)$th convergent $C_{m+1}$ since the final term on the bottom of the continued fraction is replaced with one more continuation. This means that
\begin{align*}
    C_{m+1} & = \frac{\Big( a_m + \frac{1}{a_{m+1}} \Big) p_{m-1} + p_{m-2}}{\Big( a_m + \frac{1}{a_{m+1}} \Big) q_{m-1} + q_{m-2}} \\
    & = \frac{a_{m+1} (a_m p_{m-1} + p_{m-2}) + p_{m-1}}{a_{m+1} (a_m q_m + q_{m-2}) + q_{m-1}} \\ 
    & = \frac{a_{m+1} p_m + p_{m-1}}{a_{m+1} q_m + q_{m-1}}
\end{align*}
Which is the desired formula for $C_{m+1}$. So, the equation is satisfied at $k=m+1$. 
\end{proof}

\begin{theorem}
If $C_k = p_k / q_k$ is the $k$th convergent of the finite simple continued fraction $[a_0; a_1, a_2, ..., a_n]$, then 
\[p_k q_{k-1} - q_k p_{k-1} = (-1)^{k-1}, \;\; 1\leq k \leq n\]
\end{theorem}
\begin{proof}
We use induction on $k$. The base case for $k=1$ holds true since
\[p_1 q_0 - q_1 p_0 = (a_1 a_0 + 1) \cdot 1 - a_1 \cdot a_0 = 1 = (-1)^{1-1}\]
Now, assuming that the formula is true for some $k = m$, then 
\begin{align*}
    p_{m+1} q_m - q_{m+1} p_m & = (a_{m+1} p_m + p_{m-1}) q_m - (a_{m+1} q_m + q_{m-1}) p_m \\
    & = - (p_m q_{m-1} - q_m p_{m-1}) \\
    & = - (-1)^{m-1} = (-1)^m
\end{align*}
\end{proof}

\begin{corollary}
For $1 \leq k \leq n$, $p_k$ and $q_k$ are relatively prime. 
\end{corollary}
\begin{proof}
If $d = \gcd(p_k, q_k) \neq 1$, then this implies that the left hand side has factor $d$, which must mean that the right hand side also has factor $d$. But the right hand side is $\pm 1$, leading to a contradiction. 
\end{proof}

\begin{example}
Consider the continued fraction $[0;1,1,...,1]$. The first few convergents are
\[C_0 = 0/1, \; C_1 = 1/1, \; C_2 = 1/2, \; C_3 = 2/3, \; C_4 = 3/5, \; ...\]
Because the numerator $p_k$ and denominator $q_k$ of the $k$th convergent is expressed
\begin{align*}
    p_k & = 1 \cdot p_{k-1} + p_{k-2} = p_{k-1} + p_{k-2} \\
    q_k & = 1 \cdot q_{k-1} + q_{k-2} = q_{k-1} + q_{k-2}
\end{align*}
we can see that the numerator and denominator forms a Fibonacci sequence. That is, 
\[C_k = \frac{u_k}{u_{k+1}}, \;\; k \geq 2\]
where $u_k$ denotes the $k$th Fibonacci number. 
\end{example}

Here is another useful property of convergents.

\begin{lemma}
If $q_k$ is the denominator of the $k$th convergent $C_k$ of the simple continued fraction $[a_0; a_1, ..., a_n]$, then $q_{k-1} \leq q_k$ for $1 \leq k \leq n$, with strict inequality satisfied when $k >1$. 
\end{lemma}
\begin{proof}
We prove by induction. When $k=1$, 
\[q_0 = 1 \leq a_1 = q_1\]
Assume that it is true for $k=m$. Then, 
\[q_{m+1} = a_{m+1} q_m + q_{m-1} > a_{m+1} q_m \geq 1 \cdot q_m = q_m\]
which implies that the inequality is true for $k = m+1$. 
\end{proof}

\begin{theorem}
The convergents with even subscripts form a strictly increasing sequence. 
\[C_0 < C_2 < C_4 < ... \]
The convergents with odd subscripts form a strictly decreasing sequence. 
\[C_1 > C_3 > C_5 > ...\]
Every convergent with an odd subscript is greater than every convergent with an even subscript. 
\end{theorem}
\begin{proof}
Using the previous theorems, we calculate that
\begin{align*}
    C_{k+2} - C_k & = (C_{k+2} - C_{k+1}) + (C_{k+1} - C_k )\\
    & = \bigg( \frac{p_{k+2}}{q_{k+2}} - \frac{p_{k+1}}{q_{k+1}} \bigg) + \bigg( \frac{p_{k+1}}{q_{k+1}} - \frac{p_{k}}{q_{k}} \bigg) \\
    & = \frac{(-1)^{k+1}}{q_{k+2} q_{k+1}} + \frac{(-1)^k}{q_{k+1} q_k} \\
    & = \frac{(-1)^k (q_{k+2} - q_k)}{q_k q_{k+1} q_{k+2}}
\end{align*}
Since $q_k > 0$ for all $k$ and by using the previous lemma that $q_{k+2} - q_k > 0$, $C_{k+2} - C_{k}$ has the same algebraic sign as $(-1)^k$. So, 
\begin{enumerate}
    \item If $k$ is even, then $C_{k+2} - C_{k}$ has the same sign as $1$ and is thus positive, which means that
    \[C_0 < C_2 < C_4 < ... \]
    \item If $k$ is odd, then $C_{k+2} - C_k$ has the same sign as $-1$ and is thus negative, which means that
    \[C_1 > C_3 > C_5 > ...\]
\end{enumerate}
To show that any odd numbered convergent $C_{2r-1}$ is greater than any even numbered convergent $C_{2s}$, we divide the equation $p_k q_{k-1} - q_k p_{k-1} = (-1)^{k-1}$ by $q_k q_{k-1}$ to get
\[C_k - C_{k-1} = \frac{p_k}{q_k} - \frac{p_{k-1}}{q_{k-1}} = \frac{(-1)^{k-1}}{q_k q_{k-1}}\]
This means that $C_{2j} < C_{2j-1}$. Therefore, we can put together various inequalities and combine our results so far to get
\[C_{2s} < C_{2s+2r} < C_{2s+2r-1} < C_{2r-1}\]
\end{proof}

From this, we can see that subsequent convergents alternatingly underestimate and overestimate the true value of the rational number $n$. 


\subsection{Infinite Continued Fractions}

\begin{definition}
An \textit{infinite continued fraction} is an expression of the form 
\[a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + ...}}}\]
where $a_0, a_1, a_2, ...$ and $b_1, b_2, b_3, ...$ are real numbers. An \textit{infinite simply continued fraction} has form 
\[a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{a_3 + ...}}}\]
which, for compactness, is denoted $[a_0;a_1, a_2, a_3, ...]$. If $a_0, a_1, ...$ is an infinite sequence of integers, all positive except possibly $a_0$, then the infinite simple continued fraction $[a_0; a_1, a_2, ...]$ has the value 
\[\lim_{n \rightarrow \infty} [a_0 ; a_1, a_2, ..., a_n]\]
\end{definition}

\begin{proposition}[Brouncker]
The infinite product 
\[\frac{4}{\pi} = \frac{3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdot 7 \cdot ...}{2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdot 8 \cdot ...}\]
can be converted into the identity
\[\frac{4}{\pi} = 1 + \cfrac{1^2}{2 + \cfrac{3^2}{2 + \cfrac{5^2} {2+\cfrac{7^2}{2+...}}}}\]
\end{proposition}
However, this calculation is not computationally efficient. 

\begin{proposition}[Ramanujan]
\[e^{2\pi/5} \bigg( \sqrt{\frac{5+\sqrt{5}}{2}} - \frac{1+\sqrt{5}}{2} \bigg) = \cfrac{1}{1 + \cfrac{e^{-2\pi}}{1+\cfrac{e^{-4\pi}}{1+\cfrac{e^{-6\pi}}{1+...}}}}\]
\end{proposition}

\begin{definition}
If an infinite simple continued fraction contains a block of partial denominators $a_1, a_2, ..., a_r$, then we can write it as
\[[a_0; \overline{a_1, a_2, ..., a_n}]\]
\end{definition}

\begin{theorem}
The value of any infinite continued fraction is an irrational number. 
\end{theorem}

\begin{theorem}
Two infinite continued fractions $[a_0; a_1, a_2, ...]$ and $[b_0; b_1, b_2, ...]$ are equal if and only if $a_i = b_i$ for $i = 0, 1, 2, ...$. 
\end{theorem}

\begin{corollary}
Two distinct infinite continued fractions represent two distinct irrational numbers. 
\end{corollary}

\begin{theorem}
Every irrational number has a unique representation as an infinite continued fraction, the representation being obtained from the continued fraction algorithm described in the following proof. 
\end{theorem}
\begin{proof} Given an arbitrary irrational number $x_0$, we would want to identify it with a certain sequence $[a_0; a_1, a_2, ...]$ such that the continued fraction determined by the sequence $x_0$. We first define 
\[x_1 = \frac{1}{x_0 - [x_0]}, \;\; x_2 = \frac{1}{x_1 - [x_1]}, \;\; x_3 = \frac{1}{x_2 - [x_2]}, ...\]
and then take 
\[a_0 = [x_0], \;\; a_1 = [x_1], \;\; a_2 = [x_2], \;\; a_3 = [x_3], ...\]
In general, the $a_k$ are given inductively by
\[a_k = [x_k], \;\; x_{k+1} = \frac{1}{x_k - a_k}\]
Clearly, $x_{k+1}$ is irrational if $x_k$ is irrational. Since $x_0$ is irrational, every $x_k$ is irrational. Thus, 
\[0 < x_k  - a_k = x_k - [x_k] < 1 \implies x_{k+1} = \frac{1}{x_k - a_k} > 1\]
with $a_{k+1} = [x_{k+1}] \geq 1$ for all $k \geq 0$. This leads to an infinite sequence of integers $a_0, a_1, ...$, all positive except possibly for $a_0$. Now, by defining $x_k$ in the form 
\[x_k = a_k + \frac{1}{x_{k+1}}\]
through successive substitutions, we get
\begin{align*}
    x_0 & = a_0 + \frac{1}{x_1} \\ 
    & = a_0 + \cfrac{1}{a_1 + \cfrac{1}{x_2}} \\
    & = a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{x_3}}} \\
    & = ... \\
    & = [a_0 ; a_1, a_2, ..., a_n, x_{n+1}]
\end{align*}
\end{proof}

\begin{corollary}
If $p_n / q_n$ is the $n$ convergent to the irrational number $x$, then 
\[\bigg| x - \frac{p_n}{q_n} \bigg| < \frac{1}{q_{n+1} q_n} < \frac{1}{q_n^2}\]
\end{corollary}

Combining these results, we can see that the following map 
\[\rho: \mathbb{Z}^\omega \longrightarrow \mathbb{R} \setminus \mathbb{Z}\]
that maps sequences to infinite continued fractions is bijective. 

\begin{example}
To calculate the infinite fraction form of $\pi = 3.141592...$, we use the algorithm to get
\begin{align*}
    &x_0 = \pi = 3 + (\pi-3) & a_0 = 3 \\
    &x_1 = \frac{1}{x_0 - [x_0]} = \frac{1}{0.14159265...} = 7.06251330... & a_1 = 7\\
    &x_2 = \frac{1}{x_1 - [x_1]} = \frac{1}{0.06251330...} = 15.99659440... & a_2 = 15\\
    &x_3 = \frac{1}{x_2 - [x_2]} = \frac{1}{0.99659440...} = 1.00341723... & a_3 = 1\\
    &x_4 = \frac{1}{x_3 - [x_3]} = \frac{1}{0.00341723...} = 292.63467... & a_4 = 292\\
    & ... & ...
\end{align*}
Thus, the infinite continued fraction for $\pi$ starts with 
\[\pi = [3;7, 15, 1, 292, ...]\]
But unlike most irrational numbers, there is no explicit pattern that gives a complete sequence of $a_n$. 
\end{example}

\begin{proposition}[Euler]
Here are nice representations of $e = 2.71828...$, which does have a pattern of even integers occurring in order and separated by two $1$'s. 
\[e = [2; 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, ...]\]
Moreover, the following representations have partial denominators that form an arithmetic progression. 
\begin{align*}
    & \frac{e-1}{e+1} = [0;2, 6, 10, 14, 18, ...]
    & \frac{e^2 - 1}{e^2 + 1} = [0; 1, 3, 5, 7, 9, ...]
\end{align*}
\end{proposition}

\chapter{Point Set Topology}
\section{Open Sets}
\subsection{Basis of Topologies}
\begin{definition}[Topology]
Let $X$ be a set and $\tau$ be a family of subsets of $X$. Then $\tau$ is a \textit{topology} on $X$ if: 
\begin{enumerate}
    \item $\emptyset, X \in \tau$
    \item $x_1, x_2, ..., x_n \in \tau \implies \bigcup_{i = 1}^{n} x_{i} \in \tau$ for arbitrary (not necessarily finite) $n$
    \item $\bigcap_{i=1}^{m} \in \tau$ for finite $m$. 
\end{enumerate}
A \textit{topological space} is denoted $(X, \tau)$ or $X_{\tau}$. The elements of $\tau$ are called \textit{open sets} in $X$. As implied from the definition of a topology, the union and finite intersection of any number of open sets is an open set. 
\end{definition}

Note that we restrict property 3 to be a \textit{finite} intersection because if we don't, the open ball topology on $\mathbb{R}$ would imply that 
\[ \bigcap_{i = 1}^{\infty} \Big( - \frac{1}{i}, \frac{1}{i} \Big) = 0\]
is an open set $\implies$ all points are open sets too, which can be troublesome for later purposes. 

\begin{example}[Topologies of a Set of Cardinality 3]
There are a total of 29 topologies that we can construct on $\{1, 2, 3\}$. Two such examples are 
\[\{\emptyset, \{1, 2\}, \{1, 2, 3\}\} \text{ and } \{\emptyset, 3, \{2, 3\}, \{1, 2, 3\}\}\]
\end{example}

\begin{example}
The \textit{open ball topology} on $\mathbb{R}^{n}$ include all open balls of form: 
\[ B_{r}(p) = \{ x \in \mathbb{R}^{n} \; | \; |x-p| < r \} \]
This is the usual topology in $\mathbb{R}^{n}$. It turns out that since all open balls are in $\tau_{\mathbb{R}^{2}}$, we can build any shape using the union/intersections of these open balls, such as an open square. Thus all open subsets in $\mathbb{R}^{n}$ are open sets. 
\end{example}

\begin{definition}
If $X$ is a set, a \textit{basis} for a topology on $X$ is a collection $\mathscr{B}$ of subsets of $X$ (called \textit{basis elements}) such that
\begin{enumerate}
    \item For each $x \in X$, there is at least one basis element $b \in \mathscr{B}$ containing $x$. That is, the elements of $\mathscr{B}$ covers $X$. 
    \item If $x$ belongs to the intersection of two basis elements $b_1$ and $b_2$, then there is a basis element $b_3$ containing $x$ such that $b_3 \subset (b_1 \cap b_2)$. 
\end{enumerate}
\begin{center}
    \begin{tikzpicture}
    \draw[dashed] plot [smooth cycle] coordinates {(0,0) (1.5,1) (3,0) (1.5,-1)};
    \draw[dashed] plot [smooth cycle] coordinates {(1.5,0) (3,1) (4.5,0) (3,-1)};
    \node [right] at (3,0) {$b_2$};
    \node [left] at (1.5,0) {$b_1$};
    \draw [fill=lightgray, dashed] (2.25,0) circle [radius=0.4];
    \node [right] at (2,0) {$x$};
    \draw [fill] (2.4,0) circle [radius=0.05];
    \node [above] at (2,1) {$b_3$};
    \draw (2.25,0.2) -- (2,1);
    \end{tikzpicture}
\end{center}
\end{definition}

\begin{definition}
If $\mathscr{B}$ is a basis for a topology on $X$, the \textit{topology $\tau$ generated by $\mathscr{B}$} is described as follows. A subset $U$ of $X$ is open if for each $x \in U$, there is a basis element $b \in \mathscr{B}$ such that $x \in b \subset U$. 
\end{definition}
\begin{center}
    \begin{tikzpicture}
    \draw[dashed] plot [smooth cycle] coordinates {(0,0) (1,1) (3,1) (3,0) (1,-1)};
    \node [right] at (0.5,0) {U};
    \draw[fill=lightgray,dashed] (2,0.7) circle [radius=0.35];
    \draw[fill] (2, 0.7) circle [radius=0.05];
    \node [right] at (1.95,0.7) {x};
    \node [right] at (4,-0.5) {b};
    \draw (1.95,0.6)--(4,-0.5);
    \end{tikzpicture}
\end{center}

Let us check that the collection $\tau$ generated by the basis $\mathscr{B}$ is indeed a topology on $X$. Clearly, $\emptyset$ and $X$ itself are in $\tau$. 
\\

To prove property 2, given a certain indexed family of subsets $\{U_\alpha\}_{\alpha \in I}$ of $\tau$, we must show that 
\[U = \bigcup_{\alpha \in I} U_\alpha \in \tau\]
Given $x \in U$, there exists at least one index $\alpha$ such that $x \in U_\alpha$. Since $U_\alpha \in \tau$ already, there exists a basis element $b \in \mathscr{B}$ such that $x \in b \subset U_\alpha$. But 
\[U_\alpha \subseteq U \implies b \subset U\]
So, by definition, any arbitrary union of $U$ of these subsets is also in $\tau$. 
\\

To prove property 3, we must show that 
\[W = \bigcap_{\alpha \in I} U_\alpha \in \tau\]
Given $x \in W$, by definition of a basis element, there exists a $b \in \mathscr{B}$ such that 
\[x \in b \subset (U_\beta \cap U_\gamma) \forall \beta, \gamma \in I \implies \text{ there exists } \Tilde{b} \in \mathscr{B} \text{ s.t. } x \in \Tilde{b} \subset \bigcap_{\alpha \in I} U_\alpha\]
By definition, $W$ is also open. Since this arbitrary set of subsets $\tau$ suffices the 3 properties, it is a topology of $X$ by definition. 
\\

We can construct an alternative definition of a basis with the following lemma. 

\begin{lemma}
$\mathscr{B}$ is a basis for topology $\tau$ of $X$ if and only if $\tau$ is the collection of all unions of elements in $\mathscr{B}$. That is, 
\[\tau \equiv \Big\{ \bigcup_i b_i \; \Big| \; b_i \in \mathscr{B}\Big\}\]
\end{lemma}
\begin{proof}
$(\rightarrow)$ Given a collection of elements in $\mathscr{B}$, they are also elements of $\tau$. Since $\tau$ is a topology, their union in also in $\tau$. \\
$(\leftarrow)$ Given an open set $U \in \tau$, for every point $x \in U$, by definition we can choose a basis element $b \in \mathscr{B}$ such that $x \in b \subset U$. Then, the union of all these basis elements is by definition $b$. 
\end{proof}

\begin{definition}
Suppose that $\tau$ and $\tau^\prime$ are two topologies on a given set $X$. If $\tau \subset \tau^\prime$, we say that $\tau^\prime$ is \textit{finer} than $\tau$, or equivalently, we say that $\tau$ is \textit{coarser} than $\tau^\prime$. 
\end{definition}
We can think of the topology of a set $X$ as a truck full of gravel as the open sets. If the gravel is smashed into smaller, finer pieces, then the amount of stuff that we can make from the finer gravel increases, which corresponds to a bigger topology. The trivial topology is the coarsest topology and the discrete topology is the finest. 

\begin{lemma}
Given two topologies $\tau$ and $\tau^\prime$ with their bases $\mathscr{B}$ and $\mathscr{B}^\prime$, respectively, the following are equivalent. 
\begin{enumerate}
    \item $\tau^\prime$ is finer than $\tau$. 
    \item For each $x \in X$ and basis element $b \in \mathscr{B}$ containing $x$, there exists a basis element $b^\prime \in \mathscr{B}^\prime$ such that $x \in b^\prime \subset b$. 
\end{enumerate}
\end{lemma}

\begin{example}
The set of all open balls $B_r (x)$ with $r, x \in \mathbb{R}$ of $\mathbb{R}^n$ is the basis of the open ball topology. 

The set of all open boxes in $\mathbb{R}^{n}$ of the form 
\[\prod_{i=1}^n [\alpha_i, \beta_i], \; \alpha_i, \beta_i \in \mathbb{R} \]
forms a basis of $\tau_{\mathbb{R}^{n}}$. Note that both of these bases generate the same topology. 
\end{example}

\begin{definition}
The \textit{trivial topology} of $X$ is $\{\emptyset, X\}$. The \textit{discrete topology} has a basis consisting of all points in $X$. This is the maximal topology of $X$, consisting of \textit{all} subsets of $X$. $\tau$ is denoted $2^{X}$, called the \textit{power set}.
\end{definition}

It is not hard to see that every basis uniquely determines a topology. We have learned how to go from a basis to a topology. The following lemma tells us how to identify a basis within a topology. 

\begin{lemma}
Let $X$ be a topological space, and let $\mathcal{C}$ be a collection of subsets of $X$ such that for every open set $U$ and each $x \in U$, there exists an element $c \in \mathcal{C}$ such that
\[x \in c \subset U\]
Then, $\mathcal{C}$ is a basis for the topology of $X$. 
\end{lemma}

\begin{definition}
An open set of $X$ which contains a point $x$ is called an \textit{open neighborhood} of $x$, denoted $U_x$. 
\end{definition}

\subsection{Closed Sets, Limit Points}
\begin{definition}
The complement of an open set is a \textit{closed set}. That is, given $x \in \tau_{X}, X \setminus x$ is a closed set. Note that open and closed sets are not mutually exclusive. A set might be open, closed, both, or neither. A set that is both open and closed is called \textit{clopen}.
\end{definition}

\begin{example}
A point $p$ in $\mathbb{R}^{n}$ is a closed set, since the set $\mathbb{R}^{n} \setminus \{p\}$ can be produced using a infinite union of open balls. 
\end{example}

\begin{example}
Every subset of $X$ with the discrete topology is clopen.
\end{example}

\begin{theorem}
Let $X$ be a topological space. Then, the following conditions hold
\begin{enumerate}
    \item $\emptyset$ and $X$ are clopen.
    \item Arbitrary intersections of closed sets are closed. 
    \item Finite unions of closed sets are closed. 
\end{enumerate}
\end{theorem}

\begin{definition}
Let $p$ be a point, $S$ a subset. $p$ is a \textit{limit point} of $S$ if every open neighborhood of $p$ intersects $S$ at at least one one point. Clearly, every point in $S$ is a boundary point. Additionally, the "boundary points" of an open set in $\mathbb{R}^2$ are all limit points since every open neighborhood of a boundary point has a nontrivial intersection with $S$. 
\\
\begin{center}
    \begin{tikzpicture}
    \draw[fill=lightgray, dashed] plot [smooth cycle] coordinates {(0,0) (1,1) (3,1) (3,0) (1,-1)};
    \draw [fill] (3, 1) circle [radius=0.05];
    \node [above right] at (3,1) {A};
    \draw [fill] (2,0) circle [radius=0.05];
    \node [above] at (2,0) {B};
    \draw [fill] (0,0) circle [radius=0.05];
    \node [left] at (0,0) {C};
    \draw [fill] (5,0) circle [radius=0.05];
    \node [right] at (5, 0) {D};
    \end{tikzpicture}
\end{center}
Points $A, B, C$ are limit points of the open set. However, point $D$ is not a limit point. Note that if $S$ is a sequence of points in $\mathbb{R}^{2}$ that converges to $p$ without ever hitting it, we can say that $p \not\in S$ is a limit point of $S$. 
\begin{center}
    \begin{tikzpicture}
    \draw [fill] (0, 2.2) circle [radius=0.05];
    \draw [fill] (1, 2.4) circle [radius=0.05];
    \draw [fill] (2, 2) circle [radius=0.05];
    \draw [fill] (2.5, 1.8) circle [radius=0.05];
    \draw [fill] (2.6, 1.6) circle [radius=0.05];
    \draw [fill] (2.65, 1.67) circle [radius=0.05];
    \draw [fill] (2.654, 1.64) circle [radius=0.05];
    \draw [fill] (2.6543, 1.63) circle [radius=0.05];
    \node [right] at (2.6543, 1.63) {p};
    \end{tikzpicture}
\end{center}
\end{definition}

\begin{definition}
The \textit{closure} of set $S \subseteq (X, \tau_{x})$, denoted $\Bar{S}$, is defined as 
\[ S \bigcup \{\text{all of its limit points}\} \]
\end{definition}

\begin{example}
If $S$ is an open ball, $\Bar{S}$ is the closed ball. 
\end{example}

\begin{definition}
The point $p$ is in the \textit{interior} of a set $S$ if we can find an open neighborhood $U_p \subseteq S$. It is denoted $S^{o}$. Furthermore, the union of all open sets in $S$ is $S^{o}$. 
\end{definition}

\begin{proposition}
$S$ is open if and only if $S = S^{o}$. $S^{o}$ is always open.
\end{proposition}

\begin{theorem}
The interior $S^{o}$ is the complement of the closure of the complement of S. \[ S^{o} = \big(\overline{S^{c}}\big)^{c}\]
\end{theorem}

\begin{definition}
The \textit{exterior} of a set $S$ is the complement of the closure, i.e. "strictly outside of $S$ and its boundary."
\end{definition}

\begin{definition}
The \textit{boundary} of a set $S$, denoted $\partial S$, is the set of points that are neither in the exterior nor the interior, i.e. in the closure, but not the interior of $S$. $p$ is on the \textit{boundary} of the set $S$ if every neighborhood of $p$ intersects the interior and exterior of $S$.  
\end{definition}

\begin{theorem}
Let $Y$ be a subspace of $X$ with $A$ a subset of $Y$. Let $\bar{A}$ denote the closure of $A$ in $X$. Then, the closure of $A$ in $Y$ equals $\bar{A} \cap Y$. 
\end{theorem}

\begin{theorem}
A subset of a topological space is closed if and only if it contains all of its limit points. That is, 
\[S = \bar{S}\]
\end{theorem}

\begin{definition}
Let $S \subset (X, \tau_X)$. $S$ is \textit{dense} in $X$ if every point $p \in X$ is a limit point of $S$. In other words, for any point $p \in X$ and any open neighborhood $U_p$ of $p$, $U_p \cap S$ is nontrivial. Otherwise, $p$ is a point of $S$. 
\end{definition}

The following example is a crucial fact for proving further properties of topological spaces. 

\begin{example}
$\mathbb{Q}^{n}$ is a dense set of $\mathbb{R}^{n}$ with the open ball topology. If we have the discrete topology of $\mathbb{R}^{2}$, an open neighborhood of a point is the point itself, so no limit points would exist beyond the points in $S$ itself. So $\mathbb{Q}^{n}$ is not dense in $\mathbb{R}^{n}$ with this topology. 
\end{example}

\subsection{Topologies of a Line Segment}
\begin{definition}[Open Ball Topology on Line]
The \textit{open ball topology}, which is the usual Euclidean topology, has already been explained, which we will denote $\tau_{E}$. 
\begin{center}
    \includegraphics[scale=0.25]{Open_Ball_Topology_on_Line.PNG}
\end{center}
\end{definition}

\begin{definition}[Nested Interval Topology on $(0,1)$]
In the set $X = (0,1)$, the basis of the \textit{nested interval topology} is 
\[ \Big\{ (0, 1-\frac{1}{n}) \; | \; n = 2, 3, ..., \infty \Big\} \]
In fact, the basis is equivalent to the topology itself! This topology will be denoted $\tau_{NI}$.
\begin{center}
    \includegraphics[scale=0.25]{Nested_Interval_Topology.PNG}
\end{center}
\end{definition}

\begin{definition}[Closed Interval Topology]
In the set $X = [-1, 1]$, the basis of the \textit{closed interval topology} is 
\[ \big\{ [-1, a) \; | \; a>0 \big\} \bigcup \big\{ (b, 1] \; | \; b<0 \big\} \]
This topology will be denoted $\tau_{CI}$
\begin{center}
    \includegraphics[scale=0.25]{Closed_Interval_Topology.PNG}
\end{center}
\end{definition}

\begin{definition}[Cofinite Topology]
In the set $X$, the \textit{cofinite topology}, denoted $\tau_{CF}$, is the set of \textbf{all} subsets of form $X \setminus \{\text{any finite collection of points $a_{i}'s$}\}$. 
\end{definition}

\begin{definition}[Lower Limit Topology]
The \textit{lower limit topology}, denoted $\tau_{LL}$ has basis consisting of half-open intervals in the form $[a, b), a<b$. 
\end{definition}

\subsection{Induced Topologies}
\begin{definition}[Subspace Topologies]
Given topological space $X$ and subspace $Y \subset X$, the topology of $X$ induces the topology of $Y$ in the following way. 
\[\tau_Y = \{U \cap Y\;|\; U \in \tau_X\}\]
That is, the open sets of $Y$ are defined to be the intersection of the open sets of $X$ with the space $Y$. This is called the \textit{subspace topology}. The subspace topology of a line $l$ embedded in $\mathbb{R}^2$ and that of a surface $\mathcal{L}$ embedded in $\mathbb{R}^3$ is shown. 
\begin{center}
    \includegraphics[scale=0.25]{Subspace_Topology.PNG}
\end{center}
\end{definition}

\begin{definition}[Product Topologies]
Given $(S, \tau_{S})$ and $(T, \tau_{T})$, $S \times T$ is also a topological set with topology $\tau_S \times \tau_{T}$, called the \textit{product topology}. The topology of $S \times T$ is the set of all pairs of subsets of $S$ and $T$, respectively, that are each open sets of their respective spaces. 
\end{definition}

\begin{definition}
Let $X$ be a set with a simple order relation. Let $\mathscr{B}$ be the collection of all sets of the following types. 
\begin{enumerate}
    \item All open intervals $(a, b) \subset X$
    \item All half-open intervals $[a_0, b)$, where $a_0$ is the minimum element of $X$
    \item All half-open intervals $(a, b_0]$, where $b_0$ is the maximum element of $X$. 
\end{enumerate}
This set $\mathscr{B}$ is a basis for the \textit{order topology} of $X$. If $X$ has no minimum or maximum, then there are no sets of type of 2 or 3, respectively. 
\end{definition}

\begin{example}
The standard topology on $\mathbb{R}$ is precisely the order topology derived from the usual order on $\mathbb{R}$. 
\end{example}

\begin{example}
Given $\mathbb{R} \times \mathbb{R}$ with the dictionary order, then $\mathbb{R} \times \mathbb{R}$ has neither a largest nor smallest element. Therefore, the order topology on $\mathbb{R} \times \mathbb{R}$ consists of all "intervals" of form
\[\big((a, b), (c, d) \big) \equiv  \{(x, y) \in \mathbb{R}^2 \; | \; (a, b) < (x, y) < (c, d)\}\]
A visual diagram is shown below. This means that open rays and lines are also a part of the topology of $\mathbb{R} \times \mathbb{R}$. 
\\
\begin{center}
\begin{tikzpicture}[scale=0.8]
    \draw[white, fill=lightgray] (2,-1) rectangle (5,6);
    \draw[<->] (-1,0)--(8,0);
    \draw[<->] (0,-1)--(0,6);
    \draw[->] (2,3.05)--(2,6);
    \draw[->] (5,1.95)--(5,-1);
    \draw (2,3) circle [radius=0.05];
    \draw (5,2) circle [radius=0.05];
    \draw[dashed, ->] (2,2.95)--(2,-1);
    \draw[dashed,->] (5,2.05)--(5,6);
    \node[left] at (2,3) {$(a, b)$};
    \node[right] at (5,2) {$(c,d)$};
\end{tikzpicture}
\end{center}
\end{example}

\begin{example}
The set of positive integers $\mathbb{Z}_+$ form an ordered set with a smallest element. The order topology for $\mathbb{Z}_+$ is precisely the discrete topology since every one-point set is an open set. 
\[\{n\} = (n-1, n+1)\]
\end{example}

\begin{example}
The dictionary order topology on $\{1, 2\} \times \mathbb{Z}_+$ results in every one point set being open, except for the point $(2, 1)$. Since every neighborhood of $(2,1)$ must contain some point of form $(1, n)$ for arbitrarily large $n$, $\{(2,1)\}$ is not open. 
\end{example}

\begin{definition}
If $X$ is an ordered set a $a \in X$, then there are 4 subsets of $X$ called rays determined by $a$. 
\begin{enumerate}
    \item $(a, +\infty)$ 
    \item $(-\infty, a)$
    \item $[a, +\infty)$
    \item $(-\infty, a]$
\end{enumerate}
The first two sets are called \textit{open rays}, and the latter two sets are called \textit{closed rays}. 
\end{definition}

\subsection{Hausdorff Spaces}
\begin{definition}
A topological space $X$ is called a \textit{Hausdorff space} if for each pair of distinct points $p, q \in X$, there exists neighborhoods $U_p, U_q$ that are disjoint. $X$ is also said to be \textit{$t_2$-separable.}
\begin{center}
    \includegraphics[scale=0.35]{Hausdorff_Space_Separability.PNG}
\end{center}
\end{definition}

\begin{theorem}
Every finite point set in a Hausdorff space $X$ is closed. 
\end{theorem}
\begin{proof}
It suffices to show that every one point set $\{x_0\}$ is closed. If $x$ and $x_0$ are distinct points, then by definition of Hausdorff spaces they have disjoint neighborhoods $U_x$ and $U_{x_0} \implies x \not\in \bar{\{x_0\}} \implies \{x_0\} = \bar{\{x_0\}}$, so $\{x_0\}$ is closed. 
\end{proof}

\begin{theorem}
Given Hausdorff space $X$ and subset $A \subset X$ a point $x$ is a limit point of $A$ if and only if every neighborhood of $x$ contains infinitely many point of $A$. 
\end{theorem}
\begin{proof}
$(\rightarrow)$ Assume that $x$ is a limit point of $A$ with some neighborhood $U_x$ intersecting $A$ in finitely many points. Then, let the points of intersections be 
\[\{x_1, ..., x_n\} = A \cap \{U_x \setminus \{x\} \} \]
But $U_x \setminus \{x\}$ is open $\implies H \equiv \{U_x \setminus ( \{x\} \cup \{x_1, ..., x_n\})\}$ is open. But $H \cap A = \emptyset$, contradicting the assumption that $x$ is a limit point. \\
$(\leftarrow)$ Simple. 
\end{proof}

\begin{theorem}
The product of 2 Hausdorff spaces is Hausdorff. A subspace of a Hausdorff space is a Hausdorff space. 
\end{theorem}

Generally, mathematicians consider the Hausdorff condition as a mild extra conditions on topological spaces that make it much easier to deal with. We will assume that most of the topological spaces we work with are Hausdorff. 

\subsection{Continuous Functions, Homeomorphisms}
\begin{definition}
A function $f$ between 2 topological spaces $(X, \tau_{X})$ and $(Y, \tau_{Y})$ is \textit{continuous} if the preimage of every open set in $Y$ is an open set in $X$.
\[ U \in \tau_{Y} \implies f^{-1}(U) \in \tau_{X}\]
\begin{center}    \includegraphics[scale=0.20]{Topological_Continuity_of_Functions.PNG}
\end{center}
Note that continuity of a function $f$ is not only determined by the function itself, but also by the topologies of $X$ and $Y$. Note also that $f^{-1}$ isn't necessarily a function unless $f$ is injective. Also, this definition of continuity is equivalent to the epislon delta definition of continuity of functions. 
\end{definition}

Note that to check if $f$ is continuous, it suffices to check that the preimage of every basis element of the topology of $Y$ under $f$ is open in $X$, since every open set in $Y$ can be constructed as the union of basis elements. More rigorously, an arbitrary open set $V$ of $Y$ can be written as 
\[V = \bigcup_{\alpha \in J} b_\alpha\]
Then, 
\[f^{-1} (V) = f^{-1} \Big( \bigcup_{\alpha \in J} b_\alpha \Big) = \bigcup_{\alpha \in J} f^{-1} (b_\alpha)\]

\begin{theorem}
Let $X, Y$, be topological spaces and let $f: X \longrightarrow Y$. Then, the following are equivalent. 
\begin{enumerate}
    \item $f$ is continuous. 
    \item For every subset $A$ of $X$, $f(\bar{A}) \subset \bar{f(A)}$. 
    \item For every closed set $B$ in $Y$, the set $f^{-1} (B)$ is closed in $X$. 
\end{enumerate}
\end{theorem}

\begin{definition}[Homeomorphism]
A bijective, bicontinuous function 
\[f: X \longrightarrow Y\]
between two topological spaces is called a \textit{homeomorphism} between $X$ and $Y$. If there exists at least one homeomorphism between $X$ and $Y$, then $X$ is said to be \textit{homeomorphic} to $Y$. 

The visual below shows a homeomorphism between the plane $X$ and the surface $Y$. 
\begin{center}
    \includegraphics[scale=0.25]{Homeomorphism_of_Plane.PNG}
\end{center}
\end{definition}

In fact, a homeomorphism $f$ is an equivalence relation between two topological spaces. This partitions the set of all topological spaces into \textit{homeomorphism classes}. Analogous to how isomorphisms preserve algebraic structures, homeomorphisms preserve topological structure between topological spaces. 

Additionally, not only does a homeomorphism give a bijective correspondence between points in $X$ and $Y$, but it also determines a bijection between \textit{the set of all open sets in $X$ and $Y$} (that is, a bijection between their topologies)! This bijection then allows two spaces that are homeormophic to have the same topological properties. 

\begin{proposition}
A homeomorphism $f$ between two topological spaces $(X, \tau_{x})$ and $(Y, \tau_{Y})$ preserves all topological properties (e.g. separability, countability, compactness, (path) connectedness) of $X$ onto $Y$ and $Y$ onto $X$. 
\end{proposition}

\begin{definition}
Suppose that $f: X \longrightarrow Y$ an injective continuous map with $X, Y$ topological spaces. Let $Z \equiv \im{f}$. Then, the function
\[f^\prime: X \longrightarrow Z \subset Y\]
obtained by restricting the codomain of $f$ is bijective. If $f^\prime$ happens to be a homeomorphism of $X$ with $Z$, then we say that the map
\[f: X \longrightarrow Y\]
is a \textit{topological embedding}, or more simply an \textit{embedding}, of $X$ in $Y$. 
\end{definition}

\begin{lemma}[Pasting Lemma, Gluing Lemma]
Let $X = A \cup B$, where $A, B$ are closed in $X$. Let $f: A \longrightarrow Y$ and $g: B \longrightarrow Y$ be continuous. If 
\[f(x) = g(x) \text{ for all } x \in A \cap B\]
Then $f$ and $g$ can be combined to form a continuous function $h: X \longrightarrow Y$, defined
\[h(x) \equiv \begin{cases}
      f(x) & x \in A \setminus B \\
      f(x) \text{ or } g(x) & x \in A \cap B \\
      g(x) & x \in B \setminus A
\end{cases}\]
This is shown in the following visual. 
\begin{center}
    \includegraphics[scale=0.25]{Gluing_Lemma.PNG}
\end{center}
\end{lemma}

\begin{theorem}
Let $f: A \longrightarrow X \times Y$ be given by the equation 
\[f(a) \equiv \big( f_1 (a), f_2(a) \big)\]
Then $f$ is continuous if and only if the function $f_1: A \longrightarrow X$ and $f_2: A \longrightarrow Y$ are continuous. 
\end{theorem}

However, there is no useful criterion for the continuity of a mapping 
\[f: X \times Y \longrightarrow A\]
if the domain of $f$ is a product space. One might conjecture that this $f$ is continuous if it is continuous in each variable separately, but this is in fact not true. 

\subsection{Box and Product Topologies}

There are mutliple ways to define the box and product topologies, but their construction with basis elements is most simple. 

\begin{definition}
Let $\{X_\alpha\}_{\alpha \in I}$ be an indexed (finite or countably infinite) family of topological spaces and let us take the product of these spaces
\[\prod_{\alpha \in I} X_\alpha\]
We could endow the \textit{box topology} of all open sets in the form
\[\prod_{\alpha \in I} U_\alpha\]
where $U_\alpha$ is open in $X_\alpha$ for each $\alpha \in I$. It is clear that a basis element $B$ of the box topology is of form
\[B = \prod_{\alpha \in I} B_\alpha\]
where $B_\alpha$ is a basis element of the topology of each component space $X_\alpha$. 
\end{definition}

We can visualize the elements of the box topology with the product space $\mathbb{R}^2 = \mathbb{R} \times \mathbb{R}$, where each $\mathbb{R}$ has an open ball topology. From the visual below, we can see why this is called the "box" topology. Furthermore, all basis elements of this space are arbitrary open rectangles in $\mathbb{R}^2$. 
\begin{center}
\begin{tikzpicture}
    \draw[<->] (-1,0)--(6,0);
    \draw[<->] (0,-1)--(0,4);
    \draw[dashed] (1,1)--(1,3)--(4,3)--(4,1)--(1,1);
    \node[below] at (6,0) {$\mathbb{R}$};
    \node[left] at (0,4) {$\mathbb{R}$};
    \node[below] at (1,-0.3) {$a$};
    \node[below] at (4,-0.3) {$b$};
    \node[left] at (-0.3,1) {$c$};
    \node[left] at (-0.3,3) {$d$};
    \node[rotate=90] at (0,1) {$($};
    \node[rotate=-90] at (0,3) {$($};
    \node at (1,0) {$($};
    \node at (4,0) {$)$};
\end{tikzpicture}
\end{center}

It is easy to prove that the box topology indeed satisfies the 3 properties of topologies in general. While this topology may seem quite "intuitive" for the first learner, the box topology, however, has serious limitations when extending to infinite Cartesian products of spaces. Let 
\[\pi_\beta: \prod_{\alpha \in I} X_\alpha \longrightarrow X_\beta, \; \pi_\beta \big( (x_\alpha)_{\alpha \in I}\big) \equiv x_\beta\] 
be the projection mapping of an element in the product space to the $\beta$th space. 

\begin{definition}
Let $\{X_\alpha\}_{\alpha \in I}$ be an indexed family of topological spaces with their product space defined as above. Given an open set $U_\beta \subset X_\beta$, let us define $\mathscr{S} (U_\beta) \subset \prod X_\alpha$ as 
\begin{align*}
    \mathscr{S}(U_\beta) \equiv X_1 \times X_2 \times ... \times X_{\beta -1} \times U_\beta \times X_{\beta+1} \times ... 
\end{align*}
Visually, we can interpret each $\mathscr{S} (U_\beta)$ as a "strip" in the total product space. For example in $\mathbb{R}^2$, there are two "strips" $(e, f) \times \mathbb{R}$ and $\mathbb{R} \times (g, h)$ that intersect. 
\begin{center}
\begin{tikzpicture}
    \draw[<->] (-1,0)--(6,0);
    \draw[<->] (0,-1)--(0,4);
    \draw[<->, dashed] (-1,1)--(6,1);
    \draw[<->, dashed] (-1,3)--(6,3);
    \draw[<->, dashed] (1,-1)--(1,4);
    \draw[<->, dashed] (4,-1)--(4,4);
    \node [below left] at (1,0) {$e$};
    \node [below right] at (4,0) {$f$};
    \node [above left] at (0,3) {$h$};
    \node [below left] at (0,1) {$g$};
    \draw[dashed, fill=lightgray] (1,1) rectangle (4,3);
\end{tikzpicture}
\end{center}
The topology generated by this basis is called the \textit{product topology}. Note that by the properties of topologies, we can create open sets by taking unions and finite intersections of these basis elements. This means that every open set in the product topology has form
\[\prod_{\alpha \in I} U_\alpha\]
where $U_\alpha$ is an open subset of $X_\alpha$ for finitely many $\alpha$'s and $U_\alpha = X_\alpha$ for the rest. 
\end{definition}

We can deduce some conclusions comparing these topologies. First, the product and box topologies are precisely the same if we work in finite Cartesian products of spaces, since any element of the box topology (left hand side) can be expressed as a finite intersection of some open sets (in the right hand side). That is, if $\text{card}\,I < \infty$, then 
\[\prod_{\alpha \in I} U_i = \bigcap_{\alpha \in I} \big\{ \prod_{\gamma \in I} W_\gamma \; | \; W_\gamma = U_\gamma \text{ if } \gamma = \alpha, \, W_\gamma = X_\gamma \text{ if } \gamma \neq \alpha\big\}\]
Secondly, we can see that the box topology is finer than the product topology (strictly finer if working in infinite product spaces). 

\begin{example}
The set $(0,1)^\mathbb{N} \subset \mathbb{R}^\mathbb{N}$ is clearly open in the box topology, but it is considered "too tight" to be in the product topology. However, 
\[(0,1) \times \mathbb{R} \times \mathbb{R} \times ... \]
is open in the product topology since only one (a finite amount) of the factors is not the whole space. 
\end{example}

The main difference between the construction of open sets in the box topology vs the product topology is that the box topology merely describes open sets as direct products of open sets from each coordinate space. That is,
\[U_\alpha \text{ open in } X_\alpha \implies \prod_{\alpha \in I} U_\alpha \text{ open in } \prod_{\alpha \in I} X_\alpha\]
On the other hand, the construction of the product topology is completely dependent on the construction of the projection mappings 
\[ \pi_\beta: \prod_{\alpha \in I} X_\alpha \longrightarrow X_\beta\]
to be continuous (and nothing more) so that (by definition) the preimages of open sets in $X_\beta$ under $\pi_\beta$ are open sets in $\prod X_\alpha$. Therefore, the construction of the continuous $\pi_\beta$'s canonically constructs a basis of open sets in $\prod X_\alpha$. Taking the union and finite intersection of these open sets gives us the product topology. 

\begin{theorem}
If each space $X_\alpha$ is a Hausdorff space, then 
\[\prod_{\alpha} X_\alpha\]
is also Hausdorff in both the box and product topologies. 
\end{theorem}

The following theorem reveals why the product topology is superior than the box topology in product spaces. 

\begin{theorem}
Given the function 
\[f: A \longrightarrow \prod_{\alpha \in I} X_\alpha, \; f(a) \equiv \big( f_\alpha (a) \big)_{\alpha \in I}\]
with its component functions $f_\alpha: A \longrightarrow X_\alpha$. Let $\prod X_\alpha$ have the product topology. Then the function $f$ is continuous if and only if each function $f_\alpha$ is continuous. 
\end{theorem}
\begin{proof}
Let $\pi_\beta$ be the projection of this product onto the $\beta$th component space. By construction $\pi_\beta$ is continuous $\implies \pi_\beta^{-1} (U_\beta)$ is a basis element of the product topology of $\prod X_\alpha$. \\
$(\rightarrow)$ $f$ is continuous, so $f_\beta \equiv \pi_\beta \circ f$, as the composition of continuous functions, is also continuous. \\
$(\leftarrow)$ Assume that each $f_\beta$ is continuous. Let there be an open set $U_\beta \subset X_\beta$. Then, the canonical open set $\pi_\beta^{-1}$ in the product space $\prod X_\alpha$ is also open. Now, the preimage of $\pi_\beta^{-1} (U_\beta)$ under $f$ is \begin{align*}
    f^{-1} \big( \pi_\beta^{-1} (U_\beta)\big) & = (f^{-1} \circ \pi_\beta^{-1})(U_\beta) \\
    & = (\pi_\beta \circ f)^{-1} (U_\beta) \\
    & = f_\beta^{-1} (U_\beta)
\end{align*}
Since $f_\beta$ is already assumed to be continuous, $f_\beta^{-1} (U_\beta)$ is open in $A$. 
\end{proof}

This theorem also works for the box topology only if we are working with finite product spaces. But in general, this theorem fails for the box topology. Consider the following example. 

\begin{example}
Let $\mathbb{R}^\omega$ be the countably infinite product of $\mathbb{R}$'s. Let us define the function 
\[f: \mathbb{R} \longrightarrow \mathbb{R}^\omega\]
with coordinate function defined $f_n (t) \equiv t$ for all $n \in \mathbb{N}$. Clearly, each $f_n$ is continuous. Given the box topology, we consider one basis element of $\mathbb{R}^\omega$
\[B = \prod_{i=1}^\infty (-\frac{1}{i}, \frac{1}{i})\]
Assume that $f$ is continuous, that is $f^{-1}(B)$ is open in $\mathbb{R}$. Then, it would contain some finite interval $(-\delta, \delta)$ about $0$, meaning that $f\big( (-\delta, \delta)\big) \subset B$. This implies that for each $n \in \mathbb{N}$, 
\[f_n \big( (-\delta, \delta) \big) = (-\delta, \delta) \subset \Big( -\frac{1}{n}, \frac{1}{n} \Big)\]
which contradicts the fact that $B$ is open, since the interval $(-1/n, 1/n)$ converges onto a point $0$. 
\end{example}

\subsection{The Metric Topology}
Given a set $X$, we want a notion of a distance between two elements of $X$. This can be done with topologies, either by counting the number of open sets that contain $x, y \in X$ or by using notions of separability. We can also define it using a metric. 

\begin{definition}
The \textit{metric} function $d: X \times X \longrightarrow \mathbb{R}$ is a structure endowed on a set $X$ with properties 
\begin{enumerate}
    \item $\forall x, y \in X, \; d(x, y) \geq 0, \; \; d(x, y) = 0 \iff x = y$
    \item $d(x, y) = d(y, x)$ 
    \item $d(x, y) + d(y, z) \geq d(x, z)$
\end{enumerate}
Any function $d$ satisfying these three properties can be defined to be a metric. 
\end{definition}

Given a metric space $(X, d)$, consider the \textit{$\epsilon$-ball centered at $x$}. That is, 
\[B_d (x, \epsilon) \equiv \{y \in X \; | \; d(x, y) < \epsilon\}\]
With $\epsilon$-balls, it is possible to construct an induced topology. However, note that a topology does not in general induce a metric. 

\begin{definition}
If $d$ is a metric on set $X$, then the collection of all $\epsilon$-balls $B_d (x, \epsilon)$ for $x \in X$ and $\epsilon > 0$ is a basis for a topology on $X$, called the \textit{metric topology} induced by $d$. 
\end{definition}

While we will not prove this here, this set generated by $\epsilon$-balls does indeed satisfy the properties of a topology. We can rephrase the definition as follows 

\begin{definition}
A set $U$ is open in the metric topology induced by $d$ if and only if for each $y \in U$, there exists a $\delta > 0$ such that 
\[B_d (x, \delta) \subset U\]
\end{definition}
Therefore, since there always exists a basis element that is a neighborhood of all points $x \in U$ completely within $U$, $U$ is by definition open. 

\begin{example}
The $L2$ metric induces the usual open ball topology in $\mathbb{R}^n$. In fact, this open ball topology implies the existence of the metric. 
\end{example}

\begin{example}
Given a set $X$, induce the metric $d$ defined
\[d(x, y) \equiv \begin{cases}
      1 & \text{if } x \neq y \\
      0 & \text{if } x = y
\end{cases}\]
This metric induces the discrete topology on $X$, since the basis elements of the open balls
\[B_r (x) \equiv \{ y \in X \; | \; d(x, y) <r\}\]
consists of two types of open sets. When $r \leq 1$, then $B_r (x) = x$ (since the radius is $0$). If $r > 1$, then the open set is the entire space $X$. 
\end{example}

In $\mathbb{R}$, note that every open ball is really just an interval. In fact, every open ball $(x - r, x + r)$ can be expressed with just two elements $a, b \in \mathbb{R}$, as $(a, b)$. Notice that this method of expressing an open set does not even require any metric! 

Extending this to $\mathbb{R}^n$ would indicate that the topologies of $\mathbb{R}^n$ defined by the endpoint of the open intervals would not necessarily induce any metric either. Notice that these induced topologies is \textit{not} the open ball topology, which must have an associated metric to it. Rather, this induced, non-metric topology is the box topology! While the box topology and the open ball topology are really the same topology, they are generated by inherently different bases. 

\begin{definition}
If $(X, \tau)$ is a topological space, $(X, \tau)$ is said to be \textit{metrizable} if there exists a metric $d$ on $X$ that induces the topology $\tau$ of $X$. That is, the set of all open balls of form
\[B_r (x) \equiv \{ y \in X \; | \; d(x, y) < r \}\]
is the basis of $\tau$. A \textit{metric space} is a metrizable space $X$ together with a specific metric $d$ that gives the topology of $X$. 
\end{definition}

Note that it makes no sense to say that a regular space $X$ is metrizable. A topology $\tau$ must be given in addition to $X$ to determine whether $(X, \tau)$ is metrizable. Metrizability is always highly desirable attribute for spaces, and there are many existence theorems that proves metrizability given certain conditions. 

\begin{definition}
Let $(X, d)$ be a metric space with subset $A$. $A$ is \textit{bounded} if there exists some number $M$ such that
\[d (x, y) \leq M \text{ for all } x,y \in A\]
If $A$ is bounded, the \textit{diameter} of $A$ is defined to be the number
\[\text{diam}\, A \equiv \sup{\{d(x, y) \; | \; x, y \in A\}}\]
\end{definition}

Note that boundedness on a set is not a topological property since it depends on the particular metric $d$ that is used for $X$. For example, we can construct the following metric that makes every subset in $X$ bounded. 

\begin{definition}
Let $(X, d)$ be a metric space. We define a second metric $\Tilde{d}$ on $X$ such that
\[\Tilde{d} (x, y) \equiv \min{\{d(x, y), 1\}}\]
$\Tilde{d}$ is called the \textit{standard bounded metric corresponding to $d$}. 
\end{definition}

If we construct open balls with this metric, it is easy to see that they consist of all open balls with radius less than or equal to 1. That is, the topology $\tau$ consists of all open balls
\[\tau \equiv \{B_r (x) \; | \; x \in X, r \leq 1\}\]
It is also clear that the topology induced by $\Tilde{d}$ is the same as the topology induced by $d$! The significance of this construction of the standard bounded metric is that we can now work with a basis consisting of bounded elements, which is much nicer than a basis of open balls that can have arbitrarily large radii.  

\begin{lemma}
Let $d$ and $d^\prime$ be two metrics on the set $X$, with $\tau$ and $\tau^\prime$ the topologies that they induce, respectively. Then $\tau^\prime$ is finer than $\tau$ if and only if for each $x \in X$ and each $\epsilon > 0$, there exists a $\delta > 0$ such that
\[B_{d^\prime} (x, \delta) \subset B_d (x, \epsilon)\]
That is, for every open ball at $x$ with respect to metric $d$, there exists a smaller open ball at $x$ with respect to metric $d^\prime$. 
\end{lemma}

\begin{corollary}
Given two topologies $\tau$ and $\tau^\prime$ of a set $X$, if $\tau$ is finer than $\tau^\prime$ and $\tau^\prime$ is finer than $\tau$, then $\tau = \tau^\prime$. That is, two topologies that have the same level of "fineness" are the same topologies. 
\end{corollary}

\begin{definition}
Similar to the Euclidean, or L-2 metric of $\mathbb{R}^n$, we define the \textit{Euclidean/L-2} norm on $\mathbb{R}^n$ as
\[||x||: \bigg( \sum_{i=1}^n x_i \bigg)^{\frac{1}{2})}\]
\end{definition}

\begin{definition}
The \textit{L-$\infty$ metric}, also know as the \textit{square metric}, on $\mathbb{R}^n$ is defined 
\[\rho(x, y) \equiv \max{\{|x_1 - y_1|, ..., |x_n - y_n|\}}\]
\end{definition}

We now introduce a metrization theorem on $\mathbb{R}^n$. 

\begin{theorem}
The topologies on $\mathbb{R}^n$ induced by the Euclidean metric $d$ and the square metric $\rho$ are the same as the product topology on $\mathbb{R}^n$. 
\end{theorem}
\begin{proof}
Given $x, y \in \mathbb{R}^n$, simple algebra shows that 
\begin{align*}
    & \rho(x, y) \leq d(x, y) \leq \sqrt{n} \rho(x, y) \\
    & \;\;\;\; \implies \forall x, \epsilon, \; B_d (x, \epsilon) \subset B_\rho (x, \epsilon) \text{ and } B_\rho (x, \frac{\epsilon}{\sqrt{n}}) \subset B_d (x, \epsilon)
\end{align*}
But
\[\{ B_\rho (x, \epsilon) \; | \; x \in \mathbb{R}^n, \epsilon \in \mathbb{R}\} = B_\rho (x, \frac{\epsilon}{\sqrt{n}}) \; | \; x \in \mathbb{R}^n, \epsilon \in \mathbb{R}\}\]
which means that the metric topology induced by $d$ is the same as the metric topology induced by $\rho \implies$ the two topologies are the same. We know that the topology induced by $\rho$ is the same as the product topology since 
\[\prod_{i=1}^n (x_i - r, x_i + r) = \bigcup_{k=1}^n \mathbb{R}^{k-1} \times (x_k - r, x_k + r) \times \mathbb{R}^{n-k}\]
\end{proof}
With this theorem, we have proved that given a topological space $\mathbb{R}^n$ with the product topology, there exists a metric (the Euclidean and square metric) that induces this product topology. 

Visually, we can see that every open ball in $(\mathbb{R}^n, d)$ (with the Euclidean metric) is the form to the left, while an open ball in $(\mathbb{R}^n, \rho)$ (with the square metric) is of form on the right. 
\begin{center}
\begin{tikzpicture}[scale=0.5]
    \draw [dashed] (1,0) circle [radius=2];
    \draw [dashed] (6,-2) rectangle (10,2);
    \draw [fill] (1,0) circle [radius=0.05];
    \node [above left] at (1,0) {x};
    \draw (1,0)--(3,0);
    \node [above] at (1.5,0) {r};
    \draw [fill] (8,0) circle [radius=0.05];
    \node [below right] at (8,0) {x};
    \draw (8,0)--(10,0);
    \draw (8,0)--(8,2);
    \node [right] at (8,1) {r};
    \node [above] at (9,0) {r};
\end{tikzpicture}
\end{center}
Clearly, we can form any open set of any "shape" using any arbitrary combination of these "circles" or "squares," indicating that they generate the same topology. 
\\

We can attempt to extrapolate these formulas to $\mathbb{R}^\omega$ by defining
\begin{align*}
    & d(x, y) \equiv \bigg(\sum_{i=1}^\infty (x_i - y_i)^2 \bigg)^{\frac{1}{2}} \\
    & \rho(x, y) \equiv \sup{\{|x_i - y_i|\}}
\end{align*}
However, the metrics do not in general map to elements of $\mathbb{R}$, since the sequence $(x_i - y_i)_{i \in \mathbb{N}}$ could diverge. Therefore, we can redefine the metric $\rho$ to the following bounded one. 
\[\Tilde{\rho} (x, y) \equiv \sup{\{\Tilde{d}(x_i, y_i)\}}\]
where $\Tilde{d}$ is the standard bounded metric on $\mathbb{R}$. Clearly,
\[0 \leq \Tilde{\rho}(x, y) \leq 1\]
$\Tilde{\rho}$ is indeed a metric on $\mathbb{R}^\omega$, but unfortunately, it does not induce the product topology. We extend this definition to arbitrary $\mathbb{R}^J$. 

\begin{definition}
Given an indexed set $J$ with points $x, y \in \mathbb{R}^J$, we define
\[\Tilde{\rho} \equiv \sup{\{\Tilde{d}(x_\alpha, y_\alpha)\;|\; \alpha \in J\}}\]
with $\Tilde{d}$ the standard bounded metric on $\mathbb{R}$. $\Tilde{\rho}$ is called the \textit{uniform metric on $\mathbb{R}^J$}, which induces the \textit{uniform topology}. 
\end{definition}

The uniform topology on $\mathbb{R}^J$ is finer than the product topology, and they are different if $J$ is infinite. Clearly, $0 \leq \Tilde{p} (x, y) \leq 1$, meaning that given the open ball
\[B_r (x) \equiv \{y \in \mathbb{R}^J \;|\; \Tilde{p}(y, x) < r\}\]
if $r \geq 1$, then $B_r (x) = \mathbb{R}^J$ and if $r<1$, then $B_r (x)$ consists of the $n$-dimensional box with "radius" $r$, where $n = \dim{\mathbb{R}^J}$. In $\mathbb{R}^3$, each basis element is a cube centered at $x$ with side lengths $2r$.
\begin{center}
\begin{tikzpicture}
    \draw[dashed] (0,0)--(2,0)--(2,2)--(0,2)--(1.5,2.7)--(3.5,2.7)--(3.5,0.7)--(2,0);
    \draw[dashed] (2,2)--(3.5,2.7);
    \draw[dashed] (0,2)--(0,0)--(1.5,0.7)--(1.5,2.7);
    \draw[dashed] (1.5,0.7)--(3.5,0.7);
    \draw (1,1)--(2.5,1.7);
    \draw (0.75,1.35)--(2.75,1.35);
    \draw (1.75,0.35)--(1.75,2.35);
    \draw[fill] (1.75,1.35) circle (0.05);
    \node[above left] at (1.6,1.35) {$x$};
    \node[left] at (0,1) {$2r$};
\end{tikzpicture}
\end{center}

The next theorem gives us a metric that induces the product topology on infinite dimensional $\mathbb{R}^\omega$ by slightly modifying the uniform metric on $\mathbb{R}$. However, with the box topology $\mathbb{R}^\omega$ is not metrizable. 

\begin{theorem}
Let $\Tilde{d} (a, b) \equiv \min{\{|a-b|, 1\}}$ be the standard bounded metric on $\mathbb{R}$. If $x, y \in \mathbb{R}^\omega$, we define
\[ D(x, y) \equiv \sup{\Big\{ \frac{\Tilde{d}(x_i, y_i)}{i}\Big\}}\]
Then, $D$ is a metric that induces the product topology on $\mathbb{R}^\omega$. 
\end{theorem}
It is easy to see that $0 \leq D(x, y) \leq 1$. So, given the open ball
\[B_r (x) \equiv \{y \in \mathbb{R}^\omega \; | \; D(x, y) < r\}\]
$B_r (x) = \mathbb{R}^\omega$ if $r > 1$. When $r \leq 1$, 
\[B_r (x) \equiv (y-r, y+r) \times (y-2r, y+2r) \times ... = \prod_{k=1}^\infty (y - k r , y + k r)\]
Visually, we take a cross section of this box and look at the slice within $\mathbb{R}_1 \times \mathbb{R}_2$, where the subscripts represent the first and second terms of $x$. 
\begin{center}
\begin{tikzpicture}
    \node[below left] at (0,0) {$y$};
    \draw[fill] (0,0) circle (0.05);
    \draw[<->] (0, -2)--(0,2);
    \draw[<->] (-3,0)--(3,0);
    \draw[fill] (-2,0) circle (0.05); 
    \draw[fill] (2,0) circle (0.05); 
    \draw[fill] (0,1) circle (0.05); 
    \draw[fill] (0,-1) circle (0.05); 
    \node[above left] at (-2,0) {$-2$};
    \node[above right] at (2,0) {$2$};
    \node[above right] at (0,1) {$1$};
    \node[below right] at (0,-1) {$-1$};
    \draw[fill] (0, 0.7) circle (0.05);
    \draw[fill] (1.4, 0) circle (0.05);
    \node[above left] at (0,0.7) {$r$};
    \node[below right] at (1.4,0) {$2r$};
    \draw[dashed] (-1.4, -0.7) rectangle (1.4,0.7);
    \node[right] at (0,2) {$\mathbb{R}_1$};
    \node[above] at (3,0) {$\mathbb{R}_2$};
\end{tikzpicture}
\end{center}

\begin{proposition}
Every metric topology satisfies the Hausdorff Axiom.
\end{proposition}
\begin{proof}
If $x$ and $y$ are distinct points of $(X, d)$, then letting
\[\varepsilon = \frac{1}{2} d(x, y)\]
the triangle inequality implies that $B_\varepsilon (x)$ and $B_\varepsilon (y)$ are disjoint. 
\end{proof}

We now define continuity with the metric using the $\epsilon - \delta$ definition and connect it to the topological definition of continuity. Given 2 metric spaces $(X, d)$ and $(Y, \rho)$ with $f: X \longrightarrow Y$, it is clear that $x, y \in X \implies f(x), f(y) \in Y$. Given that $d(x, y) < \delta$ for a certain $\delta$, we can guarantee that $\rho(f(x), f(y)) < \epsilon$ for some $\epsilon$. In fact, we can make $\epsilon$ as small as we wish, and there will always be a $\delta > 0$ that satisfies $d(x, y) < \delta \implies \rho(f(x), f(y)) < \epsilon$.  

\begin{definition}
A function $f: (X, d) \longrightarrow (Y, \rho)$ between metric spaces is continuous at $p$ if for all $\epsilon > 0$, there exists a $\delta > 0$ such that 
\[ d(x, p) < \delta \implies \rho ( f(x), f(p)) < \epsilon\]
If $f$ is continuous at all $p \in X$, then we can say that $f$ is continuous.
\end{definition}

\begin{theorem}
Now, we endow $(X, d), (Y, \rho)$ their open ball topologies, leading to the sets $(X, \tau_X, d), (Y, \tau_Y, \rho)$. Given function $f: X \longrightarrow Y$, we claim that $f$ is continuous according to the $\epsilon - \delta$ definition if and only if $f^{-1}(U) \in \tau_{X}$ for any $U \in \tau_Y$. That is, these two definitions of continuity are equivalent. 
\end{theorem}
\begin{proof}
($\rightarrow$) Assume $f$ is continuous according to the $\epsilon - \delta$ definition. Let $U$ be any open set in $Y$ containing the point $y$, and let $x$ be an element in $f^{-1}(U)$ such that $y = f(x)$. We must prove that $f^{-1}(U)$ is also open. Since open sets contain neighborhoods (e.g. open balls) of all of its points, we can claim that, since $U$ is open by assumption, there exists an open ball $B_y$ around $y$ with radius $\epsilon > 0$. This guarantees the existence of a point $z \in U$ such that $\rho(y, z) < \epsilon$ for any $\epsilon > 0$ that we choose. Since $f$ is continuous, for every $\epsilon >0$ that we chose previously, there exists a $\delta >0$ such that $d(x, w) \implies \rho(f(x), f(w)) < \epsilon$. Since $\rho(f(x), f(w)) < \epsilon$, we can conclude that $f(w) \in B_y \subset U$ when $d(x, w) < \delta$. Therefore, $d(x, w) < \delta \implies w \in f^{-1}(U)$. But this is equivalent to saying that if $w \in B_(x, \delta)$, then $w \in f^{-1}(U)$, which means that every single point $x \in f^{-1}(U)$ contains an open ball neighborhood fully contained in $f^{-1}(U)$. So, by definition, $f^{-1}(U)$ is open. 
\\
($\leftarrow$) Assume $f^{-1}(U)$ is open when $U$ is an open set in $Y$, i.e. $f$ is continuous under the topological definition. Let us define the open ball 
\[ B(f(x), \epsilon) \equiv \{ y \in Y \; | \; \rho(f(x), y) < \epsilon\} \in \tau_Y\]
By our assumption, $f^{-1} \big( B(f(x), \epsilon) \big)$ is an open set in $\tau_X$, and clearly, $x \in f^{-1} \big( B(f(x), \epsilon) \big)$ since $f^{-1}$ maps the point $f(x) \in B(f(x), \epsilon)$ to $x \in f^{-1} \big( B(f(x), \epsilon) \big)$. But since $f^{-1} \big( B(f(x), \epsilon) \big)$ is open, we can construct an open ball around $x$ with radius $\delta$ fully contained within the open set. Moreover, by selecting a point $p \in B(f(x), \delta) \subset f^{-1}\big( B(f(x), \epsilon) \big)$, we can guarantee that $f(p) \in B(f(x), \epsilon)$. This is precisely the $\epsilon - \delta$ definition of continuity. That is, given an $\epsilon > 0$ to be the radius of an open ball $B(f(x), \epsilon)$ in $Y$, we can always choose a $\delta > 0$ to be the radius of the open ball $B(x, \delta)$ in $X$ that is fully contained within the preimage of $B(f(x), \epsilon)$. In mathematical notation, 
\[ p \in B(x, \delta) \subset f^{-1} \big( B(f(x), \epsilon) \big) \implies f(p) \in f\big( B(x, \delta) \big) \subset B(f(x), \epsilon)\]
or equivalently in terms of metrics,
\[ d(x, p) < \delta \implies \rho (f(x), f(p)) < \epsilon\]
\end{proof} 

\begin{definition}
A sequence $(x_\alpha)$ of points in topological space $(X, \tau)$ is said to \textit{converge} to the point $x \in X$ if for every neighborhood $U$ of $x$ there exists a $N \in \mathbb{N}$ such that
\[x_n \in U \text{ for all } n \geq N\]
Furthermore, if a sequence converges, it converges to one point provided that $X$ is Hausdorff! For if $(x_\alpha)$ converges to $x$ and if $y \neq x$, then we need only choose disjoint neighborhoods of $y$ and $x$ to prove that $(x_\alpha)$, by definition, is not convergent to $y$.
\end{definition}

Visually, we can think of each $x_N$ in the sequence as a point in a metric space $(X, d)$. To see if $\{ x_i \}$ converges to a point $l \in X$, we construct an open ball $B(l, \epsilon)$ and see if all points $x_i$ after a certain $i = m$ lie within $B (l, \epsilon)$. If this can be done for all $\epsilon > 0$, then $\{ x_i \}$ converges to $l$, or 
\[\lim_{i \to \infty} \{ x_i \} = l \]

\begin{example}
The space $(0,1)$ with the nested interval topology is not Hausdorff. In fact, it is impossible to distinguish 2 points $x, y$ if $x, y \in (0, \frac{1}{2})$, meaning that the sequence
\[\frac{1}{10}, \frac{2}{10}, \frac{1}{10}, ...\]
converges to both $\frac{1}{10}$ and $\frac{2}{10}$.
\end{example} 

We can extend the applications of the Bolzano Weierstrass Lemma from analysis to metric spaces in general with the following lemma. 

\begin{lemma}[Sequence Lemma]
If $X$ be a topological space with $A \subset X$. If there exists a sequence of points of $A$ that converges to $x$, then $x \in \bar{A}$. The converse is true if $X$ is metrizable. 
\end{lemma}
\begin{proof}
$(\rightarrow)$ Our hypothesis says that $x$ is a limit point of $A$, which by definition means that $x \in \bar{A}$. \\
$(\leftarrow)$ Assuming $X$ is metrizable and $x \in \bar{A}$, let $d$ be a metric for the topology of $X$. Then, for every $n \in \mathbb{N}$, let us define a sequence of open neighborhoods of $x$ to be
\[\big(B_{\frac{1}{n}} (x) \big)\]
Since $x \in \bar{A}$, there exists a point 
\[x_n \in A \cap B_{\frac{1}{n}} (x) \text{ for all } n \in \mathbb{N}\]
This sequence $(x_n)$ that we have proved must exist converges to $x$. 
\end{proof}

\begin{theorem}
Let $f: X \longrightarrow Y$ and let $X$ be metrizable. $f$ is continuous if and only if for every convergent sequence $(x_n) \rightarrow x$ of $X$, the following sequence of $Y$ converges to $f(x)$. That is, 
\[\big( f(x_n) \big) \longrightarrow f(x)\]
\end{theorem}

We introduce additional methods of constructing continuous functions. 

\begin{lemma}
The addition, subtraction, and multiplication operations are continuous functions from $\mathbb{R} \times \mathbb{R} \longrightarrow \mathbb{R}$, and the quotient operation is a continuous function from $\mathbb{R} \times (\mathbb{R} \setminus \{0\}) \longrightarrow \mathbb{R}$. 
\end{lemma}
\begin{proof}
Standard $\epsilon-\delta$ proof. 
\end{proof}

\begin{theorem}
If $X$ is a topological space, and if $f, g: X \longrightarrow \mathbb{R}$ are continuous, then $f + g$, $f-g$, and $f \cdot g$ are also continuous. $f / g$ is continuous if $g(x) \neq 0$ for all $x \in X$. 
\end{theorem}

\begin{definition}
Let $f_n: X \longrightarrow Y$ be a sequence of functions from the set $X$ to the metric space $(Y, d)$. The sequence $(f_n)$ is said to \textit{converge uniformly} to the function $f: X \longrightarrow Y$ if, given $\epsilon > 0$, there exists a $N \in \mathbb{N}$ such that
\[d\big( f_n(x), f(x)\big) < \epsilon\]
for all $n \geq N$ and for all $x \in X$. 
\end{definition}

\begin{theorem}[Uniform Limit Theorem]
Let $f_n: X \longrightarrow Y$ be a sequence of continuous functions from topological space $X$ to a metric space $Y$. If $f_n$ converges uniformly to $f$, then $f$ is continuous. 
\end{theorem}
\begin{proof}
$(\rightarrow)$ Trivial. \\
$(\leftarrow)$ Let $V$ be open in $Y$, and let $x_0$ be a point in $f^{-1} (V)$. It suffices to prove that for every $x_0 \in f^{-1} (V)$, there exists a neighborhood $U$ of $x_0$ such that $U \subset F^{-1} (V)$ or equivalently, $F(U) \subset V$. 

Let $y_0 = f(x_0)$. Since $Y$ is a metric space with metric $d$, we know that there exists an $\epsilon$-ball $B_\epsilon (y_0)$ such that
\[B_\epsilon (y_0) \subset V\]
Then, using uniform convergence, we can choose $N \in \mathbb{N}$ such that for all $n \geq N$ and all $x \in X$, 
\[d \big( f_n (x), f(x) \big) < \frac{\epsilon}{4}\]
which also applies at the point $x = x_0$. 
\[d \big( f_n (x_0), f(x_0) \big) < \frac{\epsilon}{4}\]
Using continuity of $f_n$, choose a neighborhood $U$ of $x_0$ such that $f_n$ carries $U$ into the open $\epsilon/2$-ball centered at $f_n (x_0)$ (note that $f_n (x_0) \neq y_0$), meaning that if $x \in U$
\[d \big( f_n (x), f_n (x_0) \big) < \frac{\epsilon}{2}\]
Adding the three inequalities and using the triangle inequality, we get the fact that if $x \in U$, then 
\[d \big( f(x), f(x_0) \big) < \epsilon\]
meaning that the $f(U) \subset B_\epsilon (x_0) \subset V$. 
\end{proof}

Visually, the three inequalities represent the following open balls in $V \subset Y$.
\begin{center}
\begin{tikzpicture}[scale=0.6]
    \draw[dashed, teal] (0,0) circle [radius=8];
    \draw[fill] (0,0) circle [radius=0.05];
    \draw[fill] (-1.5,0.5) circle [radius=0.05];
    \draw[dashed, purple] (0,0) circle [radius=2];
    \draw[dashed, purple] (-1.5,0.5) circle [radius=2];
    \node[right] at (0.3,0) {$f(x_0)$};
    \node[above right] at (-1.5,0.5) {$f_N (x_0)$};
    \draw[dashed, blue] (-1.5,0.5) circle [radius=4];
    \draw[fill] (-4,3) circle [radius=0.05];
    \draw[dashed, purple] (-4,3) circle [radius=2];
    \node[right] at (-4,3) {$f_N (x)$};
    \draw[fill] (-5.5, 3.7) circle [radius=0.05];
    \node[above left] at (-5,4.5) {$f(x)$};
    \draw[-, thick] (-5.5, 3.7)--(-4,3)--(-1.5,0.5)--(0,0);
    \draw[->, thick, purple] (0,0)--(0,-2);
    \draw[->, thick, blue] (-1.5,0.5)--(-1.5,-3.5);
    \node[right, purple] at (0,-1) {$\epsilon / 4$};
    \node[left,blue] at (-1.5,-1.5) {$\epsilon / 2$};
    \draw[->, thick, teal] (0,0)--(6.128, 5.1416);
    \node[below right, teal] at (3.064, 2.57) {$\epsilon$};
\end{tikzpicture}
\end{center}

\begin{proposition}
In a metric space $(X, d)$, a set is \textit{closed} if the limit of every convergent subsequence in $X$ lies in $X$. That is, $X$ contains all of its limit points. 
\end{proposition}

\subsection{Quotient Topologies}
\begin{definition}
Let $X$ and $Y$ be topological spaces, and let $p: X \longrightarrow Y$ be a surjective map. The map $p$ is said to be a \textit{quotient map} if
\[U \text{ is open in } Y \iff p^{-1}(U) \text{ is open in } X\]
\end{definition}

Note that the conditions for being a quotient map is stronger then regular continuity. It is sometimes called \textit{strong continuity}. An equivalent condition for $p$ to be a quotient map is to require that given $A \subset Y$, 
\[A \text{ closed in } Y \iff p^{-1}(A) \text{ closed in } X\]
This equivalence follows from the fact that
\[f^{-1}(Y \setminus B) = X \setminus f^{-1}(B)\]

\begin{definition}
A subset $C \subset X$ is \textit{saturated} with respect to the surjective map $p: X \longrightarrow Y$ if for every $p^{-1} (A)$ (where $A \subset Y$) that intersects $C$, $p^{-1}(A)$ is completely contained within $C$. That is, 
\[p^{-1} \big( p(C) \big) = C\]
\end{definition}

In the visual below, we can see that $C_1$ and $C_2$ alone are not saturated, but $C_1 \cup C_2$ is saturated. Visually, for a given set $C \subset X$ to be saturated, there cannot be any points $q \not\in C$ such that $q \in p(C)$. 

\begin{center}
\begin{tikzpicture}
    \draw (0,0) ellipse (1 and 1.5);
    \draw[fill=lightgray] (0, 0.7) circle (0.5);
    \draw[fill=lightgray] (0, -0.7) circle (0.5);
    \node[above] at (0,1.5) {$X$};
    \draw (4,0) ellipse (1.3 and 1.8);
    \node[above] at (4,1.8) {$Y$};
    \draw[fill=lightgray] (4,0) ellipse (1.2 and 0.7);
    \node at (0, 0.7) {$C_1$};
    \node at (0,-0.7) {$C_2$};
    \node at (4,0) {$p(C_1) = p(C_2)$};
    \draw[->] (0.2,0.9)--(4,0.5);
    \draw[->] (0.2,-0.9)--(4,-0.5);
    \node[above] at (2, 0.7) {$p$};
    \node[below] at (2, -0.7) {$p$};
\end{tikzpicture}
\end{center}
We now introduce an alternative, equivalent definition of quotient maps. 

\begin{definition}
$p: X \longrightarrow Y$ is a quotient map if and only if $p$ is continuous and $p$ maps saturated open sets of $X$ to open sets of $Y$ (or saturated closed sets of $X$ to closed sets of $Y$). 
\end{definition}

\begin{proposition}
If $p: X \longrightarrow Y$ is a surjective, continuous map that is either open or closed (that is, maps open sets to open sets or closed sets to closed sets), then $p$ is a quotient map. 

Note however, that the converse is not true; there exists quotient maps that are neither open nor closed. 
\end{proposition}

\begin{definition}
If $X$ is a space and $A$ is a set and if $p: X \longrightarrow A$ is a surjective map, then there exists exactly one topology $\tau$ on $A$ relative to which $p$ is a quotient map. $\tau$ is called the \textit{quotient topology} induced by $p$. 
\end{definition}

To construct the quotient topology for the surjective map $p$, we must make $p$ continuous. Therfore, the topology $\tau$ on $A$ is defined by letting it consist of all subsets $U$ of $A$ such that $p^{-1}(U)$ is open in $X$. This is indeed a topology since
\begin{enumerate}
    \item $p^{-1} (\emptyset) = \emptyset$ and $p^{-1}(A) = X$
    \item $p^{-1} \Big( \bigcup_{\alpha \in J} U_\alpha \Big) = \bigcup_{\alpha \in J} p^{-1} (U_\alpha)$
    \item $p^{-1} \Big( \bigcap_{i=1}^n U_i \Big) = \bigcap_{i=1}^n p^{-1} (U_i)$
\end{enumerate}

We can also construct the quotient topology as the final topology. 

\begin{definition}
Given a mapping 
\[f: (X, \tau_X) \longrightarrow (Y, \tau_Y)\]
where $\tau_X$ is well-defind and $\tau_Y$ is not, the finest possible topology available on $Y$ that makes $f$ continuous is called the \textit{final topology of $Y$}. 
\end{definition}

Note that we say the "finest possible topology" when defining the final topology. It is because if $\tau_Y$ is too fine (e.g. if $\tau_Y = 2^Y$), then the open sets of $\tau_Y$ would be too fine and therefore would have a preimage that may not be open in $X$. 

\begin{example}
Let $p: (\mathbb{R}, \tau_\mathbb{R}) \longrightarrow \mathbb{R} / 2 \pi \mathbb{R}$. Then, the final topology of $\mathbb{R} / 2 \pi \mathbb{R}$ would be simply defined 
\[\tau_{\mathbb{R} / 2 \pi \mathbb{R}} \equiv \{U \subset \mathbb{R} / 2\pi \mathbb{R} \; | \; U = p(O), O \in \tau_\mathbb{R}\}\]
That is, the quotient topology is merely the set of all images of open sets in $\mathbb{R}$ under $f$. However, if $\mathbb{R} / 2 \pi \mathbb{R}$ has the discrete topology $2^X$, then a single equivalence class, say $[0]$, will get mapped to the collection of points $\{2 \pi k \; | \; k \in \mathbb{Z}\}$, which is clearly not open in $\mathbb{R}$. Note that the final topology (or the quotient topology) is endowed onto the codomain in order to make $f$ continuous (or a quotient mapping). 
\end{example}

\begin{proposition}
Given a relation $\sim$ on a topological space $(X, \tau_X)$, the quotient topology of the quotient space $X / \sim$, is precisely the final topology on the quotient set with respect to the quotient map $p: X \longrightarrow X / \sim$. That is, 
\[\tau_{X / \sim} \equiv \big\{U \subseteq X / \sim \; | \; \{x \in X \; | \; p(x) \in U\} \in \tau_X \big\}\]
which is the topology whose open sets are the subsets of $X / \sim$ that have an open preimage under the surjective map $p: x \mapsto [x]$. 
\end{proposition}

\begin{example}
Let $X \equiv [0,1] \cap [2,3] \subset \mathbb{R}$ and $Y y \equiv [0,2] \subset \mathbb{R}$. Then, we define $p: X \longrightarrow Y$ as 
\[p(x) \equiv \begin{cases}
      x & x \in [0,1] \\
      x-1 & x \in [2,3]
\end{cases}\]
$p$ is continuous (under subspace topology of $X \subset \mathbb{R}$), surjective, and closed, meaning that it is a quotient map. However, it is not open, since the image of the open set $[0,1]$ of $X$ is $[0,1]$, which is not open in $Y$. 
\end{example}

\begin{example}
Let $p: \mathbb{R} \longrightarrow \{a, b, c\}$ be defined as 
\[p(x) \equiv \begin{cases}
      a & x > 0 \\
      b & x < 0 \\
      c & x = 0
\end{cases}\]
Then, the quotient topology of $\{a, b, c\}$ consists of 
\[\emptyset, \{a\}, \{b\}, \{a, b\}, \{a, b, c\}\]
\end{example}

\begin{definition}
Let $X$ be a topological space, and let $\Tilde{X}$ be a partition of $X$ into disjoint subsets whose union is $X$. Let $p: X \longrightarrow \Tilde{X}$ be the surjective map mapping every point $x \in X$ to the subset that it is in. In the quotient topology induced by $p$, $\Tilde{X}$ is called the quotient space of $X$. 
\end{definition}

To construct a quotient space, we can equivalently define a relation on $X$. That is, a subset $U$ of $\Tilde{X}$ is a collection of equivalence classes, and the set $p^{-1}(U)$ is the union of equivalence classes belonging to $U$. Therefore, the typical open set of $\Tilde{X}$ is a collection of equivalence classes whose union is an open set in $X$. 

\begin{example}[Construction of a Torus]
Let $X \equiv [0,1] \times [0,1] \subset \mathbb{R}^2$. We define an equivalence relation $Y$ consisting of the equivalence classes
\begin{align*}
    &\big\{\{(x, y)\} \; | \; 0<x, y<1\big\} \cup \big\{ \{(x, 0), (x,1)\} \; | \; 0<x<1 \big\} \cup \\
    &\big\{ \{(0,y), (1,y)\} \; | \; 0<y<1 \big\} \cup \big\{ \{(0,0), (0,1), (1,0), (1,1)\} \big\}
\end{align*}
Then, the quotient topology of this quotient space consists of open sets of form
\begin{center}
\begin{tikzpicture}
    \draw (0,0) rectangle (2,2);
    \draw (3,0) rectangle (5,2);
    \draw (6,0) rectangle (8,2);
    \draw (9,0) rectangle (11,2);
    \draw[dashed] (1, 1.5) circle [radius=0.4];
    \draw[fill] (1, 1.5) circle [radius=0.03];
    \draw[dashed] (3.9,0) arc (0:180: 0.4);
    \draw[dashed] (3.9,2) arc (0:-180:0.4);
    \draw[dashed] (6,1.1) arc (-90:90:0.4);
    \draw[dashed] (8,1.9) arc (90:270:0.4);
    \draw[fill] (3.5,0) circle [radius=0.03];
    \draw[fill] (3.5,2) circle [radius=0.03];
    \draw[fill] (6,1.5) circle [radius=0.03];
    \draw[fill] (8,1.5) circle [radius=0.03];
    \draw[fill] (9,0) circle [radius=0.03];
    \draw[fill] (11,0) circle [radius=0.03];
    \draw[fill] (9,2) circle [radius=0.03];
    \draw[fill] (11,2) circle [radius=0.03];
    \draw[dashed] (9.4,0) arc (0:90:0.4);
    \draw[dashed] (9.4,2) arc (0:-90:0.4);
    \draw[dashed] (11,0.4) arc (90:180:0.4);
    \draw[dashed] (10.6,2) arc (180:270:0.4);
\end{tikzpicture}
\end{center}
This quotient space $X / Y$ is homeomorphic to the torus $S^1 \times S^1$, denoted
\[\frac{X}{Y} \cong S^1 \times S^1\]
We can visualize the construction of the equivalence relation $Y$ as a "gluing" of the rectangle $X$ by its edges and corners. 

We can check that this mapping is indeed a quotient map. First, it is clearly surjective. By realizing that individual points on the edge of $[0,1]^2$ are open sets themselves (by the subspace topology), we can prove that this map is indeed open and continuous. 
\end{example}

\begin{example}[Construction of the 2-Sphere]
Let $X$ be the closed unit ball 
\[X \equiv \{(x, y) \in \mathbb{R}^2 \; | \; x^2 + y^2 \leq 1\}\]
and define the equialence classes $R$ as 
\[R \equiv \big\{ \{(x, y)\} \; | \; x^2 + y^2 <1 \big\} \cup \{S^1\}\]
which will consist of open sets of one of the two forms
\begin{center}
\begin{tikzpicture}
    \draw (1,1) circle [radius=1];
    \draw[thick] (4,1) circle [radius=1];
    \draw[dashed] (0.5,0.9) circle [radius=0.4];
    \draw[fill] (0.5,0.9) circle [radius=0.04];
    \draw[dashed] (4,1) circle [radius=0.85];
\end{tikzpicture}
\end{center}
Then, this quotient space $X / R$ is homeomorphic to the 2-sphere
\[S^2 \equiv \{(x, y, z) \in \mathbb{R}^3 \; | \; x^2 + y^2 + z^2 = 1\}\]
Visually, we can imagine the disk being glued together by its sides to continuously form the 2-sphere. 
\end{example}

\begin{example}[Construction of the 1-Sphere]
We will show that
\[\frac{\mathbb{R}}{\mathbb{Z}} \cong S^1\]
Let us construct the set $(\mathbb{R}, \tau_{\mathbb{R}})$ with paramater $t$. We define maps
\begin{align*}
p: \mathbb{R} \longrightarrow \mathbb{R} / \mathbb{Z}, \;\; p(t) \equiv t \; (\text{mod } 1) \\
q: \mathbb[R] \longrightarrow S^1 \subset \mathbb{C}, \;\; g(t) \equiv e^{2 \pi i t} 
\end{align*}
We claim that $p$ and $q$ are both quotient mappings. Clearly, $p$ is a quotient mapping. As for $q$, it it easy to see that it is surjective (but not injective) and continuous ($\tau_{S^1}$ has the basis of open intervals on $S^1$). It is also easy to notice that given an open interval $U \subset S^1$, $q^{-1}(U)$ will be the union of open intervals equally spaced in $\mathbb{R}$. Additionally, given any open interval in $\mathbb{R}$, it maps to an open interval in $S^1$ (note that $S^1$ itself is also open). These three conditions imply that $q$ is a quotient map. We now define maps 
\[ q \circ p^{-1}: \mathbb{R} / \mathbb{Z} \longrightarrow S^1 \]
\[ p \circ q^{-1}: S^1 \longrightarrow \mathbb{R} / \mathbb{Z} \]
and claim that these maps are homeomorphisms. We can clearly see that the mapping from an open set in $\mathbb{R} / \mathbb{Z}$ to the union of spaced open intervals in $\mathbb{R}$ is an injection, and the mapping from this union of open intervals to the union of open intervals in $S^1$ is a surjection. The composition of these two mappings clearly defines a bijection. Therefore, $q \circ p^{-1}$ is proven to be a bicontinuous bijective mapping between open sets $U \subset \mathbb{R} / \mathbb{Z}$ and $V \subset S^1 \implies$ $q \circ p^{-1}$ is a homeomorphism. 

This result clearly makes sense since 
\[\frac{\mathbb{R}}{\mathbb{Z}} \cong \frac{[0,1]}{\sim}\]
where the relation $\sim$ maps every point $x \in (0,1)$ to its own equivalence class and the points $0, 1$ to one equivalence class $\{0\}$. Therefore, it is informally said that the quotient space of the real line is a circle. 

One may attempt to construct a simpler set by replacing $S^1$ with the half-open interval $[0,1)$. However, while $[0,1)$ is bijective to $\mathbb{R} / \mathbb{Z}$,
\[\frac{\mathbb{R}}{\mathbb{Z}} \not\cong [0,1)\]
That is, the two sets are not homeomorphic because the topologies of $[0,1)$ and $\mathbb{R} / \mathbb{Z}$ are not compatible. For instance, when we attempt to map the open set 
\[ \bigg\{ [x] \in \mathbb{R} / \mathbb{Z} \; | \; 0 \leq x \leq \frac{1}{4} \vee x > \frac{1}{2} \bigg\} \in \tau_{\mathbb{R} / \mathbb{Z}} \]
to $\tau_{[0,1)}$, it does not return an open set. 


Furthermore, this means that
\[S^1 \times S^1 \cong \frac{[0,1]^2}{\sim^\prime} \cong \bigg( \frac{\mathbb{R}}{\mathbb{Z}} \bigg)^2\]
where $\sim^\prime$ is the quotient mapping defined in the previous construction of the torus. 
\end{example}

\begin{example}[Construction of the Cylinder]
Let us define the cylinder as 
\[C \equiv \{(x, y, z) \in \mathbb{R}^3 \; | \; x^2 + y^2 = 1, z \in [0,1]\} \]
Then, we can see that
\[C \cong \frac{[0,1]^2}{\sim}\]
where $\sim$ is the equivalence relation defined by the quotient mapping 
\[p\big((x, y)\big) \equiv \begin{cases}
      \{(x, y)\} & x \neq 0, x \neq 1 \\
      \{(0,y), (1, y)\} & x = 0 \text{ or } x = 1
\end{cases}\]
\end{example}

Subspaces do not behave well under quotient maps. That is, if $p: X \longrightarrow Y$ is a quotient map and $A$ is a subspace of $X$, then the map $p^\prime: A \longrightarrow p(A)$ obtained by restricting both the domain and codomain of $P$ need not be a quotient map. Additionally, quotient maps are clearly not homeomorphisms, so topological properties are not preserved. 

However, composites of maps do behave nicely. 

\begin{proposition}
The composition of two quotient maps is a quotient map. 
\end{proposition}
\begin{proof}
Indeed, the composition of surjective, continuous, and open maps is surjective, continuous, and open. 
\end{proof}

However, the product of two quotient maps is not necessarily a quotient map. That is, given $p: A \longrightarrow B$ and $q: C \longrightarrow D$ are quotient maps, the map 
\[p \times q: A \times C \longrightarrow B \times D, \; (p \times q) (a \times c) \equiv p(a) \times q(c)\]
is not necessarily a quotient map. 

\begin{example}
Given $(\mathbb{R}, \tau_{\mathbb{R}})$, let us define the relation $\sim$ determined by the quotient mapping
\[p(x) \equiv \begin{cases}
      \{x\} & x \not\in \mathbb{Z} \\
      \mathbb{Z} & x \in \mathbb{Z}
\end{cases}\]
In words, this quotient map maps every integer to the equivalence class $[0]$ and maps every other point to its own class. It turns out that every interval $[j, j+1] \subset \mathbb{R}, \; j \in \mathbb{Z}$ will get mapped as a closed loop in $\mathbb{R} / \sim$ beginning and ending with $[0]$, since $j, j+1 \mapsto [0]$. So geometrically, $\mathbb{R} / \sim$ consists of an infinite number of nonintersecting closed loops starting and ending with $[0]$. 
\begin{center}
\begin{tikzpicture}[scale=0.4]
    \draw (5,0) circle (5);
    \node[left] at (0,0) {$[0]$};
    \draw[fill] (0,0) circle (0.1);
    \draw (4,0) circle (4);
    \draw (3,0) circle (3);
    \draw (2,0) circle (2);
    \draw (1,0) circle (1);
    \node[right] at (0,0) {...};
    \node[right] at (2,0) {...};
    \node[right] at (4,0) {...};
    \node[right] at (6,0) {...};
    \node[right] at (8,0) {...};
    \node[right] at (10,0) {...};
\end{tikzpicture}
\end{center}

This wacky mapping is an example of a quotient mapping that does not preserve topological structure. While it will not be proven here, it is known that $(\mathbb{R}, \tau_{\mathbb{R}})$ is 1st and 2nd countable, but $\mathbb{R} / \sim$ under this relation is not even 1st countable. 
\end{example}

We now introduce theorems of continuous maps from quotient spaces inducing other continuous maps. 

\begin{theorem}
Let $p: (X, \tau_X) \longrightarrow (Y, \tau_Y)$ be a quotient map. Let $(Z, \tau_Z)$ be a topological space and let there exist a function $f: Y \longrightarrow Z$. $f$ is continuous if and only if $f \circ p$ is continuous. 
\[\begin{tikzcd}
    X \arrow{d}{p} \arrow{rd}{f \circ p}\\
    Y \arrow{r}{f} & Z
\end{tikzcd}\]
\end{theorem}
\begin{proof}
($\rightarrow$) Assume $f$ is continuous. By definition of the quotient topology, $p$ is continuous $\implies$ $f \circ p$ is continuous. \\
($\leftarrow$) Assume $f \circ p$ is continuous $\iff (f \circ p)^{-1} (\omega) \in \tau_X$ for every $\omega \in \tau_Z \iff p^{-1} \big( f^{-1}(\omega) \big) \in \tau_X$, but $p$ is continuous, so $f^{-1}(\omega)$ is open in $Y$. Therefore, given $\omega \in \tau_{Z}$, $f^{-1} (\omega) \in \tau_Y \implies f$ is continuous. 
\end{proof}

The previous theorem determines continuity of $f$ and $f \circ p$ given a function mapping $Y \longrightarrow Z$. The following analogous theorem determines continuity of an induced map $f$ given a function mapping $X \longrightarrow Z$. 

\begin{theorem}
Let $p: (X, \tau_X )\longrightarrow (Y, \tau_Y)$ be a quotient map. Let $Z$ be a space and let $g: X \longrightarrow Z$ be a map such that $g$ is constant on the elements $x$ of each equivalence class induced by $p$. That is, if $x_1$ and $x_2$ are in the same equivalence class induced by $p$, i.e. 
\[p(x_1) = p(x_2)\]
then $g(x_1) = g(x_2)$. If $g$ is continuous, then $g$ induces a continuous map $f: X \longrightarrow Z$ such that $g = f \circ p$. That is, 
the diagram below commutes 
\[\begin{tikzcd}
    X \arrow{d}{p} \arrow{rd}{g=f \circ p}\\
    Y \arrow{r}{f} & Z
\end{tikzcd}\]
\end{theorem}

\section{Connectedness and Compactness}
We briefly define some weaker forms of separability. Note that a space being $t_2$-separable is the condition of being Hausdorff. 

\begin{definition}[$t_0, t_1$-Separability]
Two points $x_1, x_2 \in X$ with topology $\tau_{X}$ is called $t_0$\textit{-separable} if we can distinguish $x_1, x_2$ using open sets, i.e. if we can find an open set that contains $x_1$, but not $x_2$. A space $X$ with the property that any two distinct points in $X$ being $t_0$-separable is called a $t_0$-separable space. This is the weakest form of separability. 

The next level of separability is called $t_1$-separability. When given 2 distinct points $x_1, x_2$ in $t_1$-separable set $X$, we can find neighborhoods $U_{x_1}, U_{x_2}$ such that $U_{x_1} \neq U_{x_2}$. 
\begin{center}
    \includegraphics[scale=0.25]{t0_t1_Separability.PNG}
\end{center}
\end{definition}

\begin{example}
$(0,1)$ with the nested interval topology is not $t_0$-separable, since we can't distinguish $\frac{1}{4}$ and $\frac{1}{3}$.
\end{example}

\begin{example}
$(0,1)$ with the cofinite topology is $t_0$-separable, since given distinct $x_1, x_2 \in (0,1)$, we can see that $x_1 \in X \setminus {x_2}$ and $x_2 \in X \setminus {x_1}$, which are both elements of the cofinite topology. By existence of these elements, $(0,1)$ is $t_1$-separable. 
\end{example}

\subsection{Connected Spaces}
\begin{definition}
Let $X$ be a topological space. A \textit{separation} of $X$ is a pair $U, V$ of disjoint nonempty open subsets of $X$ whose union is $X$. The space $X$ is said to be \textit{connected} if there does not exist a separation of $X$. 

The visual below shows two examples of spaces that are not connected. 
\begin{center}
    \includegraphics[scale=0.25]{Not_Connected_Spaces_Examples.PNG}
\end{center}
\end{definition}

Connectedness is clearly a topological property since it is completely defined in terms of the collection of open sets in $X$. Since homeomorphisms preserves topological properties, we can say that if $X$ is connected, every space homeomorphic to $X$ is also connected. It is easy to see why the following definition of connectedness is equivalent to the first one. 

\begin{definition}
A space $X$ is \textit{connected} if and only if the only subsets of $X$ that are clopen in $X$ are the empty set and $X$ itself. 
\end{definition}

\begin{lemma}
If $Y$ is a subapce of $X$, a separation of $Y$ is a pair of disjoint nomempty sets $A$ and $B$ whose union is $Y$, neither of which contains a limit point of the other. The space $Y$ is connected if there exists no separation of $Y$. 
\end{lemma}
\begin{example}
In the space $Y = (0,1) \times (0,1) \cup (1,2) \times (0,1) \subset \mathbb{R}^2$, we can visualize the separation of $Y$ as
\begin{center}
\begin{tikzpicture}[scale=1.5]
    \draw[dashed] (0,0) rectangle (2,1);
    \draw[dashed] (1,1)--(1,0);
\end{tikzpicture}
\end{center}
Note that the dashed line is not in $Y$. Even though the dashed line contains limit points of both the left and right subset of $Y$, this does not matter. 
\end{example}


\begin{example}
Let $X$ denote a two-point space in the indiscrete topology. Clearly, there is no separation of $X$, so $X$ is connected. 
\end{example}

\begin{example}
Let $Y$ denote the subspace $[-1,0) \cup (0,1]$ of $\mathbb{R}$. Each of the sets $[-1,0)$ and $(0,1]$ is nonempty and open in $Y$ (but not in $\mathbb{R}$), so they form a separation of $Y$. Also, note that neither of these sets contains a limit point of the other (even though they have a common limit point $0$). 
\end{example}

\begin{example}
$[-1,1]$, the subspace of $\mathbb{R}$, has no separation, so it is connected. 
\end{example}

\begin{example}
The rationals $\mathbb{Q} \subset \mathbb{R}$ are not connected since given any irrational number $a$, we can write $Y$ as the union of sets
\[Y \cap (-\infty, a), \; Y \cap (a, +\infty)\]
which are open in the subspace topology. 
\end{example}

\begin{lemma}
If the sets $C$ and $D$ form a separation of $X$, and if $Y$ is a connected subset of $X$, then $Y$ lies entirely within either $C$ or $D$. 
\end{lemma}
\begin{proof}
Trivial. Easy to visualize. 
\end{proof}

\begin{theorem}
The union of a collection of connected sets that have a point in common is connected. 
\end{theorem}
\begin{center}
\begin{tikzpicture}[scale=0.5]
    \draw[fill] (0,0) circle (0.05);
    \node[above right] at (0,0) {$p$};
    \draw (1,1) circle (1.8);
    \draw (-1,1.5) circle (2.5);
    \draw (-2, -0.5) circle (3);
    \draw (2,0) circle (3);
\end{tikzpicture}
\end{center}

\begin{proof}
Let $\{A_\alpha\}$ be a collection of connected subsets of a space $X$, and let 
\[p \in \bigcap A_\alpha\]
Then, we claim that 
\[Y \equiv \bigcup A_\alpha\]
is connected. Assume $Y$ is not connected, that is, there exists $Y = C \cup D$ as a separation of $Y$. Then, $p \in C$ or $p \in D$. Without loss of generality, suppose $p \in C$. Since each $A_\alpha$ is connected, it must lie entirely within $C$ (by the previous lemma, since it contains the point $p \in C$) $\implies D = \emptyset$, a contradiction that $D$ must be nonempty. 
\end{proof}

\begin{theorem}
Let $A$ be a connected subset of $X$. If $A \subset B \subset \bar{A}$, then $B$ is also connected. 
\end{theorem}
\begin{proof}
Assume $B = C \cup D$ is a separation of $B \implies A$ must lie entirely within $C$ or $D$. Without loss of generality, suppose $A \subset C$, which implies that $\bar{A} \subset \bar{C}$. Since $\bar{C}$ and $D$ are disjoint, $B$ cannot intersect $D \implies D = \emptyset$, a contradiction. Therefore, there exists no separation of $B$. 
\end{proof}

\begin{theorem}
The image of a connected space under a continuous map is connected. 
\end{theorem}
\begin{proof}
Let $f: X \longrightarrow Y$ be a continuous map, and let $X$ be connected. We wish to prove that the image set $Z = f(X)$ is also connected. Let us denote the restriction of $f$ to $Z$ as
\[\Tilde{f}: X \longrightarrow Z\]
which is continuous and surjective. We prove by contradiction. Assume that $Z = A \cup B$ is a separation of $Z$ into 2 disjoint nonempty open sets. Then, $\Tilde{f}^{-1} (A)$ and $\Tilde{f}^{-1}(B)$ are disjoint open sets whose union is $X \implies \Tilde{f}^{-1} (A) \cup \Tilde{f}^{-1}(B)$ form a separation of $X$. This contradicts the hypothesis that $X$ is connected $\implies Z$ is connected.  
\end{proof}

\begin{theorem}
Given connected topological spaces $X_\alpha$ with $\alpha \in J$, the Cartesian products of them is connected. That is, 
\[\prod_{\alpha \in J} X_\alpha\]
with the product topology is connected. If $J$ is infinite, then the product space is not necessarily connected under the box topology. 
\end{theorem}

\begin{definition}
A simply ordered set $L$ having more than one element is called a \textit{linear continuum} if the following hold. 
\begin{enumerate}
    \item $L$ has the least upper bound property. 
    \item If $x <y$, then there exists $z$ such that $x<z<y$
\end{enumerate}
A classic example of the linear continuum is the real number line and every set homeomorphic to it. 
\end{definition}

\begin{theorem}
If $L$ is a linear continuum in the order topology, then $L$ is connected and so it every interval and ray in $L$. 
\end{theorem}

\begin{corollary}
$\mathbb{R}$ is connected, along with every interval and ray in $\mathbb{R}$. 
\end{corollary}

\begin{theorem}[Intermediate Value Theorem]
Let $f: X \longrightarrow Y$ be a continuous map of the connected space $X$ into the ordered set $Y$, with the order topology. Given $a, b \in X$ and $r \in Y$ such that $f(a)<r<f(b)$, then there exists a point $c \in X$ such that $f(c) = r$. 
\end{theorem}
\begin{proof}
Assuming the hypothesis, the sets 
\[A \equiv f(X) \cap (-\infty, r), \; B \equiv f(X) \cap (r, +\infty)\]
are disjoint. They are also nonempty since 
\[f(a) \in A, \; f(b) \in B\]
$A$ and $B$ are open since they are the intersection of open sets. Now, assume that there exists no point $c \in X$ such that $f(c) = r$. Then, 
\[f(X) = A \cup B\]
would define a separation of $X$, contradicting the fact that the image of a connected space under a continuous map must be connected. Therefore, $c$ exists. 
\end{proof}

\begin{definition}
Given points $x$ and $y$ of the space $x$, a \textit{path} in $X$ from $x$ to $y$ is a continuous map $f: [a,b] \longrightarrow X$ of some closed interval in $\mathbb{R}$ to $X$ such that $f(a) = x$ and $f(b)=y$. A space $X$ is said to be \textit{path connected} if every pair of points of $X$ can be joined by a path in $X$. 
\end{definition}

\begin{proposition}
$X$ is path connected $\implies X$ is connected. 
\end{proposition}
\begin{proof}
$X$ not connected implies that there exists disjoint open subsets $C, D$ such that $C \cup D = X$. Assume that $X$ is path connected, i.e. there exists a continuous function $g: [0,1] \longrightarrow X$. Then the preimage of $C$ and $D$ in $X$ must be open sets $g^{-1} (C), g^{-1} (D) \subset [0,1]$ such that $g^{-1}(C) \cup g^{-1}(D) = [0,1]$. But this isn't possible since $[0,1]$ is connected, so by contradiction, $X$ is not path connected. The contrapositive of this statement results in the proposition. 
\end{proof}

\begin{center}
\begin{tikzpicture}[scale=0.5]
    \draw[dashed] (5,1) circle (2);
    \draw[dashed] (0,0) circle (2);
    \node at (-1,-1) {$C$};
    \node at (6,2) {$D$};
    \draw plot [smooth] coordinates {(0,0) (2,1.5) (4.5,2)};
    \draw[fill] (0,0) circle (0.05);
    \draw[fill] (4.5,2) circle (0.05);
    \node at (-4,1) {$X = C \cup D$};
\end{tikzpicture}
\end{center}

However, note that $X$ connected $\centernot\implies$ $X$ path connected. Note the following example. 

\begin{example}
\[ f:[0,1] \longrightarrow [-1,1], \; f(x) = \sin{\frac{1}{x}}\]
$[-1,1]$ is connected, but not path connected since the path oscillates infinitely many times as it approaches $0$ from both $-1$ and $1$. 
\end{example}

The concept of homotopies is dealt with in algebraic topology, but it is worthwhile to mention it now. 

\begin{definition}
Two continuous paths from $x$ to $y$ in topological space $X$ is \textit{homotopic} if one can be continuously "deformed" into the other, such a deformation being the \textit{homotopy} between two functions. The set of linearly homotopic paths form a relation, and thus \textit{homotopy classes} can be further defined. 
\end{definition}

Visually, the set of all the curves in the space $X$ as shown are in a single homotopy class.
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0) ellipse (5 and 2);
    \draw[fill] (-4,0) circle (0.05);
    \draw[fill] (4,0) circle (0.05);
    \draw plot [smooth] coordinates {(-4,0) (-1,1) (1,1) (4,0)};
    \draw (-4,0)--(4,0);
    \draw plot [smooth] coordinates {(-4,0) (-1,0.5) (1,0.5) (4,0)};
    \draw plot [smooth] coordinates {(-4,0) (-1,-0.5) (1,-0.5) (4,0)};
    \draw plot [smooth] coordinates {(-4,0) (-1,-1) (1,-1) (4,0)};
    \node at (-2,1.3) {$X$};
    \node[left] at (-4,0) {$a$};
    \node[right] at (4,0) {$b$};
\end{tikzpicture}
\end{center}
It is clear that the space $X$ consists of a single homotopy class of curves from $a$ to $b$. However, let us define the space $Y \equiv X \setminus C$ where $C$ is a circular region in $X$. Then, $Y$ has an infinite number of homotopy classes. We show two curves, that are in two different homotopy classes. 
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0) ellipse (5 and 2);
    \draw[fill] (-4,0) circle (0.05);
    \draw[fill] (4,0) circle (0.05);
    \draw plot [smooth] coordinates {(-4,0) (-1,1) (1,1) (4,0)};
    \node[left] at (-4,0) {$a$};
    \node[right] at (4,0) {$b$};
    \draw (0,0) circle (1);
    \node at (-2,1.3) {$Y$};
    \draw[blue] plot [smooth] coordinates {(-4,0) (-2,0.5) (-1,1) (1,1) (1,-1) (-1,-1) (-1,1) (1,1) (2,0.5) (4,0)};
\end{tikzpicture}
\end{center}

\begin{definition}
A \textit{simply connected set} is a set such that all paths between any two given points are homotopic. That is, a simply connected set has one homotopy class. 
\end{definition}

\subsection{Components and Path Components}

\begin{definition}
Given $X$, define an equivalance relation on $X$ by setting $x \sim y$ if there is a connected subset of $X$ containing both $x$ and $y$. The equivalence classes are called the \textit{components}, or \textit{connected components}, of $X$. 
\end{definition}

\begin{theorem}
The components of $X$ are connected disjoint subsets of $X$ whose union is $X$, such that each connected subset of $X$ intersects only one of them. 
\end{theorem}
\begin{proof}
Trivial. 
\end{proof}

\begin{definition}
We can define another equivalence relation on the space $X$ by defining $x \sim y$ if there is a path in $X$ from $x$ to $y$. The equivalence classes are called the \textit{path components} of $X$. It can be easily shown that this is an equivalence relation. 
\end{definition}

\begin{theorem}
The path components of $X$ are path connected disjoint subsets of $X$ whose union is $X$, such that each path connected subset of $X$ intersects only one of them. 
\end{theorem}
\begin{proof}
Trivial.
\end{proof}

The property of local connectedness is also important for a space to possess. Roughly speaking, local connectivity means that each point has "arbitrarily small" neighborhoods that are connected. 

\begin{definition}
A space $X$ is said to be \textit{locally connected at $x$} if for every neighborhood $U$ of $x$, there is a connected open neighborhood $V$ of $x$ contained in $U$. If $X$ is locally connected at all of its points, then $X$ is simply said to be \textit{locally connected}. 
\end{definition}
Visually, in the space $X$, let $U$ be the union of the two open balls shown below. $U$ is clearly open, but not necessarily connected. However, we can form a  neighborhood $V$ of $x$ contained in $U$ such that $V$ is connected. 
\begin{center}
\begin{tikzpicture}[scale=0.8]
    \draw[fill] (-2,0) circle (0.05);
    \node[above] at (-2,0) {$x$};
    \draw[dashed] (-1.5,0) circle (3);
    \draw[dashed] (3,0) circle (1);
    \draw[dashed, fill=lightgray] (-2.5,0) circle (1.5);
    \node[left] at (-1.2,0) {$V$ connected};
    \node[right] at (-0.8,0) {$U$ not};
    \node[right] at (-0.8,-0.5) {connected};
    \node at (3,2) {$X$};
\end{tikzpicture}
\end{center}

Equivalently, $X$ is locally connected if there exists a basis for $X$ consisting of connected sets. Local connectedness and connectedness of a space are independent of each other. 

\begin{definition}
A space $X$ is \textit{locally path connected at $x$} if for every neighborhood $U$ of $x$, there is a path connected neighborhood $V$ of $x$ completely contained in $U$. If $X$ is locally path connected at each of its points, then it is simply said to be \textit{locally path connected}. We can visualize this condition similarly as that of local connectedness. 
\end{definition}

\begin{theorem}
A space $X$ is locally connected if and only if for every open set $U$ of $X$, each component of $U$ is open in $X$. 
\end{theorem}
\begin{proof}
$(\rightarrow)$ Suppose that $X$ is locally connected. Let $U$ be an open set of $X$ and let $C$ be a component of $U$. If $x$ is any point in $C$, by definition of local connectedness, there exists a connected neighborhood $V$ of $x$ fully contained in $U$. Since $V$ is connected, it must additionally lie completely within $C \implies C$ is open in $X$. \\
$(\leftarrow)$ Suppose that the components of open sets in $X$ are open. Given a point $x \in X$ and neighborhood $U$ of $x$, let $C$ be the component of $U$ containing $x$, which means that $C$ is connected. By hypothesis, the components of open sets are alsvo open, so $C$ is also open. Since an open, connected set $C$ exists for all $x \in X$, $X$ is locally connected. 
\end{proof}

\begin{theorem}
A space $X$ is locally path connected if and only if for every open set $U$ of $X$, each path component of $U$ is open in $X$.
\end{theorem}

\begin{theorem}
If $X$ is a topological space, each path component of $X$ lies in a component of $X$. If $X$ is locally path connected, then the components and the path components of $X$ are the same. 
\end{theorem}

\section{Compact Spaces}

\begin{definition}
A collection $\mathscr{C}$ of subsets of a space $X$ is said to \textit{cover} $X$, or to be a \textit{covering} of $X$, if the union of the elements of $\mathscr{C}$ is equal to $X$. It is called an \textit{open covering} of $X$ if its elements are open subsets of $X$. 
\end{definition}

\begin{definition}
A space $X$ is said to be \textit{compact} if every open covering of $X$ contains a finite subcovering (i.e. a finite collection of subcovers) of $X$. It may be better to think of compactness as such: If you can find any infinite open covering of the space, then it is not compact. 
\end{definition}

\begin{lemma}
Let $Y$ be a subspace of $X$. Then $Y$ is compact if and only if every covering of $Y$ by sets open in $X$ contains a finite subcollection covering $Y$. 
\end{lemma}

\subsection{Intuition behind Compactness}
The concept of compactness does not seem intuitive at first glance. The reason why compactness is such an important property for a space to have is because $X$ being compact tells us that we can \textit{always} analyze the entire $X$ using a \textit{finite} union of open sets, which can simplify the space greatly. That is, it a measure of finiteness of a space. 

It is well known that the behavior of finite sets and infinite sets can be different. For example, the four statements below are easily seen to be true whenever $X$ is a finite set, but false whenever $X$ is an infinite set. 
\begin{enumerate}
    \item (All functions are bounded) If $f: X \longrightarrow \mathbb{R}$ is a real valued function on $X$, then $f$ must be bounded. That is, there exists a finite number $M$ such that $|f(x)| \leq M$ for all $x \in X$. 
    \item (All functions attain a maximum) If $f: X \longrightarrow \mathbb{R}$ is a real-valued function on $X$, then there must exist at least one point $x_0 \in X$ such that $f(x_0) \geq f(x)$ for all $x \in X$. 
    \item (All sequences have constant subsequences) If $(x_\alpha)_{\alpha \in \mathbb{N}}$ is a sequence in $X$, then there must exist a subsequence $x_{\beta_1}, x_{\beta_2}, x_{\beta_3}, ...$ which is constant. That is, $x_{\beta_1} = x_{\beta_2} = x_{\beta_3} = \cdot = c$ for some $c \in X$. 
    \item (All covers have finite subcovers) If $V_1, V_2, V_3, \cdot \subset X$ are any collection of sets which cover $X$, then there must exist a finite sub-collection $V_{n_1}, V_{n_2}, ..., V_{n_k}$ of these sets which still cover $X$. 
\end{enumerate}

The fact that all functions on a finite set are bounded is an example of a \textit{local-to-global principle}. Namely, the hypothesis is an assertion of "local" boundedness: it asserts that $|f(x)|$ is bounded for each point $x \in X$ separately (which can depend on $x$). This collection of local boundedness can be extrapolated to global boundedness: that $|f(x)|$ is bounded by a \textit{single} bound $M$ for all $x \in X$. This local-to-global boundedness is clearly valid when $X$ is finite, but it fails when $X$ is finite. For example, consider the function
\[id: \mathbb{N} \longrightarrow \mathbb{R}\]
which is clearly not bounded by any finite element in $\mathbb{R}$. 

However, given that we endow a metric or a topology on the set $X$, we can actually find some infinite sets that are "almost finite," in the way that they satisfy a modified version of these four assertions, which are created by introducing topological concepts such as continuity, convergence, and openness. One such "almost finite" set is the closed interval $[0,1]$. 
\begin{enumerate}
    \item (All \textit{continuous} functions are bounded) If $f: X \longrightarrow \mathbb{R}$ is a real-valued continuous function on $X$, then $f$ must be bounded. (This is another type of local-to-global principle; if a function is stable with respect to local perturbations, then it is stable with respect to global perturbations).
    \item (All \textit{continuous functions} attain a maximum) If $f: X \longrightarrow \mathbb{R}$ is a real-valued continuous function on $X$, then there exists at least one point $x_0 \in X$ such that $f(x_0) \geq f(x)$ for all $x \in X$. 
    \item (All sequences have convergent subsequences) If $x_1, x_2, ... \in X$ is a sequence of points in $X$, then there must exist a subsequence $x_{n_1}, x_{n_2}, ...$ which is convergent to some limit $c \in X$. (Bolzano-Weierstrass theorem).
    \item (All open covers have finite subcovers) If $V_1, V_2, V_3, ... \subset X$ are any collection of open sets which cover $X$, then there must exist a finite subcollection $V_{n_1}, V_{n_2}, ..., V_{n_k}$ of these sets which still cover $X$. 
\end{enumerate}

However, the open interval $(0,1)$ clearly does not satisfy any of these properties. For example, the continuous function 
\[f: (0,1) \longrightarrow \mathbb{R}, \; f(x) \equiv \frac{1}{1-x}\]
does not satisfy the boundedness condition, meaning that it does not satisfy the local-to-global principle. That is, $f$ is not stable under local perturbations of $x$. As you can guess by now, these "almost finite" sets that satifies these "weakened" topological conditions are compact sets. 
\[\begin{tikzcd}
Compact \;Sets \arrow{r}{satisfies} & Compact \;Conditions \\
Finite \;Sets \arrow{r}{satisfies} & Finite \;Conditions \arrow{u}{weakened}
\end{tikzcd}\]

However, the four properties are not exactly equivalent, so we can define compactness according to the fourth property: that every open cover has a finite subcover. There are other notions of compactness, such as \textit{sequential compactness}, which is based on the third version: all sequences have convergent subsequences. 

Compactness if a powerful property of spaces with many applications. One is via appeal to local-to-global principles; one establishes local control on some function or other quantity, and then uses compactness to boost the local control to global control. Another is to locate amaxima or minima of a function. Of course, many spaces of interest are not compact. For instance, the real line $\mathbb{R}$ is not compact because contains sequences such as $1, 2, 3, \cdot$ which are "trying to escape" the real line, and are not leaving behind and convergent subsequences. However, one can recover compactness by adding a few more points to the space, a process known as \textit{compactification}. We can add one point at either end of the real line, at $+\infty$ and $-\infty$, resulting in the compact \textit{extended real line}. 


\begin{example}
The subset $Y \equiv (0,1) \times (0,1) \subset \mathbb{R}^2$ is not compact. That is, we can choose to cover the subspace by the finite union of open sets. 
\[[0,1]^2 \subset \bigcup_{k=0}^\infty \Big( \frac{2^k - 1}{2^k}, \frac{2^{k+1} - 1}{2^{k+1}} \Big) \times (0,1)\]
We show the first three elements of the infinite union that covers the open square.  \\
\begin{center}
\begin{tikzpicture}[scale=2]
    \draw[dashed] (0,0) rectangle (1,1);
    \draw[dashed, fill=lightgray] (0,0) rectangle (0.5,1);
    \draw[dashed, fill=lightgray] (0.5,0) rectangle (0.75,1);
    \draw[dashed, fill=lightgray] (0.75,0) rectangle (0.875,1);
\end{tikzpicture}
\end{center}
\end{example}

\begin{theorem}
Every closed subset of a compact space is compact. 
\end{theorem}
\begin{proof}
This proof is quite trivial. Let $Y$ be a closed subset of compact space $X$. Given a covering $\mathcal{C}$ of $Y$ by sets open in $X$, let us form an open covering $\mathscr{B}$ of $X$ by adjoining to $\mathcal{C}$ the single open set $X \setminus Y$. Then, we an see that both $\mathscr{B}$ and $\mathcal{C} \cup (X \setminus Y)$ covers $X$. 
\[\mathscr{B} = \mathcal{C} \cup (X \setminus Y)\]
Since $\mathscr{B}$ is finite, the right hand side must also be expressible as a finite union. Looking through $\mathscr{B}$, we can throw away all the open sets that are entirely in $X \setminus Y$. What remains is a finite covering of $Y$. 
\end{proof}

\begin{theorem}
Every compact subset of a Hausdorff space is closed. 
\end{theorem}
\begin{proof}
Let $Y$ be a compact subset of the Hausdorff Space $X$. We claim that $X \setminus Y$ is open. Let $x \in X \setminus Y$. Then, for each point $y_i \in Y$, we can choose disjoint neighborhoods $U_i$ of $x$ and $V_i$ of $y_i$ (using the Hausdorff condition). The collection 
\[\{V_i \; | \; y_i \in Y\}\]
is an open covering $Y$. Since $Y$ is compact, there must exist a finite number of open sets $V_1, V_2, ..., V_n$ covering $Y$. Therefore, 
\[\bigcup_{i=1}^n V_i\]
contains $Y$ and is disjoint from the intersection of open neighborhoods of $x$
\[U \equiv \bigcap_{i=1}^n U_i\]
Therfore, $U$ is an open neighborhood of $x_0$, disjoint from $Y \implies X \setminus Y$ is open $\implies Y$ is closed.
\end{proof}

This results gives the following lemma. 

\begin{lemma}
If $Y$ is a compact subset of a Hausdorff space $X$ and $x_0$ is not in $Y$, then there exist disjoint open sets $U$ and $V$ of $X$ containing $x_0$ and $Y$, respectively. 
\end{lemma}

\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0) ellipse (5 and 2);
    \draw[dashed] (-3,0) circle (1);
    \draw[fill] (-3,0) circle (0.05);
    \node[left] at (-3,0) {$x$};
    \draw (3,0) circle (1); 
    \node[below] at (3,0.8){$Y$};
    \node[below] at (3, 0.4){compact};
    \node[above] at (-3,0.3) {$U$};
    \draw[dashed] (3,0) circle (1.3); 
    \node at (2,1) {$V$};
\end{tikzpicture}
\end{center}

\begin{theorem}
The image of a compact space under a continuous map is compact.
\end{theorem}
\begin{proof}
Let $f: X \longrightarrow Y$ be continuous, and let $X$ be compact. Let $\mathcal{C}$ be a covering of the set $f(X)$ by sets open in $Y$. Then, the preimage of these sets is the collection
\[\{f^{-1}(\mathcal{A}) \; | \; \mathcal{A} \in \mathcal{C}\}\]
which clearly covers $X$. But since $X$ is compact, a finite number of them, say
\[f^{-1} (\mathcal{A}_1), f^{-1} (\mathcal{A}_2), ..., f^{-1} (\mathcal{A}_n)\]
covers $X \implies \mathcal{A}_1, \mathcal{A}_2, ..., \mathcal{A}_n$ covers $f(X)$. 
\end{proof}

\begin{theorem}
Let $f: X \longrightarrow Y$ be a bijective continuous function. If $X$ is compact and $Y$ is Hausdorff, then $f$ is a homeomorphism. 
\end{theorem}
\begin{proof}
It suffices to prove that $f$ is an open or closed mapping. We shall show that $f$ is the latter. Let $U$ be closed in $X$. By the previous theorems, $U$ is compact $\implies f(U)$ is compact in Hausdorff $Y \implies f(U)$ is closed. Therefore, $f$ is closed. 
\end{proof}

We now introduce a useful lemma that will come around in many future cases. 

\begin{lemma}[Tube Lemma]
Consider the product space $X \times Y$, where $Y$ is compact. If $N$ is an open set $X \times Y$ containing the slice $x_0 \times Y$ of $X \times Y$, then $N$ contains some tube $W \times Y$ about $x_0 \times Y$, where $W$ is a neighborhood of $x_0$ in $X$. 
\end{lemma}
\begin{center}
\begin{tikzpicture}
    \draw[dashed, fill=lightgray] (3.5,0) rectangle (4.3,5);
    \draw (0,0)--(0,5);
    \draw[<->] (-1,0)--(8,0);
    \node[right] at (8,0) {$X$};
    \node[left] at (0,2.5) {$Y$};
    \draw[<->] (-1,5)--(8,5);
    \draw[thick] (4,0)--(4,5);
    \draw[dashed] (3,0) rectangle (4.8,1);
    \draw[dashed] (3.5,0.6) rectangle (4.5,2);
    \draw[dashed] (3.1,1.8) rectangle (6,3.5);
    \draw[dashed] (2.5,3.4) rectangle (4.3,4.7);
    \draw[dashed] (2.8,4) rectangle (5, 5);
    \draw[thick] (3.5,0)--(4.3,0);
    \node[above] at (4,5) {$W$};
    \node[below] at (4,0) {$x_0$};
    \draw[fill] (4,0) circle (0.05);
    \draw[dashed] plot [smooth] coordinates {(2.5,0) (2.3, 1) (2,3) (2.2,5)};
    \draw[dashed] plot [smooth] coordinates {(5.4,0) (6.5,2) (6.5,4) (5.7,5)};
    \node[left] at (6,4.5) {$N$};
\end{tikzpicture}
\end{center}
\begin{proof}
Let us cover $x_0 \times Y$ by basis elements $U \times V$ (for the topology of $X \times Y$) lying in $N$. The space $x_0$ is compact since it is homeomorphic to $Y \implies$ we can cover $x_0 \times Y$ by finitely such basis elements
\[U_1 \times V_1, U_2 \times V_2, ..., U_n \times V_n\]
Without loss of generality, we can assume that each $U_i \times V_i$ has a nontrivial intersection with $x_0 \times Y$, since otherwise, it would be superfluous. Now, we define the intersection of all the open neighborhoods of $x_0$ in $X$ of the basis elements $U_i \times V_i$. That is, let
\[W \equiv \bigcup_{i=1}^n U_i\]
As an intersection of open sets, $W$ is also open containing $x_0$. With this well-defined tube $W \times Y$, we claim that it is entirely contained within $N$. That is, given a point $x \times y \in W \times Y$, consider the corresponding point $x_0 \times y$ that is the image of the projection of $x\times y$ onto $x_0 \times Y$. Clearly, $x_0 \times y$ belongs to some $U_k \times V_k$ (for some $k$) $\implies y \in V_k$. Since $x \in W$, $x$ is clearly in $U_k$, meaning that $x \times y \in U_k \times V_k \subset N$, as desired. 
\end{proof}

\begin{theorem}
The product of finitely many compact spaces is compact. 
\end{theorem}
\begin{proof}
Using induction, it suffices to prove that the product of 2 compact spaces is compact. Let $X$ and $Y$ be compact spaces. By the tube lemma, for each $x \in X$, there exists a neighborhood $W_x$ of $x$ such that the tube $W_x \times Y$ can be covered with finitely (by compactness of $Y$) many open sets in $X \times Y$. The collection of all neighborhoods $W_x$ is an open covering of $X$. By compactness of $X$, there exists a finite subcollection
\[W_1, W_2, ..., W_k\]
covering $X$. The finite union of the tubes 
\[\bigcup_{i=1}^k W_i \times Y\]
clearly covers $X \times Y$, meaning that $X \times Y$ is compact. 
\end{proof}

\begin{definition}
A collection $\mathcal{C}$ of subsets of $X$ is said to satisfy the \textit{finite intersection condition} if for every finite subcollection 
\[\{\mathcal{C}_1, \mathcal{C}_2, ..., \mathcal{C}_n\}\]
of $\mathcal{C}$, the intersection
\[\bigcap_{i=1}^n \mathcal{C}_i\]
is nonempty. 
\end{definition}

Clearly, the empty sets cannot below to any collection with the finite intersection property. Additionally, the condition is trivially satisfied if the intersection over the entire collection is non-empty or if the collection is nested. However, here is one example that does satisfy the finite intersection condition. 

\begin{example}
Let $X = (0,1)$ and for each positive integer $i$, $X_i$ is the set of elements of $X$ having a decimal expansion with digit $0$ in the $i$th decimal place. Then, any finite intersection of $X_i$'s is nonempty, but the intersection of all $X_i$ for $i \in \mathbb{N}$ is empty, since no element of $(0,1)$ has all zero digits. 
\end{example}

Here is an analogous example to the previous one. 
\begin{example}
In the space $\mathbb{R}$, let us define $C_i \equiv \mathbb{R} \setminus \{i\}$. That is, $C_i$ is $\mathbb{R}$ missing a point at $i$. Then, the collection of all $C_i$'s does satisfy the finite intersection condition. We show below the finite intersection of the five subsets $C_0, C_1, C_2, C_3, C_4$. 
\begin{center}
\begin{tikzpicture}[scale=0.8]
    \draw[<->] (-1,0)--(6,0);
    \draw[<->] (-1,1)--(6,1);
    \draw[<->] (-1,2)--(6,2);
    \draw[<->] (-1,3)--(6,3);
    \draw[<->] (-1,4)--(6,4);
    \draw[<->] (-1,-1)--(6,-1);
    \draw[fill=white] (0,0) circle (0.07); 
    \draw[fill=white] (1,1) circle (0.07); 
    \draw[fill=white] (2,2) circle (0.07); 
    \draw[fill=white] (3,3) circle (0.07); 
    \draw[fill=white] (4,4) circle (0.07); 
    \draw[fill=white] (0,-1) circle (0.07); 
    \draw[fill=white] (1,-1) circle (0.07); 
    \draw[fill=white] (2,-1) circle (0.07); 
    \draw[fill=white] (3,-1) circle (0.07); 
    \draw[fill=white] (4,-1) circle (0.07); 
    \node[right] at (6,-1) {$\bigcap_{i=0}^4 C_i$};
    \node[right] at (6,0) {$C_0$};
    \node[right] at (6,1) {$C_1$};
    \node[right] at (6,2) {$C_2$};
    \node[right] at (6,3) {$C_3$};
    \node[right] at (6,4) {$C_4$};
\end{tikzpicture}
\end{center}
\end{example}


\begin{theorem}
Let $X$ be a topological space. Then $x$ is compact if and only if for any collection $\mathcal{C}$ of closed sets in $X$ satisfying the finite intersection condition, the intersection 
\[\bigcap_{C \in \mathcal{C}} C\]
of all the elements of $\mathcal{C}$ is nonempty. 
\end{theorem}
\begin{proof}
Given a collection $S$ fo subets of $X$, let 
\[\mathcal{C} \equiv \{X \setminus A \; | \; A \in S\}\]
be the collection of their complements. Then, the following statements hold 
\begin{enumerate}
    \item $S$ is a collection of open sets if and only if $\mathcal{C}$ is a collection of closed sets. 
    \item The collection $S$ covers $X$ if and only if the intersection 
    \[\bigcap_{C \in \mathcal{C}} C\]
    of all the elements of $\mathcal{C}$ is empty. 
    \item The finite subcollection $\{A_1, A_2, ..., A_n\}$ of $S$ covers $X$ if and only if the intersection of the corresponding elements $C_i \equiv X \setminus A$ of $\mathcal{C}$ is empty. 
\end{enumerate}
Clearly, (1) is trivial, and (2) and (3) follows from DeMorgan's Law. 
\[X \setminus \bigcup_{\alpha \in J} A_\alpha = \bigcap_{\alpha \in J} (X \setminus A_\alpha)\]
Using statement 3, the existence of a finite collection of closed sets $C$ in $X$ satisfying the finite intersection condition is equivalent to its complements (which are open sets) covering $X$, which is precisely the definition of compactness. 
\end{proof}

Clearly, the previous example in the real line $\mathbb{R}$ shows that $\mathbb{R}$ is indeed not compact. 

\begin{corollary}
The space $X$ is compact if and only if every collection $\mathscr{C}$ of subsets of $X$ satisfying the finite intersection condition, the intersection 
\[\bigcap_{A \in \mathscr{C}} \bar{A}\]
of their closures is nonempty. 
\end{corollary}

\subsection{Compact Sets of the Real Line}
In order to construct new compact spaces from old ones, we must prove compactness for a number of fundamental spaces. The real number line is a good starting point, and in order to prove that every closed interval in $\mathbb{R}$ is compact, we only need the following theorem. 

\begin{theorem}
Let $X$ be a simply ordered set having the least upper bound property (That is, every nonempty subset of $X$ with an upper bound has a least upper bound). Then, in the order topology, every closed interval in $X$ is compact. 
\end{theorem}

\begin{corollary}
Every closed interval in $\mathbb{R}$ is compact. 
\end{corollary}

\begin{theorem}[Heine-Borel Theorem]
A subset $A$ of $\mathbb{R}^n$ is compact if and only if it is closed and bounded in the Euclidean metric $d$ or the square metric $p$. 
\end{theorem}

\begin{example}
The unit sphere $S^{n-1}$ and the closed ball $B^n$ in $\mathbb{R}^n$ are compact since they are closed and bounded. The set
\[A \equiv \{(x, \frac{1}{x}) \; | \; 0 < x \leq 1\}\]
is closed in $\mathbb{R}^2$, but is not compact since it is not bounded. The set 
\[S \equiv \{(x, \sin{\frac{1}{x}}) \; | \; 0<x\leq 1\}\]
is bounded in $\mathbb{R}^2$, but it is not compact since it is not closed. 
\end{example}

\begin{theorem}[Maximum, Minimum Value Theorem]
Let $f: X \longrightarrow Y$ be continuous, where $Y$ is an ordered set in the order topology. If $X$ is compact, then there exists points $c$ and $d$ in $X$ such that $f(c) \leq f(x) \leq f(d)$ for every $x \in X$. That is, $f$ has a maximum and a minimum at the values $d$ and $c$, respectively. 
\end{theorem}

\subsection{Limit Point Compactness}
We now state different, weaker types of compactness. 

\begin{definition}
A space $X$ is said to be \textit{sequentially compact} if every sequence of points in $X$ has a subsequence that converges to a point $x \in X$. 
\end{definition}

\begin{definition}
A space $X$ is said to be \textit{countably compact} if every countably open cover has a finite subcover. 
\end{definition}

\begin{definition}
A space $X$ is said to be \textit{limit point compact} if every infinite subset of $X$ has a limit point. 
\end{definition}

\begin{theorem}
Compactness $\implies$ limit point compactness.  
\end{theorem}

\begin{lemma}[Lebesgue Number Lemma]
Let $\mathscr{C}$ be an open covering of the metric space $(X, d)$. If $X$ is compact, then there is a $\delta > 0$ such that for each subset of $X$ having diameter than $\delta$, there exists an element of $\mathscr{C}$ containing it. This number $\delta$ is called a \textit{Lebesgue number} for the covering $\mathscr{C}$. 
\end{lemma}

Another theorem of calculus, suitably generalized to topological spaces, is stated. 
\begin{theorem}[Uniform Continuity Theorem]
Let $f: X \longrightarrow Y$ be a continuous map of the compact metric space $(X,d_X)$ to the metric space $(Y, d_Y$. Then, $f$ is uniformly continuous. That is, given $\epsilon > 0$, there exists a $\delta > 0$ such that for any two points $x_1, x_2 \in X$, 
\[d_X (x_1, x_2) < \delta \implies d_Y \big( f(x_1), f(x_2)\big) < \epsilon\]
\end{theorem}

\begin{theorem}
Let $(X, \tau)$ be a metrizable space. Then the following are equivalent: 
\begin{enumerate}
    \item $X$ is compact. 
    \item $X$ is limit point compact. 
    \item $X$ is sequentially compact. 
    \item $X$ is countably compact. 
\end{enumerate}
\end{theorem}

\subsection{Local Compactness}
\begin{definition}
A space $X$ is said to be \textit{locally compact} at $x$ if there is some compact subset $C$ of $X$ that contains a neighborhood of $x$. If $X$ is locally compact at each of its points, $X$ is simply to be \textit{locally compact}. 
\end{definition}

\begin{example}
The real line $\mathbb{R}$ is locally compact since any point $x \in \mathbb{R}$ lies within a certain closed interval $[a,b]$, which is compact. The subspace $\mathbb{Q}$ is not locally compact. 
\end{example}

Two of the most well-behaved classes of spcaes to deal with are metrizable spaces and compact Hausdorff spaces. If a given space is not one of these types, the next best thing one can hope for is that it is a subspace of one of these spaces. Clearly, a subspace of a metrizable space is itself metrizable, so one does not get any new spaces this way. However, a subspace of a compact Hausdorff space need not be compact. This leads to the question: Under what conditions is a space homeomorphic to a subspace of a compact Hausdorff space? 

\begin{definition}
Let $X$ be a locally compact Hausdorff space. Take some object outside $X$, denoted by the symbol $\infty$, and adjoin it to $X$, forming the set
\[Y = X \cup \{\infty\}\]
Topologize $Y$ by defining the collection of open sets in $Y$ to be the sets of the following types:
\begin{enumerate}
    \item $U$, where $U$ is an open subset of $X$. 
    \item $Y \setminus C$, where $C$ is a compact subset of $X$.
\end{enumerate}
Then, this space $Y$ is called the \textit{one-point compactification of $X$}. This is in some sense the minimal compactification of $X$. 
\end{definition}
We briefly show that this set of open sets on $Y$ is indeed a topology. First, $\emptyset$ is of type 1 and $Y$ itself is of type 2. Given $U_i$ of type 1 and $Y \setminus C_i$ of type 2, we have the intersections of two sets
\begin{align*}
    &U_1 \cap U_2 & \text{ is type 1} \\
    &(Y \setminus C_1) \cap (Y \setminus C_2) = Y \setminus (C_1 \cup C_2) & \text{ is type 2} \\
    &U_1 \cap (Y \setminus C_1) = U_1 \cap (X \setminus C_1) & \text{ is type 1} \\
\end{align*}
along with the arbitrary union of sets
\begin{align*}
    &\bigcup U_\alpha = U & \text{ is type 1} \\
    &\bigcup (Y \setminus C_\beta) = Y \setminus (\bigcap C_\beta) = Y \setminus C & \text{ is type 2} \\
    &(\bigcup U_\alpha) \cup ( \bigcup (Y \setminus C_\beta)) = U \cup (Y \setminus C) = Y \setminus (C \setminus U) & \text{ is type 2} \\
\end{align*}
We now present some properties of one-point compactifications. 

\begin{theorem}
Let $X$ be a locally compact Hausdorff space which is not compact, and let $Y$ be a one-point compactification of $X$. Then $Y$ is a compact Hausdorff space. Additionally, since $X \subset Y$ with $Y \setminus X$ consisting of a single point, $\bar{X} = Y$. 
\end{theorem}

\begin{example}
The one-point compactification of the real line $\mathbb{R}$ is homeomorphic to the circle $S^1$. That is, 
\[\mathbb{R} \cup \{\infty\} \cong S^1\]
$\mathbb{R} \cup \{\infty\}$ is called the \textit{extended real number line}. We can see this homeomorphism by visualizing the stereographic projection $p: S^1 \setminus \{s\} \longrightarrow \mathbb{R}$. \\
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0) circle (3);
    \node[above] at (0,3) {$s$};
    \draw[<->] (-7,0)--(7,0);
    \node[above] at (6.7,0) {$\mathbb{R}$};
    \draw[->, dashed] (0,3)--(3.2,-0.2);
    \draw[->, dashed] (0,3)--(2.7,-2.5);
    \draw[->, dashed] (0,3)--(6.8,-1);
    \draw[fill=white] (0,3) circle (0.1);
    \draw[->, dashed] (0,3)--(-2.8, -2.8);
    \draw[fill] (3,0) circle (0.05);
    \draw[fill] (-2.349,-1.866) circle (0.05);
    \draw[fill] (5.1,0) circle (0.05);
    \draw[fill] (2.622,1.458) circle (0.05);
    \draw[fill] (-1.448,0) circle (0.05);
    \draw[fill] (1.471,0) circle (0.05); 
    \draw[fill] (2.371, -1.838) circle (0.05);
    \node[left] at (2.371, -1.838) {$a$};
    \node[below left] at (1.471,0) {$p(a)$};
    \node[above left] at (-1.448,0) {$p(b)$};
    \node[right] at (-2.349,-1.866) {$b$};
    \node[above right] at (5.1,0) {$p(d)$};
    \node[above right] at (2.622,1.458) {$d$};
    \node[below right] at (3,0) {$c = p(c)$};
\end{tikzpicture}
\end{center}
\end{example}

\begin{example}
The one point-compactification of the real plane $\mathbb{R}^2$ is homeomorphic to the 2-sphere $S^2$. That is, 
\[\mathbb{R}^2 \cup \{\infty\} \cong S^2\]
We can similarly imagine this homeomorphism using the stereographic projection. 
\begin{center}
    \includegraphics[scale=0.23]{Two_Dim_Stereographic_Projection.PNG}
\end{center}
\end{example}

\begin{lemma}
Let $X$ be a Hausdorff space. Then $X$ is locally compact at $x$ if and only if for every neighborhood $U$ of $x$, there is a neighborhood $V$ of $x$ such that $\bar{V}$ is compact and $\bar{V} \subset U$. 
\end{lemma}

\begin{corollary}
Let $X$ be a locally compact Hausdorff space with $Y$ a subspace of $X$. If $Y$ is closed in $X$ or open in $X$, then $Y$ is locally compact. 
\end{corollary}

\begin{corollary}
A space $X$ is homeomorphic to an open subset of a compact Hausdorff space if and only if $X$ is locally compact and Hausdorff. 
\end{corollary}

\section{Countability and Separation Axioms}
\begin{definition}
A space $X$ is said to have a countable basis at $x$ if there exists a sequence $N_1, N_2, ...$ of open neighborhoods of $x$ such that for any neighborhood $N$ of $x$, there exists an integer $i$ such that $N_i \in N$. That is, the countable basis of neighborhoods get arbitrarily small around $x$. A space $X$ satisfying this axiom at every point $x \in X$ is said to be a \textit{first-countable space}. 
\end{definition}

In particular, every metric space is first-countable, since we can construct the sequence of open balls $B (x, \frac{1}{n})$ for each $n \in \mathbb{N}$ which forms a countable basis at $x$. 

We now generalize some previous statements about metric spaces to statements about first-countable spaces. 

\begin{theorem}
Let $X$ be a space satisfying the first countability axiom, and let $A \subset X$. 
\begin{enumerate}
    \item $x \in \bar{A}$ if and only if there exists a sequence of points in $A$ converging to $x$. 
    \item The function $f: X \longrightarrow Y$ is continuous if and only if for every convergent sequence $(x_n) \rightarrow x$ in $X$, the sequence $\big( f(x_n)\big) \rightarrow f(x)$ in $Y$. 
\end{enumerate}
\end{theorem}

\begin{definition}
A topological space $X$ is said to satisfy the \textit{second countability axiom} if $X$ has a countable basis for its topology.
\end{definition}

\begin{proposition}
Second countability implies first countability. 
\end{proposition}
\begin{proof}
If $\mathscr{B}$ is a countable basis for the topology of $X$, then the subset of $\mathscr{B}$ consisting of elements containing the point $x$ is a countable basis at $x$. 
\end{proof}

\begin{example}
The real line $\mathbb{R}$ is second countable. We can contrust a countable basis as the set of all open intervals $(a, b)$ with rational end points. Likewise, $\mathbb{R}^n$ has a countable basis, which is the collection of all products of intervals having rational end points. Additionally, $\mathbb{R}^\omega$ has a countable basis. It is the collection of all products
\[\prod_{n \in \mathbb{N}} U_n\]
where $U_n$ is an open interval with rational endpoints for finitely many values of $n$ and $U_n = \mathbb{R}$ for all other values of $n$. 
\end{example}

\begin{example}
In the uniform topology, $\mathbb{R}^\omega$ satisfies the first countability axiom (since it is metrizable). 
\end{example}

\begin{theorem}
A subspace of a first and second countable space is first and second countable, respectively. A countable product of first and second countable space is first and second countable, respectively. 
\end{theorem}

\begin{theorem}
A subset $A$ of space $X$ is said to be \textit{dense} in $X$ if $\bar{A} = X$. 
\end{theorem}

\begin{theorem}
Suppose that $X$ has a countable basis. Then, 
\begin{enumerate}
    \item Every open cover of $X$ has a countable subcover. 
    \item There exists a countable subset of $X$ which is dense in $X$. 
\end{enumerate}
\end{theorem}
\begin{proof}
a) Let $\mathscr{B} = \{B_n\}_{n \in \mathbb{N}}$ be a countable basis for $X$, and let $\mathscr{A}$ be an open covering of $X$. For each integer $n \in \mathbb{N}$, chose an element $A_n \in \mathscr{A}$ containing the basis element $B_n$. The newly formed collection $\mathscr{A}^\prime$ of all the $A_n$'s is countable since it is indexed according to a subset of $\mathbb{N}$. Furthermore, since $B_n \subset A_n$ for every $B_n$ in the basis, the $A_n$ clearly covers $X$. \\
b) From each nonempty basis element $B_n$, we choose a point $x_n$. The set 
\[D \equiv \{x_n \; | \; n \in \mathbb{N}\}\]
is dense in $X$, since given any $x \in X$, every open basis element $B_x$ about $x$ intersects $D$. That is, 
\[B_x \cap D \neq \emptyset\]
meaning that the set of points $x_n$ get arbitrarily close to $x$. 
\end{proof}

\begin{definition}
A space for which every open covering contains a countable subcovering is called a \textit{Lindelof space}. 
\end{definition}

\begin{definition}
Suppose that one-point sets are closed in $X$. Then, $X$ is said to be \textit{regular} if for each pair consisting of a point $x$ and a closed set $B$ disjoint from $x$, there exist disjoint open sets containing $x$ and $B$, respectively. $X$ is also said to be $t_3$-separable. 
\end{definition}

\begin{definition}
The space $X$ is said to be \textit{normal} if for each pair $A, B$ of disjoint closed sets of $X$, there exist disjoint open sets containing $A$ and $B$, respectively. $X$ is also said to be $t_4$-separable. 
\end{definition}

\begin{lemma}
Let $X$ be a topological space. Let one-point sets in $X$ be closed. 
\begin{enumerate}
    \item $X$ is regular if and only if given a point $x \in X$ and a neighborhood $U$ of $x$, there is a neighborhood $V$ of $x$ such that $\bar{V} \subset U$. 
    \item $X$ is normal if and only if given a closed set $A$ and an open set $U$ containing $A$, there exists an open set $V$ containing $A$ such that $\bar{V} \subset U$. 
\end{enumerate}
\end{lemma}

\begin{theorem}
\begin{enumerate}
    \item A subspace of a Hausdorff space is Hausdorff; a product of Hausdorff spaces is Hausdorff. 
    \item A subspace of a regular space is regular; a product of regular spaces is regular. 
    \item However, a subspace of a normal space is not necessarily normal; a product of normal spaces is not necessarily normal. 
\end{enumerate}
\end{theorem}

\begin{theorem}
Every metrizable space is normal. 
\end{theorem}

\begin{theorem}
Every compact Hausdorff space is normal. 
\end{theorem}

\begin{theorem}
Every regular space with a countable basis is normal. 
\end{theorem}

\begin{theorem}
Every well-ordered set $X$ is normal in the order topology. 
\end{theorem}

\subsection{The Urysohn Lemma}
\begin{theorem}[Urysohn Lemma]
Let $X$ be a normal space, and let $A, B$ be disjoint closed subsets of $X$. Let $[a,b]$ be a closed interval in the real line. Then there exists a continuous map
\[f: X \longrightarrow [a,b]\]
such that $f(x) = a$ for every $x \in A$ and $f(x) = b$ for every $x \in B$. 
\end{theorem}


\begin{definition}
If $A$ and $B$ are two subsets of the topological space $X$, and if there is a continuous function $f: X \longrightarrow [0,1]$ such that $f(A) = \{0\}$ and $f(B) = \{1\}$, it is said that \textit{$A$ and $B$ can be separated by a continuous function}. 
\end{definition}

More colloquially, the lemma states that if every pair of disjoint closed sets in $X$ can be separated by disjoint open sets, then each such pair can be separated by a continuous function. 

\begin{theorem}[Tietze Extension Theorem]
Let $X$ be a normal space and let $A$ be a closed subset of $X$. 
\begin{enumerate}
    \item Any continuous map of $A$ into the closed interval $[a,b] \subset \mathbb{R}$ may be extended to a continuous map of all $X$ into $[a,b]$. 
    \item Any continuous map $A$ into the reals $\mathbb{R}$ may be extended to a continuous map of all of $X$ into $\mathbb{R}$. 
\end{enumerate}
\end{theorem}

\subsection{The Urysohn Metrization Theorem}
\begin{theorem}[Urysohn Metrization Theorem]
Every regular space $X$ with a countable basis is metrizable. 
\end{theorem}

\begin{theorem}[Imbedding Theorem]
Let $X$ be Hausdorff. Suppose that 
\[\{f_\alpha\}_{\alpha \in J}, \; f_\alpha: X \longrightarrow \mathbb{R}\]
is a collection of continuous functions satisfying the requirement that for each point $x_0 \in X$ and each neighborhood $U$ of $x_0$, there is an index $\alpha$ such that $f_\alpha$ is positive at $x_0$ and vanishes outside $U$. Then, the function 
\[F: X \longrightarrow \mathbb{R}^J, \; F(x) \equiv \big( f_\alpha (x)\big)_{\alpha \in J}\]
is an \textit{imbedding} of $X$ in $\mathbb{R}^J$.
\end{theorem}

\section{The Tychonoff Theorem}
\begin{theorem}
An arbitrary product of compact spaces is compact under the product topology. 
\end{theorem}

\begin{definition}
A space $X$ is \textit{completely regular} if one-point sets are closed in $X$ and if for each point $x_0$ and each closed set $A$ not containing $x_0$, there is a continuous function $f: X \longrightarrow [0,1]$ such that $f(x_0) = 1$ and $f(A) = \{0\}$. 
\end{definition}

\begin{theorem}
A subspace of a completely regular space is completely regular. A product of completely regular spaces is completely regular. 
\end{theorem}

\begin{theorem}
If $X$ is completely regular, then $X$ can be imbedded in $[0,1]^J$ for some $J$. 
\end{theorem}

\begin{corollary}
Let $X$ be a space. The following are equivalent: 
\begin{enumerate}
    \item $X$ is completely regular. 
    \item $X$ is homeomorphic to a subspace of a compact Hausdorff space. 
    \item $X$ is homeomorphic to a subspace of a normal space. 
\end{enumerate}
\end{corollary}

\begin{definition}
A \textit{compactification} of a space $X$ is a compact Hausdorff space $Y$ containing $X$ such that $X$ is dense in $Y$ (that is $\bar{X} = Y$). Two compactifications $Y_1$ and $Y_2$ of $X$ are said to be \textit{equivalent} if there is a homeomorphism $h: Y_1 \longrightarrow Y_2$ such that $h(x) = x$ for every $x \in X$. 
\end{definition}

\begin{theorem}
Let $X$ be completely regular, and let $\beta(X)$ be its Stone-Cech compatification. Then every bounded continuous real-valued function on $X$ can be uniquely extended to a continuous real-valued function on $\beta(X)$. 
\end{theorem}

\begin{lemma}
Let $A \subset X$, and let $f: A \longrightarrow Z$ be a continuous map of $A$ into the Hausdorff space $Z$. There is at most one extension of $f$ to a continuous function $g: \bar{A} \longrightarrow Z$. 
\end{lemma}

\begin{theorem}
Let $X$ be completely regular. Let $Y_1, Y_2$ be two compactifications of $X$ having the extension property. Then there is a homeomorphism $\phi$ of $Y_1$ onto $Y_2$ such that $\phi(x) = x$ for each $x \in X$. 
\end{theorem}


\chapter{Ordinary Differential Equations}
\section{Systems}
The theory of ordinary differential equations allows us to study all evolutionary processes satisfying three properties. 
\begin{enumerate}
    \item Deterministic; that is, the entire past and future is determined by its present state. 
    \item Finite-dimensionality; that is, the number of parameters needed to describe any state is finite. 
    \item Differentiability; that is, the phase space of has the structure of a differentiable manifold. 
\end{enumerate}
The motion of a system in classical mechanics can be described using ordinary differential equations. However, quantum mechanics, impact theory, fluid mechanics, and heat transfer do not satisfy all three properties. 

\subsection{Phase Spaces, Phase Flows}

\begin{definition}
Given a system that can be represented by a finite number of $1$-dimensional parameters $x_1, x_2, ..., x_n$, each in their respective spaces $X_1, X_2, ..., X_n$, respectively, the \textit{phase space} of the system is the set
\[S \equiv \prod_{i=1}^n X_i\]
Notice that each element $s \in S$ represents one specific state of the system. While obvious, it should explicitly be stated that 
\[\dim{S} = n\]
\end{definition}

The abstract notion of a phase space is extremely useful, since we can now model states of the system as points in $S$. As stated before, we can form a general theory and treat $S$ as a differentiable manifold, but for simplicity, we will treat $S = \mathbb{R}^n$. 

The motion of the entire system can be described by the motion of a point over a curve in the phase space. Since the system is deterministic, the entire motion over this curve is determined by the point itself. 
\begin{definition}
Therefore, we can assign a velocity vector at each point $s \in S$ that models the motion of the point, called the \textit{phase velocity vector}. The set of all phase velocity vectors in $S$ is called the \textit{phase velocity vector field} in the phase space $S$. This vector field defines the differential equation of the process. 
\begin{center}
\includegraphics[scale=0.25]{Phase_Velocity_Vector_Field.PNG}
\end{center}
Since we are trying to model the motion of a point through $S$, it is often convenient to paramaterize the motion as a curve with the time parameter $t$. This creates a well-defined curve (blue curves in the figure above) in a new space that now has a time-axis. 
\end{definition}


\begin{definition}
Given a phase space $S$, the \textit{extended phase space} of a system is the space 
\[S \oplus \mathbb{R}\]
where $\mathbb{R}$ represents the new time axis, with parameter $t$. Note that within this theory, negative values of $t$ are well-defined, and $\dim{(S \oplus \mathbb{R})} = n+1$. 
\begin{center}
\includegraphics[scale=0.25]{Extended_Phase_Space.PNG}
\end{center}
The parameterized curve, called the \textit{integral curve}, is defined with the mapping
\[t \mapsto \big( t, \varphi(t) \big)\]
where $\varphi$ is the path of the particle through $S$. 
\end{definition}

But rather than focusing on the integral curve itself, it is useful to visualize the entire phase velocity field continuously (since we've assumed differentiability) "morphing" with respect to time. This represents a change in the entire system as time passes by. 
\begin{center}
\includegraphics[scale=0.25]{Morphing_Field.PNG}
\end{center}
With this visual in mind, we can see that there may be multiple integral curves that can go through $S \oplus \mathbb{R}$. To determine a unique integral curve, it may be necessary to define an \textit{initial point} that represents an initial condition. 

However, there may be some systems that are invariant under time. For example, swinging a pendulum or the movement of a particle is only dependent on the position and velocity of the pendulum and particle. Whether we let go of the pendulum at $t=0$ or $t=1$ does not matter. This is what we call an \textit{autonomous} system. 

\begin{definition}
An \textit{autonomous}, or \textit{time-homogeneous}, system is a system where the phase space does not have a time parameter. We can visualize this type of system as one where the phase velocity vector does not morph at all. 
\begin{center}
    \includegraphics[scale=0.25]{Autonomous_Field.PNG}
\end{center}
\end{definition}

\begin{example}[1-Dimensional Autonomous System]
Another special type of system is one that produces a one dimensional \textit{constant} phase field that changes in the same way everywhere with respect to time. We can visualize it as a vector field in $\mathbb{R}$ that stays constant as time passes (left). Since it may be hard to visualize vectors in $\mathbb{R}$, we can view them as slopes. 
\begin{center}
    \includegraphics[scale=0.25]{One_dim_auto_system.PNG}
\end{center}
\end{example}

\begin{example}[1-Dimensional General System]
A one dimensional system can be visualized as the initial vector field of $\mathbb{R}$ at $t=0$ gradually morphing as time passes. 
\begin{center}
    \includegraphics[scale=0.25]{One_dim_general_system.PNG}
\end{center}
\end{example}

\begin{example}[1-Dimensional Non-Autonomous Constant System]
Let $\nu$ be a constant, one-dimensional non-autonomous phase velocity field that changes with respect to time $t$. 
\begin{center}
    \includegraphics[scale=0.25]{Nonauto_constant_field.PNG}
\end{center}
Then, the function $\varphi$ in which its graph $\big( t, \varphi(t)\big)$ precisely overlaps the integral curves of $\nu$ can be computed by \textit{Barrow's formula}
\[\varphi(t) = x_0 + \int_{t_0}^t \nu(\tau)\, d\tau\]
Where $(t_0, x_0)$ is the initial condition of the system, and $\tau$ is a dummy variable representing time. 
\end{example}

It is also worthwhile to note that we can define the function to exist within a certain subset of the phase space and to be defined over a certain time interval within $\mathbb{R}$, rather than requiring it to be defined on the whole space itself. We will denote the time interval $I \subset \mathbb{R}$ and the subset $U \subset S$. 
\begin{center}
    \includegraphics[scale=0.25]{ODE_in_open_set.PNG}
\end{center}

\subsubsection{Dimensionality vs Order}

\begin{definition}[Dimensionality of a System]
The \textit{dimensionality} of the phase space of a system is dependent upon many things: 
\begin{enumerate}
    \item the dimension of the space that we are working in
    \item the number of particles or bodies that we observe
    \item other factors, like orientation, that may add extra parameters 
\end{enumerate}
But colloquially, the more things we have to keep track in the system, the higher the dimensionality. 
\end{definition}

\begin{definition}[Order of a System]
Formally, the \textit{order} of a differential equation is the highest order derivative that is contained within the equation. It has nothing to do with how many moving parts there are (i.e. dimensionality) and more with the rule that each moving part follows. 
\end{definition}




\begin{example}
We will state a couple examples of how many dimensions certain systems would have: 
\begin{enumerate}
    \item A point particle moving in three dimensional space in a constant force field would have $3$ spatial dimensions (each represented by a second order differential equation). Note that a constant force field means that acceleration is also constant, so acceleration is not taken into account. 
    \begin{center}
        \includegraphics[scale=0.25]{Point_Moving_in_Space.PNG}
    \end{center}
    \item A rigid body in 3-space has 6 parameters (3 for its center of mass and 3 for its orientation). 
    \begin{center}
        \includegraphics[scale=0.25]{Rigid_Body.PNG}
    \end{center}
    Therefore, a system of 3 rigid bodies in 3-space has a total of $6 \times 3 = 18$ dimensions, where each body is individually following $F = ma$ where the force $F$ is given by the gravitational force. This gives a second order differential equation for each body in terms of the positions of the other bodies. 
    \begin{center}
        \includegraphics[scale=0.25]{System_of_3_Rigid_Bodies.PNG}
    \end{center}
\end{enumerate}
\end{example}

\subsection{First Order Differential Equations}
The simplest types of differential equations are systems that contain parameters displacement and first derivative (velocity). Note that this does not necessarily mean that the dimension of the phase space is $1$. 

\begin{definition}[n-dimensional First Order Differential Equation]
An \textit{n-dimensional first order differential equation} is an equation of the form
\[y^\prime = f(t, y)\]
where $y$ is an $n$-dimensional vector representing the displacement parameters of the system, $t$ is the time parameter, and
\[f(t_0, \cdot) : \mathbb{R}^n \longrightarrow \mathbb{R}^n\]
is an $n$-dimensional vector field that determines the phase velocity field of $S$ at time $t = t_0$. It can also be written explicitly as a system as 
\[\begin{pmatrix}
y_1^\prime \\ y_2^\prime \\ \vdots \\ y_n^\prime
\end{pmatrix} = \begin{pmatrix}
f_1 (t, y) \\ f_2 (t, y) \\ \vdots \\ f_n (t, y)
\end{pmatrix}\]
This equation defines an $n$-dimensional phase velocity field that morphs as time passes, which is used to model the movement of the $n$-dimensional system. Simply put, the velocity vector that determines the evolution of the system is completely dependent on the current state of the system (value of $y$) and the time (value of $t$). 

The solution to this system is a smooth map $\varphi: I \subset \mathbb{R} \longrightarrow U \subset \mathbb{R}^n$ defined by the integral curve $t \mapsto (t, \varphi(t))$ in the extended phase space that satisfies the equation
\[\varphi^\prime (t) = f\big( t, \varphi(t) \big)\]
\end{definition}

\subsubsection{Basic One-Dimensional Examples}

\begin{example}[Normal Reproduction]
Assume that the size of a biological population is $y$ and that the rate of reproduction is proportional to the number of organisms present. This is expressed by the first order differential equation of dimension 1 
\[y^\prime = k y, \;\; k > 0\] 
\begin{center}
    \includegraphics[scale=0.2]{Normal_Reproduction.PNG}
\end{center}
The solution to the equation, given initial conditions $(t_0, y_0)$ is 
\[\varphi(t) = e^{k (t - t_0)} y_0\]
\end{example}

\begin{example}[Explosion Equation]
If we assume that the rate of reproduction is proportional to the number of pairs of individuals, we get the differential equation 
\[y^\prime = k y^2\]
The integral curves of this equation shoot off to infinity in a finite time, while the integral curves of the normal reproduction system reaches infinite when $t$ is infinite. 
\begin{center}
    \includegraphics[scale=0.25]{Explosion_Equation.PNG}
\end{center}
\end{example}

\begin{example}[Logistic Curve]
Due to limiting factors that may restrict the rate of growth of a population, we modify the equation to the following \textit{logistic equation}. 
\[x^\prime = (1 - x) x\]
Both the direction field and the integral curves are shown. 
\begin{center}
    \includegraphics[scale=0.15]{Logistic_Curve.PNG}
\end{center}
\end{example}

\begin{example}[Harvest Quotas]
Now, we model a situation where we harvest a part of the population. Let us first assume that the rate of harvest is constant. This leads to the differential equation
\[x^\prime = (1 - x) x - c\]
The quantity $c$ represents the rate of harvesting and is called the \textit{quota}. For different values of $c$, this results in the integral curves. 
\begin{center}
    \includegraphics[scale=0.2]{Harvest_Quotas.PNG}
\end{center}
However, if we harvest with a relative quota, represented by the equation
\[x^\prime = (1 - x) x - p x\]
for $0 < p < 1$, this leads us to an integral curve with a stable equilibrium point. 
\begin{center}
    \includegraphics[scale=0.2]{Relative_Quota.PNG}
\end{center}
\end{example}

\subsubsection{Additional Examples}
\begin{example}[Lotka-Volterra Model]
The simplest model describing the predator-prey relationship between two species is described by the system of differential equations (also a $2$-dimensional first order differential equation). 
\begin{align*}
    & x^\prime = k x - a x y \\
    & y^\prime = - l y + b x y
\end{align*} 
The phase space with its velocity vector field can be defined by defining the vector 
\[\begin{pmatrix}
kx - axy \\ -ly + bxy
\end{pmatrix}\]
at each point in $\mathbb{R}^2$, labeled with the $x$ and $y$ axes. 
\begin{center}
    \includegraphics[scale=0.25]{Lotka_Volterra.PNG}
\end{center}
Note that we have graphed the model such that the two parameters $x, y$ are shown and not the time, but note that the time parameter $t$ very much exists in this autonomous model. 
\begin{center}
    \includegraphics[scale=0.25]{Lotka_Autonomous.PNG}
\end{center}
The blue curve is the solution to this system, which describes the evolution of the autonomous system as time passes. 
\end{example}

\begin{example}[Pendulums]
Small oscillations of a pendulum can be approximated, using Taylor approximations, to get the differential equation 
\[x^{\prime \prime} = - k x\]
By scaling the coefficient $k$, we can make it equal to $1$ to get
\[x^{\prime \prime} = -x\]
The phase space of this system is 2 dimensional, with parameters $x_1 = x$ and $x_2 = x^\prime$. This creates the autonomous system of first order differential equations
\[x^\prime_1 = x_2, \; x_2^\prime = -x_1\]
This leads to the phase velocity vector field shown below. 
\begin{center}
    \includegraphics[scale=0.25]{Undampened_Simple_Pendulum.PNG}
\end{center}
A more accurate equation for the undampened pendulum system (by scaling $k$ again) is 
\[\theta^{\prime \prime} = -\sin{\theta}\]
Clearly, the solution to this system, given initial value of $(x_1^*, x_2^*)$, is a helix.
\begin{center}
    \includegraphics[scale=0.25]{Helix_Solution.PNG}
\end{center}
This equation can be represented as the autonomous system
\[x_1^\prime = x_2, \; x_2^\prime = - \sin{x_1} \]
which creates the phase velocity vector field
\begin{center}
    \includegraphics[scale=0.25]{Undampened_Accurate_Pendulum.PNG}
\end{center}
\end{example}

\begin{example}[Small Oscillations of Spherical Pendulums]
A spherical pendulum adds another dimension of movement (another dimension of angle and angular velocity), therefore inducing a system where the phase space is 4 dimensional. For small oscillations, the differential equations
\[x^{\prime\prime} = -x, \; y^{\prime\prime} = - y\]
is represented with the system
\[x_1^\prime = x_2, \; x_2^\prime = -x_1, \; x_3^\prime = x_4, \; x_4^\prime = - x_3\]
where $x_1 = x, x_2 = x^\prime, x_3 = y, x_4 = y^\prime$. 
\end{example}

\subsection{Existence Theory}
Before we introduce methods to solve differential equations, we will state and prove conditions for existence and uniqueness of solutions. We will only prove existence in the simplest case. 
\begin{theorem}[Existence of Solutions in a First-Order System with Phase Space Dimensionality of 1]
Let $f$ and $\partial f / \partial y$ be $C^0$ functions in a given region $U \in \mathbb{R}^2$, with $(t_0, y_0) \in D$. This means that 

Then, there exists an interval $I$ containing $t_0$ and exactly $1$ solution $\varphi$ of the differential equation 
\[y^\prime = f(t, y)\]
passing through $(t_0, y_0)$. The solution exists for values of $t$ for all points $\big(t, \varphi(t)\big) \in U$. $\varphi$ is also a continuous function with respect to $(t, t_0, y_0)$. 
\end{theorem}
In order to state the proof, we will introduce some lemmas. 

\begin{lemma}
$\varphi$ is a solution to $y^\prime = f(t, y)$ with $\varphi(t_0) = y_0$ on interval $I$ if and only if $\varphi$ satisfies the solution $y$ of the equation
\begin{equation}
    y(t) = y_0 + \int_{t_0}^t f\big( s, y(s)\big) \,ds, \;\; t \in I
\end{equation}
\end{lemma}
\begin{proof}
$(\rightarrow)$ $\varphi$ is a solution of $y^\prime = f(t, y)$, with $\varphi(t_0) = y_0 \implies \varphi^\prime (t) = f \big(t, \varphi(t) \big)$
\begin{align*}
    \implies & \int_{t_0}^t \varphi^\prime (s) \,ds = \int_{t_0}^t f \big( s, \varphi(s) \big) \, ds \\
    \implies & \varphi(t) = \varphi(t_0) + \int_{t_0}^t f\big(s, \varphi(s)\big) \,ds = y_0 + \int_{t_0}^t f \big( s, \varphi(s) \big) \,ds
\end{align*}
$(\leftarrow)$ $y(t)$ is a solution of (1) $\implies y(t)$ is continuous by the fundamental theorem of calculus. Since $f$ is also continuous, $y(t)$ is differentiable. 
\[\implies y^\prime (t) = \frac{d}{dt} \bigg( y_0 + \int_{t_0}^t f\big( s, y(s) \big) \, ds \bigg) = f\big(t, y(t) \big)\]
Putting $t=t_0, y (t_0) = y_0$, this implies that $y$ is a solution of $\varphi^\prime (t) = f(t, y)$. 
\end{proof}

The previous lemma allows us to establish the existence of a solution using (1), which is generally easier. We now define the Lipshitz inequality for functions of two variables. 

\begin{definition}
Let $f(t, y)$ be a continuous, bounded function in region $D$. For all $(t, y_1), (t, y_2) \in D$, if $f$ satisfies the inequality 
\[|f(t, y_2) - f(t, y_1)| \leq K |y_2 - y_1|\]
then $f$ is said to satisfy the \textit{Lipshitz condition} in $D$.
\end{definition}

Now, we define a series of successive approximations
\[\varphi_0 (t) = y_0, \; \varphi_{j+1} (t) = y_0 + \int_{t_0}^t f\big(s, \varphi_j (s) \big) \, ds\]
We hope that this sequence will eventually converge onto the actual $\varphi$, but we must propertly define the $\varphi_j$'s such that the points remain in the region $D$. 

\begin{lemma}
Let $\alpha = \min\{a, \frac{b}{M}\}$. Then, the successive approximations $\varphi_j$ are defined on the interval $I$ given by $|t - t_0| < \alpha$, and on this interval 
\begin{equation}
    |\varphi_j (t) - y_0| \leq M |t - t_0| < b, \;\; j = 0, 1, 2, ...
\end{equation}
\end{lemma}
\begin{proof}
Clearly, $\varphi_0 (t)$ is defined on $I$ and satisfies (2). Now assuming that for $n \geq 1$, $\varphi_n$ is defined and satisfies (2) $\implies$ the point $\big( t, \varphi(t)\big) \in D$ for $t \in I$. To prove that $\big(t, \varphi_{n+1}(t)\big) \in D$, we already know $t \in I$, so we must show that $|\varphi_{n+1} (t) - y_0| < b$. Using the intermediate value theorem,
\begin{align*}
    |\varphi_{n+1}(t) - y_0| & = \bigg| \int_{t_0}^t f\big(s, \varphi_j(s)\big) \, ds \bigg| \\
    & \leq \bigg| \int_{t_0}^t |f\big(s, \varphi_j (s)\big)|\, ds\bigg| \\
    & \leq M |t - t_0| < M\alpha < \leq b
\end{align*}
We specifically assign $\alpha$ because first, (2) implies that the successive approximations also have slopes bounded by the cone of the lines with slope $M$ and $-M$ through points $(t_0, y_0)$. The length $\alpha$ of $I$ depends on where these lines meet $D$. Either way, the $\varphi_j$'s remain in the rectangles.
\end{proof}

Now, we can prove an existence theorem. 

\begin{theorem}
Suppose $f$ and $\partial f/\partial y$ are continuous and bounded on the rectangle $D$ satisfying the Lipshitz condition. That is, 
\[|f(t, y)| \leq M, \;\; \Big| \frac{\partial f}{\partial y} \Big| \leq K\]
Then, the sucessive approximations $\varphi_j$ (defined previously) converge uniformly on the interval $I = (t_0 - \alpha, t_0 + \alpha)$ to a solution $\varphi$ of the differential equation $y^\prime = f(t, y)$ with $\varphi(t_0) = y_0$. 
\end{theorem}
\begin{proof}
The second lemma shows that $\varphi_j$ are defined on the interval $I$. Now, we define the difference between $\varphi_j$ adn $\varphi_{j+1}$ in the interval $[t_0, t_0 + \alpha]$ and $[t_0 - \alpha, t_0]$. Using the Lipshitz condition, 
\begin{align*}
    r_j (t) = |\varphi_{j+1} (t) - \varphi_j (t)| & = \bigg| \int_{t_0}^t f\big(s, \varphi_j (s)\big) - f\big(s, \varphi_{j-1} (s) \big) \,ds\bigg| \\
    & \leq \int_{t_0}^t |f\big(s, \varphi_j (s)\big) - f\big( s, \varphi_{j-1} (s)\big)|\,ds \\
    & \leq K \int_{t_0}^t \varphi_j (s) - \varphi_{j-1} (s) \,ds \\
    & = K \int_{t_0}^t r_{j-1} (s) \,ds, \;\; j = 1, 2, ...
\end{align*}
When $j=0$, 
\begin{align*}
    r_0 (t) = |\varphi_1 (t) - \varphi_0 (t)| & = \bigg| \int_{t_0}^t f \big(s, \varphi(s)\big) \,ds \bigg| \\
    & \leq \int_{t_0}^t |f\big(s, \varphi(s)\big)\,ds \leq M (t - t_0) 
\end{align*}
Now, using induction, we prove that 
\[r_j (t) \leq \frac{M K^j (t-t_0)^{j+1}}{(j+1)!}, \;\; j = 0, 1, 2, ...; t_0 \leq t \leq t_0 + \alpha\]
The base case suffices. When $j=0$, 
\[r_0 (t) \leq M (t-t_0)\]
Now assume that the statement is true for $j=p-1$, for $p \geq 1$. Then, 
\begin{align*}
    r_p (t) \leq K \int_{t_0}^t r_{p-1} (s) \, ds & \leq K \int_{t_0}^t \frac{M K^{p-1} (s - t_0)^p}{p!} \,ds \\
    & = \frac{M K^p}{p!} \cdot \bigg( \frac{(s-t_0)^{p+1}}{p+1} \bigg|_{t_0}^t \bigg) \\
    & = \frac{M K^p (s - t_0)^{p+1}}{(p+1)!}, \;\; t_0 \leq t \leq t_0 + \alpha
\end{align*}
\end{proof}
Integrating this fact into the main proof, we have
\begin{align*}
    r_j (t) \leq \frac{M K^j |t - t_0|^{j+1}}{(j+1)!} & = \frac{M (K |t - t_0|)^{j+1}}{K (j+1)!}\\
    & < \frac{M \alpha^{j+1} K^{j+1}}{K (j+1)!} \\
    & = \frac{M (K \alpha)^{j+1}}{K (j+1)!} 
\end{align*}
This implies that
\begin{align*}
    \sum_{j=0}^\infty r_j (t) & = \frac{M}{K} \sum_{j=0}^\infty \frac{ (K \alpha)^{j+1}}{(j+1)!} \\
    & = \frac{M}{K} e^{\alpha K} \\
\end{align*}
This implies that 
\[\sum_{j=0}^\infty \big( \varphi_{j+1} (t) - \varphi_{j} (t) \big)\]
absolutely and uniformly converges in the interval $I$ where $|t - t_0| < \alpha$ to some function of $t$, determined arbitrarily by $\varphi (t)$. 

To see the rate and error bound of convergence, we already defined
\begin{align*}
    & \varphi(t) = \varphi_0 (t) + \sum_{n=0}^\infty \big(\varphi_{n+1} (t) - \varphi_n (t)\big) \\
    \implies & \varphi (t) - \varphi_j (t) = \sum_{n=0}^\infty \big(\varphi_{n+1} (t) - \varphi_n (t)\big) \\
    \implies & |\varphi(t) - \varphi_j (t)| \leq \sum_{n=j}^\infty |\varphi_{n+1} (t) - \varphi_n (t)| \\
    & \leq \sum_{n=j}^\infty r_n (t) \leq \frac{M}{K} \sum_{n=j}^\infty \frac{(K \alpha)^{n+1}}{(n+1)!} \\
    & \leq \frac{M}{K} \frac{(K \alpha)^{j+1}}{(j+1)!} \sum_{n=0}^\infty \frac{(K\alpha)^n}{n!} = \frac{M}{K} \frac{(K\alpha)^{j+1}}{(j+1)} e^{K \alpha}
\end{align*}
It is clear that 
\[\epsilon_j = \frac{(K \alpha)^{j+1}}{(j+1)!} \rightarrow 0 \text{ as } j \rightarrow \infty\]
To prove continuity of $\varphi(t)$ on $I$, we let $\epsilon > 0$ and assign 
\begin{align*}
    \varphi(t+h) - \varphi(t) & = \varphi(t+h) - \varphi_j (t+h) + \varphi_j (t+h) - \varphi_j (t) + \varphi_j (t) - \varphi(t) 
\end{align*}
which, by the triangle inequality, implies that
\begin{align*}
    \implies |\varphi(t+h) - \varphi(t)| & \leq |\varphi(t+h) \varphi_j  (t+h)| + |\varphi_j (t+h) - \varphi_j (t)| + |\varphi_j (t) - \varphi(t)| \\
    & \leq 2 \varepsilon_j + |\varphi_j (t+h) - \varphi_j (t)| 
\end{align*}
Choosing $j$ sufficiently large and $|h|$ sufficiently small, using 
\[\lim_{j \rightarrow \infty} \varepsilon_j = 0\]
and continuity of $\varphi_j (t)$, we can make
\[|\varphi(t+h) - \varphi(t)| \leq |\varphi_j (t+h) - \varphi_j (t)| < \varepsilon, \;\; \text{as } h \rightarrow 0\]
$\implies \varphi(t)$ is continuous since the limit exists at $t$ that matches the actual value. 

To show that the $\varphi(t)$ satisfies the integral equation in the first lemma, we see that
\begin{align*}
    \lim_{j \rightarrow \infty} \varphi_j (t) = \varphi(t) & \implies \lim_{j \rightarrow \infty} \int_{t_0}^t f\big( s, \varphi_j (s)\big) \, ds = \int_{t_0}^t f\big(s, \varphi(s)\big) \,ds \\
    & \implies \lim_{j \rightarrow \infty} \varphi_{j+1} (t) = \lim_{j \rightarrow \infty} \bigg( y_0 \int_{t_0}^t f \big(s, \varphi_j (s)\big) \,ds\bigg) \\
    & \implies \varphi (t) = y_0 + \int_{t_0}^t f\big(s, \varphi_ (s) \big) \, ds 
\end{align*}
Using the first lemma, we see that $\varphi$ therefore satisfies the differential equation $y^\prime = f(t, y)$ with initial conditions $\varphi(t_0) = y_0$. 

\begin{corollary}
The error committed by $\varphi_j (t)$ satisfies the estimate 
\[|\varphi (t) - \varphi_j (t)| \leq \frac{M}{K} \frac{(K \alpha)^{j+1}}{(j+1)!} e^{K \alpha} \;\;\; \forall t \in I\]
In fact, the conditions of this theorem implies the uniqueness of solutions of $y^\prime = f(t, y)$. However, we can prove existence without uniqueness. 
\end{corollary}

\begin{theorem}
Suppose $f \in C^0$ in rectangle $R$ with $f$ bounded; that is, $|f(t, y)| \leq M$ for all $(t, y) \in R$. Let $\alpha = \min\{a, b /M\}$. Then, there exists a solution $\varphi$ of differential equation
\[y^\prime = f(t, y)\]
with $\varphi(t_0) = y_0$ existing on interval $|t - t_0| < \alpha$. 
\end{theorem}

Now, we prove the uniqueness of solutions. 
\begin{lemma}[Gronwall Inequality]
Let $K > 0$ be a constant, and $f, g \in C^0$ be nonnegative on interval $\alpha \leq t \leq \beta$ satisfying 
\[f(t) \leq K + \int_\alpha^t f(s)\,g(s) \,ds \;\; \forall t \in [\alpha, \beta]\]
Then, 
\[f(t) \leq K \exp \bigg( \int_{\alpha}^t g(s) \,ds \bigg) \;\; \forall t \in [\alpha, \beta]\]
\end{lemma}
\begin{proof}
Let 
\[U(t) = K + \int_\alpha^t f(s) \, g(s) \, ds \implies U (\alpha) = K\]
Then, $f(t) \leq U(t)$, which implies, by the fundamental theorem of calculus and $g(t) \geq 0$, that 
\begin{align*}
    & U^\prime (t) = f(t)\,g(t) \leq U(t) \, g(t) \;\; (\alpha \leq t \leq \beta) \\
    \implies & U^\prime (t) - U(t) \, g(t) \leq 0
\end{align*}
which implies
\begin{align*}
    & U^\prime (t) \bigg( - \exp \Big( \int_\alpha^t g(s) \, ds \Big)\bigg) - U(t) \, g(t) \bigg( - \exp \Big( \int_\alpha^t g(s) \, ds \Big)\bigg) \\
    & = \Bigg( U(t) \bigg( - \exp \Big( \int_\alpha^t g(s) \, ds \Big)\bigg) \Bigg)^\prime \leq 0 \\
    \implies & \int_\alpha^t \frac{d}{dr} \bigg( U(r) \bigg( - \exp \Big( \int_\alpha^r g(s) \, ds \Big)\bigg) \bigg) \,dr \\
    & = U(t) \, \exp \Big( -\int_\alpha^t g(s)\,ds \Big) - U(\alpha) \leq 0 \\
    \implies & f(t) \leq U(t) \leq U(\alpha) \, \exp \Big( \int_\alpha^t g(s)\,ds \Big) = K \exp \Big( \int_\alpha^t g(s) \, ds\Big) 
\end{align*}
\end{proof}

\begin{theorem}
Let $f, \partial f/ \partial y \in C^0$ be bounded in rectangle $R \equiv \{(t, y) \;|\; |t-t_0| < \alpha, |y - y_0| < b\}$. Then there exists at most one solution of $y^\prime = f(t, y)$ satisfying $\varphi(t_0) = y_0$. 
\end{theorem}
\begin{proof}
Since the hypothesis of this theorem establishes the existence of at least one solution $\varphi$, it suffices to prove that any two solutions are equal. Assume that $\varphi_1, \varphi_2$ are two different solutions on a common interval $J$. By the first lemma, we have for all $t \in J$
\begin{align*}
    &\varphi_1 (t) = y_0 + \int_{t_0}^t f\big(s, \varphi_1 (s)\big) \,ds \\
    &\varphi_2 (t) = y_0 + \int_{t_0}^t f\big(s, \varphi_2 (s)\big) \,ds
\end{align*}
which implies (using the Lipshitz condition) that
\begin{align*}
    & \varphi_2 (t) - \varphi_1 (t) = \int_{t_0}^t f\big(s, \varphi_2 (s)\big) - f\big(s, \varphi_1 (s)\big) \, ds \\
    \implies & |\varphi_2 (t) - \varphi_1 (t)| \leq \bigg|\int_{t_0}^t |f\big(s, \varphi_2 (s)\big) - f\big(s, \varphi_1 (s)\big)| \, ds\bigg| \\
    & \leq K \bigg| \int_{t_0}^t |\varphi_2 (s) - \varphi_1 (s) | \bigg|
\end{align*}
Using Gronwall's inequality and setting $K=0, g(s) = 1$, and $f(t) = |\varphi_2 (t) - \varphi_1 (t)|$, we have
\[\leq K \bigg| \int_{t_0}^t |\varphi_2 (s) - \varphi_1 (s) | \bigg| \leq 0 \cdot \exp \bigg( \int_{\alpha}^t 1\,ds \bigg) = 0\]
$\implies |\varphi_2 (t) - \varphi_1 (t)| = 0 \implies \varphi_1 = \varphi_2$, a contradiction. 
\end{proof}

Finally, we prove continuity of $f$ with respect to initial conditions. 
\begin{theorem}
let $f, \partial f/ \partial y \in C^0$ be bounded in region $D$ and satisfy the Lipshitz condition. Let $\varphi$ be the solution of $y^\prime = f(t, y)$ with $\varphi(t_0) = y_0$ and let $\psi$ be the solution of $y^\prime = f(t, y)$ with $\psi(\hat{t}_0) = \hat{y}_0$. Assume that $\varphi$ and $\psi$ both exist on interval $[a, b]$. Then for each $\varepsilon > 0$, there exists a $\delta > 0$ such that if $|t - \hat{t}| < \delta$ and $|y - \hat{y}| < \delta$, then 
\[|\varphi(t) - \psi(\hat{t})| < \varepsilon, \;\; a < t, \hat{t} < b\]
\end{theorem}

\section{Methods of Solution}

\subsection{Basic Methods for First Order Scalar-Valued DEQs}
\subsubsection{Variables Separable}
\begin{definition}[Separable DEQs and Solution]
A differential equation in the form
\[y^\prime = g(t) h(y)\]
is called a \textit{variables-separable equation}. 

Assume that given solution $\varphi$, $h\big( \varphi(t)\big) \neq 0$ for all $t \in I$. Then, we rearrange the equation and integrate either indefinitely or definitely, where $y = \varphi(t)$. Note that there is no difference between finding solutions using indefinite or definite integration. 
\[\varphi^\prime (t) = g(t) h(\varphi(t)) \implies \frac{y^\prime}{h(y)} = g(t)\]
\begin{enumerate}
    \item Indefinitely, we can use substitution $y = \varphi(t)$ to get
    \[\int \frac{\varphi^\prime (t)}{h(\varphi(t))} \, dt = \int g (t) \, dt \implies \int \frac{1}{h(y)} \,dy = \int g(t)\,dt\]
    This can be remembered with the mnemonic
    \[\frac{dy}{dt} = g(t) h(y) \implies \frac{1}{h(y)} dy = g(t) dt \implies \int \frac{1}{h(y)} dy = \int g(t) dt\]
    \item Definitely, we can use the same substitution $y = \varphi(s)$, where $y_0 = \varphi(t_0)$, to get
    \[\int_{t_0}^t \frac{\varphi^\prime (s)}{h(\varphi(s))} \, ds = \int_{t_0}^t g(t)\, dt \implies \int_{y_0}^y \frac{1}{h(\Tilde{y})} \, d\Tilde{y} = \int_{t_0}^t g(\Tilde{t})\, d\Tilde{t}\]
    where we can treat $\Tilde{y}$ and $\Tilde{t}$ as dummy variables. 
\end{enumerate}
Both methods define the solution implicitly, but it may or may not be possible to solve it explicitly as $y = \varphi(t)$. However, by the implicit function theorem, we can guarantee the existence of a function $y = \varphi(t)$ within a neighborhood of $(t_0, y_0)$. 
\end{definition}

\subsubsection{First Order Linear Equations}
\begin{definition}[First-Order Linear DEQ and Solution]
A differential equation of the form 
\[y^\prime + a_1 (t) y = b(t)\]
is called a \textit{first order linear differential equation}. 

To solve this, we assume that there is a function $\mu (t)$, called the \textit{integrating factor}, with the property that 
\[\mu(t) a_1 (t) = \mu^\prime (t)\]
This can be calculated with the following derivation =
\begin{align*}
    \frac{\mu^\prime (t)}{\mu (t)} = a_1 (t) & \implies \big( \ln{\mu(t)}\big)^\prime = a_1 (t) \\
    & \implies \ln{\mu(t)} = \int a_1 (t) \, dt + k \\
    & \implies \mu(t) = e^{\int a_1(t)\,dt + k} = k e^{\int a_1 (t) \,dt}
\end{align*}
Okay, now what? Well multiplying this integrating factor on both sides conveniently gives us a left hand side in the form of the product rule of differentiation. 
\begin{align*}
     \mu(t) b(t) & = \mu(t) y^\prime + \mu(t) a_1 (t) y \\
     & = \mu(t) y^\prime + \mu^\prime (t) y \\
     & = \big( \mu(t) y(t) \big)^\prime
\end{align*}
Integrating both sides gives us 
\[\mu(t) y(t) = \int \mu(t) b(t) \,dt + c\]
Summarizing, the solution, if it exists, has explicit form of
\[y(t) = \frac{1}{\mu(t)} \bigg(\int \mu(t) b(t) \,dt + c\bigg), \;\;\; \mu(t) = k e^{\int a_1 (t)\,dt}\]
\end{definition}

\subsubsection{Exact Equations}
\begin{definition}[Exact DEQs and Solutions]
Let $\psi: \mathbb{R}^2 \longrightarrow \mathbb{R}$ be a $C^1$ function with partial derivatives $\psi_t$ and $\psi_y$. A differential equation of the form 
\[\psi_t (t, y) + \psi_y (t, y) y^\prime = 0\]
is called an \textit{exact differential equation}. The left hand side can be transformed as such: 
\[\psi_t (t, y) + \psi_y (t, y) y^\prime = \frac{d}{dt} \psi \big( t, y(t)\big) = 0\]
This implies that the solution can be written implicitly as 
\[\psi \big(t, y(t)\big) = c\]
\end{definition}

\subsubsection{Bernoulli Differential Equations}
\begin{definition}[Bernoulli DEQs and Solutions]
A differential equation of the form 
\[y^\prime + p(t)\,y = q(t)\, y^{n}\]
is called a \textit{Bernoulli differential equation}. To solve this, we first divide by $y^n$ to get
\[y^{-n} y^\prime + p(t)\,y^{1-n} = q(t)\]
and use the substitution $v = y^{1-n}, v^\prime = (1-n)y^{-n} y^\prime$ to plug into the equation and get
\[\frac{1}{1-n} v^\prime + p(t) v = q(t)\]
This is a first order linear differential equation that we can solve for $v$ and solve back for $y$. 
\end{definition}

\subsection{2nd Order Equations Solvable by 1st Order Methods}
A small class of 2nd order differential equations, which have the general form 
\[y^{\prime \prime} = f(t, y, y^\prime)\]
can be reduced by substitution to a system of first order differential equations. There are two types of equations: 
\begin{enumerate}
    \item Equation of form $y^{\prime \prime} = g(t, y^\prime)$ can be solved with the substitution $p = y^\prime$ to create the new equation 
    \[p^\prime = g(t, p)\]
    which may be solved for $p$ using any of the first order methods. We can then integrate $p$ again to find $y$, adjusting the extra constant to satisfy the initial conditions $\varphi(t_0) = y_0$. That is, if $p = \psi(t)$ is the solution, 
    \[\varphi (t) = y_0 + \int_{t_0}^t \psi (s) \,ds\]
    \item Equation of form $y^{\prime \prime} = h(y, y^\prime)$ can be transformed into a pair of first order equations (i.e. a first order vector-valued equation). That is, let $\varphi$ be the solution such that $\varphi(0) = y_0, \varphi^\prime(0) = z_0$. We substitute 
\[p(t) = \varphi^\prime (t) \implies p^\prime (t) = \varphi^{\prime \prime} (t)\]
Assuming we found a solution $y = \varphi(t)$, suppose we can invert it to a function of $y$. That is, $t = s(y)$. This implies that
\[y^\prime = \varphi^\prime (t) = p(t) = p\big( s(y) \big) \equiv q(y)\]
Then, 
\[\varphi^{\prime \prime} (t) = p^\prime (t) = \frac{d q}{d y} \varphi^\prime (t) = \frac{d q}{d y} p(t) = \frac{d q}{d y} q(y)\]
which implies that the equation can be decomposed to the following system of linear equations
\begin{align*}
    & \frac{d q}{d y} q (y) = h\big(y, q(y)\big) \\
    & y^\prime = q(y)
\end{align*}
We first find the solution of the first equation (which may not always be possible). If $z_0 = 0$, $q \equiv 0$ may be a solution $\implies \varphi(t) = y_0$. If $q \equiv 0$ is not a solution, we find $q = \psi (t)$, substitute it into the second equation to find the solution (using variables separable), and then verify it by substituting $\varphi$ into the original second order differential equation. 
\end{enumerate}

\subsection{Numerical Methods: Euler's Algorithm}
\begin{definition}[Euler's Algorithm]
Given a differential equation $y^\prime = f(t, y)$, we follow these steps to create an approximation graph passing through $(t_0, y_0)$. 
\begin{enumerate}
    \item Let the interval be $[t_0, t_0 + \alpha]$. Divide the interval into $n$ (not necessarily equally spaced) sub-intervals $[t_i, t_{i+1}]$ (for simplicity, assume equally spaced). 
    \item At each point $(t_i, y_i)$, calculate the slope of the graph $m_i$ by plugging the values into the equation $f(t_i, y_i)$. 
    \item From each point $(t_i, y_i)$, calculate $(t_{i+1}, y_{i+1})$ using the straight-line graph 
    \[y_{i+1} = y_i + m_i (t_{i+1} - t_i) = y_i + f(t_i, y_i) (t_{i+1} - t_i)\]
\end{enumerate}
This create a piecewise linear function that serves as an approximation for the true integral curve. 
\begin{center}
    \includegraphics[scale=0.3]{Euler_Algorithm.PNG}
\end{center}
\end{definition}

\begin{theorem}[Error Bound for Euler's Algorithm]
The cumulative error bound for Euler's algorithm is
\[\sum_{k=1}^n |T_k| = \frac{1}{2} M h^2 n = \frac{1}{2} \alpha M h\]
\end{theorem}
\begin{proof}
Let $\varphi(t)$ be the exact solution. At $(t_k, y_k)$ and $(t_{k+1}, y_{k+1})$, 
\[\varphi(t_{k+1}) = \varphi(t_k) + \int_{t_k}^{t_{k+1}} f\big(t, \varphi(t)\big) \, dt\]
The formula for the approximate solution is
\[y_{k+1} = y_k + (t_{k+1} - t_k) f(t_k, y_k)\]
Therefore, the local error per point is 
\begin{align*}
    T_k & \equiv |\varphi(t_{k+1}) - y_{k+1}| \\
    & = \bigg| \int_{t_k}^{t_{k+1}} f\big(t, \varphi(t)\big)\, dt - (t_{k+1} - t_k) f(t_k, y_k) \bigg| 
\end{align*}
We wish to establish an upper bound on $T_k$. For convenience of notation, let us denote $F(t) = f\big(t, \varphi(t)\big)$. This means that 
\[T_k = \bigg| \int_{t_k}^{t_{k+1}} F(t)\,dt - (t_{k+1} - t_k ) F(t_k) \bigg| \]
The mean value theorem says that there exists some $s_k \in (t_k, t)$ such that 
\[F(t) - F(t_k) = (t - t_k) F^\prime (s_k)\]
which implies that
\begin{align*}
    \int_{t_k}^{t_{k+1}} F(t)\, dt & = \int_{t_k}^{t_{k+1}} F(t_k) + (t - t_k) F^\prime (s_k)\,dt \\
    & = \int_{t_k}^{t_{k+1}} (t - t_k) F^\prime (s) \, dt + (t_{k+1} - t_k) F (t_k) \\
    \implies & T_k = \bigg| \int_{t_k}^{t_{k+1}}  (t - t_k) F^\prime (s_k)\, dt \bigg|
\end{align*}
Let 
\[M \equiv \max_{t_0 \leq t \leq t_0 + \alpha} \big| F^\prime (t) \big|\]
Then, 
\begin{align*}
    F^\prime (t) & = \frac{\partial F}{\partial t} \big(t, \varphi(t)\big) + \bigg( \frac{\partial F}{\partial y} \big(t, \varphi(t)\big) \bigg) \cdot \varphi^\prime (t) \\
    & = \frac{\partial F}{\partial t} \big(t, \varphi (t)\big) + \bigg(\frac{\partial F}{\partial y} \big(t, \varphi(t)\big) \bigg) f \big(t, \varphi(t)\big)
\end{align*}
Using the triangle inequality, we get
\[M \leq \max_R \Big| \frac{\partial F}{\partial t} (t, y)\Big| + \max_R \Big| \frac{\partial F}{\partial y} (t, y)\Big| \cdot \max_R \Big| f(t, y) \Big|\]
This means that the bound for $M$ can be calculated explicitly with the inequality above. It can be checked that
\[M \leq \int_{t_k}^{t_{k+1}} (t - t_k) \, dt = \frac{M}{2}(t_{k+1} - t_k)^2 \]
Assuming equal subdivisions, we can let $t_{k+1} - t_k = h = \frac{\alpha}{n}$ and conclude that 
\[T_k \leq \frac{1}{2} M h^2\]
Therefore, the cumulative error bound is 
\[\sum_{k=1}^n |T_k| = \frac{1}{2} M h^2 n = \frac{1}{2} \alpha M h\]
\end{proof}

\section{Linear Differential Equations}

\begin{definition}[nth Order Linear DEQ]
A \textit{$n$th order linear differential equation} has the form
\[a_0 (t) y^{(n)} + a_1 (t) y^{(n-1)} + \ldots + a_{n-1} (t) y^\prime + a_n (t) y = f(t)\]
where $a_0, a_1, \ldots, a_n, f \in C^0$ over interval $I \subset \mathbb{R}$. Using the linear operator 
\[\mathcal{L}_n : C^n (\mathbb{R}) \longrightarrow C^0 (\mathbb{R}), \; \mathcal{L}_n (y) \equiv a_0 y^{(n)} + a_1 y^{(n-1)} + \ldots + a_{n-1} y^\prime + a_n y\]
where 
\[\mathcal{L}_n (y) (t) \equiv \bigg( \sum_{i=0}^n a_i y^{(n-i)} \bigg) (t) = \sum_{i=0}^n a_i (t) y^{(n-i)} (t)\]
the DEQ can be written as
\[\mathcal{L}_n (y) (t) = f(t), \text{ or } \mathcal{L}_n (y) = f\]
The DEQ is said to be \textit{homogeneous} iff $f = 0$ and \textit{inhomogeneous} iff $f \neq 0$. 
\end{definition}

In general linear differential equations are important since it is often the case that we reduce nonlinear differential equations to linear ones with approximations. For example, the equation for the pendulum is approximated as
\[\frac{d^2 \theta}{d t^2} + \frac{g}{L} \sin{\theta} = 0 \implies \frac{d^2 \theta}{d t^2} + \frac{g}{L} \theta = 0\]
for small $\theta$. 

\begin{example}
Consider the equation 
\[t y^{\prime \prime} + \cos{(t)} y^\prime + \Big( 1 - \frac{1}{1+t}\Big) y = 2t\]
$1 - \frac{1}{1+t}$ is discontinuous at $t_0 = -1$, and this equation is not of second order at $t=0$. Therefore, valid intervals $I$ must be a subset of 
\[(-\infty, -1) \cup (-1, 0) \cup (0, \infty)\]
for which there exists a unique solution. 
\end{example}

\subsection{Solving Homogeneous Linear DEQs}
This entire section is grounded in this theorem. 
\begin{theorem}[The Fundamental Set]
It can be seen that the set of functions $y = \varphi(t)$ that are solutions to the homogeneous equation $\mathcal{L}_n (y) = 0$ is simply just the kernel of $\mathcal{L}_n$, which is a subset of $C^n (\mathbb{R})$. Then, 
\[\dim \ker{\mathcal{L}} = n \]
The basis of $\ker{\mathcal{L}}$ is called the \textit{fundamental set}, and given that $\{\varphi_1, \varphi_2, \ldots, \varphi_n\}$ is this basis, the general solution is a linear combination of them. 
\[\varphi = \sum_i k_i \varphi_i, \;\;\; k_i \in \mathbb{R}\]
\end{theorem}

This reduces the problem of finding a general solution to just finding $n$ linearly independent ones. 

\begin{definition}[Wronskian]
Let $f_1, f_2, \ldots, f_n$ be of class $C^{n-1} (\mathbb{R})$ in interval $I \subset \mathbb{R}$. Then, the \textit{Wronskian} is defined
\[W(f_1, f_2, \ldots, f_n) \equiv \det{\begin{pmatrix}
f_1&\ldots&f_n\\
\vdots&\ddots&\vdots\\
f_1^{(n-1)}&\ldots&f_n^{(n-1)}
\end{pmatrix}}\]
\end{definition}

A simple application of the Wronskian is shown. 
\begin{theorem}
Let $\varphi_1, \varphi_2, \ldots, \varphi_n$ be any $n$ special solutions of the $n$th order linear homogeneous equation $\mathcal{L}(y) = 0$. Then, the set is linearly independent if and only if 
\[W(\varphi_1, \ldots, \varphi_n) \neq 0\]
Note that this theorem only works when the $\varphi_i$'s are known to be solutions. 
\end{theorem}
\begin{proof}
Suppose that $W(\varphi_1, \ldots, \varphi_n) (t) \neq 0$ for all $t \in I$ and that $\varphi_1, \ldots, \varphi_n$ are linearly dependent. This means that there exists a nontrivial linear combination summing up to $0$, and differentiating the equation on both sides gives the following (by abuse of notation, we will denote $W$ as the Wronskian matrix, not the determinant): 
\begin{align*}
    W(\varphi_1, \ldots, \varphi_n) \begin{pmatrix}
    b_1 \\ b_2 \\ \vdots \\ b_n \end{pmatrix} = \begin{pmatrix}
    0 \\ 0 \\ \vdots \\ 0 \end{pmatrix} \iff
    \begin{cases}
    b_1 \varphi_1 (t) + b_2 \varphi_2 (t) + \ldots + b_n \varphi_n (t) = 0 \\
    b_1 \varphi^\prime_1 (t) + b_2 \varphi^\prime_2 (t) + \ldots + b_n \varphi^\prime_n (t) = 0 \\
    \ldots \\
    b_1 \varphi^{(n-1)}_1 (t) + \ldots + b_n \varphi^{(n-1)}_n (t) = 0 
    \end{cases}
\end{align*}
For each fixed $t \in I$, by hypothesis $W$ is nonsingular, meaning that the only solution satisfying $W b = 0$ is when $b = 0$ itself. But this contradicts our assumption that $b \neq 0$, and so we have proved that
\[W(\varphi_1, \ldots, \varphi_n) \neq 0 \implies \varphi_1, \ldots, \varphi_n \text{ linearly independent}\]
Now, given that $W(\varphi_1, \ldots, \varphi_n) (t) = 0$ for some $t_0 \in I$, assume that $\varphi_1, \ldots, \varphi_n$ are linearly independent. $W(\varphi_1, \ldots, \varphi_n)(t_0)$ (interpreted as a matrix) is singular, the kernel of $W(\varphi_1, \ldots, \varphi_n)(t_0)$ is nontrivial; that is, there exists a nontrivial solution $b \neq 0$ to 
\[W(\varphi_1, \ldots, \varphi_n)(t_0) \begin{pmatrix}
b_1 \\ \vdots \\ b_n \end{pmatrix}= \begin{pmatrix} 
0 \\ \vdots \\ 0 \end{pmatrix}\]
To show linear dependence of the $\varphi_i$'s, we define a solution $\psi$ of the DEQ above as
\[\psi (t) = b_1 \varphi_1 (t) + b_2 \varphi_2 (t) + \ldots + b_n \varphi_n (t)\]
where $(b_1, \ldots, b_n)^T$ is any solution of $W(t_0) b = 0$ above. Since the system above tells us that
\[\psi(t_0) = 0, \psi^\prime (t_0) = 0, \ldots, \psi^{(n-1)} (t_0) = 0\]
it follows that $\psi= 0$ for all $t \in I$ is a solution. This means that we have found $b_1, \ldots, b_n$ such that 
\[\psi = \sum_{i=1}^n b_i \varphi_i (t) = 0\]
contradicting the assumption that $\varphi_i$'s were linearly independent. Therefore, 
\[W(\varphi_1, \ldots, \varphi_n) = 0 \text{ for some } t_0 \in I \implies \varphi_1, \ldots, \varphi_n \text{ linearly dependent}\]
\end{proof}

\subsubsection{Homogeneous Equations with Constant Coefficients}
Let us have the $n$th order linear homogeneous equation with constant coefficients $k_i \in \mathbb{R}$. 
\[\mathcal{L}_n (y) \equiv k_0 y^{(n)} + k_1 y^{(n-1)} + \ldots + k_{n-1} y^\prime + k_n y = 0\]
Now, assume that a solution in the form $e^{zt}$ is valid for $z \in \mathbb{C}$ (explained later). Then, 
\begin{align*}
    \mathcal{L}(e^{zt}) & = k_0 (e^{zt})^{(n)} + k_1 (e^{zt})^{(n-1)} + \ldots + k_{n-1} (e^{zt})^\prime + k_n (e^{zt}) \\
    & = k_0 z^n e^{zt} + k_1 z^{n-1} e^{zt} + \ldots + k_{n-1} z e^{zt} + k_n e^{zt} \\
    & = e^{zt} \big( k_0 z^n + k_1 z^{n-1} + \ldots + k_{n-1} z + k_n \big) = 0
\end{align*}

\begin{definition}[Characteristic Polynomial]
Given the linear DEQ $\mathcal{L}_n (y) = 0$, the \textit{characteristic polynomial} of $\mathcal{L}_n$ is 
\[\sum_{i=0}^n k_i z^{n-i}\]
\end{definition}

Since $e^{zt} \neq 0$ for all values of $z$, we must find all zeroes of the characteristic polynomial. By the fundamental theorem of algebra, there exists $n$ solutions in $\mathbb{C}$, but it turns out that we can turn them into real solutions using the following lemma. 

\begin{lemma}
Given that we have complex valued solution $\varphi$ to $\mathcal{L}(y) = 0$, where
\[\varphi = e^{z^* t} = e^{(\alpha + \beta i) t} = e^{\alpha t} \big(\cos{\beta t} + i \sin{\beta t}\big)\]
and $z^*$ is a complex solution to the characteristic polynomial, the functions 
\begin{align*}
    \text{Re}(\varphi) & = e^{\alpha t} \cos{\beta t} \\
    \text{Com}(\varphi) & = e^{\alpha t} \sin{\beta t} 
\end{align*}
are real solutions to the DEQ. 
\end{lemma}
\begin{proof}
Since $z^* = \alpha + \beta i$ is a zero of the polynomial, its complex conjugate $\overline{z^*} = \alpha - \beta i$ is also a zero, meaning that the following two functions are solutions. 
\begin{align*}
    \varphi & = e^{(\alpha + \beta i)t} = e^{\alpha t} \big( \cos{\beta t} + i \sin{\beta t}\big) \\
    \overline{\varphi} & = e^{(\alpha - \beta i)t} = e^{\alpha t} \big(\cos{\beta t} - i \sin{\beta t}\big) 
\end{align*}
By linearity of $\ker{\mathcal{L}}$, the following are also solutions
\[\text{Re}(\varphi) = \frac{\varphi + \overline{\varphi}}{2}, \;\; \text{Com}(\varphi) = \frac{\varphi - \overline{\varphi}}{2}\]
\end{proof}

\begin{lemma}
Given differential equation $\mathcal{L}(y) = 0$, let its characteristic polynomial have real root $z^*$ with multiplicity $m > 1$. Then, all the following are also real solutions of the DEQ:  
\[e^{z^* t}, t e^{z^* t}, t^2 e^{z^* t}, \ldots, t^{m-1} e^{z^* t}\]
If this root $z^*$ is complex then its complex conjugate $\overline{z^*}$ must also be a root of multiplicity $m$, and so in addition to $e^{z^* t}, \ldots, t^{m-1} e^{z^* t}$, the following are also (complex) solutions of $\mathcal{L}(y) = 0$. 
\[e^{\overline{z^*} t} = \overline{e^{z^* t}}, \; t e^{\overline{z^*} t} = \overline{t e^{z^* t}}, \; t^2 e^{\overline{z^*} t} = \overline{t^2 e^{z^* t}}, \; \ldots, t^{m-1} e^{\overline{z^*} t} = \overline{t^{m-1} e^{z^* t}}\]
and we can construct a basis of real-valued functions from these $2 (m-1)$ functions. 
\begin{align*}
    &\text{Re}(e^{z^* t}), \text{Re}(t e^{z^* t}), \text{Re}(t^2 e^{z^* t}), \ldots,  \text{Re}(t^{m-1} e^{z^* t}) \\
    &\text{Com}(e^{z^* t}), \text{Com}(t e^{z^* t}), \text{Com}(t^2 e^{z^* t}), \ldots, \text{Com}(t^{m-1} e^{z^* t})
\end{align*}
\end{lemma}

We can summarize all this in the following theorem. 

\begin{theorem}[Solving Homogeneous Linear DEQs with Constant Coefficients]
Let
\[L_n (y) \equiv \sum_{i=0}^n a_i y^{(n-i)} = a_0 y^{(n)} + a_1 y^{(n-1)} + ... + a_{n-1} y^\prime + a_n y = 0, \; a_i \in \mathbb{R} \]
be a $n$th order linear DEQ with constant coefficients and let
\[p_n (z) = a_0 z^n + a_1 z^{n-1} + \ldots + \ldots + a_{n-1} z + a_n\]
be its characteristic polynomial with distinct roots $z_1, z_2, \ldots, z_s (s \leq n)$, each root $z_i \in \mathbb{C}$ having multiplicity $m_i$. Note that $\sum_j m_j = n$ and 
\[p_n (z) = \prod_{i=1}^s (z - z_i)^{m_i}\]
Then, the $n$ functions form the complex fundamental set of the solutions of $\mathcal{L}_n (y) = 0$. 
\begin{align*}
    \{ e^{z_1 t}, t e^{z_1 t}, ..., t^{m_1 - 1} e^{z_1 t},  \\
    e^{z_2 t}, t e^{z_2 t}, ..., t^{m_2 - 1} e^{z_2 t}, \\
    ................................... \\
    e^{z_s t}, t e^{z_s t}, ..., t^{m_s - 1} e^{z_s t}
\end{align*}
If any function $t^w e^{z_v t}$ (for $0 \leq w \leq m_s - 1, 1 \leq v \leq s$) is complex, then its conjugate $\overline{t^w e^{z_v t}}$ is also in the fundamental set and we can change the basis of the span of complex functions into the following basis of real functions having the same span:
\[\{t^w e^{z_v t}, \overline{t^w e^{z_v t}}\} \implies \{\text{Re}(t^w e^{z_v t}), \text{Com}(t^w e^{z_v t})\}\]
\end{theorem}

\begin{example}
The solutions to the equation $y^{\prime \prime} + y^\prime + y = 0$ is 
\[\varphi_1 (t) = \exp \Big(\frac{-1+i\sqrt{3}}{2} t \Big), \;\; \varphi_2 (t) = \exp \Big( \frac{-1 - i \sqrt{3}}{2} t\Big) \]
This implies, by the previous theorem, that the fundamental set of real solutions is
\begin{align*}
    Re \big(\varphi_1 (t)\big) & = Re \bigg( e^{-\frac{1}{2} t} \Big( \cos{\Big(\frac{\sqrt{3}}{2}\Big)} + i \sin{\Big(\frac{\sqrt{3}}{2}\Big)}\Big) t\bigg) \\
    & = e^{-\frac{1}{2} t} \cos{\Big(\frac{\sqrt{3}}{2} t\Big)}  \\
    Com \big(\varphi_1 (t)\big) & = e^{-\frac{1}{2} t} \sin{\Big(\frac{\sqrt{3}}{2} t\Big)} 
\end{align*}
\end{example}

We state the 2nd-order case separately since it is seen often in physical phenomena. 

\begin{corollary}[Solutions to 2nd-Order Linear DEQs]
Every solution $\varphi$ of $y^{\prime\prime} + py^\prime + q y = 0$ with $p, q \in \mathbb{R}$ and $p^2 \neq 4 q$ is defined on $-\infty < t < \infty$ and has the form 
\[\varphi(t) = c_1 e^{z_1 t} + c_2 e^{z_2 t}\]
where $z_1, z_2$ are roots of the equation $z^2 + p z + q = 0$. Furthermore, 
\begin{enumerate}
    \item If $p^2 > 4q$, then $z_1, z_2 \in \mathbb{R}$ and are distinct. 
    \item If $p^2 < 4q$, then $z_1, z_2 \in \mathbb{C}$ with $z_1 = \bar{z_2} \implies$ if $z_1 = \alpha +\beta i$ is a solution, a general solution can be expressed 
\[\varphi(t) = e^{\alpha t} \big( a_1 \cos{\beta(t)} + a_2 \sin{\beta(t)}\big)\]
    \item If $p^2 = 4q$, then $z^2 + p q + p = 0$ has a double root at $z = -\frac{p}{2} \implies$ a solution is $e^{- \frac{p}{2} t}$. The other solution is of the form, $t e^{- \frac{p}{2} t}$, making the general solution 
    \[(a_1 + a_2 t) e^{-\frac{p}{2} t}\]
\end{enumerate}
\end{corollary}
\begin{proof}
(1) and (2) are quite trivial. For (3), we know that $\varphi(t) = e^{-\frac{p}{2} t}$ is a solution, and we will try to construct another linearly independent solution. This important process that we will employ is analogous to the \textit{reduction of order} process that will be explained later. We assume that the second solution is of form
\[\psi (t) = e^{-\frac{p}{2} t} w (t)\]
Assume that $\psi (t)$ is a solution of $y^{\prime\prime} + p y^\prime + q y = 0$. Then manually differentiating, we get 
\begin{align*}
    \psi (t) & = e^{-\frac{p}{2}t} w(t) \\
    \psi^\prime (t) & = e^{-\frac{p}{2} t} w^\prime (t) - \frac{p}{2} e^{-\frac{p}{2} t} w(t) \\
    \psi^{\prime\prime} (t) & = e^{-\frac{p}{2} t} w^{\prime \prime} (t) - p e^{-\frac{p}{2} t} w^\prime (t) + \frac{p^3}{4} e^{-\frac{p}{2} t} w(t) 
\end{align*}
Plugging these into the differential equation and simplifying gives us
\begin{align*}
    \psi^{\prime\prime} (t) + p \psi^\prime (t) + q \psi (t) & = e^{-\frac{p}{2} t} \bigg( w^{\prime\prime} (t) + \Big( q - \frac{p^2}{4} \Big) w(t) \bigg) \\
    & = e^{-\frac{p}{2} t} w^{\prime\prime} (t) = 0
\end{align*}
Note that by hypothesis, $p^2 = 4q$. Since $e^{-\frac{p}{2} t} \neq 0$, 
\[w^{\prime\prime} (t) = 0 \implies w (t) = a_1 + a_2 t \implies \psi(t) = e^{-\frac{p}{2} t} (a_1 + a_2 t)\]
\end{proof}

\subsubsection{Reduction of Order}
We elaborate on the method used in the previous section and introduce the reduction of order method. 

\begin{theorem}[Reduction of Order of 2nd-Order Linear DEQs]
Given the homogeneous linear differential equation with nonconstant coefficients 
\[\mathcal{L}_2 (y) = a_0 (t) y^{\prime\prime} + a_1 (t) y^\prime + a_2 (t) y = 0\]
where $a_0, a_1, a_2$ are $C^0$ on $I$ and $a_0 (t) \neq 0$ on $I$, assume that we know a solution $\varphi_1$. Then, the second solution is
\[\varphi_2 (t) = \varphi_1 (t) \int_{t_0}^t \frac{1}{\varphi_1^2 (\sigma)} \exp \bigg(- \int_{t_0}^\sigma \frac{a_1 (s)}{a_0 (s)}\,ds \bigg) \, d\sigma\]
\end{theorem}
\begin{proof}
Since we know solution $\varphi_1$, we assume that the second solution is of form $\varphi_2 (t) = w (t) \varphi_1 (t)$ and try to find a nonconstant function satisfying the DEQ. Since,
\begin{align*}
    \varphi_2 & = w \varphi_1 \\
    \varphi_2^\prime & = w^\prime \varphi_1 + w \varphi_1^\prime \\
    \varphi_2^{\prime\prime} & = w^{\prime\prime} \varphi_1 + 2 w^\prime \varphi_1^\prime + w \varphi_1^{\prime\prime}
\end{align*}
We have
\[\mathcal{L}_2 (\varphi_2) = a_0 \varphi_1 w^{\prime\prime} + (2 a_0 \varphi_1^\prime + a_1 \varphi_1) w^\prime + w \mathcal{L}_2 (\varphi_1) \text{ for all } t \in I\]
But since $\mathcal{L}_2 (\varphi_1) = 0$, 
\[\mathcal{L}_2 (\varphi_2) = a_0 \varphi_1 w^{\prime\prime} + (2 a_0 \varphi_1^\prime + a_1 \varphi_1) w^\prime\]
But notice that this is a first-order linear equation in $w^\prime$! What we have essentially done is use the fact that $\mathcal{L}_2 (\varphi_1) = 0$ to "reduce" the the DEQ from a second-order equation to a first-order one. Letting $v = w^\prime$ gives 
\[v^\prime + \bigg( 2 \frac{\varphi_1^\prime}{\varphi_1} + \frac{a_1}{a_0} \bigg) v = 0\]
Separating variables we obtain the solution
\[v(t) = \frac{1}{\varphi_1^2 (t)} \exp \bigg(- \int_{t_0}^t \frac{a_1(s)}{a_0 (s)} \,ds \bigg) \implies w(t) = \int_{t_0}^t \frac{1}{\varphi_1^2 (\sigma)} \exp \bigg(- \int_{t_0}^\sigma \frac{a_1(s)}{a_0 (s)} \,ds \bigg) \,d\sigma \]
\end{proof}

This process can be repeated for higher order equations, we show it for 3rd-order equations. 

\begin{theorem}[Reduction of Order of 3rd-Order DEQs]
Given the homogeneous linear differential equation with nonconstant coefficients
\[\mathcal{L}_3 (y) = a_0 (t) y^{\prime\prime\prime} + a_1 (t) y^{\prime\prime} + a_2 (t) y^\prime + a_3 (t) y = 0\]
where $a_0, a_1, a_2, a_3$ are $C^0$ on $i$ and $a_0 (t) \neq 0$ on $I$, assume that we know a solution $\varphi_1$. Then, the second and third solutions are
\[\varphi_2 = \varphi_1 \int_{t_0}^t \gamma_1(s)\,ds, \;\;\varphi_3 = \varphi_1 \int_{t_0}^t \gamma_2(s)\,ds\]
where $\gamma_1, \gamma_2$ are the solutions of differential equation
\[a_0 \varphi_1 v^{\prime\prime} + (3a_0 \varphi_1^\prime + a_1 \varphi_1) v^\prime + (3 a_0 \varphi_1^{\prime\prime} + 2a_1 \varphi_1^\prime + a_2 \varphi_1) v = 0\]
\end{theorem}
\begin{proof}
We assume that the second solution is of form $\varphi_2 (t) = w(t) \varphi_1(t)$ and compute the derivatives 
\begin{align*}
    \varphi_2 & = w \varphi_1 \\
    \varphi_2^\prime & = w^\prime \varphi_1 + w \varphi_1^\prime \\
    \varphi_2^{\prime\prime} & = w^{\prime\prime} \varphi_1 + 2 w^\prime \varphi_1^\prime + w \varphi_1^{\prime\prime} \\
    \varphi_2^{\prime\prime\prime} & = w^{\prime\prime\prime} \varphi_1 + 3 w^{\prime\prime} \varphi_1^\prime + 3 w^\prime \varphi_1^{\prime\prime} + w \varphi_1^{\prime\prime\prime}
\end{align*}
Substituting these into $\mathcal{L}_3 = 0$ and simplifying gives
\[\mathcal{L}_3 (\varphi_2) = a_0 \varphi_1 w^{\prime\prime\prime} + (3a_0 \varphi_1^\prime + a_1\varphi_1) w^{\prime\prime} + (3 a_0 \varphi_1^{\prime\prime} + 2a_1 \varphi_1^\prime + a_2 \varphi_1) w^\prime + w \mathcal{L}_3 (\varphi_1) \text{ for all } t\in I\]
Again, since $\mathcal{L}_3 (\varphi_1) = 0$, we get
\[\mathcal{L}_3 (\varphi_2) = a_0 \varphi_1 w^{\prime\prime\prime} + (3a_0 \varphi_1^\prime + a_1\varphi_1) w^{\prime\prime} + (3 a_0 \varphi_1^{\prime\prime} + 2a_1 \varphi_1^\prime + a_2 \varphi_1) w^\prime\]
which is really just a 2nd order equation in $w^\prime$. Substituting $v = w^\prime$ gives us
\[\mathcal{L}_3 (\varphi_2) = a_0 \varphi_1 v^{\prime\prime} + (3a_0 \varphi_1^\prime + a_1 \varphi_1) v^\prime + (3 a_0 \varphi_1^{\prime\prime} + 2a_1 \varphi_1^\prime + a_2 \varphi_1) v \]
Therefore, we have successfully reduced the order of this DEQ. Upon finding the two solutions $\gamma_1, \gamma_2$, the solution will be of form 
\[\varphi_2 = \varphi_1 \int_{t_0}^t \gamma_1(s)\,ds, \;\;\varphi_3 = \varphi_1 \int_{t_0}^t \gamma_2(s)\,ds\]
\end{proof}

\subsubsection{Cauchy-Euler's Equation}

\begin{definition}
A \textit{Cauchy-Euler equation of order $n$} has the form 
\[t^n y^{(n)} + a_1 t^{n-1} y^{(n-1)} + a_2 t^{n-2} y^{(n-2)} + ... + a_{n-1} t y^\prime + a_n y = 0, \;\; a_i \in \mathbb{R}\]
\end{definition}

There are two ways we can explicitly solve for this equation. Since the most common Cauchy-Euler equation is the second-order one, we will solve the following 
\[t^2 y^{\prime \prime} + a t y^\prime + b y = 0\]
\begin{enumerate}
    \item A trial solution $y = t^m$ can be used to directly solve for basic solutions (guess and check method). We assume a trial solution $y = t^m$. Differentiating it gives
    \[y^\prime (t) = m t^{m-1}, \;\; y^{\prime\prime} (t) = m (m-1) t^{m-2}\]
    Substituting into the original equation and simplifying gives: 
    \[t^2 \big( m(m-1)t^{m-2}\big) + at \big( m t^{m-1}\big) + b \big( t^m \big) = 0 \implies m^2 + (a-1) m + b = 0\]
    There are three possible cases: 
    \begin{enumerate}
        \item Two distinct roots $m_1, m_2$: 
        \[y = c_1 x^{m_1} + c_2 x^{m_2}\]
        \item One repeated root $m$: 
        \[y = c_1 x^m \ln{x} + c_2 x^m\]
        Note that this solution is found using the reduction of order. 
        \item Complex conjugate roots $\alpha \pm \beta i$: 
        \[y = c_1 x^{\alpha} \cos(\beta \ln{x}) + c_2 x^\alpha \sin(\beta \ln{x})\] 
        This can be easily derived by using Euler's formula. 
    \end{enumerate}
    \item 
\end{enumerate}


Consider the equation of the form 

We can use substitution $|t| = e^s$ to reduce the equation to have constant coefficients. 


\begin{enumerate}
    \item $t > 0, t = e^s \implies s = \log(t), y(t) = y(e^s) = w(s) = w \big( \log(t)\big)$. This implies that
    \begin{align*}
        & \frac{d y}{d t} = \frac{dw}{ds} \frac{ds}{dt} = \frac{1}{t} \frac{dw}{ds} \\
        \implies & \frac{d^2 y}{dt^2} = -\frac{1}{t^2} \frac{dw}{ds} + \frac{1}{t} \frac{d}{dt} \bigg( \frac{dw}{ds}\bigg) = \frac{1}{t^2} \bigg( \frac{d^2 w}{ds^2} - \frac{dw}{ds} \bigg) \\
        \implies & \text{substituting, } \frac{d^2 w}{ds^2} - \frac{dw}{ds} + a_1 \frac{dw}{ds} + a_2 w(s) = 0 \\
        \implies & w^{\prime\prime} + (a_1 - 1) w^\prime + a_2 w = 0
    \end{align*}
    \item When $t<0$, the procedure is similar. 
\end{enumerate}
This results in the equation $L(w) =0$ having the general solution 
\[\begin{cases}
c_1 e^{z_1 s} + c_2 e^{z_2 s} & z_1 \neq z_2 \text{ roots of } z^2 + (a_1 - 1) z + a_2 = 0 \\
(c_1 + c_2 s) e^{z_1 s} & z_1 = z_2 \text{ roots of ''}
\end{cases}\]
This means that the solution of $L(y) = 0$ is one of
\[\begin{cases}
\varphi(t) = c_1 |t|^{z_1} + c_2 |t|^{z_2} \\
\varphi(t) = (c_1 + c_2 \log|t|) |t|^{z_1}
\end{cases}\]
If $t \in \mathbb{C}$, $e^{z \log|t|} = |t|^2$, assuming that $z = \alpha + \beta i$. This means that 
\begin{align*}
    |t|^2 = e^{(\alpha + \beta i) \log|t|} & = e^{\alpha \log|t|} \big( \cos{(\beta \log|t|)} + i \sin{(\beta \log|t|)}\big) \\
    & = |t|^\alpha \big( \cos{(\beta \log|t|)} + i \sin{(\beta \log|t|)}\big)
\end{align*}



\subsection{Solving Inhomogeneous Linear DEQs}
\begin{definition}[Inhomogeneous Linear DEQ]
An \textit{inhomogeneous linear equation} is a linear differential equation in the form
\[\mathcal{L}_n (y) = f\]
where $f \neq 0$. $f \neq 0$ usually denotes that there is an external force acting on the system. 
\end{definition}

\begin{example}[Dampened Linear Mass-Spring System with Periodic External Force]
The dampened linear mass-spring system subjected to given periodic external force $A \cos{\omega t}$ is represented by the linear DEQ
\[y^{\prime \prime} + by^\prime + \frac{k}{m} y = \frac{A}{M} \cos{\omega t}\]
\end{example}

The following theorem provides insight into the structure of the solutions for these systems. 
\begin{theorem}
Suppose $\psi_p$ is a particular solution of $\mathcal{L}_n (y) = f$ on $I$ and suppose $\varphi_1, \varphi_2, ..., \varphi_n$ are $n$ linearly independent solutions of the homogeneous equation 
\[\mathcal{L}_n (y) = 0\]
Then, every solution $\psi$ of $\mathcal{L}_n (y) = f$ has general form
\[\psi = \psi_p + \sum_{i=1}^n c_i \varphi_i\]
That is, the set of all solutions is an $n$ dimensional affine subspace within the space of all continuous functions. 
\end{theorem}
\begin{proof}
Let $\psi_p$ be a particular solution of $\mathcal{L}_n (y) = f$ and $\psi_0$ be any solution of $\mathcal{L}_n (y) = 0$. Then, $\psi_0 \in \ker{\mathcal{L}_n}$, which means that by linearity of $\mathcal{L}_n$, 
\[\mathcal{L}_n (\psi_p + k \psi_0) = \mathcal{L}_n (\psi_p) + k \mathcal{L}_n (\psi_0) = f + 0 = f\]
\end{proof}

We have reduced the problem of solving inhomogeneous DEQs into solving the homogeneous version and finding a particular solution. 

\subsubsection{Variation of Constants}
We now attempt to find a particular solution $\psi_p$ for a second order linear inhomogeneous equation. The great thing about the method below is that as long as the functions $a_0 \neq 0, a_1, a_2, f$ are continuous over certain interval $I \subset \mathbb{R}$, it always provides us with a specific solution. 


\begin{theorem}[Variation of Constants Formula for 2nd-Order Linear DEQs]
Given inhomogeneous linear DEQ
\[\mathcal{L}_2(y) = a_0 (t) y^{\prime \prime} + a_1 (t) y^\prime + a_2 (t) y = f\]
where $a_0, a_1, a_2, f$ are all continuous on $I$, assume that we have the general solution $\varphi = c_1 \varphi_1 + c_2 \varphi_2$ for $\mathcal{L}_2(y) = 0$. Then, a particular solution $\psi_p$ for $\mathcal{L}_2 (y) = f$ is given by the \textit{Variation of Constants formula} 
\begin{align*}
    \psi_p & = \varphi_1 (t) \Bigg( - \int_{t_0}^t \frac{f(s)\,\varphi_2 (s)}{ a_0 (s) W(\varphi_1, \varphi_2) (s)}\,ds \Bigg) + \varphi_2 (t) \Bigg( \int_{t_0}^t \frac{f(s)\,\varphi_1 (s)}{ a_0 (s) W(\varphi_1, \varphi_2) (s)}\,ds \Bigg) \\
    & = \psi_p (t) = \int_{t_0}^t \frac{f(s) \, \big( \varphi_2 (t) \varphi_1 (s) - \varphi_1(t) \varphi_2 (s)\big)}{a_0 (s) \, W(\varphi_1, \varphi_2) (s)}\,ds
\end{align*}
\end{theorem}
\begin{proof}
We assume that the particular solution is of the form 
\[\psi_p = u_1 \varphi_1 + u_2 \varphi_2\]
and that we have found these functions $u_1, u_2$. This assumption is quite arbitrary, but we will see why this works later. This implies that
\begin{align*}
    &\psi_p^\prime = (u_1 \varphi_1 + u_2 \varphi_2)^\prime  = u_1 \varphi_1^\prime + u_2 \varphi_2^\prime + u_1^\prime \varphi_1 + u_2^\prime \varphi_2 \\
    & \psi_p^{\prime \prime} = u_1 \varphi_1^{\prime \prime} + u_2 \varphi_2^{\prime \prime} + 2 u_1^\prime \varphi_1 + 2 u_2^\prime \varphi_2^\prime + u_1^{\prime \prime} \varphi_2 + u_2^{\prime \prime} \varphi_2
\end{align*}
With these derivatives, we can expand out the equation $\mathcal{L}_2 (\psi_p) = f$ to get
\begin{align*}
    \mathcal{L}_2(\psi_p) = \mathcal{L}_2 (u_1 \varphi_1 + u_2 \varphi_2) & = a_0 (u_1 \varphi_1 + u_2 \varphi_2)^{\prime\prime} + a_1 (u_1 \varphi_1 + u_2 \varphi_2)^{\prime} + a_0 (u_1 \varphi_1 + u_2 \varphi_2) \\
    & = ... \\
    & = a_0 \big( (\varphi_1 u_1^{\prime\prime} + \varphi_2 u_2^{\prime \prime}) + 2(\varphi_1^\prime u_1^\prime + \varphi_2^\prime u_2^\prime)\big) + a_1 (\varphi_1 u_1^\prime + \varphi_2 u_2^\prime) = f
\end{align*}
We would like to obtain some sort of relation from this last equation. If we assume that 
\[\varphi_1 u_1^\prime + \varphi_2 u_2^\prime = 0\]
for all $t \in I$, then $(\varphi_1 u_1^\prime + \varphi_2 u_2^\prime)^\prime = \varphi_1 u_1^{\prime\prime} + \varphi_2 u_2^{\prime\prime} + \varphi_1^\prime u_1^{\prime} + \varphi_2^\prime u_2^{\prime} = 0$ and thus
\[a_0 \big( (\varphi_1 u_1^{\prime\prime} + \varphi_2 u_2^{\prime \prime}) + 2(\varphi_1^\prime u_1^\prime + \varphi_2^\prime u_2^\prime)\big) + a_1 (\varphi_1 u_1^\prime + \varphi_2 u_2^\prime) = f \implies \varphi_1^\prime u_1^\prime + \varphi_2^\prime u_2^\prime = \frac{f}{a}\]
Notice our line of reasoning so far: Assuming the existence of a solution of form $\psi_p = u_1 \varphi_1 + u_2 \varphi_2$ (and that $\varphi_1 u_1^\prime + \varphi_2 u_2^\prime = 0$) implies that $\varphi_1^\prime u_1^\prime + \varphi_2^\prime u_2^\prime = \frac{f}{a}$. However, we can reason backwards and state this: If we can find two equations $u_1, u_2$ satisfying $\varphi_1 u_1^\prime + \varphi_2 u_2^\prime = 0$ and $\varphi_1^\prime u_1^\prime + \varphi_2^\prime u_2^\prime = \frac{f}{a}$, then $\varphi_p = u_1 \varphi_2 + u_2 \varphi_2$ satisfies $\mathcal{L}_2 (\varphi_p) = f$ on $I$. So assume that there exists $u_1, u_2$ such that (written in matrix form)
\[\begin{pmatrix}
\varphi_1 & \varphi_2 \\
\varphi_1^\prime & \varphi_2^\prime
\end{pmatrix} \begin{pmatrix}
u_1^\prime \\u_2^\prime
\end{pmatrix} = \begin{pmatrix}
0 \\ f / a_0
\end{pmatrix}\]
Using Cramer's rule, we solve for $u_1^\prime, u_2^\prime$ and integrate to get $u_1, u_2$. 
\begin{align*}
    u_1^\prime = \frac{1}{W(\varphi_1, \varphi_2)} \det{\begin{pmatrix} 0 & \varphi_2 \\ f / a_0 & \varphi_2^\prime
    \end{pmatrix}} = \frac{-f \varphi_2}{a_0 W(\varphi_1, \varphi_2)} \implies u_1 (t) = \int_{t_0}^t \frac{-f(s)\,\varphi_2 (s)}{ a_0 (s) W(\varphi_1, \varphi_2) (s)}\,ds \\
    u_2^\prime = \frac{1}{W(\varphi_1, \varphi_2)} \det{\begin{pmatrix} \varphi_1 & \varphi_1^\prime \\ 0 & f / a_0
    \end{pmatrix}} = \frac{f \varphi_1}{a_0 W(\varphi_1, \varphi_2)} \implies u_2 (t) = \int_{t_0}^t \frac{f(s)\,\varphi_1 (s)}{ a_0 (s) W(\varphi_1, \varphi_2) (s)}\,ds
\end{align*}
Therefore, 
\[\psi_p (t) = u_1 (t) \varphi_1 (t) + u_2 (t) \varphi_2 (t) = \int_{t_0}^t \frac{f(s) \, \big( \varphi_2 (t) \varphi_1 (s) - \varphi_1(t) \varphi_2 (s)\big)}{a_0 (s) \, W(\varphi_1, \varphi_2) (s)}\,ds\]
\end{proof}


\begin{theorem}[Variation of Constants Formula]
For an $n$th order linear differential equation 
\[\mathcal{L}_n (y) = a_0 (t) y^{(n)} + a_1 (t) y^{(n-1)} + \ldots + a_{n-1} (t) y^\prime + a_n (t) y = f\]
Let the fundamental set of its homogeneous counterpart $\mathcal{L}_n (y) = 0$ be $\varphi_1, \ldots, \varphi_n$. Then, upon solving the system 
\[\begin{pmatrix}
\varphi_1 & \varphi_2 & \ldots & \varphi_n \\
\varphi_1^\prime & \varphi_2^\prime & \ldots & \varphi_n^\prime\\
\vdots & \vdots & \ddots & \vdots \\
\varphi_1^{(n-1)} & \varphi_2^{(n-1)} & \ldots & \varphi_n^{(n-1)} 
\end{pmatrix} \begin{pmatrix}
u_1^\prime \\ u_2^\prime \\ \vdots \\ u_n^\prime 
\end{pmatrix} = \begin{pmatrix}
0 \\ \vdots \\ 0 \\ f / a_0
\end{pmatrix}\]
for $u_1^\prime, u_2^\prime, \ldots, u_n^\prime$, we find $\psi_p$ to be
\[\psi_p (t) = \sum_{i=1}^n u_i (t) \varphi_i(t) = \sum_{i=1}^n \Big( \int_{t_0}^t u_i^\prime (s)\,ds \Big) \varphi_i (t)\]
\end{theorem}


\section{Series Solutions of Linear Equations}
A wider class of differential equations has solutions that can be expanded into a power series than ones that can be solved in closed form (that is, expressed in terms of elementary functions). 

\begin{example}
Given the differential equation
\[y^{\prime \prime} = -\sin{(y)} - y^\prime, \; \varphi(0) = \frac{\pi}{4}, \varphi^\prime (0) = 0\]
Assuming that $\varphi$ is an analytic function, we can write the Taylor series 
\[\varphi(t) = \varphi(0) + \varphi^\prime (0) t + ... = \sum_{j=0}^\infty \frac{\varphi^{(j)} (0)}{j!} t^j\]
We can solve for each derivative manually by plugging it into the equation
\begin{align*}
    & \varphi^{\prime\prime} (0) = -\sin{\big( \varphi(0)\big)} - \varphi^\prime (0) = - \frac{\sqrt{2}}{2} \\
    & \varphi^{\prime\prime\prime} (0) = -\cos{\big(\varphi(0)\big)} \varphi^{\prime\prime}(0) - \varphi^{\prime\prime} (0) = \frac{\sqrt{2}}{2} \\
    & \varphi^{(4)} (0) = \sin{\Big(\varphi(0)\big)} \big( \varphi^\prime (0)\big)^2 - \cos{\Big(\varphi(0)\big)} \varphi^{\prime\prime} (0) - \varphi^{(3)} (0) = \frac{1-\sqrt{2}}{2}
\end{align*}
Doing this recursively, the expansion of the solution $\varphi$ begins with the terms 
\[\varphi(t) = \frac{\pi}{4} - \frac{\sqrt{2}}{2} \frac{t^2}{2!} + \frac{\sqrt{2}}{2} \frac{t^3}{3!} + \frac{1-\sqrt{2}}{2} \frac{t^4}{4!} + ...\]
\end{example}

\subsubsection{Review of Power Series}
Every power series 
\[\sum_{n=0}^\infty c_n t^n\]
has a radius of convergence $R \geq 0$ over $\mathbb{C}$. Some more properties: 
\begin{enumerate}
    \item The series converges absolutely for $|t| < R$. 
    \item Assigning $f(t) = \sum c_n t^n$ for $|t| < R, f \in C^\infty$, then 
    \[f^{(k)}(t) = \sum_{n=k}^\infty \frac{n!}{k!} c_n t^{n-k}\]
    with radius of convergence also $R$.
    \item If $[a, b]$ is the interval of convergence, then 
    \[\int_a^b f(s) \,ds = \sum_{n=0}^\infty c_n \int_a^b s^n \, ds\]
    In particular, 
    \[\int_0^t f(s)\,ds = \sum_{n=0}^\infty \frac{c_n}{n+1} t^{n+1}\]
    which also has a radius of convergence $R$. 
    \item Identity theorem for power series. If $g(t) = \sum d_n t^n$ is another power series with ROC $= \Tilde{R}$, and $f(t) = g(t)$ on some interval in which the series both converge, then $d_n = c_n$ for all $n$. In particular, if the sum of a power series is $0$ for all $t \in I$, then every coefficient in the series must be $0$. 
    \item $f, g$ converge $\implies f+g$ converges within the ROC of both $f$ and $g$. 
    \item $f, g$ converges $\implies fg$ converges within the ROC of both $f$ and $g$. 
\end{enumerate}

\begin{definition}
$f$ is \textit{analytic at $t=a$} if and only if it can be expanded into a Taylor series 
\[f(t) = \sum_{n=0}^\infty c_n (t-a)^n, \;\; c_n = \frac{f^{(n)}(n)}{k!}\]
with radius of convergence $R > 0$. 
\end{definition}
It is assumed that the reader is familiar with basic convergence tests such as the ratio test and the comparison test. 

\begin{lemma}
Let $f, g$ be analytic functions. That is, they can be expressed
\[f(t) = \sum_{n=p}^\infty c_n (t-a)^n, \;\;\; g(t) = \sum_{n=q}^\infty d_n (t-a)^n\]
Without loss of generality, suppose $p < q$ and $d_q \neq 0$. Then, $f$ and $g$ are linearly independent on every interval $I$ in which $f, g$ converges. 
\end{lemma}
\begin{proof}
This proof is trivial using linear algebra since $f$ is expressed using more basis vectors. 
\end{proof}

\subsection{2nd Order Linear Equations w/ Analytic Coefficients}
\begin{example}
Despite what we have learned, the differential equation 
\[y^{\prime\prime} (t) - t y = 0, \;\; \varphi(t_0) = a, \varphi^\prime (t_0) = b\]
cannot be solved with any of the previous methods, but there does exist unique solutions for all $t$. We wish to find a solution using a new method. Assume that $\varphi(t)$ is analytic at $t= t_0$. That is, it can be expanded
\[\varphi(t) = c_0 + c_1 (t-t_0) + c_2 (t-t_0)^2 + \ldots = \sum_{k=0}^\infty c_k (t-t_0)^k\]
that converges in an interval $|(t-t_0)| < A$ (we will not worry about convergence yet). We can calculate
\begin{align*}
    \varphi^{\prime\prime} (t) - t \varphi(t) & = \sum_{k=2}^\infty k(k-1) c_k (t-t_0)^{k-2} - \sum_{k=0}^\infty c_k (t-t_0)^{k+1} \\
    & = 2 c_2 + \sum_{k=3}^\infty \big( k(k-1) c_k - c_{k-3}\big) (t-t_0)^{k-2} = 0
\end{align*}
if and only if $\varphi(t)$ is a solution of $y^{\prime\prime} - t y = 0$. This implies that 
\begin{align*}
    & 2 c_2 = 0, k(k-1) c_k - c_{k-3} = 0 \\
    \implies & c_2 = 0, c_3 = \frac{1}{2 \cdot 3} c_0, c_4 = \frac{1}{3 \cdot 4} c_1, c_5 = \frac{1}{4 \cdot 5} c_2, ... \\
    \implies & \begin{cases}
    c_{3m} = \frac{(1)(4)...(3m-2)}{(3m)!} c_0 \\
    c_{3m+1} = \frac{(2)(5)(8)...(3m-1)}{(3m+1)!} c_1 \\
    c_{3m+2} = 0
    \end{cases}
\end{align*}
which proves us an explicit definition of $\varphi$ dependent on initial conditions $a = \varphi(0) = c_0, b = \varphi^\prime (0) = c_1$. Therefore, a candidate for a solution is
\begin{align*}
    \varphi(t) & = a \varphi_1 (t) + b \varphi_2 (t) \\
    & = a \bigg( 1 + \sum_{m=1}^\infty \frac{(1)(4)...(3m-2)}{(3m)!} (t-t_0)^{3m} \bigg) + b \bigg( 1 + \sum_{m=1}^\infty \frac{(2)(5)...(3m-1)}{(3m+1)!} (t-t_0)^{3m+1} \bigg)
\end{align*}
We can see that this infinite series converges for $|(t-t_0)| < \infty$. 
\end{example}

\begin{theorem}[Existence of Analytic Solutions of 2nd-Order Linear DEQs of Analytic Coefficients]
Given equation (with leading coefficient $1$)
\[y^{\prime\prime} + p(t) y + q(t) y = f(t)\]
If $p, q, f$ are analytic at $t_0$, then there exists a unique solution $\varphi$ satisfying $\varphi (t_0) = a, \varphi^\prime (t_0) = b$. This solution is analytic at $t = t_0$, with expansion
\[\varphi(t) = \sum_{k=0}^\infty c_k (t-t_0)^k\]
converging for at least those values of $t$ converging on $p, q$ and $f$. The coefficients $c_k$ can be determined recursively by direct substitution into the differential equation. 
\end{theorem}

Notice that this series method can be very useful computationally. For values close to $t_0$, we can calculate the series up to a certain number of coefficients to gain a good approximation of the actual function. 

\begin{example}[Legendre Equation]
Given the equation
\[(1 - t^2) y^{\prime \prime} - 2 t y^\prime + \alpha (\alpha + 1) y = 0\]
with $\alpha$ a given constant. In order to determine whether this differential equation has a series solution about $t=0$, we use the previous theorem. We modify the equation to
\begin{align*}
    y^{\prime\prime} - \frac{2 t}{1 - t^2} y^\prime + \frac{\alpha (\alpha + 1)}{1 - t^2} y = 0 \;\;\; (t \neq \pm 1) 
\end{align*}
The coefficient functions are indeed analytic. That is, 
\begin{align*}
    & - \frac{2t}{1 - t^2} = -2 t (1 + t^2 + t^4 + ... ) = -2t \sum_{k=0}^\infty t^{2k} \\
    & \frac{\alpha(\alpha+1)}{1 - t^2} = \alpha (\alpha + 1) \sum_{k=0}^\infty t^{2k}
\end{align*}
with a radius of convergence of $1$. Therefore, the conditions of the theorem are satisfied, and the Legendre equation has a unique analytic solution satisfying $\varphi(0) = a, \varphi^\prime (0) = b$ for all $a, b$. 
\end{example}

\subsection{Singular Points of Linear Equations}
Many differential equations which arise in applications, the so-called equations of mathematical physics, fail to satisfy the hypotheses of the theorem stating the existence of analytic solutions. That is, there are points $t = t_0$ where the coefficients are not analytic (usually because it is unbounded). They usually pop up when we divide the entire equation by the leading coefficient $a_0 (t)$, which leads to one of the non-leading coefficients to become un-analytic when it is of the form 
\[\frac{a_i(t)}{a_0 (t)} \]
We formalize this below 

\begin{definition}[Singular Point]
$t = t_0$ is a \textit{singular point} of the differential equation
\[\mathcal{L}_n (y) = a_0 (t) y^{(n)} + a_1 (t) y^{(n-1)} + \ldots + a_{n-1} (t) y^\prime + a_n (t) y = 0\]
if $a_0, a_1, \ldots, a_n$ are analytic at $t_0$ and $a_0 (t_0) = 0$, but $a_1, \ldots, a_n$ are not all zero at $t_0$. A point that is not a singular point is called an \textit{ordinary point}. 
\end{definition}

In relation to the theorem on the existence of analytic solutions, we would like to clarify that given singular point $t_0$ and non-singular point $t_1$, 
\begin{align*}
    \text{At } t = t_1 & \implies \text{Analytic solution exists (theorem)} \\
    \text{At } t = t_0 & \implies \text{Analytic solution could exist or not} 
\end{align*}
That is, the theorem tells us that given equation
\[y^{\prime\prime} + p(t) y + q(t) y = f(t)\]
where $p, q, f$ are analytic at $t_1$ (i.e. $t_1$ is ordinary), we are guaranteed the existence of a analytic solution in a neighborhood of $t_1$. However, if $p, q$ are somehow not analytic, then there \textit{may or may not} be an analytic solution. This will be elaborated in the following example. 

\begin{example}[Nonexistence of Analytic Solutions in 1st-Order Cauchy-Euler Equation]
Consider the first-order Cauchy-Euler equation centered around $t = t_0$
\[(t - t_0) y^\prime + a y = 0\]
where $a$ is a constant. Then, there cannot be an analytic solution to this DEQ at $t = t_0$ since the coefficients of the equivalent, equation
\[y^\prime = -\frac{a}{t-t_0} y\]
A special solution for this DEQ is $y = (t - t_0)^{-a}$, which is graphed (along with the phase velocity vector space/slope field) for when $a > 0, a = 0$, and $a < 0$. 
\begin{center}
    \includegraphics[scale=0.25]{Singular_Point_of_1st_Cauchy_Euler.PNG}
\end{center}
Given that $a > 0$, we can see that the solution is clearly unbounded at $t = t_0$, so there does not exist an analytic function. However, if $a \leq 0$, then there does exist an analytic function. 
\end{example}

\begin{example}[Nonexistence of Analytic Solutions in 2nd-Order Cauchy-Euler Equation]
Consider the second-order Cauchy-Euler equation centered around $t = t_0$
\[(t - t_0)^2 y^{\prime\prime} + (t - t_0) a_1 y^\prime + a_2 y = 0\]
where $a_1, a_2$ are constants. Then, we can see that there cannot be analytic solutions to this DEQ at $t= t_0$ since the coefficients of the equivalent, normalized equation
\[y^{\prime\prime} + \frac{a_1}{t - t_0} y^\prime + \frac{a_2}{(t-t_0)^2} y = 0\]
are unbounded at $t = t_0$. However, in a neighborhood of any point $t_1 \neq t_0$, there does exist analytic solutions. Assuming $a_1 = a_2 = 1$, we can see that the solution $y = \varphi(t) = \cos(\ln{(t-t_0)}) + \sin(\ln{(t - t_0)})$ oscillates infinitely as $t \rightarrow t_0$. 
\begin{center}
    \includegraphics[scale=0.25]{Oscillates_Infinitely.PNG}
\end{center}
Furthermore, by setting this up as a system of first order equations using $y = y, x = y^\prime$, we get
\begin{align*}
    y^\prime & = x \\
    x^{\prime} & = y^{\prime\prime} = - \frac{a_1}{t - t_0} x - \frac{a_2}{(t - t_0)^2} y
\end{align*}
Normalizing $a_1 = a_2 = 1$, we give the phase velocity vector field for the three time periods $t = t_0 - 1, t_0, t_0 + 1$. 
\begin{center}
    \includegraphics[scale=0.25]{Singular_Point_of_2nd_Cauchy_Euler.PNG}
\end{center}
\end{example}

The behavior of the solutions near the singular point $t_0$ (whether it is actually analytic or not) depends on how rapidly $a_0 (t)$ approaches zero as $t \rightarrow t_0$. For this reason, we distinguish two different types of singular points, with the first being the regular one. 

\begin{definition}[Regular Singular Point]
The point $t_0$ is called a \textit{regular singular point} of the equation 
\[\mathcal{L}_n (y) = a_0 (t) y^{(n)} + a_1 (t) y^{(n-1)} + \ldots + a_{n-1} (t) y^\prime + a_n (t) y = 0\]
if it is a singular point and if 
\[p_1 (t) = \frac{a_1 (t)}{a_0 (t)}, \; p_2 (t) = \frac{a_2 (t)}{a_0 (t)}, \ldots, p_n (t) = \frac{a_n (t)}{a_0 (t)}\]
have the property that $(t - t_0) p_1 (t), (t - t_0)^2 p_2 (t), \ldots, (t - t_0)^n p_n (t)$ are all analytic at $t_0$. It immediately follows that the equation $\mathcal{L}_n (y) = 0$ has a regular singular point at $t = t_0$ if and only if it can be written in the form:
\begin{align*}
    & a_0 (t) y^{(n)} + a_1 (t) y^{(n-1)} + \ldots + a_{n-1} (t) y^\prime + a_n (t) y = 0\\
    \implies & y^{(n)} + \frac{a_1 (t)}{a_0 (t)} y^{(n-1)} + \ldots + \frac{a_{n-1}}{a_0 (t)} (t) y^\prime + \frac{a_n (t)}{a_0 (t)} y = 0 \\
    \implies & (t - t_0)^n y^{(n)} + (t - t_0)^n \frac{a_1 (t)}{a_0 (t)} y^{(n-1)} + \ldots + (t - t_0)^n \frac{a_{n-1}}{a_0 (t)} (t) y^\prime + (t - t_0)^n \frac{a_n (t)}{a_0 (t)} y = 0 \\
    \implies & (t - t_0)^n y^{(n)} + (t - t_0)^{n-1} \bigg((t-t_0) \frac{a_1 (t)}{a_0 (t)}\bigg) y^{(n-1)} + \ldots + \bigg( (t-t_0)^n \frac{a_n (t)}{a_0 (t)} \bigg) y = 0 \\
    \implies & (t - t_0)^n y^{(n)} + (t - t_0)^{n-1} \alpha_1 (t) y^{(n-1)} + \ldots + (t - t_0) \alpha_{n-1} (t) y^\prime + \alpha_n (t) y = 0
\end{align*}
Therefore, the equation $\mathcal{L}_n (y) = 0$ has a regular singular point if it can be written in the form
\[\sum_{i=0}^n (t - t_0)^{n-i} \alpha_i (t) y^{(n-i)} = 0, \;\;\;\; \alpha_i (t) = (t - t_0)^i \frac{a_i (t)}{a_0 (t)}\]
where the $\alpha_i$'s are analytic at $t = t_0$. If a singular point $t = t_0$ is not regular, then it is called an \textit{irregular singular point}. 
\end{definition}

\begin{example}
We list three examples of equations and their corresponding singular points. 
\begin{enumerate}
    \item The Euler equation 
    \[(t - t_0)^2 y^{\prime\prime} + (t - t_0) a_1 y^\prime + a_2 y = 0\]
    is the simplest example of an equation which has a regular singular point at $t = t_0$. 
    \item The equation 
    \[t^2 y^{\prime\prime} + \frac{3}{2} t y^\prime + ty = 0\]
    has $t = 0$ as a regular singular point because $p(t) = \frac{3}{2t}, q(t) = \frac{1}{t}$ have the property that $t p(t) = \frac{3}{2}, t^2 q(t) = t$ are both analytic everywhere.
    \item The equation 
    \[(t-1)^3 y^{\prime\prime} + 2(t-1)^2 y^\prime - 7ty = 0\]
    does not have a regular singular point at $t = 1$. 
\end{enumerate}
\end{example}

\subsubsection{Change of Basis}
To simplify the process, we can perform a change of basis 
\[t \mapsto x = t - t_0\]
which allows us to transform the singular point $t_0$ to the origin without changing the form of the equation in any essential way. Therefore, we would let 
\[\overline{\alpha}_i (x) = \alpha_i (t_0 + x) \text{ for all } i = 1, 2, \ldots, n\]
which are analytic at $x = 0$ since $\alpha_i$ is analytic at $t = t_0$. Furthermore, we define
\[\overline{y}(x) = y (t_0 + x)\]
and by the chain rule, we have
\[\frac{d \overline{y}}{dx} = y^\prime (t_0 + x) = y^\prime (t), \frac{d^2 \overline{y}}{dx^2} = y^{\prime\prime} (t_0 + x) = y^{\prime\prime} (t), \ldots, \frac{d^n \overline{y}}{dx} = y^{(n)} (t_0 + x) = y^{(n)} (t)\]
Therefore, the equation simplifies as such: 
\begin{align}
    & (t - t_0)^n y^{(n)} + (t - t_0)^{n-1} \alpha_1 (t) y^{(n-1)} + \ldots + (t - t_0) \alpha_{n-1} (t) y^\prime + \alpha_n (t) y = 0 \\
    \implies & x^n \bar{y}^{(n)}(x) + x^{n-1} \bar{\alpha}_1(x) \bar{y}^{(n-1)} (x) + \ldots + x \bar{\alpha}_{n-1} (x) \bar{y}^\prime (x) + \bar{\alpha}_n (x) \bar{y} = 0
\end{align}
Therefore, if $\bar{y}(x)$ is a solution of the second equation with regular singular point $x = 0$, then the function $y(t) = \bar{y} (t - t_0)$ is a solution of the first equation with regular singular point $t = t_0$. 

Therefore, we will assume that such a preliminary simplification has been made, and without loss of generality, we will consider a $n$th order homogeneous linear differential equation with regular singular point (changed accordingly to be at $t = 0$) to be of form
\[t^n y^{(n)} + t^{n-1} \alpha_1 (t) y^{(n-1)} + \ldots + t^2 \alpha_{n-2} (t) y^{\prime\prime} + t \alpha_{n-1} (t) y^\prime + \alpha_n (t) y = 0\]
where the $\alpha_i$'s are given functions analytic at $t = 0$ and having power series expansions 
\[\alpha_i (t) = \sum_{k=0}^\infty \alpha_{ik} t^k\]
which converge in some interval $|t|<r$. 

\subsubsection{Examples}

\begin{example}
The following DEQ can be changed as such
\begin{align*}
    2ty^{\prime\prime} + y^\prime + ty & = 0 \implies t^2 y^{\prime\prime} + \frac{1}{2} ty^\prime + \frac{1}{2} t^2 y = 0 \\
    & = t^2 y^{\prime\prime} + t \alpha_1 (t) y^\prime + \alpha_2 (t) y = 0
\end{align*}
where
\[\alpha_1 (t) = \frac{1}{2}, \;\; \alpha_2 (t) = \frac{1}{2} t^2\]
which are both analytic at $t = 0$, making $t = 0$ a regular singular point. If both $\alpha_1, \alpha_2$ were constants, this following equation would be the Euler equation, making one of the solutions to be of form $|t|^z$. But since $\alpha_2$ is not a constant, we attempt to find a solution of form 
\[|t|^z \sum_{k=0}^\infty c_k t^k, \;\;\; c_0 \neq 0\]
where the constants $z, c_k$ are determined by substitution into the differential equation within some interval of convergence around $t = 0$. Since $t = 0$ is a singular point, we separate the cases $t>0$ and $t<0$. We first consider the case $t>0$ and try the following solution of $\varphi$ and its derivatives (assuming $\varphi \in C^2$): 
\begin{align*}
    \varphi (t) & = t^z \sum_{k=0}^\infty c_k t^k = \sum_{k=0}^\infty c_k t^{z+k} \\
    \varphi^\prime (t) & = \sum_{k=0}^\infty c_k (z+k) t^{z+k-1} \\
    \varphi^{\prime\prime} (t) & = \sum_{k=0}^\infty c_k (z+k)(z+k-1) t^{z+k-2} 
\end{align*}
We substitute this into the equation and simplify it, where we set the indicial polynomial as $f(z) = z (z - \frac{1}{2})$ (we can find this by looking at the quadratic term in $z$ having coefficient $c_0$). 
\begin{align*}
    0 & = t^2 \varphi^{\prime\prime} (t) + \frac{1}{2} t \varphi^\prime (t) + \frac{1}{2} t^2 \varphi (t) \\
    & = c_0 z \bigg(z - \frac{1}{2}\bigg) t^z + c_1 (z+1) \bigg( z+\frac{1}{2}\bigg) t^{z+1} + \sum_{k=0}^\infty \bigg( (z+k) \Big(z+k-\frac{1}{2} \Big) c_k + \frac{1}{2} c_{k-2}\bigg) t^{z+k}\\
    & = t^z \Bigg( c_0 f(z) + c_1 f(z+1) t + \sum_{k=2}^\infty \bigg( f(z+k) c_k + \frac{1}{2} c_{k-2} \bigg)\Bigg) 
\end{align*}
The equality implies that every coefficient of every power of $t$ vanishes on the right hand side. Since we assumed $c_0 \neq 0$, we have
\begin{align*}
    &f(z) = 0 \\
    &c_1 f(z+1) = 0 \\
    &f(z+k) c_k + \frac{1}{2} c_{k-2} = 0 \text{ for } k = 2, 3, 4, \ldots 
\end{align*}
$f(z) = 0 \implies z = 0$ or $z = \frac{1}{2}$. 
\begin{enumerate}
    \item When $z = \frac{1}{2}$, this must mean that $c_1 = 0$ in order to satisfy the equation $c_1 f(z+1) = 0$. We can rewrite the relation $f(z+k) c_k + \frac{1}{2} c_{k-2} = 0$ as
    \[c_k = \frac{-1}{2 f(k + \frac{1}{2})} c_{k-2} = -\frac{1}{2k (k+\frac{1}{2})} c_{k-2}\]
    Remember that $c_0 \neq 0$ is arbitrary and that $c_1 = 0$, so we can manually calculate 
    \begin{align*}
        c_{2m-1} & = 0 \\
        c_{2m} & = (-1)^m \frac{c_0}{2 \cdot 4 \cdot 6 \ldots 2m \cdot 5 \cdot 9 \ldots (4m+1)} = (-1)^m c_0 \bigg( \prod_{i=1}^m 2i (4i + 1) \bigg)^{-1}
    \end{align*}
    for $m = 1, 2, \ldots $. Substituting these quantities into the series $\varphi(t) = t^z \sum_{k=0}^\infty c_k t^k$ gives
    one candidate for a solution of the differential equation for $t>0$:
    \[\varphi_1 (t) = t^{1/2} \Bigg( 1 + \sum_{m=1}^\infty (-1)^m \bigg( \prod_{i=1}^m 2i (4i + 1) \bigg)^{-1} t^{2m} \Bigg) \]
    Note that the $c_0$, which is just a constant factor, has been normalized to $1$. 
    \item When $z = 0$, we find that $c_1 = 0$ ($c_0$ still arbitrary), but we rewrite the relation $f(z+k) c_k + \frac{1}{2} c_{k-2} = 0$ as 
    \[c_k = \frac{-1}{2 f(k)} c_{k-2} = -\frac{1}{2k (k-\frac{1}{2})} c_{k-2}\]
    Leading to
    \begin{align*}
        c_{2m-1} & = 0 \\
        c_{2m} & = (-1)^m \frac{c_0}{2 \cdot 4 \cdot 6 \ldots 2m \cdot 3 \cdot 7 \ldots (4m-1)} = (-1)^m c_0 \bigg( \prod_{i=1}^m 2i (4i - 1) \bigg)^{-1}
    \end{align*}
    for $m = 1, 2, \ldots $. Substituting and normalizing $c_0 = 1$, we obtain the second candidate for a solution of the DEQ when $t>0$ as
    \[\varphi_2 (t) = 1 + \sum_{m=1}^\infty (-1)^m \bigg( \prod_{i=1}^m 2i (4i - 1) \bigg)^{-1} t^{2m}\]
\end{enumerate}
Using the ratio test, we can find out that for the series $\varphi_1, \varphi_2$, 
\[\bigg|\frac{a_{m+1}}{a_{m}}\bigg| \rightarrow 0 \text{ as } m \rightarrow \infty\]
where $a_m$ is the $m$th term of the series. Therefore, both $\varphi_1, \varphi_2$ converges within $(-\infty, \infty)$. Therefore, we have found solutions of the form 
\[|t|^z \sum_{k=0}^\infty c_k t^k\]
for when $t>0$ (the value $t=0$ must be omitted because the differential equation has no meaning at the singular point $t=0$). It is easy to prove that $\varphi_1$ and $\varphi_2$ are linearly independent. The above calculations are all valid for $t<0$ if $t^z$ is replaced by $|t|^z = e^{z \log{|t|}}$, and still leads to the same solutions $\varphi_1, \varphi_2$ for the interval $(-\infty, 0)$.
\end{example}

Therefore, we can see that the assumption that a given DEQ has a solution of the form 
\[|t|^z \sum_{k=0}^\infty c_k t^k\]
leads to a quadratic equation in $z$, the indicial equation, and each root of the indicial equation leads to two linearly independent solutions of the differential equation. However, an indicial polynomial may have a double root, which will require extra work to find the second solution. 

\begin{example}
The differential equation $t y^{\prime\prime} + y^\prime + y = 0$, which may be written as 
\[t^2 y^{\prime\prime} + t y^\prime + ty = 0\]
Clearly, $t=0$ is a regular singular point. Assuming the existence of solution of the form $\varphi(t) = |t|^z \sum_{k=0}^\infty c_k t^k$ on some interval, we consider the case $t>0$. With some steps omitted, we have
\[t^2 \varphi^{\prime\prime} (t) + t \varphi^\prime (t) + t \varphi(t) = t^z \bigg( f(z) c_0 + \sum_{k=1}^\infty \big( f(k+z) c_k + c_{k-1} \big) t^k \bigg)\]
where the indicial polynomial is $f(z) = z^2$, having a double root $z=0$. Since every term on the right hand side vanishes, we have
\begin{align*}
    f(k+z) c_k + c_{k-1} = 0 & \implies c_k = -\frac{c_{k-1}}{k^2}, \;\;\;\; k = 1, 2, 3, \ldots \\
    & \implies c_k = c_0 \prod_{i=1}^k -\frac{1}{i^2}
\end{align*}
By substituting in the $c_k$'s, we have (for $t>0$)
\[\varphi(t) = 1 + t^z \sum_{k=1}^\infty \bigg(\prod_{i=1}^k -\frac{1}{i^2}\bigg) t^k\]
Similar calculations show that the same solution pops up for $t<0$. The ratio test tells us that the interval of convergence for $\varphi(t)$ is $(-\infty, \infty)$. We will talk about how to find the second solution later. 
\end{example}

Note in the previous example that although the differential equation makes no sense at the singular point $t = 0$, the function defined by the series 
\[\sum_{k=0}^\infty c_k t^k\]
is well defined 

\begin{example}
The DEQ $t y^{\prime\prime} + ty^\prime - y = 0$, which can be rewritten as
\[t^2 y^{\prime\prime} + t^2 y^\prime - ty = 0\]
has $t = 0$ has a regular singular point. When $t>0$, we calculate
\[^2 y^{\prime\prime} + t^2 y^\prime - ty =  = t^z \bigg( f(z) c_0 + \sum_{k=1}^\infty \big( f(k+z) c_k + (k+z-2) c_{k-1}\big) t^k \bigg)\]
where $f(z) = z (z-1)$. For every term to vanish, $z = 0$ or $z = 1$. 
\begin{enumerate}
    \item Taking $z = 1$, we have 
    \[c_k = -\frac{(k-1) c_{k-1}}{k (k+1)}, \;\; k = 1, 2, \ldots\]
    which gives $c_k = 0$ and taking $c_0 = 1$, have have solution $\varphi_1 (t) = |t|$, which is clearly convergent. 
    \item When $z=0$, the recursion formula becomes
    \[k(k-1) c_k + (k-2) c_{k-1} = 0, \;\; k = 1, 2, \ldots\]
    But taking $k=1$, $c_1$ must be determined from the relation 
    \[0 \cdot c_1 - c_0 = 0\]
    But since $c_0 \neq 0$, this is impossible and there can be no solution of the assumed form corresponding to the root $z=0$. However, a solution of a different form does exist. 
\end{enumerate}
\end{example}

\subsubsection{Regular Singular Point Theorem}
We can neatly summarize our theory of finding solutions of equation with singular points with the following theorem. 

\begin{theorem}[Regular Singular Point Theorem of 2nd-Order Homogeneous Linear DEQs]
Consider the differential equation
\[t^2 y^{\prime\prime} + t \alpha_1 (t) y^\prime + \beta (t) y = 0\]
where $\alpha_1, \beta$ are analytic at regular singular point $t = 0$ and have expansions
\[\alpha (t) = \sum_{k=0}^\infty \alpha_k t^k, \;\;\; \beta(t) = \sum_{k=0}^\infty \beta_k t^k\]
which converge for $|t|<r$ for some $r>0$. Let $z_1, z_2$ be the roots of the indicial equation
\[f(z) = z(z-1) + \alpha_0 z + \beta_0 = 0\]
with Re$(z_1) \geq$ Re$(z_2)$. Then, there is always a solution of the form 
\[\varphi_1 (t) = |t|^{z_1} \sum_{k=0}^\infty c_k t^k \;\;\;\;\; (c_0 = 1)\]
in the punctured interval $0<|t|<r$ whose coefficients $c_k$ can be determined recursively from the equations
\[f(z_1 + k) c_k = - \sum_{j=0}^{k-1} \big((j+z)\alpha_{k-j} + \beta_{k-j}\big) c_j, \;\;\;\;\; k = 1, 2, \ldots\]
As for the second solution, there are three possible cases: 
\begin{enumerate}
    \item If $z_1 \neq z_2, z_1 - z_2 \not\in \mathbb{Z}$, then there is a second, linearly independent solution of the form 
    \[\varphi_2 (t) = |t|^{z_2} \sum_{k=0}^\infty \hat{c}_k t^k \;\;\;\;\; (\hat{c}_0 = 1)\]
    also in the punctured interval $0 < |t| < r$. The coefficients $\hat{c}_k$ can also be solved using the recursive formula above, with $z_1$ replaced by $z_2$ and $c_k$ replaced by $\hat{c}_k$. 
    \item If $z_1 = z_2$, then the second (linearly independent) solution is of form
    \[\varphi_2 (t) = |t|^{z_1 + 1} \bigg( \sum_{k=0}^\infty b_k t^k\bigg) + \varphi_1 (t) \log{|t|}\]
    valid for $0<|t|<r$, whose coefficients $b_k$ can be determined by direct substitution into the DEQ. 
    \item If $z_1 - z_2 \in \mathbb{N}$, then there is a second linearly independent solution of form 
    \[\varphi_2 (t) = |t|^{z_2} \bigg( \sum_{k=0}^\infty b_k t^k \bigg) + a \varphi_1 (t) \log{|t|}\]
    valid for $0<|t|<r$, where $a$ is a constant (possibly $0$) and the coefficients $b_k$ can be determined by direct substitution into the DEQ. 
\end{enumerate}
\end{theorem}

Note that it is simpler in practice to substitute the assumed formula of the solution into the DEQ than to use the recursive formulas to solve for the coefficients. 

\subsubsection{The Bessel Equation}

\begin{definition}[Bessel Equation]
The \textbf{Bessel equation} arises in a natural way in many mathematical physics problems having axial/cylindrical symmetry, and is written in the form 
\[\mathcal{L}_n (y) = t^2 y^{\prime\prime} + t y^\prime + (t^2 - p^2) y = 0\]
where constant $p \in \mathbb{C}$ and Re$(p) \geq 0$. The point $t = 0$ is a regular singular point, and the equation is of form $t^2 y^{\prime\prime} + t \alpha(t) y^\prime + \beta(t) y = 0$. 
\end{definition}

\begin{definition}
Recall the gamma function
\[\Gamma (z) = \int_0^\infty e^{-x} x^{z-1} \,dx, \;\;\;\;\; \text{Re}(z) > 0\]
and its properties: 
\begin{enumerate}
    \item $\Gamma(z)$ is well defined and continuous for Re$(z) > 0$. 
    \item $\Gamma(1) = 1, \Gamma(\frac{1}{2}) = \sqrt{\pi}$
    \item $\Gamma(z) = (z-1) \Gamma (z-1)$ for Re$(z) > 1$ from integration by parts. 
    \item $\Gamma(z) = z!$ for $z \in \mathbb{N}$. 
    \item We can define $\Gamma$ for negative non-integer numbers $z$ using the recursion formula 
    \[\Gamma(z) = \frac{\Gamma(z+k)}{z (z+1) \ldots (z+k-1)}\]
    by choosing a positive integer $k$ such that Re$(z+k)>0$. Therefore, we can define $\Gamma$ for all complex numbers $z$ except for when Re$(z) \in \{0, -1, -2, -3, \ldots\}$. The graph of $\Gamma$ in $\mathbb{R} \times \mathbb{R}$ is shown. 
    \begin{center}
        \includegraphics[scale=0.25]{Gamma_plot.png}
    \end{center}
\end{enumerate}
\end{definition}

\begin{theorem}[The Bessel Function]
Given the Bessel equation 
\[t^2 y^{\prime\prime} + t y^\prime + (t^2 - p^2) y = 0, \;\; p \in \mathbb{C}, \text{Re}(p) \geq 0\]
where $t = 0$ is a regular singular point. 
\begin{enumerate}
    \item If $p \not\in \mathbb{N} \cup \{0\}$, then the following \textit{Bessel functions of the first kind} $J$ (of index $p, -p$) 
    \begin{align*}
        J_p (t) & = \bigg| \frac{t}{2}\bigg|^p \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma(p+m+1)} \bigg(\frac{t}{2}\bigg)^{2m} \\
        J_{-p} (t) & = \bigg| \frac{t}{2}\bigg|^{-p} \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma(m-p+1)} \bigg(\frac{t}{2}\bigg)^{2m}
    \end{align*}
    are two linearly independent solutions for $0 < |t| < \infty$. 
    \item If $p = 0$, then the Bessel function of the first kind and second kind, both of index $0$
    \begin{align*}
        J_0 (t) & = \sum_{m=0}^\infty \frac{(-1)^m}{(m!)^2} \bigg( \frac{t}{2}\bigg)^{2m} \\
        K_0 (t) & = - \sum_{m=1}^\infty \Bigg( \frac{(-1)^m}{(m!)^2} \bigg(1 + \frac{1}{2} + \ldots + \frac{1}{m} \bigg) \bigg(\frac{t}{2}\bigg)^{2m} \Bigg) + J_0 (t) \log{t}
    \end{align*}
    are two linearly independent solutions for $0 < |t|<\infty$. 
    \item If $p$ is a positive integer $n$, then the Bessel function of the first kind of index $n$ and the \textit{Bessel function of the second kind} $K$ (of index n)
    \begin{align*}
        J_n (t) & = \bigg| \frac{t}{2}\bigg|^n \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma(n+m+1)} \bigg(\frac{t}{2}\bigg)^{2m} \\
        K_n (t) & = -\frac{1}{2} \bigg|\frac{t}{2}\bigg|^{-n} \bigg(\sum_{k=0}^{n-1} \frac{(n-k-1)!}{k!} \bigg(\frac{t}{2}\bigg)^{2k} + \frac{1}{n!}\bigg(1 + \frac{1}{2} + \ldots + \frac{1}{n}\bigg)\bigg(\frac{t}{2}\bigg)^{2n} \Bigg) \\
        & -\frac{1}{2} \bigg(\frac{t}{2} \bigg)^n \sum_{k=0}^\infty \frac{(-1)^k}{k!(k+n)!} \bigg(\Big(1 + \ldots + \frac{1}{k}\Big) + \Big(1 + \frac{1}{2} + \ldots + \frac{1}{k+n}\Big) \bigg) \bigg(\frac{t}{2}\bigg)^{2k} \\
        & + J_n (t) \log{|t|}
    \end{align*}
\end{enumerate}
\end{theorem}
\begin{proof}
We now derive the solutions to this Bessel equation. By the regular singular point theorem, since
\[\alpha (t) = 1, \;\; \beta(t) = -p^2 + t^2\]
which both converge for $|t|<\infty$, the indicial equation is 
\[f(z) = z(z-1) + z + -p^2 = z^2 - p^2\]
which has zeroes $z_1 = p, z_2 = -p$ (remember we assumed (Re$(p) \geq 0$). If $p \neq 0$ and if $z_1 - z_2 = 2p$ is not a positive integer (i.e. $p$ is not $0$, an integer, or a half-integer), there exists two linearly independent solutions $\varphi_1, \varphi_2$ of the equation, valid for $0<|t|<\infty$, of the form
\begin{align*}
    \varphi_1 (t) & = |t|^p \sum_{k=0}^\infty c_k t^k \;\;\;\;\; (c_0 \neq 0) \\
    \varphi_2 (t) & = |t|^{-p} \sum_{k=0}^\infty \hat{c}_k t^k \;\;\;\; (\hat{c}_0 \neq 0)
\end{align*}
where coefficients $c_k, \hat{c}_k$ are determined recursively by substitution. We first compute $\varphi_1$ and assume $t>0$. Substituting
\[\varphi_1^\prime (t) = \sum_{k=0}^\infty c_k (p+k) t^{p+k-1}, \;\;\; \varphi_1^{\prime\prime} = \sum_{k=0}^\infty c_k (p+k) (p+k-1) t^{p+k-2}\]
into the equation and simplifying gives
\[\mathcal{L}_2 \big( \varphi_1 (t)\big) = t^p \bigg( f(p) c_0 + f(p+1) c_1 t + \sum_{k=0}^\infty \big( f(p+k) c_k + c_{k-2}\big) t^k \bigg) = 0\]
for which we conclude that 
\[f(p+1) c_1 = 2p + 1 = 0 \implies p = -\frac{1}{2} \text{ or } c_1 = 0\]
But since Re$(p)\geq 0$, this means that $c_1 = 0$. We use the recursive relations
\[f(p+k) c_k + c_{k-2} = k (2p+k) c_k + c_{k-2} = 0\]
which implies that
\begin{align*}
    c_{2m-1} & = 0 \\
    c_{2m} & = \frac{(-1)^m c_0}{2^{2m} m! (p+1)(p+2) \ldots (p+m)} 
\end{align*}
for $m = 1, 2, \ldots$. Therefore, the solution can be written as
\[\varphi_1 (t) = c_0 |t|^p \Bigg( 1 + \sum_{m=1}^\infty \frac{(-1)^m t^{2m}}{2^{2m} m! (p+1) (p+2) \ldots (p+m)} \Bigg)\]
Since we can let $c_0$ be any nonzero constant, we define it using the Gamma function as
\[c_0 = \frac{1}{2^p \Gamma(p+1)}\]
resulting in the solution
\[J_p = \bigg| \frac{t}{2}\bigg|^p \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma(p+m+1)} \bigg(\frac{t}{2}\bigg)^{2m}\]
called the \textit{Bessel function of the first kind of index $p$}. It is well defined for all $t \in \mathbb{R}$ and satisfies the DEQ for $0 < |t| < \infty$. 
\end{proof}

\subsubsection{Singularities at Infinity}
We can also study the behavior of solutions of the equation
\[\mathcal{L}_2 (y) = y^{\prime\prime} + p(t) y^\prime + q(t) y = 0\]
as $|t| \rightarrow \infty$ by making the change of variable $t = 1/x$ and studying the behavior of solutions of the resulting equation as $x \rightarrow 0$. Thus, we let $\varphi$ be a solution of the original DEQ for $|t|>R$ and let
\[\psi(x) = \varphi(\frac{1}{x}), \;\; \bar{p}(x) = p(\frac{1}{x}), \;\; \bar{q}(x) = q(\frac{1}{x})\]
which should all be well-defined for $|x|<1/R$. By the chain rule, we have
\begin{align*}
    \varphi^\prime (t) & = -\frac{1}{t^2} \psi^\prime (x) = -x^2 \psi^\prime (x) \\
    \varphi^{\prime\prime} (t) & = \frac{1}{t^4} \psi^{\prime\prime} (x) + \frac{2}{t^3} \psi^\prime (x) = x^4 \psi^{\prime\prime}(x) + 2x^3 \psi^\prime (x) 
\end{align*}
Substituting this in shows that $\psi$ satisfies the new equation
\[\bar{\mathcal{L}}_2 (z) = x^4 z^{\prime\prime} + \big( 2x^3 - x^2 \bar{p}(x)\big) z^\prime + \bar{q} (x) z= 0\]
in which $x$ is the independent variable and $z$ is the function. Therefore, if $\psi$ satisfies $\bar{\mathcal{L}}_2 (z) = 0$ and if $\varphi(t) = \psi(1/t)$, then $\varphi$ satisfies $\mathcal{L}_2 (y) = 0$. Our results lead to the following theorem. 

\begin{theorem}[Singularities at Infinity]
$\infty$ is an ordinary point, a regular singular point, or an irregular singular point for the equation $\mathcal{L}_2 (y) = 0$ if and only if $0$ is respectively an ordinary point, a regular singular point, or an irregular singular point for the equation $\bar{\mathcal{L}}_2 (z) = 0$. 
\end{theorem}

\begin{example}
Given the equation
\[y^{\prime\prime} + a y^\prime + by = 0, \;\;\;\;\; a, b \in \mathbb{R}\]
The change of variable $t = 1/x$ transforms this equation to
\[x^4 z^{\prime\prime} + (2x^3 - ax^2) z^\prime + bz = 0\]
which has an irregular singular point at $x = 0$. Therefore, the original equation has an irregular singular point at $t = \infty$. 
\end{example}

\section{Systems of DEQs}

\subsection{First-Order Systems}
We expand on the theory of solving first order differential equations by studying systems of them, which can be worked on using vector algebra/calculus. 

\begin{definition}[System of 1st Order Equations]
A system of $n$ first order equations can be put in the form 
\[y^\prime = f(t, y) \begin{cases}
y_1^\prime  = f_1 (t, y_1, y_2, \ldots, y_n) \\
y_2^\prime  = f_2 (t, y_1, y_2, \ldots, y_n) \\
\ldots \\
y_n^\prime  = f_n (t, y_1, y_2, \ldots, y_n) 
\end{cases}\]
where $f: D \subset \mathbb{R} \times \mathbb{R}^n \longrightarrow \mathbb{R}^n$ is defined in some $(n+1)$-dimensional region $D$ ($\mathbb{R}$ being the time continuum and $\mathbb{R}^n$ being the $n$-dimensional phase space). That is, at a certain time $t = t_0$, 
\[f(t_0, \cdot): \mathbb{R}^n \longrightarrow \mathbb{R}^n\]
determines the phase velocity vector field of $\mathbb{R}^n$ for that instance of time. If the system is autonomous, then the vector field does not morph. As shown before, we can visualize the following. 
\begin{enumerate}
    \item System with 1-dimensional phase space (i.e. a system of one equation) 
    \begin{center}
        \includegraphics[scale=0.26]{System_w_1_dim_Phase_Space.PNG}
    \end{center}
    \item System with 2-dimensional phase space (two equations). The solution shown is 
    \[\varphi: \mathbb{R} \longrightarrow \mathbb{R}^2, \;\; y = \varphi(t) \iff \begin{pmatrix}y_1 \\ y_2
    \end{pmatrix} = \begin{pmatrix} \varphi_1 \\ \varphi_2 \end{pmatrix} (t) = \begin{pmatrix} \varphi_1 (t) \\ \varphi_2 (t) \end{pmatrix}\]
     \begin{center}
        \includegraphics[scale=0.26]{System_w_2_dim_Phase_Space.PNG}
    \end{center}
    \item Systems with higher-dimensional phase spaces are harder to visualize, but we just imagine a time continuum $\mathbb{R}$ where at each point $t_0 \in \mathbb{R}$, there is a vector space $\mathbb{R}^n$ with a vector field $f(t_0, \cdot): \mathbb{R}^n \longrightarrow \mathbb{R}^n$ associated with it. In the visual below, the phase space are shown to be $\mathbb{R}^3$ (when it is really $\mathbb{R}^n$), with $D$ being represented by its cross sections in the time axis (e.g. $D_{t_0}$ is the cross section of $D$ at $t=t_0$). The solution curve $\varphi$ isn't explicitly shown (only the points on the curve at times $t=t_0, t_1, t_2$), but it would be of form 
    \[\varphi: \mathbb{R} \longrightarrow \mathbb{R}^3, y = \varphi(t) \iff \begin{pmatrix}
    y_1 \\ y_2 \\ y_3 \end{pmatrix} = \begin{pmatrix}
    \varphi_1 \\ \varphi_2 \\ \varphi_3 \end{pmatrix} (t) = \begin{pmatrix}
    \varphi_1 (t)\\ \varphi_2(t) \\ \varphi_3(t) \end{pmatrix}\]
     \begin{center}
        \includegraphics[scale=0.26]{System_w_n_dim_Phase_Space.PNG}
    \end{center}
\end{enumerate}
To find the solution of the system means to find the $n$ equations $y_1 = \varphi_1 (t), y_2 = \varphi_2 (t), \ldots, y_n = \varphi_n (t)$, which is equivalent to finding the vector-valued path function 
\[y = \varphi(t) = \begin{pmatrix} \varphi_1 (t) \\ \vdots \\ \varphi_n (t) \end{pmatrix}, \varphi: I \subset \mathbb{R} \longrightarrow \mathbb{R}^n\]
such that
\begin{enumerate}
    \item the point $\big(t, \varphi(t)\big) \in D$ for each $t \in I$
    \item $\varphi^\prime (t)$ exists for each $t \in I$
    \item $\varphi^\prime (t) = f \big( t, \varphi(t)\big)$ for every $t \in I$ 
\end{enumerate}
To solve an initial value problem for the system with initial condition 
\[\varphi(t_0) = \eta, \;\;\; \eta \in \mathbb{R}^n \text{ and } (t_0, \eta) \in D\]
means to find a solution $\varphi$ of the system such that $\varphi(t_0) = \eta$. 
\end{definition}

The study of first order equations is quite nice because we can reduce a high-order scalar differential equation of form
\[y^{(n)} = g(t, y, y^\prime, \ldots, y^{(n-1)})\]
to the following system with a change of variable $y_1 = y, y_2 = y^\prime, \ldots, y_n = y^{(n-1)}$. 
\[\begin{pmatrix}
y_1 \\ y_2 \\ \vdots \\ y_{n-1} \\ y_n
\end{pmatrix}^\prime = \begin{pmatrix}
y_2 \\ y_3 \\ \vdots \\ y_n \\ g(t, y_1, y_2, \ldots, y_n)
\end{pmatrix} \iff \begin{cases}
y_1^\prime = y_2 \\
y_2^\prime = y_3 \\
\ldots \\
y_{n-1}^\prime = y_n \\
y_n^\prime = g(t, y_1, y_2, \ldots, y_n)
\end{cases}\]

\begin{example}
We can write 
\[2 y^{\prime\prime} - 5 y^\prime + y = 0, \;\; y(3) = 6, y^\prime (3) = -1\]
We can define the following functions to get
\[\begin{cases}
    x_1 (t) = y(t) \\
    x_2 (t) = y^\prime (t) 
\end{cases} \implies \begin{cases}
x_1^\prime = y^\prime = x_2 \\
x_2^\prime = y^{\prime\prime} = -\frac{1}{2} x_1 + \frac{5}{2} x_2
\end{cases} \]
This gives the matrix equation
\[\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}^\prime = \begin{pmatrix}
0 & 1 \\ -1/2 & 5/2
\end{pmatrix} \begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}, \;\; \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} (3) = \begin{pmatrix} 6 \\ -1 \end{pmatrix}\]
Solving this system is equivalent to finding a function $\varphi: \mathbb{R} \longrightarrow \mathbb{R}^2$ satisfying the equation. 
\end{example}  

It naturally extends that a system of high-order scalar differential equations can be reduced to a system of systems (creating a larger system) of first-order differential equations. 

\begin{example}
The system 
\begin{align*}
    y^{\prime\prime} & = \sin{(t)} y^\prime + 2y - 4 \\
    y^{\prime\prime\prime} & = e^t y^{\prime\prime} - 2\sin{(4\pi t)} y
\end{align*}
can be reduced (with substitution $y_1 = y, y_2 = y^\prime, y_3 = y^{\prime\prime}$) to 
\begin{align*}
    y_1^\prime & = y_2 \\
    y_2^\prime & = y_3 \\
    y_2^\prime & = \sin(t) y_2 + 2y_1 - 4 \\
    y_3^\prime & = e^t y_3 - 2\sin{(4\pi t)} y_1
\end{align*}
Note that even though this system consists of first-order equations, it cannot be put simply into vector form since there are two equations involving $y_2^\prime$. We can attempt to solve the system excluding $y_2^\prime = y_3$
\end{example}

\begin{theorem}[Existence, Uniqueness of Solutions in a System of First-Order DEQs]
Given the system of first-order DEQs 
\[y^\prime = f(t, y)\]
Let the partial derivatives of $f: \mathbb{R} \times \mathbb{R}^n \longrightarrow \mathbb{R}^n$
\[\frac{\partial f}{\partial y_k}, \;\; k = 1, 2, \ldots, n\]
be continuous in $D$. That is, for a given $t = t_0$, the phase velocity vector field $f(t_0, \cdot): \mathbb{R}^n \longrightarrow \mathbb{R}^n$ is $C^1$. Then, given any initial point $(t_0, \eta) \in D$, there exists a unique solution $\varphi$ of the system $y^\prime = f(t, y)$ satisfying the initial condition $\varphi(t_0) = \eta$. The solution $\varphi$ exists for any interval $I$ containing $t_0$ for which the points $\big(t, \varphi(t)\big)$ lie in $D$. Furthermore, the solution $\varphi$ is continuous with respect to $t_0, t$, and $\eta$. 
\begin{center}
    \includegraphics[scale=0.25]{Continuous_w_respect_to_3_things.PNG}
\end{center}
\end{theorem}

We briefly state a useful result. 

\begin{lemma}[Gronwall Inequality]
Let $K \geq 0$ be a constant and $f, g$ be nonnegative $C^0$ functions on some interval $\alpha \leq t \leq \beta$ satisfying the inequality
\[f(t) \leq K + \int_\alpha^t f(s) g(s) \, ds \text{ for } \alpha \leq t \leq \beta\]
Then, 
\[f(t) \leq K \exp \bigg( \int_{\alpha}^t g(s) \,ds \bigg) \text{ for } \alpha \leq t \leq \beta\]
\end{lemma}

\subsection{Linear Systems of DEQs}
Remember that higher-order systems can be reduced to a system of first-order DEQs, so it makes sense to talk about a system of first-order linear DEQs. 

\begin{definition}[Linear Systems of DEQs]
The system $y^\prime = f(t, y)$ linear in the components of $y$ has the form 
\begin{align*}
    y_1^\prime & = a_{11}(t) y_1 + a_{12}(t) y_2 + \ldots + a_{1n}(t) y_n + g_1 (t) \\
    y_2^\prime & = a_{21}(t) y_1 + a_{22}(t) y_2 + \ldots + a_{2n}(t) y_n + g_2 (t) \\
    \vdots & = \vdots \\
    y_n^\prime & = a_{n1}(t) y_1 + a_{n2}(t) y_2 + \ldots + a_{nn}(t) y_n + g_n (t)
\end{align*}
which can be represented as a matrix equation, where $A: \mathbb{R} \longrightarrow \text{Mat}(n \times n, \mathbb{R}), g: \mathbb{R} \longrightarrow \mathbb{R}^n$. 
\[y^\prime = A(t) y + g(t) \iff \begin{pmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{pmatrix}^\prime = \begin{pmatrix}
a_{11}(t) & a_{12} (t) & \ldots & a_{1n}(t) \\
a_{21}(t) & a_{22} (t) & \ldots & a_{2n}(t) \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1}(t) & a_{n2} (t) & \ldots & a_{nn}(t) 
\end{pmatrix} \begin{pmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{pmatrix} + \begin{pmatrix}
g_1 (t) \\ g_2 (t) \\ \vdots \\ g_n (t) 
\end{pmatrix}\]
\end{definition}

It is actually true that there exists a unique solution to this linear system as long as $\eta$ is finite. This is formalized in the theorem below. 

\begin{theorem}[Existence of Unique Solutions of Linear Systems]
Let matrix-valued function $A(t)$ and vector valued function $g(t)$ be continuous on some interval $a \leq t \leq b$. Then, if $a\leq t_0 \leq b$ and if $|\eta| < \infty$, the system of linear DEQs
\[y^\prime = A(t) y + g(t)\]
has a unique solution $y = \varphi(t)$ satisfying initial condition $\varphi(t_0) = \eta$ and existing on the interval $a \leq t \leq b$. 
\end{theorem}

\subsubsection{Homogeneous Linear Systems of DEQs}

Note that a first-order homogeneous linear system is of form 
\[y^\prime = A(t) y\]
Note that the scalar analogue of a homogeneous first-order linear DEQ can be changed to the above form as such 
\begin{align*}
    a_0 (t) y^\prime + a_1 (t) y = 0 & \implies a_0 (t) y^\prime = - a_1 (t) y \\
    & \implies y^\prime = -\frac{a_1 (t)}{a_0 (t)} y
\end{align*}
where we treat $y, y^\prime$ as $1$-dimensional vectors, and $-a_1(t)/a_0 (t)$ as a $1 \times 1$ matrix. 

Just as in the scalar case, the solutions to the linear system forms a vector space. 

\begin{theorem}[Fundamental Set of Solutions]
Given the first-order linear homogeneous system 
\[y^\prime = A(t) y\]
with $A: \mathbb{R} \longrightarrow \text{Mat}(n \times n, \mathbb{C})$ being continuous over interval $I \subset \mathbb{R}$, the solutions of this system over $I$ form an $n$-dimensional subspace within $C^1(\mathbb{R}, \mathbb{C}^n)$, the space of all continuously differentiable functions mapping $\mathbb{R} \longrightarrow \mathbb{C}^n$. The basis of this space is called the \textit{fundamental set of solutions}. 
\end{theorem}
\begin{proof}
We can rearrange the system as 
\begin{align*}
    -y_1^\prime + a_{11}(t) y_1 + a_{12}(t) y_2 + \ldots + a_{1n}(t) y_n = 0 \\
    -y_2^\prime + a_{21}(t) y_1 + a_{22}(t) y_2 + \ldots + a_{2n}(t) y_n = 0 \\
    \vdots = \vdots \\
    -y_n^\prime + a_{n1}(t) y_1 + a_{n2}(t) y_2 + \ldots + a_{nn}(t) y_n = 0 
\end{align*}
and put it into matrix form
\[\begin{pmatrix}
a_{11}(t) & \ldots & a_{1n} (t) & -1 & \ldots & 0 \\
\vdots & \ddots &\vdots (t) & \vdots & \ddots& \vdots \\
a_{n1}(t) & \ldots & a_{nn} (t) & 0 & \ldots & -1 
\end{pmatrix} \begin{pmatrix}y_1  \\ \vdots \\ y_n \\ y_1^\prime \\ \vdots \\ y_n^\prime \end{pmatrix} = 0\]
The kernel of this linear mapping has dimension $n$. 
\end{proof}

\begin{example}[4th Order DEQ into System of 1st-Order DEQs in Matrix Form]
We can write the following homogeneous 4th order differential equation 
\[y^{(4)} + 3 y^{\prime\prime} - \sin{(t)} y^\prime + 8y = t^2, \;\; y(0) = 1, y^\prime (0) = 2, y^{\prime\prime} (0) = 3, y^{(3)} (0) = 4 \]
into the system by making the substitutions 
\begin{align*}
    & x_1 = y \implies x_1^\prime = y^\prime = x_2 \\
    & x_2 = y^\prime \implies x_2^\prime = y^{\prime\prime} = x_3 \\
    & x_3 = y^{\prime\prime} \implies x_3^\prime = y^{(3)} = x_4 \\
    & x_4 = y^{(3)} \implies x_4^\prime = y^{(4)} = -8y + \sin{(t)} y^\prime - 3y^{\prime\prime} + t^2 = -8x_1 + \sin{(t)} x_2 - 3x_3 + t^2
\end{align*}
which leads to the matrix equation
\[x^\prime =  \begin{pmatrix} 
0&1&0&0\\
0&0&1&0\\
0&0&0&1\\
-8&\sin(t)&-3&0
\end{pmatrix} x
+ \begin{pmatrix} 
0\\0\\0\\t^2
\end{pmatrix}, x (0) = \begin{pmatrix} 
1\\2\\3\\4
\end{pmatrix}\]
\end{example}

\begin{definition}[Solution Matrix, Fundamental Matrix]
Given that $\varphi_1, \varphi_2, \ldots, \varphi_n: \mathbb{R} \longrightarrow \mathbb{R}^n$ are $n$ solutions to the homogeneous matrix differential equation $y^\prime = A(t) y$, the $n \times n$ matrix whose columns are solutions is called a \textit{solution matrix}.

Then $n \times n$ matrix with its columns being the $n$ linearly independent solutions on $I$ is called the \textit{fundamental matrix}. 
\[\Phi = \begin{pmatrix}
| & | & \ldots & | \\
\phi_1 & \phi_2 & \ldots & \phi_n \\
| & | & \ldots & |
\end{pmatrix} = \begin{pmatrix}
\phi_{11}(t) & \phi_{21} (t) & \ldots & \phi_{n1} (t) \\
\phi_{12} (t) & \phi_{22} (t) & \ddots & \phi_{n2} (t) \\
\vdots & \vdots & \ddots & \vdots \\
\phi_{1n} (t) & \phi_{2n} (t) & \ldots & \phi_{nn} (t)
\end{pmatrix}\]
Note that a fundamental matrix is not unique (that is, two different fundamental matrices $\Phi, \Tilde{\Phi}$ can exist), but since the column space of $\Phi$ and $\Tilde{\Phi}$ are the same, we can change any fundamental matrix into another with a linear change of basis. That is, given the passive transformation matrix $P$, 
\[\Phi = P^{-1} \Tilde{\Phi} P\]
Furthermore, the fundamental matrix $\Phi (t)$ has the property that any solution of the matrix DEQ can be expressed as a linear combination of the column space of $\Phi(t)$. That is, every solution $\psi (t)$ can be constructed as
\[\psi (t) = \Phi (t) c, \;\;\; c = \begin{pmatrix} 
c_1 \\ \vdots \\ c_n \end{pmatrix} \]
\end{definition}

\begin{theorem}[Abel's Formula]
If $\Phi$ is a solution matrix of $y^\prime = A(t) y$ on $I$ and if $t_0$ is any point of $I$, then 
\[\det{\Phi(t)} = \det{\Phi(t_0)} \exp\bigg( \int_{t_0}^t \sum_{j=1}^n a_{jj} (s) \, ds\bigg) \text{ for every } t \in I\]
It immediately follows that since $t_0$ is arbitrary, either 
\begin{enumerate}
    \item $\det{\Phi(t)} \neq 0$ for each $t \in I$, or 
    \item $\det{\Phi(t)} = 0$ for every $t \in I$ 
\end{enumerate}
\end{theorem}

\begin{corollary}
A solution matrix $\Phi$ of the matrix equation 
\[y^\prime = A(t) y\]
on interval $I$ is a fundamental matrix if and only if 
\[\det{\Phi(t)} \neq 0 \text{ for every } t \in I\]
Practically, this means that to test whether a solution matrix is a fundamental matrix, it suffices to evaluate its determinant at one point! 
\end{corollary}

Note that this corollary has a very close relationship with the previously mentioned theorem on how the Wronskian is used to determine the linear independence of solutions to a linear DEQ $\mathcal{L}_n (y) = 0$. More specifically, if we take a $n$th order linear DEQ satisfying the hypothesis of the Wronskian theorem, we can change it to a system of first-order linear equations and apply the previous corollary to determine linear independence of solutions. Both approaches are exactly the same. 

\subsubsection{Linear Inhomogeneous Systems}
It is obvious that due to the \textit{forcing term} $g(t)$ (representing the external force on the system), the form of solution of the inhomogeneous system 
\[y^\prime = A(t) y + g(t)\]
is 
\[\varphi(t) = \psi(t) + \Phi(t) c\]
where $\psi$ is a special solution to the DEQ over interval $I$. Since we know how to find the fundamental matrix $\Phi$, all it remains is to find $\psi$. We can do this using the multivariate variation of constants formula. 

For notational purposes, we write for vector valued functions $f: \mathbb{R} \longrightarrow \mathbb{R}^n$, where $f_1, f_2, \ldots, f_n$ are the basis functions, 
\[\int_a^b f(x)\,ds = \begin{pmatrix}
\int_a^b f_1 (x)\,ds \\ \vdots \\ \int_a^b f_n(x)\,ds
\end{pmatrix}\]

\begin{theorem}[Multivariate Variation of Constants Formula]
Given the inhomogeneous first-order linear system 
\[y^\prime = A(t) y + g(t)\]
if $\Phi$ is the fundamental matrix of its homogeneous counterpart $y^\prime = A(t) y$ on interval $I \subset \mathbb{R}$, then the special function given by the variation of constants formula 
\[\psi (t) = \Phi (t) \int_{t_0}^t \Phi^{-1} (s) g(s) \,ds\]
is the unique solution of the original DEQ satisfying the initial condition on $I$
\[\psi (t_0) = 0\]
(Notice that $\Phi^{-1}$ is always well defined since $\Phi$ is nonsingular) This means that every solution $\phi$ of the DEQ has the form 
\[\phi(t) = \psi (t) + \phi_h (t)\]
where $\varphi_h$ is the solution of the homogeneous system satisfying the same initial condition at $t_0$ as $\varphi$ (e.g. $\varphi_h (t_0) = \eta$). This makes it such that the initial conditions are met: 
\[\varphi(t_0) = \psi(t_0) + \varphi_h (t_0) = 0 + \eta = \eta\]
\end{theorem}

\subsection{Linear Systems with Constant Coefficients}
If the homogeneous system 
\[y^\prime = A(t) y\]
has constant coefficients (i.e. $A$ consists of constant terms), then we can obtain an explicit formula of the fundamental matrix. 

Also, to reduce confusion, 
\begin{enumerate}
    \item $Ax$ will be used to denote matrix $A$ multiplied by vector $x$
    \item $xA$ will be used to denote scalar $x$ multiplied to matrix $A$ (row vector multiplication will not be seen in this section)
\end{enumerate}

\begin{theorem}[Fundamental Matrix of a Linear System with Constant Coefficients]
Given the system of $n$ linear equations 
\[y^\prime = A y, \;\;\;\;\; A \in \text{Mat}(n \times n, \mathbb{C})\]
the matrix
\[\Phi(t) = e^{(t-t_0)A} = \sum_{m=0}^\infty \frac{((t-t_0)A)^m}{m!}\]
is the fundamental matrix with $\Phi(t_0) = I$ on $(-\infty, \infty)$. 
\end{theorem}
\begin{proof}
$\Phi(t_0) = I$ is obvious from substitution. Assuming $t_0 = 0$, we differentiate $At: \mathbb{R} \longrightarrow \text{Mat}(n \times n, \mathbb{R})$ with respect to $t$ to get
\[\big( e^{tA} \big)^\prime = A + \frac{tA^2} {1!} + \frac{t^2 A^3}{2!} + \ldots + \frac{t^{k-1} A^{k}}{(k-1)!} + \ldots = A e^{tA}\]
This means that given any constant vector $c \in \mathbb{R}^n$, we have
\[\big( e^{tA} \big)^\prime c = A e^{tA} c \implies \big( e^{tA} c\big)^\prime = A (e^{tA} c)\]
and so $e^{tA}$ is a solution matrix. Furthermore, since $\det{ \Phi(0)} = \det{I} = 1$, it is a fundamental matrix (by the corollary to Abel's formula). 
\end{proof}

Note that given an arbitrary matrix $A$, it is stupid to calculate $e^{A}$ explicitly. Rather, we can use a change of basis to put it into Jordan Canonical Form $J$. 
\[A = P^{-1} J P\]
Then, it is clear that
\[e^A = e^{P^{-1} J P} = P^{-1} e^J P\]
Finding the eigendecomposition of a linear mapping, which may require working over the field $\mathbb{C}$ (or by introducing generalized eigenvectors over $\mathbb{R}$). This entire process is talked in detail in the linear algebra chapter. 

Another trick that may work in some cases is the following lemma. 

\begin{lemma}
If two $n \times n$ matrices commute, then
\[e^{M} \cdot e^{P} = e^{M + P} \]
\end{lemma}
\begin{proof}
Trivial using the Baker-Campbell-Hausdorff formula. 
\end{proof}

Finally, we mentioned a greatly simplified variation of constants formula for the case when we solve a inhomogeneous system of linear DEQs with constant coefficients. 

\begin{corollary}[Multivariate Variation of Constants Formula for Constant Coefficient Systems]
Given inhomogeneous system of $N$ linear DEQs 
\[y^\prime = A y + g(t), \;\;\;\;\; A \in \text{Mat}(n \times n, \mathbb{R}), g \in C^0\]
with initial conditions $\varphi(t_0) = \eta$, then a specific solution of the system is 
\[\psi (t) = \int_{t_0}^t e^{(t-s)A} g(s) \,ds , \text{ where } \psi(t_0) = 0\]
meaning that the general solution to this equation is 
\[\varphi(t) = e^{(t - t_0)A} \eta + \int_{t_0}^t e^{(t-s)A} g(s) \,ds \;\;\;\;\; -\infty < t< \infty\]
where $\varphi(t_0) = \eta$. 
\end{corollary}

\begin{example}
Given the initial value problem 
\[y^\prime = Ay + g(t) \iff \begin{pmatrix} y_1 ^\prime \\ y_2^\prime \end{pmatrix} = \begin{pmatrix} 2 & 1 \\ -1 & 4 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} + \begin{pmatrix} e^{3t} \\ 1 \end{pmatrix}, \;\;\; \varphi(0) = \eta\]
Then, we have
\begin{align*}
    \Phi(t) & = e^{tA} = e^{3t} \begin{pmatrix} 1-t & t \\ -t & 1+t \end{pmatrix} \\
    \Phi(t) \Phi^{-1} (s) & = e^{(t-s)A} = e^{3(t-s)} \begin{pmatrix} 1 - (t-s) & t-s \\ -(t-s) & 1+(t-s) \end{pmatrix} \\
    e^{(t-s)A} g(s) & = e^{3t} \begin{pmatrix}
    1-(t-s)+e^{-3s}(t-s) \\ -(t-s) + e^{-3s} (1+t-s)\end{pmatrix}
\end{align*}
Therefore, 
\[\varphi(t) = e^{3t} \begin{pmatrix} 1-t & t \\ -t & 1+t \end{pmatrix} \eta + e^{3t} \int_{0}^t \begin{pmatrix} 1-(t-s) + e^{-3s} (t-s) \\
-(t-s) + e^{-3s}(1+t-s) \end{pmatrix} \,ds\]
which can be easily evaluated. 
\end{example}

\subsubsection{Asymptotic Behavior of Solutions}
In many cases, in order to apply the variation of constants formula 
\[\varphi(t) = e^{(t - t_0)A} \eta + \int_{t_0}^t e^{(t-s)A} g(s) \,ds \;\;\;\;\; -\infty < t< \infty\]
and others derived from it, we must know how the matrix $e^{tA}$ behaves. For example, in order to measure the growth of solutions of as $t \rightarrow \infty$, we need to estimate 
\[\lim_{t\rightarrow \infty} \varphi(t)\]
where $|\cdot|$ is the L-1 norm. But this cannot be done without knowing a useful estimate of $|e^{tA}|$. 

\begin{theorem}
Given $\lambda_1, \lambda_2, \ldots, \lambda_k$ are distinct eigenvalues of $A$, where $\lambda_j$ has multiplicity $n_j$ and $n_1 + \ldots + n_k = n$, let $\rho$ be any real number such that 
\[\rho > \max_{j=1, \ldots, k} \big( \text{Re}(\lambda_i)\big)\]
Then, there exists a constant $K > 0$ such that
\[|e^{tA}| \leq K e^{t \rho} \text{ for } 0 \leq t < \infty\]
\end{theorem}

Its applications really lies within its corollary. 

\begin{corollary}
If all eigenvalues of $A$ have real parts negative, then every solution $\varphi(t)$ of the system
\[y^\prime = A y\]
approaches $0$ as $t \rightarrow + \infty$. More precisely, there exists constants $\Tilde{K} > 0$, $\sigma > 0$ such that
\[|\varphi(t)|< \Tilde{K} e^{-\sigma t}, \;\;\; (0 \leq t < \infty)\]
\end{corollary}

\begin{theorem}[Upper Bound on Growth Rate of Solutions of Nonhomogeneous Linear System with Constant Coefficients]
Suppose that in the linear inhomogeneous system 
\[y^\prime = A y + g(t)\]
the function $g(t)$ grows no faster than an exponential function; that is, there exists real constants $M > 0, T \geq 0$, and $a \in \mathbb{R}$ such that
\[|g(t)| \leq M e^{at} \text{ for all } t \geq T\]
Then, every solution $\varphi$ of the system grows no faster than an exponential function. That is, there exists real constants $K>0, b$ such that
\[|\varphi(t)| \leq K e^{bt} \text{ for all } t \geq T\]
The derivative $\varphi^\prime (t)$ also grows no faster than an exponential function. 
\end{theorem}

\section{Laplace Transforms}
Laplace transforms extends our toolkit for solving linear differential equations (and systems of them) by reducing an initial value problem into an algebra problem, which can be summarized by the diagram below, where $\mathcal{L}$ represents the transform. 
\[
  \begin{tikzcd}
    \text{Algebra Problem} \arrow{r}{solution} &  Y(t)\\
    \text{DEQ Problem} \arrow{u}{\mathcal{L}} \arrow{r}{solution} & y = \varphi(t) \arrow{u}{\mathcal{L}}
  \end{tikzcd}
\]
Laplace transforms also allows us to work with piecewise continuous functions. 

The method of Laplace Transforms does not actually allow us to solve new types of differential equations. Rather, it is useful because it enables us to find one particular solution of the differential equation which satisfies the initial conditions directly, rather than first finding the general solution and then using the initial conditions to determine constants. 

\begin{definition}[Functions of exponential growth at infinity]
A function on $0 < t < \infty$ is said to be \textit{of exponential growth at infinity} if it satisfies
\[|f(t)| \leq M e^{ct}\]
for some real constants $M>0$ and $c$, for all sufficiently large $t$. 
\end{definition}

\begin{definition}[Function Class $\Lambda$]
The \textit{class $\Lambda$} of functions is defined as those functions on $0<t<\infty$ which are
\begin{enumerate}
    \item absolutely integrable on $0$ 
    \item piecewise continuous on $(0, \infty)$
    \item of exponential growth at infinity
\end{enumerate}
Clearly, the functions $1, t, t^n (n \in \mathbb{N}), \sin{t}, \cos{t}, e^{zt} (z \in \mathbb{C})$ are in class $\Lambda$, but $e^{t^2} \not\in \Lambda$. 
\end{definition}

\begin{definition}[Laplace Transform]
Let $f \in \Lambda$. The \textit{Laplace transform} of $f$ is denoted $\mathcal{L}\{f(t)\}$ or $F(t)$, defined
\[F(s) \equiv \int_0^\infty f(t)e^{-s t} \, dt = \lim_{A \rightarrow \infty} f(t) e^{-st}\,dt \]
Sometimes, the Laplace transform may be defined by setting the lower limit to $- \infty$. 
\[F(t) \equiv \int_{-\infty}^\infty f(t) e^{-s t}\,dt\]
\end{definition}

\begin{example}
The Laplace transformation of constant function $1$ is 
\[\int_0^\infty e^{-st}\,dt = \lim_{A \rightarrow \infty} \int_0^A e^{-st} \,dt = \lim_{A \rightarrow \infty} \bigg( \frac{1}{s} - \frac{e^{-sA}}{s} \bigg) = \frac{1}{s}\;\;\;\; (\text{Re}(s) > 0)\]
Clearly, the integral does not converge for Re$(s) \leq 0$. The Laplace transform of $e^{zt}$ is
\[\mathcal{L} (e^{zt}) = \frac{1}{s-z} \;\;\;\; (\text{Re}(s)> \text{Re}(z))\]
\end{example}

From the examples before and our notation of the transform, we can see and prove the following. 

\begin{proposition}[Linearity of the Laplace Transform]
The Laplace transform is a linear map with respect to its function argument. That is, 
\[\mathcal{L} \{a f + b g\} = a \mathcal{L}\{f\} + b \mathcal{L}\{g\}\]
This means that if $f: \mathbb{R} \longrightarrow \mathbb{C}$ is a complex-valued function
\[f(t) = u(t) + i v(t)\]
Then, 
\[\mathcal{L}\big(f(t)\big) = \mathcal{L}\big(u(t) + i v(t) \big) = \mathcal{L} \big( u(t) \big) + i \mathcal{L} \big( v(t)\big)\]
That is, 
\[\text{Re}\big((\mathcal{L}(f(t))\big) = \mathcal{L}( \text{Re}(f(t))), \text{Com}\big((\mathcal{L}(f(t))\big) = \mathcal{L}( \text{Com}(f(t)))\]
\end{proposition}


\subsubsection{Common Laplace Transforms}
\begin{example}
Given $z = \alpha + i \beta \in \mathbb{C}$, with $\alpha, \beta \in \mathbb{R}$, and $f(t) = e^{zt}$, we have
\begin{align*}
    \mathcal{L} (e^{zt}) & = \mathcal{L} (e^{\alpha t} e^{i \beta t}) = \mathcal{L} \big( e^{\alpha t} \cos{\beta t} + i e^{\alpha t} \sin{\beta t}\big) \\
    & = \frac{1}{s-z} = \frac{1}{z - \alpha - i \beta} \\
    & = \frac{s - \alpha + i \beta}{(s-\alpha)^2 + \beta^2}
\end{align*}
By linearity, we can take the real and complex parts of this transform to get
\begin{align}
    \mathcal{L} \big(e^{\alpha t} \cos{\beta t} \big) & = \frac{s-\alpha}{(s-\alpha)^2 + \beta^2} \\
    \mathcal{L} \big(e^{\alpha t} \sin{\beta t} \big) & = \frac{\beta}{(s-\alpha)^2 + \beta^2}
\end{align}
Taking $\alpha = 0$ gives us
\[\mathcal{L} \big( \cos{\beta t}\big) = \frac{s}{s^2 + \beta^2}, \;\;\; \mathcal{L}\big( \sin{\beta t}\big) = \frac{\beta}{s^2 + \beta^2} \;\;\; \text{Re}(s) > 0\]
\end{example}

To compute the Laplace transforms functions of some other forms, we can use the following theorem. 

\begin{theorem}
The Laplace transform of a function $f$ in the class $\Lambda$ has derivatives of all orders, given by
\[F^{(k)} (s) = (-1)^k \int_0^\infty t^k e^{-st} f(t)\,dt, \;\;\;\; k = 1, 2, \ldots\]
Furthermore, $f(t) \in \Lambda \implies t^k f(t) \in \Lambda$ for every positive integer $k$, and its Laplace transform is given by
\[\mathcal{L}\big( t^k f(t) \big) = (-1)\]
\end{theorem}

\begin{corollary}
It follows immediately that
\begin{align*}
    \mathcal{L}\big( t^k\big) & = (-1)^k \frac{d^k}{d s^k} \bigg( \frac{1}{s} \bigg) = \frac{k!}{s^{k+1}} \;\;\; (\text{Re}(s) > 0) \\
    \mathcal{L}\big( t^k e^{zt}\big) & = (-1)^k \frac{d^k}{ds^k} \bigg( \frac{1}{s-z} \bigg) = \frac{k!}{(s-z)^{k+1}} \;\;\; (\text{Re}(s) > \text{Re}(z))
\end{align*}
\end{corollary}

Another theorem for computing Laplace transforms. 

\begin{theorem}
If the function $f \in \Lambda$ has a Laplace transform $F$, then for any constant $a \in \mathbb{C}$, 
\[\mathcal{L}\big(e^{at} f(t) \big) = F(s-a)\]
\end{theorem}
\begin{proof}
It is easy to prove that $e^{at} f(t) \in \Lambda$, since 
\[|f(t)| \leq M e^{ct} \implies |e^{at} f(t)| \leq e^{\alpha t} M e^{ct} = M e^{(a+c)t}\]
and thus $e^{at} f(t)$ is of exponential growth at infinity. Calculating the Laplace transform, we get
\[\mathcal{L}\big(e^{at} f(t) \big) = \int_0^\infty e^{-st} e^{at} f(t) \,dt = \int_0^\infty e^{-(s-a)t} f(t) \,dt = F(s - a)\]
\end{proof}

We conclude this subsection by providing a table of common Laplace transforms. 

\begin{theorem}[Table of Common Laplace Transforms]
Here we have some common transforms, where $a \in \mathbb{R}$ is a constant. Note that the gamma function
\[\Gamma(t) \equiv \int_{0}^\infty e^{-x} \, x^{t-1}\,dx\]
is an extension of the factorial function to the real numbers. 
\begin{enumerate}
    \item $f(t) = e^{a t} \implies F(t) = \frac{1}{s-a}$
    \item $f(t) = t^n, n \in \mathbb{N} \implies F(t) = \frac{n!}{s^{n+1}}$
    \item $f(t) = t^p, p > -1 \implies F(t) = \frac{\Gamma(p+1)}{t^{p+1}}$
    \item $f(t) = \sin(at) \implies F(t) = \frac{a}{t^2 + a^2}$
    \item $f(t) = \cos(at) \implies F(t) = \frac{t}{t^2 + a^2}$ 
    \item $f(t) = t \sin(at) \implies F(t) = \frac{2 a t}{(t^2 + a^2)^2}$
    \item $f(t) = t \cos(at) \implies F(t) = \frac{t^2 - a^2}{(s^2 + a^2)^2}$
    \item $f(t) = \sin(a t + b) \implies F(t) = \frac{t \sin(b) + a \cos(b)}{t^2 + a^2}$
    \item $f(t) = \cos(a t + b) \implies F(t) = \frac{t \cos(b) - a \sin(b)}{t^2 + a^2}$
\end{enumerate}
\end{theorem}

\subsubsection{Laplace Transforms of Derivatives}
Now that we know how to calculate Laplace transforms, we must extend this to derivatives of functions in order to integrate it within differential equations. 

\begin{lemma}
Let $f$ be a differentiable function in the class $\Lambda$ whose derivative also belongs to the class $\Lambda$, and let the Laplace transform of $f$ be $F$. Then, 
\[\mathcal{L} \big( f^\prime (t) \big) = s F(s) - f(0) \]
\end{lemma}
\begin{proof}
We use the definition of Laplace transform and integrate by parts to get 
\begin{align*}
    \mathcal{L}\big( f^\prime (t) \big) & = \int_0^\infty e^{-st} f^\prime (t) \,dt = \lim_{A \rightarrow \infty} e^{-st} f^\prime (t) \,dt \\
    & = \lim_{A\rightarrow \infty} \bigg( e^{-st} f(t) \big|_0^A + \int_0^A s e^{-st} f(t)\,dt\bigg) \\
    & = - f(0) + s\int_0^\infty e^{-st} f(t) \,dt = s F(s) - f(0)
\end{align*}
where we used the fact ($f \in \Lambda \implies f$ is of exponential growth at infinity) that 
\[\lim_{A \rightarrow \infty} e^{-sA} f(A) = 0\]
for sufficiently large Re$(s)$. 
\end{proof}

\begin{definition}[The Class $\Lambda^k$]
For each positive integer $k$, define $\Lambda^k$ to be the class of $C^k((0, \infty))$ (defined over $(0, \infty)$) functions in $\Lambda$ whose derivatives up to order $k$ also belong to $\Lambda$. That is, 
\[\Lambda^k = \{f \in C^k((0, \infty))\;|\; f, f^\prime, f^{\prime\prime}, \ldots, f^{(k)} \in \Lambda \}\]
\end{definition}

\begin{theorem}[Laplace Transform of Derivatives]
If $f \in \Lambda^k$ for some positive integer $k$, and if $F$ is the Laplace transform of $f$, then for any $1 \leq j \leq k$, 
\begin{align*}
    \mathcal{L}\big( f^{(j)} (t) \big) & = s^j F(s) - \sum_{i=1}^j s^{j-i} f^{(i-1)}(0) \\
    & = s^j F(s) - s^{j-1} f(0) - s^{j-2} f^\prime (0) - \ldots - s f^{(j-2)}(0) - f^{(j-1)} (0)
\end{align*}
\end{theorem}
\begin{proof}
Using the lemma, proof by induction on $j$ for any fixed $k$. 
\end{proof}

Note that in order to solve a differential equation using Laplace transforms, we must know the initial values $\varphi(0), \varphi^\prime (0), \ldots$ at $t = 0$ (must be at $0$!) for us to simplify the algebraic equation that is produced. This is shown in the examples. 

\begin{example}
Given the first-order differential equation with initial conditions
\[y^\prime + a y = 0, \;\;\; \varphi_0 (0) = y_0\]
where $a, y_0$ are given constants. Assuming that the solution is in the class $\Lambda^1$, we try to find this using Laplace transforms. Let $Y_0 (s) = \mathcal{L}( \varphi_0)$. Then,
\begin{align*}
    \mathcal{L}\big(\varphi_0^\prime (t) + a \varphi_0 (t)\big) & = \mathcal{L}\big(\varphi_0^\prime (t)\big) + a \mathcal{L}\big(\varphi_0 (t)\big) \\
    & = s Y_0 (s) - \varphi_0 (0) + a Y_0 (s) = 0
\end{align*}
So, 
\[(s+a) Y_0 (s) = y_0 \implies Y_0 (s) = \frac{y_0}{s+a}\]
Now the only problem remaining is to find a function whose Laplace transform is this expression. By direct verification, we can see that $\varphi_0 (t) = y_0 e^{-at}$ is indeed the solution. 
\end{example}

\begin{example}
The Laplace transform of the nonhomogeneous first-order linear DEQ 
\[y^\prime + a y= f(t), \;\;\; \varphi(0) = y_0\]
is (where $Y(s) = \mathcal{L}(\varphi)$)
\[s Y(s) - \varphi(0) + a Y(s) = F(s) \implies Y(s) = \frac{y_0}{s+a} + \frac{F(s)}{s+a}\]
Therefore, we must find a function which has this expression as its Laplace transform. By the previous example, we know that $t_0 e^{-at}$ satisfies the first term, but we have no method as yet of finding a function whose Laplace transform is 
\[\frac{F(s)}{s+a}\]
This suggests that we will need a method of finding a function whose Laplace transform is the product of two given functions $F(s)$ and $1/(s+a)$. 
\end{example}

This final example shows what would happen if we tried to take the Laplace transform of linear DEQ with nonconstant coefficients. 

\begin{example}
Taking the Laplace transform of 
\[y^\prime + 2t y = 0, \;\;\; \psi(0) = y_0\]
gives (where $\mathcal{L}(\psi) = Z(s)$) 
\[sZ(s) - \psi(0) - 2Z^\prime (s) = 0\]
While in the previous problems the equation was greatly simplified into an algebraic problem, here we have a differential equation which is no simplier than the original problem. 
\end{example}

Clearly, this example suggests that the usefulness of the Laplace transform method is limited mainly to equations with constant coefficients. 

\subsection{Heaviside Step, Dirac Delta Functions}
\begin{definition}[Heaviside Step Function]
A \textit{Heaviside (step) function}, denoted as $H$, $\mathbb{I}$, or $u$, is defined
\[H(x) \equiv \begin{cases}
0 & x < 0 \\
1  & x \geq 0
\end{cases}\]
Clearly, it can be horizontally translated $c$ units to result in the function $H(t-c) = u_c$ which is $1$ if $t \geq c$ and $0$ otherwise. 
\begin{center}
    \includegraphics[scale=0.23]{Heaviside.PNG}
\end{center}
\end{definition} 

Looking back a Heaviside step functions, we can combine them to create more complicated models. For example, we can redefine the piecewise function
\[f(t) = \begin{cases}
-4 & t < 6 \\
25 & 6 \leq t < 8 \\
16 & 8 \leq t < 30 \\
10- & t \geq 30
\end{cases}\]
in terms of Heaviside functions as such
\[f(t) = -4 + 29 u_6 (t) - 9 u_8 (t) - 6 u_{30} (t)\]
This is analogous to a "switch" that we can turn on or off. Furthermore, we can use Heaviside functions to "shift" functions horizontally a certain length $c$ while turning them "off" for values of $t < c$ and "on" for values $t \geq c$. This can be written as 
\[g(t) \equiv u_c (t) \, f(t - c)\]
To find the Laplace transform of $g(t)$, we can evaluate it as such. 
\begin{align*}
    \mathcal{L} \{u_c (t) \, f(t -c)\} & = \int_0^\infty e^{-s t} u_c (t) f(t-c) \,dt \\
    & = \int_c^\infty e^{-st} f(t-c) \,dt 
\end{align*}
Substituting $u = t - c$ gives
\begin{align*}
     \mathcal{L} \{u_c (t) \, f(t -c)\} & = \int_0^\infty e^{-s (u+c)} f(u) \,du \\
     & = e^{-cs} \int_0^\infty e^{-su} f(u)\,du \\
     & = e^{-cs} F(s)
\end{align*}
This leads to the following formulas. 
\begin{theorem}
The Laplace transforms for Heaviside functions are:
\begin{align*}
    & \mathcal{L} \{u_c (t) f(t-c)\} = e^{-ct} F(t) \\
    & \mathcal{L} \{u_c (t)\} = \frac{e^{-ct}}{t}
\end{align*}
\end{theorem}

\begin{definition}[Dirac Delta Function]
The \textit{Dirac delta function} is a generalized function or distribution that models forces exerted over small time frames. It can be thought of as a function $\delta$ satisfying the properties 
\begin{align*}
    & 1. \delta (t - a) = 0, \;\; t \neq a \\
    & 2. \int_{a-\varepsilon}^{a+\varepsilon} \delta(t-a) \,dt, \;\; \varepsilon > 0 \\
    & 3. \int_{a-\varepsilon}^{a+\varepsilon} f(t) \delta(t-a) \,dt = f(a), \;\; \varepsilon > 0
\end{align*}
Alternatively, it may be evaluated as the limit of a Gaussian distribution centered at $a$ where $\sigma \rightarrow 0$. That is, 
\[\delta(t) = \lim_{\sigma \rightarrow 0} \text{Normal}(a, \sigma^2)\]
\begin{center}
    \includegraphics[scale=0.23]{Dirac_Delta.PNG}
\end{center}
\end{definition}

To apply the Dirac delta function in Laplace transforms, we calculate
\[\mathcal{L} \{ \delta(t-a)\} = \int_0^\infty e^{-st} \delta(t-a) \,dt = e^{-as}\]
given that $a>0$. 

\begin{proposition}
More generally, we have
\[\mathcal{L}\{u_c (t) f(t-c)\} = e^{-cs} F(s)\]
where $F$ is the Laplace transform of $f$. 
\end{proposition}

\begin{lemma}
The derivative of the Heaviside function $u_a (t)$ is the Dirac delta function centered at $a$. That is, 
\[u_a^\prime (t) = \delta (t - a)\]
\end{lemma}
\begin{proof}
With a bit of background in probability, the cumulative distribution function (CDF) of the Dirac delta function is defined
\[\int_{-\infty}^t \delta(u - a)\,du = \begin{cases}
0 & t < a \\
1 & t \geq a
\end{cases}\]
But this is precisely the definition of the Heaviside function. By the fundamental theorem of calculus, we have
\[u^\prime_a (t) = \frac{d}{d t} \int_{-\infty}^t \delta(u-a)\, du = \delta(t-a)\]
\end{proof}

\subsection{Inverse Laplace Transform}

\begin{definition}[Inverse Laplace Transform]
The \textit{Inverse Laplace transform} is the inverse of a Laplace transform. That is, 
\[\mathcal{L}\big( f(t)\big) = F(s) \implies  \mathcal{L}^{-1} \big(F(s)\big) = f(t)\]
\end{definition}

Now, as we have mentioned in the previous examples, we would like to derive a certain method to find the inverse transform of a function. 

\begin{theorem}[Inverse Laplace Transforms of Products of Functions]
We assume that we are given two functions $f(t), g(t)$, with their Laplace transforms $\mathcal{f} = F(s), \mathcal{g} = G(s)$. Then, 
\[\mathcal{L}\bigg(\int_0^t f(t-v) g(v)\,dv \bigg) = F(s)G(s)\]
That is, given the function $F(s) G(s)$ (with their respective inverse transforms known), its inverse Laplace transform is
\[\mathcal{L}^{-1} \big( F(s) G(s)\big) = \int_0^t f(t-v) g(v)\,dv\]
given by the convolution integral of $f$ and $g$. 
\end{theorem}
\begin{proof}
We let $H(s) = F(s) G(s)$ and try to find the function $h(t)$ where $\mathcal{L}(h) = H(s)$. If there is such as function $h$, then 
\begin{align*}
    \mathcal{L}\big(h(t)\big) & = \int_0^\infty e^{-st} h(t)\,dt \\
    & = F(s) G(s) = \int_0^\infty e^{-su} f(u) \,du \int_0^\infty e^{-sv} g(v)\,dv
\end{align*}
where Re$(s)>\sigma = \max{(\alpha, \beta)}$, where $F(s) = \mathcal{L}(f)$ for Re$(s)>\alpha$ and $G(s) = \mathcal{L}(g)$ for Re$(s)>\beta$ ($\alpha, \beta \in \mathbb{R}$). Since each integral converges absolutely for Re$(s) > \sigma$, we can write the product of the two integrals as the iterated integral (using Fubini's theorem) 
\begin{align*}
    \int_0^\infty e^{-st} h(t) \,dt & = \int_0^\infty \int_0^\infty e^{-s(u+v)} f(u) g(v)\,du \,dv \\
    & = \int_0^\infty g(v) \bigg(\int_0^\infty e^{-s(u+v)} f(u)\,du\bigg)\,dv \\
    & = \int_0^\infty g(v) \bigg( \int_0^\infty e^{-st} f(t-v) \,dt \bigg)\,dv \\
    & = \int_0^\infty e^{-st} \bigg( \int_0^t f(t-v) g(v)\,dv \bigg) \,dt
\end{align*}
where the second to last step was done by making the change of variable $u+v = t$ for Re$(s) > \sigma$. Therefore, 
\begin{align*}
    F(s) G(s) & = \int_0^\infty e^{-st} h(t) \,dt = \int_0^\infty e^{-st} \bigg( \int_0^t f(t-v) g(v)\,dv \bigg) \,dt \\
    \implies & h(t) = \int_0^t f(t-v) g(v)\,dv
\end{align*}
\end{proof}

\begin{proposition}
$\mathcal{L}$ is a linear operator. 
\[\mathcal{L}^{-1} \{ a F + b G\} = a \mathcal{L}^{-1} \{F\} + b \mathcal{L}^{-1} \{G\}\]
\end{proposition}

\begin{corollary}
The only function in the class $\Lambda$ whose Laplace transform is identically $0$ is the zero function. 
\end{corollary}

\begin{example}
We compute 
\[\mathcal{L}^{-1} \bigg( \frac{1}{s^2 -1}\bigg) =\mathcal{L}^{-1} \bigg( \frac{1}{(s+1)(s-1)}\bigg)\]
Since 
\[\mathcal{L}^{-1} \bigg(\frac{1}{s-1}\bigg) = e^t, \; \mathcal{L}^{-1}\bigg(\frac{1}{s+1}\bigg) = e^{-t}\]
we have
\[\mathcal{L}^{-1} \bigg(\frac{1}{(s+1)(s-1)}\bigg) = \int_0^t e^{t-u} e^{-u} \,du = e^t \int_0^t e^{-2u} \,du = \frac{1}{2} \big(e^t - e^{-t}\big)\]
We can also compute it using partial fraction decomposition and by using the linearity of $\mathcal{L}^{-1}$. 
\begin{align*}
    \mathcal{L}^{-1} \bigg( \frac{1}{s^2-1}\bigg) & = \frac{1}{2} \Bigg( \mathcal{L}^{-1} \bigg( \frac{1}{s-1} \bigg) - \mathcal{L}^{-1} \bigg(\frac{1}{s+1}\bigg) \Bigg) \\
    & = \frac{1}{2} \big( e^t - e^{-t} \big) 
\end{align*}
\end{example}

\begin{example}
We compute 
\[\mathcal{L}^{-1} \bigg( \frac{1}{s^2(s^2 + 1)}\bigg)\]
we know that
\[\mathcal{L}^{-1} \bigg(\frac{1}{s^2}\bigg) = t, \;\; \mathcal{L}^{-1} \bigg( \frac{1}{s^2+1}\bigg) = \sin{t}\]
So,
\[\mathcal{L}^{-1} \bigg( \frac{1}{s^2 (s^2+1)}\bigg) = \int_0^t (t-u) \sin{u} \,du = t \int_0^t \sin{u}\,du - \int_0^t u \sin{u}\,du = t - \sin{t}\]
Using partial fractions, we have
\[\mathcal{L}^{-1} \bigg(\frac{1}{s^2(s^2 + 1)} \bigg) = \mathcal{L}^{-1} \bigg( \frac{1}{s^2} \bigg) - \mathcal{L}^{-1} \bigg(\frac{1}{s^2 + 1} \bigg) = t - \sin{t}\]
\end{example}

\begin{example}
Here is an example where we use only partial fractions. Since
\[G(s) = \frac{86 s - 78}{(s+3) (s - 4) (5s - 1)} = -\frac{3}{s+3} + \frac{2}{s-4} + \frac{5}{5s-1}\]
we have 
\begin{align*}
    \mathcal{L}^{-1} \{G(s)\} & = \mathcal{L}^{-1} \{-\frac{3}{s+3} + \frac{2}{s-4} + \frac{5}{5s-1}\} \\
    & = -3 e^{-3t} + 2 e^{4 t} + e^{t/5}
\end{align*}
\end{example}

Therefore, for rational functions of the form 
\[\frac{N(s)}{D(s)}\]
where $N, D$ are polynomials with the degree of $N$ less than the degree of $D$, we can take advantage of partial fractions to compute its inverse Laplace transform. 

\begin{example}
Solve the following differential equation. 
\[2 y^{\prime\prime} + 3 y^\prime - 2y = t e^{-2t}, \;\; y(0) = 0, y^\prime (0) = -2\]
We take the Laplace transforms of all the terms in the differential equation to get
\[2\big( t^2 Y(t) - t y(0) - y^\prime (0)\big) + 3 \big( t Y(t) - y(0)\big) - 2 Y(t) = \frac{1}{(t+2)^2}\]
which, after simplification, gives
\[(2t^2 + 3t - 2) Y(t) + 4 = \frac{1}{(t+2)^2}\]
Solving for $Y$, we get
\begin{align*}
    Y(t) & = \frac{1}{(2t-1)(t+2)^3} - \frac{4}{(2t-1)(t+2)} \\
    & = \frac{1}{125} \bigg(\frac{-96}{s-\frac{1}{2}} + \frac{96}{s+2} - \frac{10}{(s+2)^2} - \frac{25}{(s+2)^3} \bigg)
\end{align*}
The inverse transform of this gives 
\[y(t) = \frac{1}{125} \Big( -96 e^{\frac{t}{2}} + 96 e^{-2t} - 10t e^{-2t} - \frac{25}{2} t^2 e^{-2t}\Big) \]
\end{example}

We now deal with Heaviside functions in this next example. 
\begin{example}
Solve the following initial value problem. 
\[2 y^{\prime\prime} + 10 y = 3 u_{12} (t) - 5 \delta(t - 4), \;\; y(0) = -1, y^\prime (0) = -2\]
We take the Laplace transform 
\begin{align*}
    & 2 \big( t^2 Y(t) - t y(0) - y^\prime (0) \big) + 10 Y(t) = \frac{3 e^{-12t}}{t} - 5 e^{-4 t} \\
    \implies & (2 t^2 + 10) Y(t) + 2t + 4 = \frac{3 e^{-12t}}{t} - 5 e^{-4t}
\end{align*}
and solve for $Y$
\begin{align*}
    Y(t) & = 3 e^{-12t} \bigg(\frac{1}{t (2t^2 + 10)} \bigg) - 5e^{-4t} \bigg(\frac{1}{2t^2 + 10} \bigg) - \frac{2t+4}{2t^2 + 10} \\
    & = 3 e^{-12t} \bigg(\frac{1}{10t} - \frac{1}{10(t^2+5)} \bigg) - 5e^{-4t} \bigg(\frac{1}{2t^2 + 10} \bigg) - \frac{2t+4}{2t^2 + 10} \\
    & = 3 e^{-12t} F(t) - 5 e^{-4t} G(t) - H(t)
\end{align*}
Using the rules for inverse transforming Dirac delta functions, we can get
\[y (t) = 3 u_{12} (t) f(t-12) - 5 u_4 (t) g(t-4) - h(t)\]
where 
\begin{align*}
    & f(t) = \frac{1}{10} - \frac{1}{10} \cos{(\sqrt{5} t)} \\
    & g(t) = \frac{1}{2 \sqrt{5}} \sin{(\sqrt{5}t} \\
    & h(t) = \cos{(\sqrt{5}t)} + \frac{2}{\sqrt{5}} \sin{(\sqrt{5}t}
\end{align*}
\end{example}

In general, the best tool for systematically solving inverse Laplace transforms is a table, experience, and luck. 

Finally, we conclude by saying that not every type of function is necessarily the Laplace transform of some other function. For example, this theorem: 

\begin{theorem}
If $f$ belongs to the class $\Lambda$ and if $F(s)$ is its Laplace transform, then 
\[\lim_{\text{Re}(s) \rightarrow\infty} F(s) = 0\]
Furthermore, not only does $F(s) \rightarrow 0$ as $s \rightarrow \infty$, but in fact $|s F(s)|$ remains bounded as Re$(s) \rightarrow \infty$. Clearly, not all functions have this property. 
\end{theorem}
\begin{proof}
Since $f \in \Lambda$, it is of exponential growth at infinity, meaning $|f(t)| \leq Me^{ct}$ for some $M>0, c$ and sufficiently large $t$. This means that
\begin{align*}
    |F(s)| & \leq M \int_0^\infty |e^{-st}| e^{ct} \, dt \\
    & = M \int_0^\infty e^{-\text{Re}(s) t} e^{ct}\,dt = \frac{M}{\text{Re}(s) - c}, \;\;\; (\text{Re}(s) > c)
\end{align*}
and it is clear that this limit approaches $0$ as Re$(s) \rightarrow \infty$. 
\end{proof}

In actuality, it is often impossible to find the inverse transform for a general function explicitly. 

\section{Numerical Methods of Solving DEQs}
In many problems the only effective method for obtaining information about the solution of a differential equation is to use a numerical approximation procedure. In this section, we will talk about
\begin{enumerate}
    \item the Euler Method and modified Euler Method
    \item the Milne Method
    \item Runge-Kutta Methods
\end{enumerate}
For simplicity, we constrain our view to single first-order differential equations. 

\subsection{The Euler Method and Modified Euler Method}
Given the first-order differential equation
\[y^\prime = f(t, y) \text{ with initial conditions } \varphi(t_0) = y_0\]
we wish to find an approximation to the value of the solution $\varphi$ at $t = t_0 + T$. By the fundamental rule of calculus, we know that assuming that $f(t, y)$ is $C^1$ for $t \in (t_0, t_0 + T)$, 
\begin{align*}
    \varphi(t) & = \varphi(t_0) + \int_{t_0}^t \varphi^\prime (s) \,ds \\
    & = y_0 + \int_{t_0}^t f\big(s, \varphi(s) \big)\,ds
\end{align*}
In visual terms, we just take $y_0$ and add the area under the derivative curve $\varphi^\prime (s)$ from $t_0$ to whatever $t$ we would like. 
\begin{center}
    \includegraphics[scale=0.25]{Fundamental_Theorem_of_Calculus.PNG}
\end{center}
Since we know $y_0$, finding $f(t_0 + T)$ rests entirely on solving the integral representing the area under the velocity curve. Euler's method is simply doing this with left-hand Riemann sums. Note that while it is conventional that a the rectangles have the same width, they do not necessarily need to be. 
\begin{enumerate}
    \item 2 Riemann rectangles (even and uneven). 
    \begin{center}
        \includegraphics[scale=0.25]{2_Riemann.PNG}
    \end{center}
    \item 3 Riemann rectangles (even and uneven). 
    \begin{center}
        \includegraphics[scale=0.25]{3_Riemann.PNG}
    \end{center}
    \item 4 Riemann rectangles (even and uneven). 
    \begin{center}
        \includegraphics[scale=0.25]{4_Riemann.PNG}
    \end{center}
\end{enumerate}
In fact, the question of the best choice of unequal spacing is a major unsolved mathematical problem. We formalize this algorithm in the following steps. 

\begin{theorem}[Euler's Method]
Given the first order DEQ $y^\prime = f(t, y)$ with initial conditions $\varphi(t_0) = y_0$, say that we would like to approximate the value of $\varphi(t_0 + T)$. Then, the \textit{Euler method} gives us steps: 
\begin{enumerate}
    \item Divide the interval $[t_0, t_0 + T]$ into $N$ (not necessarily equal) subintervals by specifying intermediate points
    \[t_0 < t_1 < t_2 < \ldots < t_{N-1} < t_N = t_0 + T\]
    For simplicity of calculations later, we will assume equal spacing, with spacing $h = T/N$. 
    \item Looking at points $t_k$ and $t_{k+1}$ for $k = 1, \ldots, N-1$, we can approximate the value of $y_{k+1}$ with $y_k$ using Riemann rectangles. 
    \begin{align*}
        y_{k+1} = y_k + \int_{t_k}^{t_{k+1}} f\big(s, \varphi(s)\big)\,ds  & \implies y_{k+1} = y_k + (t_{k+1} - t_k) f(t_k, y_k) \\
        & \implies y_{k+1} = y_k + h f(t_k, y_k)
    \end{align*}
    \begin{center}
        \includegraphics[scale=0.25]{Eulers_Method.PNG}
    \end{center}
    \item Use step 2 to find $y_1$, then $y_2$, and so on until $y_N \approx \varphi(t_N) = \varphi(t_0 + T)$ is found. Then terminate. 
\end{enumerate}
Furthermore, for some constant $M$, the local truncation error of the Euler method (for each step) is 
\[|T_k| \leq \frac{1}{2} M h^2\]
that is, no greater than a constant multiple of $h^2$, while the cumulative truncation error of it is
\[|\varphi(t_n) - y_n| \leq \frac{1}{2} M h^2 N = \frac{1}{2} M T h\]
that is, no greater than a constant multiple of $h$. 
\end{theorem}

Since the cumulative error bound is bounded by a linear function of $h$, we can make the error as small as we want by making the $h$ arbitrarily small. However, the truncation error for Euler's method is too large and is not used in applications. Rather, it is more efficient to use a more sophisticated method of approximation where the cumulative truncation error is no greater than a constant multiplied by some higher power of $h$. 

An obvious improvement is to change the method of approximation of integrals from left-hand Riemann sums (taken at the start point of each interval) to Riemann rectangles taken at the midpoint of each interval. This method of approximation is called \textit{midpoint quadrature}
\begin{center}
    \includegraphics[scale=0.28]{Midpoint_Quadrature.PNG}
\end{center}

\begin{theorem}[Modified Euler's Method]
Given the first order DEQ $y^\prime = f(t, y)$ with initial conditions $\varphi(t_0) = y_0$, say that we would like to approximate the value of $\varphi(t_0 + T)$.Then, the \textit{modified Euler's method} gives us steps: 
\begin{enumerate}
    \item Divide the interval $[t_0, t_0 + T]$ into $N$ equal subintervals (of length $h$), where $N$ is an even number, by specifying intermediate points
    \[t_0 < t_1 < t_2 < \ldots < t_{N-1} < t_N = t_0 + T\]
    \item Rather than integrating over one subinterval $[t_k, t_{k+1}]$, we integrate over two subintervals $[t_k, t_{k+2}]$ and approximate it using the value of the function at $t_{k+1}$, the midpoint of the interval. That is, 
    \begin{align*}
        y_{k+2} = y_k + \int_{t_k}^{t_{k+2}} f\big(s, \varphi(s)\big)\,ds & \implies y_{k+2} = y_k + (t_{k+2} - t_k) f(t_{k+1}, y_{k+1}) \\
        & \implies y_{k+2} = y_k + 2 h f(t_{k+1}, y_{k+1})
    \end{align*}
    \begin{center}
        \includegraphics[scale=0.25]{Modified_Euler_Method.PNG}
    \end{center}
    Note that the modified Euler's method expresses $y_{k+2}$ in terms of both $y_k$ and $y_{k+1}$. This is a problem, since in the first step we know only $y_0$ but not $y_1$ in order to calculate $y_2$. Therefore, we must solve for $y_1$ with some other method, such as Euler's method or approximating using Taylor series (provided the function is analytic). 
    \item Use step to to find $y_2$, then $y_4$, then $y_6$, and so on until $y_N \approx \varphi(t_N) = \varphi(t_0 + T)$ is found. Then terminate. 
\end{enumerate}
Furthermore, for some constant $M$, the local truncation error of the modified Euler method (for each step) is 
\[|T_k| \leq \frac{M}{3} h^3\]
that is, no greater than a constant multiple of $h^2$, while the cumulative truncation error of it is no great than a constant multiple of $h^2$. 
\end{theorem}

\begin{example}[Comparison of Euler Algorithm and Modified Version on Approximating $e$]
By setting $h = 0.1$, we estimate $e$ where $\varphi(1) = e$. Remember the differential equation with this solution is $y^\prime = f(t, y) = y$. Using Euler's method we have
\[y_{k+1} = y_k + 0.1 y_k = 1.1y_k\]
Doing this iteratively 10 times starting at $y_0 = 1$ gives us $1.1^{10} = 2.593$. However, using the modified Euler's method, we have 
\[y_{k+2} = y_k + 0.2 f(t_{k+1}, y_{k+1})\]
We can first approximate $y_1 = \varphi(0.1) = 1 + 0.1 + \frac{1}{2} (0.1)^2 + \ldots$ using a power series expansion, giving $y_1 \approx 1.105$ (correct to 3 decimal places). Since $f(t, y) = y$, we get 
\[y_{k+2} = y_k + 0.2 y_{k+1}\]
Calculating these values $y_2, y_3, \ldots$, we get $e \approx 2.713$, which is considerably better than the $2.593$ approximation. 
\end{example}

Another way to approximate definite integrals is to use trapezoidal sums as a method of approximation. 
\[\int_{t_k}^{t_{k+1}} f\big(s, \varphi(s)\big)\,ds \approx \frac{h}{2}\big( f(t_k, \varphi(t_k)) + f(t_{k+1}, \varphi(t_{k+1}))\big)\]

\begin{center}
    \includegraphics[scale=0.28]{Trapezoidal_Sum.PNG}
\end{center}

\begin{theorem}[Improved Euler's Method]
Given the first order DEQ $y^\prime = f(t, y)$ with initial conditions $\varphi(t_0) = y_0$, say that we would like to approximate the value of $\varphi(t_0 + T)$, then the \textit{improved Euler method} gives us steps: 
\begin{enumerate}
    \item Divide the interval $[t_0, t_0 + T]$ into $N$ (not necessarily equal) subintervals by specifying intermediate points 
    \[t_0 < t_1 < t_2 < \ldots < t_{N-1} < t_N = t_0 + T\]
    For simplicity of calculations later, we will assume equal spacing, with spacing $h = T/N$. 
    \item Looking at points $t_k$ and $t_{k+1}$ for $k = 1, \ldots, N-1$, we can approximate the value of $y_{k+1}$ with $y_k$ using trapezoids.
    \begin{align*}
        y_{k+1} = y_k + \int_{t_k}^{t_{k+1}} f\big( s, \varphi(s)\big)\,ds & \implies y_{k+1} = y_k + \frac{h}{2} \big(f(t_k, y_k) + f(t_{k+1}, y_{k+1}\big) 
    \end{align*}
    Note that the improved Euler method expresses $y_{k+1}$ implicitly rather than explicitly. There are methods for dealing with implicit formulas, but we leave it at this. 
    \item Use step 2 to find $y_2$, then $y_3$, and so on until $y_N \sum \varphi(t_N)$ is found. 
\end{enumerate}
\end{theorem}

\subsection{The Milne Method}
The Milne method gives us a quadratic approximation to certain integrals. 

\begin{lemma}[Simpson's Rule]
\textit{Simpson's rule} gives the approximation 
\[\int_{t_k}^{t_{k+2}} f\big(s, \varphi(s)\big)\,ds \approx \frac{h}{3} \big( f(t_k, \varphi(t_k)) + 4 f (t_{k+1}, y_{k+1}) + f(t_{k+2}, y_{k+2})\big)\]
\end{lemma}
\begin{proof}
This approximation pops up from attempting to find a quadratic graph of best fit for arbitrary function $y = f(t, \varphi(t))$. For convenience, we assign $F(t) = f(t, \varphi(t))$. Now, we must determine constants $a, b, c$ so that the parabola
\[y = a + b(s - t_{k+1}) + c(s - t_{k+1})^2\]
with vertex $(t_{k+1}, a)$ passes through the points $(t_k, F(t_k)), (t_{k+1}, F(t_{k+1})), (t_{k+2}, F(t_{k+2}))$. 
\begin{center}
    \includegraphics[scale=0.27]{Quadratic_Milne.PNG}
\end{center}
Since $h = t_{k+2} - t_{k+1} = t_{k+1} - t_k$, we have the set of conditions
\begin{align*}
    F(t_k) & = a - bh + ch^2 \\
    F(t_{k+1}) & = a \\
    F(t_{k+2}) & = a + bh + ch^2
\end{align*}
We can solve this system to get
\[a = F(t_{k+1}), \;\;\;\;\; c = \frac{F(t_{k+2}) - 2 F (t_{k+1}) + F(t_k)}{2 h^2}\]
We then integrate this quadratic approximation
\begin{align*}
    \int_{t_k}^{t_{k+2}} \big( a + b(s - t_{k+1}) + c(s - t_{k+1})^2 \big) \,ds & = \bigg( as - \frac{b}{2} (s - t_{k+1})^2 + \frac{c}{3} (s - t_{k+1})^3 \bigg) \bigg|^{t_{k+2}}_{t_k} \\
    & = 2 ah + \frac{2}{3} ch^3
\end{align*}
Note that we do not even need to find the value of $b$. Substituting the solutions $a, c$ in, we get Simpson's Rule. 
\end{proof}

\begin{theorem}[Milne Method]
Given the first order DEQ $y^\prime = f(t, y)$ with initial conditions $\varphi(t_0) = y_0$, say that we would like to approximate the value of $\varphi(t_0 + T)$. Then, the \textit{Milne method} gives us steps: 
\begin{enumerate}
    \item Divide the interval $[t_0, t_0 + T]$ into $N$ (not necessarily equal) subintervals by specifying intermediate points 
    \[t_0 < t_1 < t_2 < \ldots < t_{N-1} < t_N = t_0 + T\]
    For simplicity of calculations later, we will assume equal spacing, with spacing $h = T/N$. 
    \item Rather than integrating over one subinterval $[t_k, t_{k+1}]$, we integrate over two subintervals $[t_k, t_{k+2}]$ and approximate it using Milne's formula:
    \begin{align*}
        y_{k+2} = y_k & + \int_{t_k}^{t_{k+2}} f\big(s, \varphi(s)\big)\,ds \\
        \implies & y_{k+2} = y_k + \frac{h}{3} \big( f(t_k, \varphi(t_k)) + 4 f (t_{k+1}, y_{k+1}) + f(t_{k+2}, y_{k+2})\big)
    \end{align*}
    Note that this solves for $y_{k+2}$ implicitly (which isn't a problem when dealing with linear equations), and you need to know both $y_k$ and $y_{k+1}$ in order to calculate $y_{k+2}$. 
    \item Use step 2 to find $y_2, y_3, \ldots$ until $y_N \approx \varphi(t_N)$ is found. Then terminate. 
\end{enumerate}
Furthermore, the cumulative truncation error of the Milne method is no greater than a constant multiple of $h^4$. 
\end{theorem}

We can now state a very important theorem on error bounds of one-step methods (applying to the Euler method, but not to the Milne method). 

\begin{theorem}[Truncation Error Bounds on One-Step Methods]
Suppose that $f(t, y) \in C^1$ for $t_0 \leq t \leq t_0 + T$ and all $y$. Suppose 
\[y_1, y_2, \ldots, y_N\]
are the approximations calculated by some one-step method with step length $h$ to the solution $\varphi$ of 
\[y^\prime = f(t, y), \;\;\;\; \varphi(t_0) = y_0\]
If the local truncation error is no greater than $\epsilon$, then the cumulative truncation error is no greater than a constant multiple of $\epsilon/h$. 
\end{theorem}

This theorem shows that if the local truncation error of a one-step process is no greater than a constant multiple of $h^p$, then the cumulative truncation error is no grater than a constant multiple of $h^{p-1}$. Analogous results can be proved for two-steps methods (and for methods involving any finite number of steps). Therefore, the accuracy of approximation is improved if a method whose truncation error involves a higher power of $h$ is used. 

\subsection{Stability, Consistency, and Convergence}

\begin{definition}[Round-Off Errors]
When we use a numerical method to obtain an approximation to the solution of a differential equation, we are trying to find a set of numbers 
\[y_1, y_2, y_3, \ldots, y_N\]
defined by the method, where $y_N$ is the final approximation. However, due to the floating-point nature of numbers in computers, we actually round-off all numbers calculated to a specific number of significant figures, obtaining a slightly different set of numbers
\[z_1, z_2, z_3, \ldots, z_N\]
the difference
\[r_k = |z_k - y_k|, \;\; k = 1, 2, \ldots, N\]
is called the \textit{round-off error}. The $h$ value is also called the \textit{mesh}. 
\end{definition}

\begin{definition}[Finite-Difference Methods]
\textit{Finite-difference} methods are a class of numerical techniques for solving differential equations by approximating derivatives with finite differences. Both the spatial domain and time interval are discretized (i.e. broken up into a finite number of steps), and the value of the solution at these discrete points is approximated by solving algebraic equations containing finite differences and values from nearby points. 
\end{definition}

\begin{definition}[Consistency, Stability, Convergence]
We now define three common terms that describes numerical methods. 
\begin{enumerate}
    \item \textit{Consistency}: A finite difference method is considered consistent if by reducing the mesh and time step size, the truncation error terms could be made to approach $0$. In this case the solution to the difference equation would approach the true solution of the DE. 
    \item \textit{Stability}: A finite difference approximation is stable if the errors (truncation, round-off, etc.) decay (i.e. remain bounded, preferably within some deducible function) as the computation proceeds from one marching step to the next. 
    \item \textit{Convergence}: The solution to the finite difference approximation approaches the true solution of the DE when the mesh is refined (step size reduced). This means that the approximation $y_N$ tend to the actual solution as $h \rightarrow 0$. 
\end{enumerate}
\end{definition}

Every method mentioned in this section is convergent. Obviously, a method which is not convergent is useless for obtaining numerical approximations. It is possible to give conditions for stability and consistency of numerical methods which are easy to verify. If we do this, we can use the following theorem to prove convergence. 

\begin{theorem}[Lax Equivalence Theorem]
A finite difference approximation method satisfying consistency (meaning truncation error approaches $0$ when step size and mesh size goes to $0$) and stability (meaning error goes on diminishing as time step passes) is convergent. 
\end{theorem}

It turns out that the Milne method may be numerically instable, which is why it is not always suitable, despite its small truncation error. 

\subsection{Runge-Kutta Methods}
Let us revisit Taylor polynomials that serve as approximations to differentiable functions. Let $\varphi$ be the solution of the differential equation 
\[y^\prime = f(t, y) , \;\;\;\; \varphi(t_0) = y_0\]
Assuming that $\varphi$ has a continuous second derivative on the interval $[t_0, t_0 + T]$, we can use Taylor's theorem (with the Lagrange form of the remainder) to write the first order approximation centered at $t_0$.  
\[\varphi(t) = \varphi(t_0) + (t - t_0) \varphi^\prime (t_0) + \frac{(t - t_0)^2}{2!} \varphi^{\prime\prime} (\zeta)\]
for some $\zeta \in (t_0, t)$. If $t_1 = t_0 + h$, then
\begin{align*}
    \varphi(t_1) & = \varphi(t_0) + h \varphi^\prime (t_0) + \frac{h^2}{2!} \varphi^{\prime\prime} (\zeta) \\
    & = \varphi(t_0) + h f(t_0, y_0) + \frac{h^2}{2!} \varphi^{\prime\prime} (\zeta) \\
    & \approx y_0 + h f(t_0, y_0)
\end{align*}
where the approximation is gotten by neglecting the term $\frac{h^2}{2!} \varphi^{\prime\prime} (\zeta)$. If we divide the interval $[t_0, t_0 + T]$ into $N$ subintervals of length $h$ by defining the partition points $t_k = t_0 + kh$ ($k = 0, 1, \ldots, N$), we can use this procedure to obtain an iterative formula
\[y_{k+1} = y_k + hf(t_k, y_k)\]
with local truncation error $\frac{h^2}{2!} \varphi^{\prime\prime} (\zeta)$. This first-order approximation is, of course, just Euler's algorithm. 

If we look at the second degree Taylor expansion 
\[\varphi(t) = \varphi(t_0) + (t - t_0) \varphi^\prime (t_0) + \frac{(t - t_0)^2}{2!} \varphi^{\prime\prime} (t_0) + \frac{(t - t_0)^3}{3!} \varphi^{\prime\prime\prime} (\zeta)\]
we can ignore the error term but we still have to deal with the second order term. We can evaluate $\varphi^{\prime\prime} (t_0)$ by differentiating $\varphi^\prime (t) = f(t, \varphi(t))$ using the chain rule, which gives
\begin{align*}
    \varphi^{\prime\prime} (t) & = f_t \big( t, \varphi(t)\big) + f_y \big(t, \varphi(t)\big) \varphi^\prime (t) \\
    & = f_t \big(t, \varphi(t)\big) + f_y \big( t, \varphi(t)\big) f\big(t, \varphi(t)\big)
\end{align*}
Where $f_t$ and $f_y$ represents the partial derivatives with respect to $t$ and $y$, respectively. Note that when computing $f_t (t, \varphi(t))$, we should keep $\varphi(t)$ constant, and when computing $f_y (t, \varphi(t))$, we should keep $t$ constant while deriving with respect to $y = \varphi(t)$. Do not get confused by this. This ultimately leads to the iterative approximation formula
\[y_{k+1} = y_k + h f(t_k, y_k) + \frac{h^2}{2!} \big( f_t (t_k, y_k) + f_y (t_k, y_k) f(t_k, y_k)\big)\]
with local truncation error $\frac{h^3}{3!} \varphi^{\prime\prime\prime} (\zeta)$. This is a plausible means of obtaining numerical approximations, but it suffers from the disadvantage of having to calculate derivatives of $f$, which isn't easy for a computer to do. This problem persists for procedures using higher-order Taylor approximations. 

The Runge-Kutta method is an attempt to obtain formulas equivalent to Taylor approximations which do not involve derivatives of $f$. There are many variations of Runge-Kutta methods, but we will describe the most common version. 

\begin{theorem}[Runge-Kutta Method]
Given the first order DEQ $y^\prime = f(t, y)$ with initial conditions $\varphi(t_0) = y_0$, say that we would like to approximate the value of $\varphi(t_0 + T)$. Then, the \textit{Runge-Kutta method} gives us steps: 
\begin{enumerate}
    \item Divide the interval $[t_0, t_0 + T]$ into $N$ (not necessarily equal) subintervals by specifying intermediate points 
    \[t_0 < t_1 < t_2 < \ldots < t_{N-1} < t_N = t_0 + T\]
    For simplicity of calculations later, we will assume equal spacing, with spacing $h = T/N$. 
    \item Given the value $y_k$, we can approximate the value $y_{k+1}$ using the one-step process
    \[y_{k+1} = y_k + \frac{h}{6} (p_1 + 2p_2 + 2p_3 + p_4)\]
    where 
    \begin{align*}
        p_1 & = f(t_k, y_k) & & p_2 = f\bigg( t_k + \frac{h}{2}, y_k + \frac{h p_1}{2}\bigg)  \\
        p_3 & = f\bigg( t_k + \frac{h}{2} , y_k + \frac{h p_2}{2} \bigg) & & p_4 = f(t_{k+1}, y_k + h p_3)
    \end{align*}
\end{enumerate}
The term $\frac{1}{6} (p_1 + 2p_2 + 2p_3 + p_4)$ represents an "average" slope of $\varphi$ over the interval $[t_k, t_{k+1}]$. More specifically, 
\begin{enumerate}
    \item $p_1$ is the slope at $t_1$
    \item $p_2$ is an approximation of the slops at the midpoint of the interval obtained by means of the Euler method
    \item $p_3$ is a second approximation to the slope at the midpoint
    \item $p_4$ is an approximation to the slope at $t_{k+1}$ obtained by means of the Euler method with slope $p_3$. 
\end{enumerate}
Even though it requires a lot of calculations, it is an explicit one-step procedure that does not require calculation of derivative of $f$. Furthermore, it is equivalent to a 4th order Taylor formula, and the local truncation error of the Runge-Kutta method is no greater than a constant multiple of $h^5$. 
\end{theorem}

\begin{example}[Deriving a Runge-Kutta Formula equivalent to 2nd-Order Taylor Formula]
Earlier in this subsection, we have found that the second order approximation formula for $\varphi$ is 
\[y_{k+1} = y_k + h f(t_k, y_k) + \frac{h^2}{2!} \big( f_t (t_k, y_k) + f_y (t_k, y_k) f(t_k, y_k)\big)\]
which requires us to compute derivatives. We will demonstrate how to obtain a Runge-Kutta formula equivalent to this 2nd-order Taylor formula. We will assume a method of form 
\[y_{k+1} = y_k + h \Big( af(t_k, y_k) + b f\big( t_k + \alpha h, y_k + \beta h f(t_k, t_k)\big)\Big)\]
where $a, b, \alpha, \beta$ are constants to be determined. By Taylor's theorem for functions of two variables we write
\[f\big(t_k + \alpha h, y_k + \beta h f(t_k, y_k)\big) = f(t_k, y_k) + \alpha h f_t (t_k, y_k) + \beta h f(t_k, y_k) f_y (t_k, y_k) + R h^2\]
where $R$ is a remainder term involving the second-order partial derivatives of $f$. Substituting this into the original form gives
\begin{align*}
    y_{k+1} = y_k + h(a + b) f(t_k, y_k) + h^2 \big( \alpha b f_t (t_k, y_k) + \beta b f(t_k, y_k) f_y (t_k, y_k)\big) + R b h^3
\end{align*}
Comparing this with the original approximation formula for $\varphi$ (with derivatives), we can compare each term and see that if
\[a + b = 1, \;\;\;, \alpha b = \frac{1}{2}, \;\;\; \beta b = \frac{1}{2}\]
then the approximations obtained by these two formulas differ only by the term $R b h^3$. Thus, any quadruples of constants satisfying these conditions is a Runge-Kutta formula of the desired type. For example, choosing $a = \frac{1}{2}, b = \frac{1}{2}, \alpha = 1, \beta = 1$, gives
\[y_{k+1} = y_k + \frac{h}{2} \big( f(t_k, y_k) + f(t_{k+1}, y_k + h f(t_k, y_k))\big)\]
which is equivalent in accuracy to a three-term Taylor formula. Also note that this formula is similar to the improved Euler method. 
\end{example}

\subsection{Numerical Methods for Systems and Equations of Higher Order}
Everything in this section had been designed for first-order equations, but these methods are equally suitable for systems of differential equations. We can write a system of equations as a vector equation
\[y^\prime = f(t, y) \iff \begin{cases}
y_1^\prime & = f_1 (t, y_1, y_2, \ldots, y_n) \\
y_2^\prime & = f_2 (t, y_1, y_2, \ldots, y_n) \\
\vdots & = \vdots \\
y_n^\prime & = f_n (t, y_1, y_2, \ldots, y_n)
\end{cases}\]
where $y \in \mathbb{R}^n$ and $f: \mathbb{R}^n \times \mathbb{R} \longrightarrow \mathbb{R}^n$. We can apply the approximation methods developed in this chapter to the system by applying them to each component in the vector equation. 

\begin{example}
Consider the system 
\[u^\prime = v, \;\;\;\; v^\prime = g(t, u, v)\]
This can be written in form 
\[y^\prime = f(t, y) \iff \begin{pmatrix} u \\ v \end{pmatrix}^\prime = \begin{pmatrix} v \\ g(t, u, v) \end{pmatrix} \]
The Euler method applied to this system leads to a pair of iterative formulas 
\[\begin{pmatrix} u_{k+1} \\ v_{k+1} \end{pmatrix} = \begin{pmatrix} u_k \\ v_k \end{pmatrix} + h \begin{pmatrix} v_k \\ g(t_k, u_k, v_k) \end{pmatrix} \implies \begin{cases} u_{k+1} & = u_k + h v_k \\
v_{k+1} & = v_k + h g(t_k, u_k, v_k) \end{cases}\]
Therefore, once we are given initial values $u_0$ and $v_0$, and once we have found both $u_k$ and $v_k$, we can use this to compute $u_{k+1}$ and $v_{k+1}$. 
\end{example}

As we have seen before, higher order equations can be treated as a system of first-order DEQs, which can then be solved numerically on each component equation. 

\chapter{Algebraic Topology}
\section{Homotopy}
\begin{definition}
Let $X, Y$ be topological space and let $F_0, F_1: X \longrightarrow Y$ be continuous maps. A \textit{homotopy} from $F_0$ to $F_1$ is a continuous map (with respect to elements $t \in [0,1]$)
\[H: X \times I \longrightarrow Y\]
where $I = [0,1]$, satisfying
\begin{align*}
    & H(x, 0) = F_0 (x) \\
    & H(x, 1) = F_1 (x) 
\end{align*}
for all $x \in X$. We can visualize this homotopy as a continuous deformation of (the images of) $F_0$ to $F_1$. We can also think of the parameter $t$ as a "slider control" that allows us to smoothly transition from $F_0$ to $F_1$ as the slider moves from $0$ to $1$, and vice versa. The figures below represents the homotopies between the one-dimensional curves (left) and 2-dimensional surfaces (right), $\im{F_0}$ and $\im{F_1}$, with dashed lines. 
\begin{center}
\begin{tikzpicture}[scale=0.5]
    \draw[thick] plot [smooth] coordinates{(-4,0) (-3.3,0.8) (-0.5,1.2) (1,2.1) (2.5,3)};
    \draw[thick] plot [smooth] coordinates{(-3,-2) (-2,-1.5) (0,-1) (2,0.5) (3,0.8)};
    \draw[dashed, ->] (-4,0)--(-3,-2); 
    \draw[dashed, ->] (-3.3,0.8)--(-2,-1.5);
    \draw[dashed, ->] (-0.5,1.2)--(0,-1);
    \draw[dashed, ->] (1,2.1)--(2,0.5);
    \draw[dashed, ->] (2.5,3)--(3,0.8);
    \draw[fill] (-4,0) circle (0.05); 
    \draw[fill] (-3,-2) circle (0.05);
    \draw[fill] (2.5,3) circle (0.05);
    \draw[fill] (3,0.8) circle (0.05); 
    \node[above] at (-0.5,1.2) {$F_0$};
    \node[below] at (0,-1) {$F_1$};
\end{tikzpicture}
\end{center}
If there exists a homotopy from $F_0$ to $F_1$, then we say that $F_0$ and $F_1$ are \textit{homotopic}, denoted
\[F_0 \simeq F_1\]
\end{definition}


\begin{definition}
If the homotopy satisfies 
\[H(x,t) = F_0 (x) = F_1 (x)\]
for all $t \in I$ and $x \in S$, which is a subset of $X$, then the maps $F_0$ and $F_1$ are said to be \textit{homotopic relative to $S$}. 
\end{definition}

This is clearly an equivalence relation defined on $C^0 (X, Y)$, the set of all continuous functions from $X$ to $Y$.
\begin{enumerate}
    \item Identity. Clearly, $F$ is homotopic to itself by setting $H(x, t) \equiv F(x)$ for all $t \in [0,1]$. 
    \item Symmetry. Given homotopy $H(x, t)$ from $F_0$ to $F_1$, the homotopy $H^{-1} (x, t) \equiv H(x, 1-t)$ maps from $F_1$ to $F_0$. 
    \item Transitivity. Given homotopy $H_1$ from $F_1$ to $F_2$, and homotopy $H_2$ from $F_2$ to $F_3$, the homotopy defined
    \[H_3 (x, t) \equiv \begin{cases}
          H_1 (x, 2t) & 0 \leq t \leq \frac{1}{2} \\
          H_2 (x, 2t - 1) & \frac{1}{2} \leq t \leq 1
    \end{cases}\]
    is indeed a homotopy from $F_1$ to $F_3$. 
\end{enumerate}

\begin{definition}
The space of homotopy classes from topological space $X$ to $Y$ is denoted
\[[X, Y] \equiv \frac{C^0 (X, Y)}{\sim}\]
where $\sim$ is the homotopy relation. 
\end{definition}

\begin{lemma}
Homotopy is compatible with function composition in the following sense. If $f_1, g_1: X \longrightarrow Y$ are homotopic, and $f_2, g_2: Y \longrightarrow Z$ are homotopic, then $f_2 \circ f_1$ and $g_2 \circ g_1$ are homotopic. That is, given the two homotopies
\begin{align*}
    & H_1: X \times [0,1] \longrightarrow Y \\
    & H_2: Y \times [0,1] \longrightarrow Z
\end{align*}
we can naturally define a third homotopy 
\[H_3: X \times [0,1] \longrightarrow Z, \; H(x, t) \equiv H_2 (x, t) \circ H_1(x, t)\]
which is continuous since compositions of continuous functions are continuous. 
\end{lemma}

\begin{example}
If $f, g: \mathbb{R} \longrightarrow \mathbb{R}^2$ is defined as a
\[f(x) \equiv (x, x^3), \; g(x) \equiv (x, e^x)\]
then the map 
\[H: \mathbb{R} \times [0,1] \longrightarrow \mathbb{R}^2, \; H(x, t) \equiv \big( x, (1-t) x^3 + t e^x \big) \]
is a homotopy between them. 
\end{example}

\begin{example}
Let $id_B: B^n \longrightarrow B^n$ be the identity function on the unit $n$-disk, and let $c_0: B^n \longrightarrow B^n$ be the $0$-function sending every vector to $0$. Then, $id_B$ and $c_0$ are homotopic, with homotopy explicitly defined
\[H: B^n \times [0,1] \longrightarrow B^n, \; H(x, t) \equiv (1-t) x\]
\end{example}

\begin{example}
If $C \subseteq \mathbb{R}^n$ is a convex set and $f, g: [0,1] \longrightarrow C$ are paths with the same endpoints, then there exists a \textit{linear homotopy} given by 
\[H: [0,1] \times [0,1] \longrightarrow C, \; (s, t) \mapsto (1-t) f(s) + t g(s)\]
We can extend this example. Let $f, g: \mathbb{R} \longrightarrow \mathbb{R}$ be 2 continuous functions. Then $f \simeq g$, since we can construct $F: [0,1] \times \mathbb{R} \longrightarrow \mathbb{R}$ defined
\[F(x, t) \equiv (1-t) f(x) + t g(x)\]
(Note that the set of continuous functions from $\mathbb{R}$ to $\mathbb{R}$ is a convex set.)
\end{example}
This leads to our definition of \textit{path homotopies}, which is just a specific type of homotopy. 

\begin{definition}
Suppose $X$ is a topological space. Two paths $f_0, f_1: I \longrightarrow X$ are said to be \textit{path homotopic}, denoted
\[f_0 \sim f_1\]
if they are homotopic relative to $\{0, 1\}$. This means that there exists a continuous map $H: I \times I \longrightarrow X$ satisfying
\begin{align*}
    &H(s, 0) = f_0 (s), \; s \in I \\
    &H(s, 1) = f_1 (s), \; s \in I \\
    &H(0, t) = f_0 (0) = f_1 (0), t \in I \\
    &H(1, t) = f_1 (1) = f_0 (1) , t \in I
\end{align*}
\end{definition}
We can visualize two paths (sharing the same endpoints) being path homotopic if we can "continuously deform" one onto another. \\
\begin{center}
\begin{tikzpicture}[scale=0.5]
    \draw (0,0) ellipse (5 and 3); 
    \draw[fill] (-4,0) circle (0.05); 
    \draw[fill] (4,0) circle (0.05);
    \draw[dashed] (-4,0)--(4,0);
    \draw plot [smooth] coordinates{(-4,0) (0,2) (4,0)};
    \draw[dashed] plot [smooth] coordinates{(-4,0) (0,1) (4,0)};
    \draw[dashed] plot [smooth] coordinates {(-4,0) (0,-1) (4,0)};
    \draw plot [smooth] coordinates {(-4,0) (0,-2) (4,0)};
    \node[left] at (-4,0) {$p$};
    \node[right] at (4,0) {$q$};
\end{tikzpicture}
\end{center}
We can notice that for any given points $p, q \in X$, path homotopy is an equivalence class on the set of all paths from $p$ to $q$. 

\begin{definition}
The equivalence class of a path $f$ is called a \textit{path class}, denoted $[f]$. Note that in the diagram above, there is only one equivalence class of paths. 
\end{definition}

We can define a multiplicative structure on paths as such. This is the first step to create a group structure on the set of certain paths. 

\begin{definition}
Given two paths $f, g$ such that $f(1) = g(0)$, their product is the path defined
\[(f \cdot g) (s) \equiv \begin{cases}
      f(2s) & 0 \leq s \leq \frac{1}{2} \\
      g(2s - 1) & \frac{1}{2} \leq s \leq 1
\end{cases}\]
It is easy to visualize the product of two paths as the longer path created by "connecting" the two smaller paths. 
\begin{center}
\begin{tikzpicture}[scale=0.4]
    \draw (0,0) circle (5);
    \draw[fill] (-3.5,-1) circle (0.05);
    \draw[fill] (-2,2) circle (0.05);
    \draw[fill] (3,1) circle (0.05);
    \node[above] at (-2,2) {$q$};
    \node[right] at (3,1) {$r$};
    \node[below] at (-3.5, -1) {$p$};
    \draw[blue] plot [smooth] coordinates{(-3.5,-1) (-3.4,0) (-2.2, 1) (-2,2)};
    \draw[red] plot [smooth] coordinates{(-2,2) (0,2.3) (1.7, 1) (3,1)};
\end{tikzpicture}
\end{center}
It is also easy to see that if $f \sim f^\prime$ and $g \sim g^\prime$, 
\[f \cdot g \sim f^\prime \cdot g^\prime\]
\end{definition}

We can also define the product of these equivalence classes as
\[[f] \cdot [g] \equiv [f \cdot g]\]
Notice that multiplication of paths is not associative in general, but it is associative up to path homotopy. That is, 
\[([f] \cdot [g]) \cdot [h] = [f] \cdot ([g] \cdot [h])\]

\begin{definition}
If $X$ is a topological space and $q \in X$, a "loop" in $X$ based at $q$ is a path in $X$ such that
\[f: I\longrightarrow X, \; f(0) = f(1) = q\]
The set of path classes of loops based at $q$ is denoted
\[\pi_1 (X, q)\]
Equipped with the product operation of paths defined before, $(\pi_1 (X, q), \cdot)$ is called the \textit{fundamental group of $X$ based at $q$}. The identity element of this group is the path class of the constant path $c_q(s) \equiv q$, and the inverse of $[f]$ is the path class of 
\[f^{-1} (s) \equiv f(1-s)\]
which is the reverse path of $f$. 
\end{definition}

Note that while the fundamental group in general depends on the point $q$, it turns out that, up to isomorphism, this choice makes no difference as long as the space is path connected. 

\begin{lemma}
Let $X$ be a path connected topological space, with $p, q \in X$. Then, 
\[\pi_1 (X, p) \simeq \pi_1 (X, q)\]
for all $p, q$. 
\end{lemma}

Therefore, it is conventional to write $\pi_1 (X)$ instead of $\pi_1 (X, q)$ when $X$ is path connected. 

\begin{example}
Consider the space $X \equiv B_2 \setminus B_1$, which is the 2-disk without the unit disk in $\mathbb{R}^2$. Given an arbitrary point $p \in X$, there exists an infinite number of path classes of $X$ at $p$, denoted $[p_i]$, where $i$ corresponds to how many times the paths loop around the hole. The first three path classes are shown below. 
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0) circle (3);
    \draw[fill=lightgray] (0,0) circle (1);
    \draw[fill] (-1.8, 1.8) circle (0.05);
    \node[above left] at (-1.75, 1.75) {$p$};
    \draw[red] (-1.5, 1.4) circle (0.5);
    \node[red] at (-1, 1.9) {$p_0$};
    \node[blue] at (-2.2, 0) {$p_1$};
    \node at (1.1, -1.1) {$p_2$};
    \draw[blue] (0,0) circle (2.5455);
    \draw plot [smooth] coordinates{(-1.8, 1.8) (0, 1.3) (1.4, 0) (0, -1.4) (-1.4, 0) (0, 1.4) (1.4, 0) (0, -1.4) (-1.4, 0) (-1.8, 1.8)};
\end{tikzpicture}
\end{center}
It is clear that $[p_0]$ is the identity, and the group operation rule is
\[[p_i] \cdot [p_j] = [p_{i+j}]\]
meaning that $\pi_1(X, p)$ is the infinite discrete group generated by $[p_0]$ and $[p_1]$. 
\end{example}

\begin{proposition}
Let $\mathcal{A}$ be a convex subset of $\mathbb{R}^n$, endowed with the subspace topology, and let $X$ be any topological space. Then, any 2 continuous maps $f,g: X \longrightarrow \mathcal{A}$ are homotopic. 
\end{proposition}
\begin{proof}
Since $\mathcal{A}$ is convex, the homotopy defined 
\[F(x, t) \equiv (1-t) f(x) + t g(x)\]
exists. 
\end{proof}

\begin{proposition}
If $X$ is a path connected space, the fundamental groups based at different points are all isomorphic. That is, 
\[\pi_1 (X, p) \simeq \pi_1 (X, q)\]
for all $p, q \in X$. 
\end{proposition}

\begin{definition}
If $X$ is path connected and for some $q \in X$, the group $\pi_1 (X, q)$ is the trivial group consisting of $[c_q]$ alone, then we say that $X$ is \textit{simply connected}. By definition, this means that every loop is path homotopic to a constant path. 
\end{definition}

\begin{proposition}
Let $X$ be a path connected topological space. $X$ is simply connected if and only if any 2 loops based on the same point are path homotopic. 
\end{proposition}

We can also expect that since homotopy is clearly a topological property, it is preserved under continuous maps. We state this result formally in the following lemma.

\begin{lemma}
If $F_0, F_1: X \longrightarrow Y$ and $G_0, G_1: Y \longrightarrow Z$ are continuous maps such that $F_0 \simeq F_1$ and $G_0 \simeq G_1$, then 
\[G_0 \circ F_0 \simeq G_1 \circ F_1\]
Similarly, if $f_0, f_1: I \longrightarrow X$ are path homotopic, and $F: X \longrightarrow Y$ is a continuous map, then 
\[F \circ f_0 \sim F \circ f_1\]
Thus, if $F: X \longrightarrow Y$ is a continuous maps, for each $q \in X$, we can construct a well-defined map
\[F_*: \pi_1 (X, q) \longrightarrow \pi_1 \big( Y, F(q)\big)\]
by setting
\[F_* ([f]) \equiv [F \circ f]\]
\end{lemma}

\begin{lemma}
If $F: X \longrightarrow Y$ is a contiuous map, then the induced map 
\[F_* : \pi_1(X, q) \longrightarrow \pi_1 \big( Y, F(q)\big)\]
is a group homomorphism. 
\begin{tikzpicture}
    \node at (0,0) {x};
\end{tikzpicture}
That is, $F_*$ preserves multiplicative structure of the loops. 
\end{lemma}

\begin{theorem}[Properties of the Induced Homomorphism]
\begin{enumerate}
    \item Let $F: X \longrightarrow Y, G: Y \longrightarrow Z$ be continuous maps. Then for any $q \in X$, 
    \[(G \circ F)_* = G_* \circ F_* : \pi_1 (X, q) \longrightarrow \pi_1 \big(Z, G(F(q))\big)\]
    \item For any space $X$ and any $q \in X$, the homomorphism induced by the identity map $id_X: X \longrightarrow X$ is the identity map 
    \[id: \pi_1 (X, q) \longrightarrow \pi_1 (X, q)\]
    \item If $F: X \longrightarrow Y$ is a homeomorphism, then 
    \[F_* : \pi_1 (X, q) \longrightarrow \pi_1\big( Y, F(q)\big)\]
    is an isomorphism. That is, homeomorphic spaces have isomorphic fundamental groups.  
\end{enumerate}
\end{theorem}

\begin{example}
The fundamental group of $S^1 \subset \mathbb{C}$ based at $0$ is the infinite cyclic group generated by the path class of the loop
\[\alpha: I \longrightarrow S^1, \; \alpha(s) \equiv e^{2 \pi i s}\]
\end{example}

\begin{theorem}
If $F: X \longrightarrow Y$ is a homotopy equivalence, then for each $p \in X$, 
\[F_* : \pi_1 (X, p) \longrightarrow \pi_1 \big( Y, F(p) \big)\]
is an isomorphism. 
\end{theorem}

The following proposition will be revisited when studying manifolds. 

\begin{proposition}
The fundamental group of any topological manifold is countable. 
\end{proposition}

\subsection{Homotopy Equivalence}
\begin{definition}
Given two topological spaces $X$ and $Y$, a homotopy equivalence between $X$ and $Y$ is a pair of continuous maps $f:X \longrightarrow Y$ and $g: Y \longrightarrow X$ such that 
\[g \circ f \simeq id_X \text{ and } f \circ g \simeq id_Y\]
The equivalence classes under $\simeq$ are called \textit{homotopy types}. If such a pair $f, g$ exists, $X$ and $Y$ are said to be \textit{homotopy equivalent}, or of the same homotopy type. 
\end{definition}

\begin{definition}
Spaces that are homotopy equivalent to a point are called \textit{contractible}. That is, $X$ is contractible if and only if 
\[X \simeq \{x_0\}\]
\end{definition}

Visually, two spaces are homotopy equivalent if they can be transformed into one another by bending, shrinking, and expanding operations. 

\begin{example}
A solid disk is homotopy equivalent to a single point, since one can deform the disk along radial lines to a point. 
\end{example}

\begin{example}
A mobius strip is homotopy equivalent to a closed (untwisted) strip. 
\end{example}

Notice from the visualization of homotopy equivalence the following proposition. 

\begin{proposition}
$X, Y$ homeomorphic $\implies$ $X, Y$ homotopy equivalent. However, the converse is not true. 
\end{proposition}
\begin{proof}
Just set $f = f$ and $g = f^{-1}$. 
\end{proof}

\begin{example}
A torus is not homotopy equivalent to $Y$, which also implies that they are not homeomorphic either. 
\begin{center}
\begin{tikzpicture}[scale=0.35]
    \draw (0,0) ellipse (6 and 3);
    \draw plot [smooth] coordinates{(2.7,0.5) (2, 0.2) (0,0) (-2, 0.2) (-2.7, 0.5)};
    \draw plot [smooth] coordinates{(2, 0.2) (1, 0.4) (0, 0.5) (-1, 0.4) (-2, 0.2)};
    \draw (14,0) circle (4);
    \draw[dashed] (14,0) ellipse (4 and 1.3);
    \node at (8,0) {$\not\simeq$};
\end{tikzpicture}
\end{center}
\end{example}

Furthermore, like homeomorphisms, homotopy equivalence is a relation on the set of all topological spaces. 
\begin{enumerate}
    \item Identity. Just set $f, g = id_X$
    \item Symmetricity. Given $X \simeq Y$ with $f: X \longrightarrow Y, g: Y \longrightarrow X$, we set $f^\prime \equiv g$ and $g^\prime \equiv f$ and use these functions $f^\prime, g^\prime$ to find out that $Y \simeq X$. 
    \item Transitivity. Let us have $X \simeq Y$ with functions $f_1, g_1$ and $Y \simeq Z$ with functions $f_2, g_2$. Then, we define new functions 
    \[f_3 \equiv f_2 \circ f_1: X \longrightarrow Z, \; g_3 \equiv g_1 \circ g_2: Z \longrightarrow X\]
    which follows to $f_3 \circ g_3 = id_Z$ and $g_3 \circ f_3 = id_X$. 
\end{enumerate}

\begin{proposition}
$\mathbb{R}^n$ is homotopically equivalent to a point $\{0\}$.
\end{proposition}
\begin{proof}
We claim that the continuous maps (canonical injection and projection)
\[id_{\mathbb{R}^n}: \{0\} \longrightarrow \mathbb{R}^n , \; p_0 : \mathbb{R}^n \longrightarrow \{0\}\]
have the property that 
\[id_{\mathbb{R}^n} \circ p_0 \simeq id_{\mathbb{R}^n} , \; p_0 \circ id_{\mathbb{R}^n} \simeq id_{\{0\}}\]
The right-hand homotopy is trivial since $id_{\mathbb{R}^n} \circ p_0 = id_{\mathbb{R}^n}$, and as for the left-hand homotopy, we can explicitly define it as
\[H: [0,1] \times \mathbb{R}^n \longrightarrow \mathbb{R}^n\]
with
\[H(t, x) \equiv (t) (id_{\mathbb{R}^n} \circ p_0 )(x) + (1-t) \, id_{\mathbb{R}^n} (x) = (1-t)\, id_{\mathbb{R}^n} (x)\]
\end{proof}

\begin{example}
$S^1 \simeq \mathbb{R}^2 \setminus \{0\}$, and more generally, $S^{n-1} \simeq \mathbb{R}^n \setminus \{0\}$. We can see this with the canonical injection and projections
\[id_{\mathbb{R}^2}: S^1 \longrightarrow \mathbb{R}^2 \setminus \{0\}, \; \pi_{S^1}: \mathbb{R}^2 \setminus \{0\} \longrightarrow S^1\]
and find that
\[id_{\mathbb{R}^2} \circ \pi_{S^1} \simeq id_{\mathbb{R}^2}, \; \pi_{S^1} \circ id_{\mathbb{R}^2} \simeq id_{S^1}\]
where the right-hand homotopy is trivial, and the left hand homotopy is defined explicitly as
\[H(x, t) \equiv t (id_{\mathbb{R}^2} \circ \pi_{S^1})(x) + (1-t) (id_{\mathbb{R}^2})(x)\]
\end{example}

\begin{definition}
A function $f$ is said to be \textit{null homotopic} if it is homotopic to a constant function. This is sometimes called a \textit{null-homotopy}. 
\end{definition}

\begin{example}
Take a look at a function $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$, which represents an arbitrary surface in $\mathbb{R}^2 \oplus \mathbb{R}$. Now, observe the constant function $c(x, y) \equiv c$, which represents a plane parallel to the $x, y$-plane. Clearly, we can imagine a deformation of the surface of $f$ to the flat surface of $c$ with the homotopy
\[H(x, t) \equiv t \, f(x) + (1-t) c(t)\]
which visually represents a linear deformation of $c$ to $f$. Therefore, $f$ is null-homotopic. 
\end{example}

\begin{example}
A map $f: S^1 \longrightarrow X$ is null homotopic precisely when it can be continuously extended to a map 
\[\Tilde{f}: D^2 \longrightarrow X\]
that agrees with $f$ on the boundary $\partial D^2 = S^1$. Visually, the existence of $\Tilde{f}$ allows us to continuously deform the image of $f$ in $S^1 \oplus X$ to a level curve $f(x) = c$ existing in $S^1 \oplus X$. 
\end{example}

\begin{proposition}
A space $X$ is contractible if any only if the identity map from $X$ to itself, which is always a homotopy equivalence, is null homotopic. 
\end{proposition}

\begin{example}
Let $Y$ be the following gray subset of the plane, and let $X$ be the figure-8 shape. 
\\
\begin{center}
\begin{tikzpicture}
    \draw (-2,0) circle (1);
    \draw (2,0) circle (1);
    \draw[blue] plot [smooth cycle] coordinates{(0,0) (-2.5, 1.5) (-3.5, 0) (-2.5, -1.5)};
    \draw[blue] plot [smooth cycle] coordinates{(0,0) (2.5, 1.5) (3.5, 0) (2.5, -1.5)};
    \draw plot [smooth cycle] coordinates{(0, 1) (1,1.3) (2.5, 2) (4,0) (2.5, -2) (1, -1.3) (0, -1) (-1, -1.3) (-2.5, -2) (-4, 0) (-2.5, 2) (-1, 1.3)};
    \draw[thick, red, ->] (0.55, 1.1)--(0.7,0.7);
    \draw[thick, red, ->] (-0.55, 1.1)--(-0.7,0.7);
\end{tikzpicture}
\end{center}
Then $Y \simeq X$, where the corresponding functions are
\begin{align*}
    & F: X \longrightarrow Y, \text{ the canonical inclusion} \\
    & F: Y \longrightarrow X, \text{ the projection onto X}
\end{align*}
Then, $G \circ F = id$ and $F \circ G$ is homotopic to the identity, with homotopy defined
\[H(x, t) \equiv t (F \circ G) (x) + (1-t) (id_Y) (x)\]
which can be visualized by $H(x, s)$ being the point you get from $x$ by moving a fraction $s$ along the red arrow towards $X$. 
\end{example}

\section{Homeomorphism Groups}

\begin{definition}
The \textit{homeomorphism group} of a topological space $X$ is the group consisting of all homeomorphisms from $X$ to $X$, with function composition as the group operation.
\end{definition}

\begin{theorem}
Homeomorphism groups of homeomorphic topological spaces are isomorphic as groups. 
\end{theorem}

\chapter{Smooth Manifolds}

Manifolds are invaluable in generalizing multiple ideas. For example, it allows us to generalize the concepts to calculus to spaces that are not only globally, but \textit{locally} Euclidean. 

\section{Smooth Manifolds}
\subsection{Topological Manifolds and Topological Properties}
\begin{definition}[Topological Manifold, Coordinate Chart, Atlas]
Suppose $M$ is a topological space. $M$ is a (real) \textit{topological manifold of dimension $N$} if
\begin{enumerate}
    \item $M$ is Hausdorff: for every pair of points $p, q \in M$, there exists disjoint open subsets $U, V \subset M$ such that $p \in U$, $q \in V$. 
    \item $M$ is second countable: There exists a countable basis for the topology of $M$. 
    \item $M$ is locally homeomorphic to $\mathbb{R}^N$: There exists a covering of open sets in $M$ where each open set is homeomorphic to an open set in $\mathbb{R}^N$. The visual below shows a 1-dimensional and 2-dimensional manifold. 
    \begin{center}
    \includegraphics[scale=0.20]{1_2_dim_Manifold_Coordinate_Chart.PNG}
    \end{center}
\end{enumerate}
Given open cover $U_1, \ldots, U_n$ with their respective homeomorphism maps $\varphi_1, \ldots, \varphi_n$ where
\[\varphi_i : U_i \longrightarrow \mathbb{R}^n\]
and component maps
\[\varphi_i \equiv (x_{i1}, x_{i2}, ..., x_{in})\]
their pairs $(U_i, \varphi_i)$ are called \textit{coordinate charts}. The collection of all coordinate charts 
\[\mathcal{A} = \{(U_i, \varphi_i)\}_{i=1}^n\]
is called the \textit{atlas} of $M$. 
\end{definition}

Note that the Hausdorff and second-countability condition is sometimes ommitted from the definition of a manifold, but we keep it since: 
\begin{enumerate}
    \item many manifolds in nature have these properties. 
    \item we can deduce must more interesting properties about manifolds with these assumptions.
\end{enumerate}

\begin{theorem}[Product Manifolds]
Let $M_1, M_2, ..., M_n$ be topological manifolds of dimensions $m_1, m_2$ $...m_n$, respectively. Then, the product space 
\[\prod_{i=1}^n M_i\]
is also a topological manifold with 
\[\dim{\prod_{i=1}^n M_i} = \sum_{i=1}^n m_i \]
\begin{center}
    \includegraphics[scale=0.25]{Product_Manifolds.PNG}
\end{center}
\end{theorem}


\begin{example}[Graphs of Continuous Functions]
Given a continuous function $f: U \longrightarrow \mathbb{R}^m$, its graph
\[\Gamma (f) \equiv \{(x, y) \in \mathbb{R}^n \times \mathbb{R}^m \; | \;  x\in U, y = f(x)\}\]
with the subspace topology is a topological manifold. Actually, this manifold is \textit{globally homeomorphic} to an open set in $\mathbb{R}^n$, meaning that this is trivially a manifold. 
\end{example}

\begin{example}[Unit Sphere]
The unit sphere $S^n$ is a topological manifold since we can construct an atlas of charts formed by the stereographic projection. We show the stereographic projection for a $1$-sphere. 
\begin{center}
    \includegraphics[scale=0.25]{1_dim_Stereographic_Projection.PNG}
\end{center}
\end{example}

\begin{example}
The $n$-sphere with the induced open ball topology of $\mathbb{R}^{n+1}$ is not homeomorphic to $\mathbb{R}^{n}$ since $S^{n}$ is compact and $\mathbb{R}^{n}$ is not. However, the $n$-sphere with one point $p \in S^{n}$ removed, $(S^{n} \setminus{\{p\}}, \tau_{\mathbb{R}^{n+1}} |_{S^{n} \setminus{\{p\}}})$ \textit{is} homeomorphic to $\mathbb{R}^{n}$ and is also not compact. We can visualize this homeomorphism by imagining the "hole" getting larger and stretching $S^{2}$ out to "look like" $\mathbb{R}^{2}$.
\end{example}

\begin{example}
The $n$-turous, defined
\[\mathbb{T}^n \equiv \prod_n S^1\]
is a product manifold. 
\end{example}

We end this section by stating a theorem that gives topological manifolds a nice basis structure. Recall that a subset $U$ in a topological space $X$ is said to be \textit{precompact} if the closure $\bar{U}$ is compact. 

\begin{lemma}[Basis of Topological Manifolds]
Every topological manifold has a countable basis of precompact coordinate balls. 
\begin{center}
    \includegraphics[scale=0.23]{Precompact_Basis.PNG}
\end{center}
\end{lemma}

\begin{lemma}[Fundamental Groups of Topological Manifolds]
The fundamental group of any topological manifold is countable. 
\end{lemma}

\subsection{Smooth Structures}
Note that even though topological manifolds bear some resemblance to Euclidean space, we cannot do calculus on them since derivatives are not invariant under homeomorphisms. For example, compare the two homeomorphisms $\varphi_1, \varphi_2: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ (shown by visualizing the images of the grid lines), where
\[\varphi_1 (u, v) = (u, v) \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \varphi_2 (u, v) = (u^{1/3}, v^{1/3})\]
\begin{center}
    \includegraphics[scale=0.22]{Nonexistent_Derivative_Homeomorphism.PNG}
\end{center}
Given function $f: M \longrightarrow \mathbb{R}^m$, if topological manifold $M$ has chart $\varphi_1$, $f$ will be considered smooth at $\varphi^{-1}(0)$, but if $M$ has chart $\varphi_2$, $f$ will not be considered smooth at $\varphi^{-2}(0)$. 

Clearly, it is a problem if two different charts around a point gives contradicting things about its smoothness. We can fix this by introducing a structure that makes smoothness invariant. First, recall the definition of a diffeomorphism. 

\begin{definition}[Diffeomorphism]
If smooth $f: U \subset \mathbb{R}^n \longrightarrow V \subset \mathbb{R}^m$ is bijective and has a smooth inverse map, then $f$ is said to be a \textit{diffeomorphism}. That is, a diffeomorphism is a homeomorphism where both the function and its inverse is smooth. More specifically, 
\begin{enumerate}
    \item If $f, f^{-1}$ is of class $C^k$, then it is a $C^k$-diffeomorphism. 
    \item $f, f^{-1}$ is of class $C^\infty$, then it is a $C^\infty$-diffeomorphism, or a smooth diffeomorphism.
\end{enumerate}
\end{definition}

\begin{definition}[Transition Maps, Smooth Atlases]
Let $M$ be a topological manifold with $(U, \varphi), (V, \psi)$ two charts such that $U \cap V \neq \emptyset$. Then, the composite map (between Euclidean spaces)
\[\psi \circ \varphi^{-1} : \varphi(U \cap V) \longrightarrow \psi(U \cap V)\]
is called the \textit{transition map} from $\varphi$ to $\psi$. 
\begin{center}
    \includegraphics[scale=0.27]{Transition_Map.PNG}
\end{center}
The two charts are said to be smoothly (or $C^k$) compatible if either 
\begin{enumerate}
    \item $U \cap V = \emptyset$, or
    \item the transition map $\psi \circ \varphi^{-1}$ is a smooth (or $C^k$) diffeomorphism. Since $\psi \circ \varphi^{-1}$ is a map between Euclidean spaces, this means that $\psi \circ \varphi^{-1}$ has continuous partial derivatives. 
\end{enumerate}
An atlas $\mathcal{A}$ is called a \textit{smooth ($C^k$) atlas} if any 2 charts in $\mathcal{A}$ are smoothly ($C^k$) compatible with each other. 
\end{definition}

\begin{example}
A transition map can be defined between two stereographic projections of the 1-sphere $\delta_{1}: S^{1} \setminus{\{p\}} \longrightarrow \mathbb{R}$ and $\delta_{2}: S^{1} \setminus{\{q\}} \longrightarrow \mathbb{R}$, where $p$ and $q$ are diametrically opposite points of $S^{1}$. By placing $\mathbb{R}$ within $S^{1}$ orthogonal to the line segment $\overline{PQ}$ and intersecting the center of $S^{1}$, we find that the transition function $\delta_{1} \circ \delta_{2}^{-1}(n) = \delta_{2} \circ \delta_{1}^{-1}(n) = \frac{1}{n}$.  
\begin{center}
    \includegraphics[scale=0.25]{1_dim_projection_transition_function.PNG}
\end{center}
\end{example}

Let's go back to our example problem earlier. Given an open neighborhood $M$ around $0 \in \mathbb{R}^2$, the two (global) charts $\varphi_1, \varphi_2$ are not smoothly compatible since 
\[(\varphi_2 \circ \varphi_1^{-1})(u, v) = (u^{1/3}, v^{1/3})\]
is not smooth. Therefore, they cannot be a part of the same smooth atlas. 

Our previous problem hints at another one: Which atlas is the "right" one? In general, there will be many possible choices of atlases that give the "same" smooth structure. The 3 following atlases shown below (consisting of one global chart, for simplicity), are all viable. 
\begin{center}
    \includegraphics[scale=0.32]{Different_Atlases.PNG}
\end{center}
In the visual above, notice that
\begin{enumerate}
    \item $\mathcal{A}_1, \mathcal{A}_2, \mathcal{A}_3$ are all smooth atlases (trivially).
    \item $\varphi_1$ and $\varphi_2$ are smoothly compatible $\implies \mathcal{A}_{12} = \{(M, \varphi_1), (M, \varphi_2)\}$ is a smooth atlas. 
    \item $\varphi_3$ is not smoothly compatible with either $\varphi_1$ nor $\varphi_2$. This implies that $\mathcal{A}_{13} = \{(M, \varphi_1), (M, \varphi_3)\}, A_{23} = \{(M, \varphi_2), (M, \varphi_3)\}$ are not smooth atlases.
\end{enumerate}
Clearly, $\varphi_1$ and $\varphi_2$ are closely related as they are smoothly compatible. Furthermore, 
\[\mathcal{A}_1 \subset \mathcal{A}_{12}, \;\;\; \mathcal{A}_2 \subset \mathcal{A}_{12}\]
Now, imagine an atlas that contains $(M, \varphi_1), (M,\varphi_2)$, and all other possible charts that are smoothly compatible with $\varphi_1$ and $\varphi_2$. This creates a "maximal" smooth atlas. 

\begin{definition}[Maximal Smooth Atlas]
A \textit{maximal smooth ($C^k$)atlas} is a smooth ($C^k$) atlas that is not contained in any strictly larger smooth atlas. In other words, it is the largest possible atlas in which every chart is smoothly ($C^k$) compatible with one another. 
\end{definition}

The existence of this maximal smooth ($C^k$) atlas wouldn't be as helpful without the following lemma, which allows us to easily describe it. 

\begin{lemma}[Induced Maximal Smooth Atlases of Topological Manifolds]
Let $M$ be a topological $n$-manifold. 
\begin{enumerate}
    \item Every smooth atlas for $M$ is contained in a unique maximal smooth atlas. 
    \item Two smooth atlases for $M$ determine the same maximal smooth atlas if and only if their union is a smooth atlas. 
\end{enumerate}
That is, let $A_1, \ldots, A_a, B_1, \ldots, B_b, C_1, \ldots, C_c$ be a collection of smooth atlases on $M$ such that any union of the $A_i$'s, any union of the $B_i$'s, and any union of the $C_i$'s, are smooth atlases. Then, we can imagine all of the $A_i$'s as subsets of the unique maximal atlas $A^*$, all of the $B_i$'s as subsets of the unique maximal atlas $B^*$, and all of the $C_i$'s as subsets of the unique maximal atlas $C^*$. 
\begin{center}
    \includegraphics[scale=0.25]{Maximal_Smooth_Atlas_Classes.PNG}
\end{center}
Therefore, there can exist many smooth structures for topological manifold $M$. 
\end{lemma}

From the lemma, we can clearly see that the atlases form an equivalence class, one for smooth structure. 

\begin{definition}[Smooth Equivalence Relation]
Two atlases $A_1, A_2$ are \textit{smoothly ($C^k$) equivalent} if $A_1 \cup A_2$ forms a smooth ($C^k$) atlas. Note that $C^k$-equivalence is a relation, and so the collection of all atlases that are $C^k$-equivalent forms a $C^k$-equivalence class, which is actually detremined uniquely by the maximal atlas. 
\end{definition}

\begin{definition}[Smooth ($C^k$) Structure, Smooth ($C^k$) Manifolds]
Three closely related definitions: 
\begin{enumerate}
    \item A \textit{smooth ($C^k$) structure} on a topological $n$-manifold $M$ is a maximal smooth ($C^k$) atlas.
    \item A \textit{smooth ($C^k$) manifold} is a pair $(M, \mathcal{A})$, $M$ being a topological manifold and $\mathcal{A}$ a smooth ($C^k$) structure. 
    \item A chart, or a coordinate map, of a smooth manifold, is called a \textit{smooth chart}. 
\end{enumerate}
\end{definition}

Three final things to mention:
\begin{enumerate}
    \item There exist topological manifolds that admit no smooth structures at all. So, we cannot add a smooth structure to every topological manifold. 
    \item It is generally not convenient to define a smooth structure by explicitly describing a maximal smooth atlas, since such an atlas contains many charts. Fortunately, by the previous lemma, we only need to specify \textit{some} smooth atlas, which will induce a maximal smooth atlas. 
    \begin{align*}
        \text{Specify } A_i & \implies \text{Smooth Structure} = A^*\\
        \text{Specify } B_i & \implies \text{Smooth Structure} = B^*\\
        \text{Specify } C_i & \implies \text{Smooth Structure} = C^*
    \end{align*}
    \item In many cases, one proves that a topological manifold $M$ has a smooth atlas by directly computing and seeing that $\psi \circ \varphi^{-1}$ is smooth, for every pair $\psi, \varphi$ in the atlas. Clearly, all of the $\psi \circ \varphi^{-1}$ are homeomorphisms (as compositions of homeomorphisms), and since we've proved them to be smooth, it automatically follows that they are diffeomorphisms. 
\end{enumerate}

\begin{definition}[Other Classes of Manifolds] Let $M$ be a manifold. 
\begin{enumerate}
    \item A $C^0$ manifold is just a topological manifold. 
    \item If the transition mappings of $M$ can be expressed as real analytic (i.e. expressible as a convergent power series in a neighborhood of each point), then $M$ is said to have a $C^\omega$ structure, making $M$ a \textit{real-analytic manifold}. 
    \item If $M$ has an even dimension $2m$, then we can use the fact that $\mathbb{R}^{2m} \simeq \mathbb{C}^m$ to define a $C^m$ structure, making $M$ a \textit{complex manifold}. 
\end{enumerate}
\end{definition}

\begin{example}
Consider $\mathbb{R}$ with the charts $(\mathbb{R}, \text{id})$ and $(\mathbb{R}, x^3)$. Each of these charts cover $\mathbb{R}$, but they are not $C^\infty$-compatible (since $\sqrt[3]{x}$ is not $C^\infty$), which means that they generate different maximal atlases. In fact, in $\mathbb{R}$, there are an infinitely many non-compatible maximal atlases each giving the topological space $\mathbb{R}$ the structure of a differentiable manifold. 
\end{example}

We can actually prove a stronger theorem. 

\begin{theorem}[Distinct Smooth Structures on Positive-Dimensional Smooth Manifolds]
Let $M$ be a nonempty topological manifold of dimension $n \geq 1$. If $M$ has a smooth structure, then it has uncountably many distinct ones. 
\end{theorem}

\subsubsection{Local Coordinate Representations}
We describe how one usually thinks about coordinate charts on a smooth manifold. Once we shoose a smooth chart $(U, \varphi)$ on $M$, the coordinate map 
\[\varphi: U \longrightarrow \Tilde{U} \subset \mathbb{R}^n\]
can be thought of as giving an \textit{identification} between $U$ and $\Tilde{U}$. Using this identification, we can think of $U$ simultaneously as an open subset of $M$ and as an open subset of $\mathbb{R}^n$. You can visualize this identification by thinking of a "grid" drawn on $U$ representing the inverse images of the coordinate lines under $\varphi$. 
\begin{center}
    \includegraphics[scale=0.25]{Grid_Identification.PNG}
\end{center}
Using this identification, we can represent point $p \in U$ by its coordinates
\[\big( x^1, x^2, ..., x^n \big) = \varphi(p)\]
and think of this $n$-tuple as \textit{being} the point $p$ (even though $p$, as an abstract point, really has no coordinates). This is typically expressed by saying that $\big( x^1, ..., x^n\big)$ is the (local) coordinate representation for $p$" or "$p = \big( x^1, ..., x^n\big)$ in local coordinates." Note that the curves (lines) do not necessarily have to be rectilinear. The projected lines from Euclidean space onto the manifold can be of any shape, including polar, as long as it is a homeomorphism. 

\begin{definition}[Einstein Summation Notation]
Due to the abundance of summations in this chapter, we will abbreviate such a sum as such 
\[\sum_i x^i E_i = x^i E_i\]
\end{definition}


\subsubsection{Construction of a Smooth Manifold}
When defining a smooth manifold, we start with a topological space and check that it is a topological manifold, and then we specify a smooth structure. The following lemma combines these steps into one. 

\begin{lemma}[Smooth Manifold Construction Lemma]
Let $M$ be a set, and suppose we are given a collection $\{U_\alpha\}$ of subsets of $M$, together with an injective map $\varphi_\alpha: U_\alpha \longrightarrow \mathbb{R}^n$ for each $\alpha$, such that the following properties are satisfied:
\begin{enumerate}
    \item For each $\alpha$, $\varphi_\alpha (U_\alpha)$ is an open subset of $\mathbb{R}^n$.
    \item For each $\alpha$ and $\beta$, $\varphi_\alpha (U_\alpha \cap U_\beta)$ and $\varphi_\beta (U_\alpha \cap U_\beta)$ are open in $\mathbb{R}^n$. 
    \item Whenever $U_\alpha \cap U_\beta \neq \emptyset$, $\varphi_\alpha \circ \varphi_\beta^{-1}: \varphi_\beta (U_\alpha \cap U_\beta) \longrightarrow \varphi_\alpha (U_\alpha \cap U_\beta)$ is a diffeomorphism. 
    \item $M$ is second countable. 
    \item $M$ is Hausdorff. 
\end{enumerate}
Then, $M$ has a unique smooth manifold structure such that each $(U_\alpha, \varphi_\alpha)$ is a smooth chart. 
\end{lemma}

\subsection{Manifolds with Boundaries}
We may come across manifolds which have a "boundary" of some sort, such as the closed unit ball in $\mathbb{R}^n$ and the closed upper hemisphere in $S^n$. 

\begin{definition}[Euclidean Upper Half-Space]
The \textit{closed $n$-dimensional upper half-space} $\mathbb{H}^n \subset \mathbb{R}^n$ is defined
\[\mathbb{H}^n \equiv \big\{ (x^1, x^2, ..., x^n) \in \mathbb{R}^n \;|\; x^n \geq 0\big\}\]
$\mathbb{H}^2$ and $\mathbb{H}^3$ are shown below. 
\begin{center}
    \includegraphics[scale=0.25]{Half_Euclidean_Space.PNG}
\end{center}
Clearly, $\mathbb{H}^n$ has the subspace topology induced by that of $\mathbb{R}^n$, allowing charts to map open neighborhoods of boundary points. We also define
\begin{align*}
    \Int(\mathbb{H}^n) \equiv \big\{ (x^1, x^2, ..., x^n) \in \mathbb{R}^n \;|\; x^n > 0\big\} \\
    \partial(\mathbb{H}^n) \equiv \big\{ (x^1, x^2, ..., x^n) \in \mathbb{R}^n \;|\; x^n = 0\big\}
\end{align*}
\end{definition}

\begin{definition}[Smooth Maps between Subsets]
Note that a smooth map from an arbitrary subset $A \subset \mathbb{R}^n$ to $\mathbb{R}^k$ is defined to be a map that admits a smooth extension to an open neighborhood of each point. 
\begin{center}
    \includegraphics[]{}
\end{center}
\end{definition}

\begin{definition}[Topological Manifold with Boundary]
An \textit{$n$-dimensional topological manifold with boundary} is a second-countable Hausdorff space $M$ that is locally homeomorphic to $\mathbb{H}^n$. 

An open subset $U \subset M$ together with a homeomorphism $\varphi$ from $U$ to an open subset of $\mathbb{H}^n$ is called a chart.
\begin{enumerate}
    \item $(U, \varphi)$ is an \textit{interior chart} if $\varphi(U) \subset \Int(\mathbb{H}^n)$. 
    \item $(U, \varphi)$ is a \textit{boundary chart} if $\varphi(U) \cap \partial \mathbb{H}^n \neq \emptyset$
\end{enumerate}
\begin{center}
    \includegraphics[scale=0.25]{Interior_Boundary_Chart.PNG}
\end{center}
A point $p \in M$ is a \textit{boundary point} if its image under some smooth shart is in $\partial \mathbb{H}^n$; the set of all such boundary points is denoted $\partial M$. The set of all interior points of $M$ is denoted Int$(M)$. Furthermore, it turns out that
\[M = \text{Int}(M) \sqcup \partial M\]
That is, $M$ can be partitioned into its interior and boundary. 
\end{definition}

To define a smooth structure on a manifold with boundary, we must be able to define smooth maps that encompasses cases between boundary charts. 

\begin{definition}
Thus, if $U$ is an open subset of $\mathbb{H}^n$, a map $F: U \longrightarrow \mathbb{R}^k$ is smooth if for each $x \in U$ there exists an open neighborhood $V \subset \mathbb{R}^n$ of $x$ and a smooth map (extension) $\Tilde{F}: V \longrightarrow \mathbb{R}^k$ that agrees with $F$ on $V \cap \mathbb{H}^n$. 
\end{definition}

\begin{definition}[Smooth Manifold with Boundary]
Let $M$ be a topological manifold with boundary. A \textit{smooth structure} for $M$ is defined to be a maximal smooth atlas, i.e. a collection of charts whose domains cover $M$ and whose transition maps (and inverses) are smooth as in it admits smooth extensions. With such a structure, $M$ is called a \textit{smooth manifold with boundary}. 
\end{definition}


Note that the boundary of manifold $M$ and the boundary of $M$ as a subset of a bigger topological space are two completely different sets. 

\begin{example}
Let $B^2$ be the open unit disk in $\mathbb{R}^2$. Then, $\bar{B^2}$, the closed unit disk, is a smooth manifold with boundary, with the boundary being the circle $S^1$. However, if we interpret $B^2$ as a topological subspace 
\begin{enumerate}
    \item $\mathbb{R}^2$, the topological boundary is $S^1$. 
    \item $\mathbb{R}^3$, the topological boundary is $\bar{B^2}$. 
    \item $\bar{B^2}$, the topological boundary is $\emptyset$. 
\end{enumerate}
\end{example}

Furthermore, every smooth $n$-manifold can be considered a smooth $n$-manifold with boundary by composing each chart mapping with a diffeomorphism from $\mathbb{R}^n$ to $\mathbb{H}^n$ such as
\[\big(x^1, ..., x^{n-1}, x^n \big) \mapsto \big( x^1, ..., x^{n-1}, e^{x^n} \big)\]
This modifies all manifold charts to take its values in $\Int(\mathbb{H}^n)$ without affecting the smooth compatibility condition. 
Also, given a smooth $n$-manifold with boundary $M$, $\Int(M)$ is also a topological $n$-manifold since the subfamily of all smooth interior charts is also a smooth atlas. 

\section{Smooth Maps}

\begin{definition}[Smooth Maps from Manifolds to Euclidean Space]
If $M$ is a smooth $n$-manifold, a function $f: M \longrightarrow \mathbb{R}^k$ is said to be \textit{smooth} if for every $p \in M$, there exists a smooth chart $(U, \varphi)$ for $M$ whose domain contains $p$ and such that the composite function, called the \textit{coordinate representation of $f$}
\[\hat{f} = f \circ \varphi^{-1}: \varphi(U) \subset \mathbb{R}^n \longrightarrow \mathbb{R}^k\]
is smooth. 
\begin{center}
    \includegraphics[scale=0.24]{Function_Manifold_to_Euclidean_Space.PNG}
\end{center}
By definition, $f$ is smooth if and only if its coordinate representation is smooth in some smooth chart around every point. 
\end{definition}

The set of smooth real-valued functions $f: M \longrightarrow \mathbb{R}$ is denoted as $C^\infty (M)$. Since sums and constant multiples of smooth functions are smooth, $C^\infty (M)$ is a vector space. 

\begin{definition}[Smooth Maps between Manifolds]
Let $M, N$ be smooth $m, n$-manifolds, and let $F: M \longrightarrow N$ be any map. Then, $F$ is a \textit{smooth map} if for every $p \in M$, there exist smooth charts $(U, \varphi)$ containing $p$ and $(V, \psi)$ containing $F(p)$ such that $F(U) \subset V$ and the composite map 
\[\psi \circ F \circ \varphi^{-1}: \varphi(U) \subset \mathbb{R}^m \longrightarrow \psi(V) \subset \mathbb{R}^n\]
is smooth (in the regular Euclidean sense). The abstraction of $F$ does not do us much good computation wise, so more often than not, we look at the \textit{coordinate representation of $F$}
\[\hat{F} \equiv \psi \circ F \circ \varphi^{-1}\]
In here, $\hat{F}$ is really just a representation of the abstract map $F$ in specific local coordinates determined by $\varphi$ and $\psi$. Once $\varphi, \psi$ are determined, we can often ignore the distinction between $F$ and $\hat{F}$. 

Application-wise, there are three ways to prove that a particular map is smooth: 
\begin{enumerate}
    \item Write the map in smooth local coordinates and recognize its component functions as compositions of smooth elementary functions. 
    \item Exhibit the map as a composition of known smooth maps. 
    \item Use some special-purpose theorem that applies to the particular case. 
\end{enumerate}
\begin{center}
    \includegraphics[scale=0.25]{Functions_between_Manifolds.PNG}
\end{center}
\end{definition}

\begin{theorem}[Properties of Smooth Maps between Manifolds]
Given $M, N$ smooth $m, n$-manifolds, with arbitrary map $F: M \longrightarrow N$, we have the following properties: 
\begin{enumerate}
    \item If $F$ is smooth, then $F$ is continuous. 
    \item The composition of smooth maps between smooth manifolds is smooth. 
    \item If there exists an open cover $\{U_\alpha\}_\alpha$ of $M$ and smooth maps $F_\alpha: U_\alpha \longrightarrow N$ such that they agree on overlaps
    \[F_\alpha \big|_{U_\alpha \cap U_\beta} = F_\beta \big|_{U_\alpha \cap U_\beta} \text{ for all } \alpha, \beta\]
    then there exists a unique smooth map $F: M \longrightarrow N$ such that $F$ agrees with all the $F_\alpha$'s. 
\end{enumerate}
The last property is convenient for when we wish to construct a global smooth map from local ones. 
\end{theorem}
\begin{proof}
We prove the first two properties: 
\begin{enumerate}
    \item Suppose $F: M \longrightarrow N$ is smooth. The definition of smoothness guarantees that for every $p \in M$, we can choose smooth charts $(U, \varphi)$ containing $p$ and $(V, \psi)$ containing $F(p)$ such that $F(U) \subset V$ and $\psi \circ F \circ \varphi^{-1}: \psi(U) \longrightarrow \varphi(V)$ is smooth, hence continuous. Since $\varphi$ and $\psi$ are homeomorphisms, this implies that
    \[F \big|_U = \psi^{-1} \circ \big( \psi \circ F \circ \varphi^{-1} \big) \circ \varphi : U \longrightarrow V\]
    is continuous, as a composition of continuous maps. Since $F$ is continuous at each point, it is continuous on $M$.
    \item Looking at the diagram below, we can see that since $F, G$ are smooth, the mappings (between Euclidean spaces) $\theta \circ F \circ \varphi^{-1}$ and $\psi \circ G \circ \theta^{-1}$ are smooth, meaning that their composition
    \[(\psi \circ G \circ \theta^{-1}) \circ (\theta \circ F \circ \varphi^{-1}) = \psi \circ (G \circ F) \circ \varphi^{-1}\]
    is smooth. By definition, this means that $G \circ F$ is smooth. 
    \begin{center}
        \includegraphics[scale=0.25]{Composition_of_Smooth_Manifold_Mappings.PNG}
    \end{center}
\end{enumerate}
\end{proof}

\subsubsection{Clarification of Multiple Meanings of Smoothness}
We emphasize that the smoothness of a map $F$ between manifolds depends \textbf{only} on the smoothness of its coordinate representation $\hat{F}$! This warning is more clearly explained through the following example. 

\begin{example}[Mappings between Lines with Different Smooth Structures]
Let us have manifold $\mathbb{R}$ with the standard smooth structure determined by global mapping id$: \mathbb{R} \longrightarrow \mathbb{R}$. Let us have a second manifold $\Tilde{\mathbb{R}}$ with smooth structure determined by global mapping $\psi(x) = x^{1/3}$. Now, let us have mappings (between manifolds) $F_1, F_2, F_3: \mathbb{R} \longrightarrow \Tilde{\mathbb{R}}$ where $F_1 (x) = x, F_2 (x) = x^3, F_3(x) = x^6$, as shown below. 
\begin{center}
    \includegraphics[scale=0.25]{Real_Line_Manifold_Functions.PNG}
\end{center}
Then,
\begin{align*}
    \psi \circ F_1 \circ \text{id}^{-1} (x)= x^{1/3} & \implies F_1 \text{ not smooth} \\
    \psi \circ F_2 \circ \text{id}^{-1}(x) = x & \implies F_2 \text{ smooth} \\
    \psi \circ F_3 \circ \text{id}^{-1}(x) = x^{2} & \implies F_3 \text{ smooth} 
\end{align*}
\end{example}

Note that the smoothness of the $F_i$'s when interpreting them as mappings between manifolds gives results compared to when we interpret them as regular mappings between Euclidean space. For example, $F_1$ is not smooth in the manifold sense even though it is clearly smooth in the Euclidean sense (since it is the identity mapping).  

\subsection{Diffeomorphisms}
\begin{definition}[Diffeomorphism]
A \textit{diffeomorphism} between smooth manifolds $M$ and $N$ is a smooth bijective map $F: M \longrightarrow N$ that has a smooth inverse. It is said that $M$ and $N$ are \textit{diffeomorphic} if there exists a diffeomorphism between them, denoted as 
\[M \approx N\]
This is in fact an equivalence relation. Just as two topological spaces are considered to be the same if they are homeomorphic, two smooth manifolds are essentially indistinguishable if they are diffeomorphic. Clearly, diffeomorphisms preserve the dimensionalities of $M$ and $N$. 
\end{definition}

Clearly, if $M$ is any smooth manifold and $(U, \varphi)$ is a smooth coordinate chart on $M$, then $\varphi: U \longrightarrow \varphi(U) \subset \mathbb{R}^n$ is a diffeomorphism (by definition). 

\begin{example}
Let $B^n$ be the open unit ball in $\mathbb{R}^n$ (each with the standard smooth structure). Then, the map 
\[F: B^n \longrightarrow \mathbb{R}^n, \; F(x) \equiv \frac{x}{1 - ||x||^2}\]
is a diffeomorphism. 
\end{example}

\begin{example}[Mappings between Lines with Different Smooth Structures]
In the diagram below regarding a previous example, we have the three maps $F_1, F_2, F_3: \mathbb{R} \longrightarrow \Tilde{\mathbb{R}}$, where $\mathbb{R}$ is a smooth manifold with the standard smooth structure, and $\Tilde{\mathbb{R}}$ is a smooth manifold with the smooth structure consisting of $\psi$. 
\begin{center}
    \includegraphics[scale=0.25]{Real_Line_Manifold_Functions.PNG}
\end{center}
To find out whether $F_i$ is a diffeomorphism, we must confirm that $F_i$ is bijective, smooth, and $F_i^{-1}$ is smooth. 
\begin{enumerate}
    \item $F_1$ is clearly bijective. $\psi \circ F_1 \circ id^{-1} (x) = x^{1/3}$, so $F_1$ is not smooth. $id \circ F_1^{-1} \circ \psi^{-1} = x^3$, so $F_1^{-1}$ is smooth. 
    \item $F_2$ is clearly bijective. $\psi \circ F_2 \circ id^{-1} (x) = x$, so $F_2$ is smooth. $id \circ F_2^{-1} \circ \psi^{-1} = x$, so $F_2^{-1}$ is smooth.
    \item $F_3$ is not bijective. $\psi \circ F_3 \circ id^{-1} (x) = x^2$, so $F_3$ is smooth. Since $F_3$ is not injective, $F_3^{-1}$ is not well-defined. 
\end{enumerate}
Therefore, $F_2$ is the only diffeomorphism out of the three observed functions. 
\end{example}

\begin{definition}[Local Diffeomorphism]
$F: M \longrightarrow N$ is called a \textit{local diffeomorphism} if every point $p \in M$ has a neighborhood $U$ such that $F(U)$ is open in $N$ and 
\[F \big|_U : U \longrightarrow F(U)\]
is a diffeomorphism. 
\end{definition}

\subsubsection{Nondiffeomorphic Smooth Structures on Manifolds}
We already found out that there are many distinct structures on a positive-dimensional smooth manifold (in fact, an uncountable number of them). Furthermore, we have seen in this section that there may exist a diffeomorphism between the two copies of the topological manifold, each with distinct smooth structures ($F_2 (x) = x^3$ was a diffeomorphism between $(\mathbb{R}, \text{id})$ and $(\mathbb{R}, \psi)$. 

This leads to the more interesting question of whether a given topological manifold admits smooth structures that are \textit{not} diffeomorphic to each other (as in, there exists no diffeomorphism $F$ between two copies of a given topological manifold, each with distinct smooth structures). 

\begin{definition}[Diffeomorphic Smooth Structures]
Given a topological manifold $M$, let $\mathcal{A}_1$ and $\mathcal{A}_2$ any two smooth structures on $M$. Then, 
\[(M, \mathcal{A}_1) \approx (M, \mathcal{A}_2)\]
if there exists some diffeomorphism $F: (M, \mathcal{A}_1) \longrightarrow (M, \mathcal{A}_2)$. If the underlying manifold $M$ is known, then we write this more concisely as
\[\mathcal{A}_1 \approx \mathcal{A}_2\]
and say that
\begin{enumerate}
    \item $\mathcal{A}_1$ and $\mathcal{A}_2$ are diffeomorphic smooth structures on $M$, or
    \item $\mathcal{A}_1$ and $\mathcal{A}_2$ are identical smooth structures on $M$ up to diffeomorphism.
\end{enumerate}
In fact, the properties of smooth mappings imply that this relation $\approx$ endowed on the set of all smooth structures of $M$ forms equivalence classes of diffeomorphic smooth structures. 

Visually, given that $A^*, B^*, C^*, \ldots$ are smooth structures on $M$, they can be classified further into their respective diffeomorphism classes. 
\begin{center}
    \includegraphics[scale=0.25]{Diffeomorphism_Classes.PNG}
\end{center}
\end{definition}

\begin{example}[Diffeomorphic Smooth Structures of $\mathbb{R}$]
Since $F_2 = x^3$ is a diffeomorphism between $(\mathbb{R}, \text{id})$ and $(\Tilde{\mathbb{R}}, \psi)$, the two atlases $\{\mathbb{R}, \text{id}\}$ and $\{\mathbb{R}, \psi\}$ are diffeomorphic smooth structures: 
\[\{\mathbb{R}, \text{id}\} \approx \{\mathbb{R}, \psi\}\]
It turns out that every smooth structure of $\mathbb{R}$ is equivalent in this sense. That is, there is only one smooth structure on $\mathbb{R}$ up to diffeomorphism. 
\end{example}


\begin{theorem}[Classification of Nondiffeomorphic Smooth Structures on $\mathbb{R}^n$]
The classification of smooth structures on Euclidean space is as follows: 
\begin{enumerate}
    \item When $n \neq 4$, $\mathbb{R}^n$ has one unique smooth structure up to diffeomorphism.
    \item $\mathbb{R}^4$ has uncountably many distinct smooth structures, no two of which are diffeomorphic to each other! The study of \textit{exotic $\mathbb{R}^4$}s arises from this phenomenon. 
\end{enumerate}
\end{theorem}

For compact manifolds, the situation is even more fascinating.

\begin{theorem}[Classification of Nondiffeomorphic Smooth Structure on $\mathbb{S}^n$]
The table below details the number of unique smooth structures on $\mathbb{S}^n$ (for $n$ up to $12$) up to diffeomorphism. 
\begin{center}
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c}
    n & 1 & 2&3&4&5&6&7&8&9&10&11&12 \\
    \hline
    Smooth Struc. on $\mathbb{S}^n$ & 1&1&1&?&1&1&28&2&8&6&992&1
\end{tabular}
\end{center}

Notice that the number of smooth structures on the exotic $4$-sphere is still unanswered. 
\end{theorem}

\subsection{Lie Groups}
\begin{definition}[Lie Group]
A \textit{Lie group} is a smooth manifold $G$ that is also a group in the algebraic sense, with the property that 
\begin{enumerate}
    \item the multiplication map $m: G \times G \longrightarrow G, \;\; m(g, h) \equiv g h$ is smooth. That is, the function $\phi \circ m \circ (\varphi \times \psi)^{-1}: \mathbb{R}^{2m} \longrightarrow \mathbb{R}^m$ in the visual below is smooth in the Euclidean sense.  
    \begin{center}
        \includegraphics[scale=0.28]{Lie_Group_Multiplication.PNG}
    \end{center}
    \item the inversion map $i: G \longrightarrow G, \;\; i(g) \equiv g^{-1}$ is smooth. That is, the function $\theta \circ i \circ \varphi^{-1}: \mathbb{R}^m \longrightarrow \mathbb{R}^m$ in the visual below is smooth in the Euclidean sense.  
    \begin{center}
        \includegraphics[scale=0.29]{Lie_Group_Inversion.PNG}
    \end{center}
\end{enumerate}
\end{definition}

\begin{definition}[Lie Group Homomorphism]
If $G$ and $H$ are Lie groups, a \textit{Lie group homomorphism} from $G$ to $H$ is a smooth map $F: G \longrightarrow H$ that is also a group homomorphism. 
The smoothness of $F$ (a smooth property) and its preservance of the algebraic structure of $G$ (an algebraic property) can be comphrensively shown in the commutative diagram below.
\[
  \begin{tikzcd}
    \mathbb{R}^m \times \mathbb{R}^m & G \times G \arrow{l}{\varphi \times \varphi} \arrow{r}{m_1} \arrow{d}{F \times F} & G \arrow{r}{\varphi} \arrow{d}{F} & \mathbb{R}^m \\
    \mathbb{R}^n \times \mathbb{R}^n & H \times H \arrow{l}{\psi \times \psi} \arrow{r}{m_2} & H \arrow{r}{\psi} & \mathbb{R}^n
  \end{tikzcd}
\]
Note that
\begin{enumerate}
    \item $\varphi \times m_1 \times (\varphi \times \varphi)^{-1} : \mathbb{R}^m \times \mathbb{R}^m \longrightarrow \mathbb{R}^m$ and $\psi \circ m_2 \circ (\psi \times \psi)^{-1}: \mathbb{R}^n \times \mathbb{R}^n \longrightarrow \mathbb{R}^n$ are smooth since $G$ and $H$ are Lie groups. 
    \item $F \circ m_1: G \times G \longrightarrow H$ and $m_2 \circ (F \times F): G \times G \longrightarrow H$ are smooth since $F$ is a Lie group homomorphism. Note that since $F \circ m_1$ and $m_2 \circ (F \times F)$ are smooth maps between manifolds, it really means that the maps 
    \begin{align*}
        \psi \circ F \circ m_1 \circ (\varphi \times \varphi)^{-1}: &\mathbb{R}^m \times \mathbb{R}^m \longrightarrow \mathbb{R}^n \\
        \psi \circ m_2 \circ (F \times F) \circ (\varphi \times \varphi)^{-1}: &\mathbb{R}^m \times \mathbb{R}^m \longrightarrow \mathbb{R}^n
    \end{align*}
    are smooth in the Euclidean sense. 
\end{enumerate}
$F$ is called a \textit{Lie group isomorphism} if it is also a diffeomorphism, which implies that it has an inverse that is also a Lie group homomorphism. This means that $G$ and $H$ are \textit{isomorphic Lie groups}, meaning that they are indistinguishable as topological spaces, smooth manifolds, and as algebraic structures. 
\end{definition}

\subsection{Smooth Covering Maps, Proper Maps}

\subsection{Partitions of Unity}
Recall the Gluing Lemma from topology, which allows us to construct continuous maps by "gluing together" maps defined on subspaces. 

\begin{lemma}[Pasting Lemma, Gluing Lemma]
Let $X = A \cup B$, where $A, B$ are closed in $X$. Let $f: A \longrightarrow Y$ and $g: B \longrightarrow Y$ be continuous. If 
\[f(x) = g(x) \text{ for all } x \in A \cap B\]
Then $f$ and $g$ can be combined to form a continuous function $h: X \longrightarrow Y$, defined
\[h(x) \equiv \begin{cases}
      f(x) & x \in A \setminus B \\
      f(x) \text{ or } g(x) & x \in A \cap B \\
      g(x) & x \in B \setminus A
\end{cases}\]
\end{lemma}

For smooth manifolds, however, the gluing lemma is of limited usefulness, since the produced map, while continuous, is rarely smooth. Observe the following example. 

\begin{example}
Given two functions $f_+: [0, \infty) \longrightarrow \mathbb{R}$ and $f_-: (-\infty, 0] \longrightarrow \mathbb{R}$ defined by 
\begin{align*}
    f_+(x) = + x, & x \in [0, \infty) \\
    f_-(x) = - x, & x \in (-\infty, 0]
\end{align*}
are both smooth and agree at the point $0$ where they overlap, but the continuous map $f: \mathbb{R} \longrightarrow \mathbb{R}$ that they define, $f(x) = |x|$, is not smooth at the origin. 
\end{example}

Partitions of unity solves this problem as tools for patching together local smooth maps into global ones. We must first establish the existence of smooth functions that are positive in a specified part of a manifold and identically zero in some other part. 

\begin{lemma}
The function $f: \mathbb{R} \longrightarrow \mathbb{R}$ defined by 
\[f(t) \equiv \begin{cases}
      e^{-1/t} & t > 0 \\
      0 & t \leq 0
\end{cases}\]
is smooth. 
\end{lemma}
\begin{proof}
By induction, showing that the $k$th derivative of $f$ is of the form
\[f^{(k)} (t) = \frac{p_k (t)}{t^{2k}} e^{-1/t}\]
\end{proof}

\begin{lemma}
There exists a smooth function $h: \mathbb{R} \longrightarrow \mathbb{R}$, called the \textit{cutoff function}, such that 
\[h(t) \equiv \begin{cases}
      1 & t \leq 1 \\
      0 < h(t) < 1 & 1 < t < 2 \\
      0 & t \geq 2
\end{cases}\]
\end{lemma}

\begin{definition}
If $f$ is any real-valued or vector-valued function on a topological space $M$, the \textit{support of $f$}, denoted by supp$f$, is the closure of the set of points where $f$ is nonzero. 
\[\text{supp} f \equiv \text{cl} \big(\{p \in M\;|\; f(p) \neq 0\}\big)\]
If supp$f$ is contained in some set $U$, we say that $f$ is \textit{supported in $U$}. A function $f$ is said to be \textit{compactly supported} if supp$f$ is a compact set. Clearly, every function on a compact space is compactly supported. 
\end{definition}

\begin{lemma}
There is a smooth function $H: \mathbb{R}^n \longrightarrow \mathbb{R}$ such that $0 \geq H(x) \geq 1$ everywhere, $H \equiv 1$ on $\bar{B}_1 (0)$, and supp$H = \bar{B}_2 (0)$, where $B_i (c)$ is the open ball with radius $i$ centered at $c$. 
\end{lemma}
\begin{proof}
Just set $H(x) = h(||x||)$,  where $h$ is the cutoff function. 
\end{proof}

We can visualize the function $H$ in the preceding lemma by assigning a greyscale color to the space $\mathbb{R}^n$ ($1$ representing black, $0$ representing white, and everything in between is greyscale). Then, $H$ would produce a black closed ball of radius $1$ in $\mathbb{R}^n$, with a smoothly changing shade of grey outside the ball of radius $1$ but in the ball of radius $2$, which then smoothly transitions to white for the rest of $\mathbb{R}^n \setminus B_2 (0)$. 

The function $H$ constructed in this lemma is an example of a \textit{smooth bump function}, a smooth real-valued function that is equal to $1$ on a specified closed set (in this case, $\bar{B}_1 (0)$) and is supported in a specified open set (in this case, any open set containing $\bar{B}_2 (0)$). Later, we will generalize this notion to manifolds. 

\subsubsection{Paracompactness}
In order to rigorously define the existence of partitions of unity, we must introduce some technical definitions. The biggest takeaway from this section is that a smooth manifold $M$ that is paracompact admits a smooth partition of unity. 

\begin{definition}
Let $X$ be a topological space. A collection $\mathcal{U}$ of subsets of $X$ is said to be \textit{locally finite} if each point of $X$ has a neighborhood that intersects at most finite many of the sets in $\mathcal{U}$. 

Clearly, an open cover of $X$ where each open set intersects finitely many others is locally finite.
\end{definition}

\begin{definition}
Given an open cover $\mathcal{U}$ of $X$, another open cover $\mathcal{V}$ is called a \textit{refinement} of $\mathcal{U}$ if for each $V \in \mathcal{V}$ there exists some $U \in \mathcal{U}$ such that $V \subset U$ (in a way, $\mathcal{V}$ is finer than $\mathcal{U}$).  
\end{definition}

\begin{definition}
A topological space $X$ is \textit{paracompact} if every open cover of $X$ admits a locally finite refinement. 
\end{definition}

\begin{proposition}
Let $M$ be a smooth manifold. Every open cover of $M$ has a regular refinement. In particular, $M$ is paracompact. 
\end{proposition}

\begin{definition}
Let $M$ be a topological space, and let $\mathcal{X} = \{X_\alpha\}_{\alpha \in A}$ be an arbitrary open cover of $M$. A \textit{partition of unity subordinate to $\mathcal{X}$} is a collection of continuous functions $\{ \psi_\alpha: M \longrightarrow \mathbb{R}\}$ with the following properties. 
\begin{enumerate}
    \item $0 \leq \psi_\alpha (x) \leq 1$ for all $\alpha \in A$ and all $x \in M$. 
    \item supp$\psi_\alpha \subset X_\alpha$. 
    \item The set of supports $\{$supp$\psi_\alpha\}$ is locally finite. 
    \item $\sum_{\alpha \in A} \psi_\alpha (x) = 1$ for all $x \in M$. 
\end{enumerate}
A \textit{smooth} partition of unity is one for which each of the functions $\psi_\alpha$ is smooth. 
\end{definition}

\begin{theorem}[Existence of Partitions of Unity]
If $M$ is a smooth manifold and $\mathcal{X} = \{X_\alpha\}_{\alpha \in A}$ is any open cover of $M$, there exists a smooth partition of unity subordinate to $\mathcal{X}$. 
\end{theorem}

\begin{proposition}[Existence of Bump Functions]
Let $M$ be a smooth manifold. For any closed set $A \subset M$ and any open set $U$ containing $A$, there exists a smooth bump function for $A$ supported in $U$. 
\end{proposition}

\section{Tangent Vectors}
In order to utilize linear approximations on smooth manifolds, we introduce the notion of a tangent space on a manifold. 
\subsubsection{Geometric Tangent Vectors}
Let us assign a vector space, called a \textit{tangent space} to each point in $\mathbb{R}^n$. That is, the \textit{geometric tangent space} to $\mathbb{R}^n$ at the point $a \in \mathbb{R}^n$ is defined
\[\mathbb{R}_a^n \equiv \{(a, v) \;|\; v \in \mathbb{R}^n \}\]
under the natural operations
\begin{align*}
    v_a + w_a & \equiv (v + w)_a \\
    c (v_a) & \equiv (c v)_a
\end{align*}
A \textit{geometric tangent vector} in $\mathbb{R}^n$ is an element of this space, denoted $v_a$, and $\mathbb{R}^n_a \simeq \mathbb{R}^n$. Note that while these tangent spaces are isomorphic, we distinguish them with the subscripts $a$ representing the point. 

When looking at other sets in Euclidean space, such as $S^{n-1} \subset \mathbb{R}^n$, we can define the tangent space as the space of vectors that are orthogonal to the radial unit vector through $a$. But this definition is limited within the confines of Euclidean space and not for abstract manifolds. Therefore, we must utilize the concept of directional derivatives, which is provided by a tangent vector, to construct tangent spaces. 

For example, a geometric tangent vector $v_a \in \mathbb{R}^n_a$ yields a map
\[D_v \big|_a: C^\infty (\mathbb{R}^n) \longrightarrow \mathbb{R}\]
which takes the directional derivative in the directoin $v$ at $a$.
\[D_v \big|_a f = D_v f(a) = \frac{d}{dt} \bigg|_{t=0} f(a + t v)\]
This differential operation at the point $a$ is linear and satisfies the product rule
\[D_v \big|_a (f g) = f(a) D_v \big|_a g +g(a) D_v \big|_a f\]
If $v_a = v^i e_i |_a$ in terms of the standard basis (where $e_i |_a$ is the basis of $\mathbb{R}^n_a$), then by the chain rule $D_v |_a f$ can be written more concretely as
\[D_v \big|_a f = v^i \frac{\partial f}{\partial x^i} (a)\]

\begin{definition}
If $a \in \mathbb{R}^n_a$, a linear map $X: C^\infty (\mathbb{R}^n) \longrightarrow \mathbb{R}$ is called a \textit{derivation at $a$} if it satisfies the following product rule 
\[X (f g) = f(a) X g + g(a) X f\]
Furthermore, let $T_a (\mathbb{R}^n)$ denote the set of all derivations of $C^\infty (\mathbb{R}^n)$ at $a$. Let us endow this set with the operations of addition and scalar multiplication 
\begin{align*}
    (X + Y) f & \equiv X f + Y f \\
    (c X) f & \equiv c (X f)
\end{align*}
It can be checked that if $X, Y$ are derivations (i.e. satisfies linearity and the product rule), then $X + Y$ and $c X$ are also derivations, which makes $T_a (\mathbb{R}^n)$ a vector space. 
\end{definition}

\begin{proposition}
For any $a \in \mathbb{R}^n$, the map $v_a \mapsto D_v |_a$ is an isomorphism from $\mathbb{R}_a^n$ to $T_a (\mathbb{R}^n)$. 
\end{proposition}

\begin{corollary}
For any $a \in \mathbb{R}^n$, the $n$ derivations 
\[\frac{\partial}{\partial x^1} \bigg|_a, ..., \frac{\partial}{\partial x^n} \bigg|_a, \;\; \frac{\partial}{\partial x^i} \bigg|_a f = \frac{\partial f}{\partial x^i} (a)\]
form a basis for $T_a (\mathbb{R}^n)$, which therefore has dimension $n$. These basis vectors are more commonly known as the partial derivatives of the $C^\infty$ function $f$ at the point $a$. 
\end{corollary}
\begin{proof}
Use the fact that 
\[\frac{\partial}{\partial x^i} \bigg|_a = D_{e_i} \big|_a\]
\end{proof}

So far, given the Euclidean space $\mathbb{R}^n$, we have constructed this: for every $a \in \mathbb{R}^n$, the tangent space $T_a (\mathbb{R}^n)$ consists of vectors that are also derivations of $C^\infty (\mathbb{R}^n)$. In other words, we can view the tangent space at $a$ as the vector space of linear differential operators that each take in a $C^\infty$ function $f: \mathbb{R}^n \longrightarrow \mathbb{R}$ and outputs the directional derivative of $f$ in direction $v$, evaluated at $a$, which is a real number. It turns out that in each tangent space at, say $a \in \mathbb{R}^n$, there exists a basis of directional derivatives (more commonly known as the partial derivatives) in direction $e_i$, the basis vectors, and of course, evaluated at point $a$. 

\subsubsection{Tangent Vectors on Manifolds}

Before we define tangent spaces on a smooth manifold $M$, recall that the definition of a smooth (or $C^\infty$) function $f: M \longrightarrow \mathbb{R}$ says that there exists a smooth chart $(U, \varphi)$ for $M$ whose domain contains $p$ and the composite function
\[f \circ \varphi^{-1}: \mathbb{R}^n \longrightarrow \mathbb{R}\]
is smooth on the open subset $\varphi(U) \subset \mathbb{R}^n$. In other words, we are defining the smoothness of $f$ really through the smoothness of $f \circ \varphi^{-1}$. 

\begin{definition}
Let $M$ be a smooth manifold and let $p$ be a point of $M$. A linear map $X: C^\infty (M) \longrightarrow \mathbb{R}$ is called a \textit{derivation at $p$} if it satisfies 
\[X(f g) = f(p) X g + g(p) X f\]
for all $f, g \in C^\infty (M)$. The set of all derivatives at $p$ is a vector space called the \textit{tangent space to $M$ at $p$}, and is denoted by $T_p M$. An element of $T_p M$ is called a \textit{tangent vector at $p$}. 
\end{definition}

Therefore, we can think of the tangent space of point $p$ in a smooth manifold $M$ as the space of all directional derivatives of a smooth function 
\[f \circ \varphi^{-1}: \mathbb{R}^n \longrightarrow \mathbb{R}\]
evaluated at the point $\varphi^{-1} (p)$. It is good to visualize tangent vectors to an abstract smooth manifold $M$ as arrows that are tangent to $M$ and whose base points are attached to $M$ at the given point. Theorems about tangent vectors must always be proved using the abstract definition in terms of derivations, but the intuition should be guided by the geometric picture. 

\subsection{Pushforwards}
We now observe the way that tangent vectors behave under smooth maps. In the case of a smooth map between Euclidean spaces, the total derivative of the map at a point (represented by its Jacobian matrix) is a linear map that represents the "best linear approximation" to the map near the given point. In the manifold case, there is a similar linear map, but it acts between tangent spaces. 

\begin{definition}
Given smooth manifolds $M$ and $N$ with a smooth map $F: M \longrightarrow N$, we can define for each $p \in M$ a map
\[F_*: T_p M \longrightarrow T_{F(p)} M, \; \big(F_* X \big) (f) \equiv X \big( f \circ F \big) \]
to be the \textit{pushforward associated with $F$}. Note that $X$ is a tangent vector of $M$, while $F_* X$ is a tangent vector of $N$. Furthermore, if $f \in C^\infty(N)$, then $f \circ F \in C^\infty (M)$, which is consistent with the operations. 

The operation $F_* X$ is clearly linear and it satisfies the product rule because
\begin{align*}
    (F_* X) (f g) & = X \big((fg) \circ F \big) \\
    & = X \big( (f \circ F) (g \circ F) \big) \\
    & = f \circ F(p) X(g \circ F) + g \circ F(p) X (f \circ F) \\
    & = f\big(F(p)\big) \big( F_* X \big) (g) + g \big( F(p)\big) \big( F_* X\big) (f)
\end{align*}

\begin{lemma}[Properties of Pushforwards]
Let $F: M \longrightarrow N$ and $G: N \longrightarrow P$ be smooth maps, and let $p \in M$. Then, 
\begin{enumerate}
    \item $F_*: T_p M \longrightarrow T_{F(p)} M$ is linear. 
    \item $(G \circ F)_* = G_* \circ F_* : T_p M \longrightarrow T_{G \circ F (p)} P$. 
    \item $\big( \Id_M \big)_* = \Id_{T_p M} : T_p M \longrightarrow T_p M$. 
    \item If $f$ is a diffeomorphism, then $F_*: T_p M \longrightarrow T_{F(p)} N$ is an isomorphism. 
\end{enumerate}
\end{lemma}
\end{definition}

Note that while the tangent space is defined in terms of smooth functions on the whole manifold, coordinate charts are in general defined on open subsets. The key point is that the tangent space is really a purely local construction. 

\begin{proposition}
Suppose $M$ is a smooth manifold with $p \in M$ and $X \in T_p M$. If $f$ and $g$ are both smooth functions on $M$ that agree on some neighborhood of $p$, then $X f = X g$. 
\end{proposition}

Clearly, this implies that tangent spaces of open submanifolds can be naturally identified with those of the whole manifold. 

\begin{proposition}
Let $M$ be a smooth manifold and let $U \subset M$ be an open submanifold with $i: U \longrightarrow M$ the canonical inclusion map. Then, for any $p \in U$, 
\[i_* : T_p U \longrightarrow T_p M\]
is an isomorphism. 
\end{proposition}

This identification of $X$ to $i_* X$ just says that they are the \textit{same derivation}, with the exception that $X$ acts on functions on the bigger manifold $M$ instead of functions on $U$. This is a harmless claim, since functions can be defined locally. This means that any tangent vector $X \in T_p M$ can be unambiguously applied to functions defined only in a neighborhood of $p$ and not necessarily on all of $M$. 

Note that every finite-dimensional vector space has a natural smooth manifold structure that is independent of any choice of basis or norm. The follow proposition shows that the tangent space to a vector space can be naturally identified with the vector space itself. 

\begin{proposition}[Tangent Space to a Vector Space]
For each finite dimensional vector space $V$ and each point $a \in V$, there is a natural isomorphism $V \rightarrow T_a V$ such that for any linear map $L: V \longrightarrow W$ the following diagram commutes. 
\[\begin{tikzcd}
    V \arrow{r}{\cong} \arrow{d}{L}& T_aV \arrow{d}{L_*} \\
    W \arrow{r}{\cong} & T_{L_a}W 
\end{tikzcd}\]
\end{proposition}

\subsection{Computations in Coordinates}
The work that we have done is quite abstract, so we will do some down-to-earth computations in local coordinates. Let $(U, \varphi)$ be a smooth coordinate chart on $M$. Note that $\varphi$ is a diffeomorphism from $U$ to an open subset $\Tilde{U} \subset \mathbb{R}^n$. Thus, treating $\varphi(U) = \Tilde{U}$ as a submanifold of the manifold $\mathbb{R}^n$, the pushforward of the function $\varphi: U \longrightarrow \mathbb{R}^n$
\[\varphi_* : T_p M \longrightarrow T_{\varphi(p)} \mathbb{R}^n\]
is an isomorphism. We know that $T_{\varphi(p)} \mathbb{R}^n$ has a basis consisting of the derivations $\partial /\partial x^i \big|_{\varphi(p)}, i = 1, 2, ..., n$. Therefore, the pushforwards of these vectors under $(\varphi^{-1})_*$ form a basis for $T_p M$. The images of these vectors will be denoted
\[\frac{\partial}{\partial x^i} \bigg|_p = \big( \varphi^{-1} \big)_* \frac{\partial}{\partial x^i} \bigg|_{\varphi(p)}\]
It is clear that $\partial / \partial x^i \big|_p $ acts on smooth functions $f: U \longrightarrow \mathbb{R}$ by
\[\frac{\partial}{\partial x^i} \bigg|_p \equiv \frac{\partial}{\partial x^i} \bigg|_{\varphi(p)} \big( f \circ \varphi^{-1} \big) = \frac{\partial \hat{f}}{\partial x^i} (\hat{p})\]
where $\hat{f} = f \circ \varphi^{-1}$ is the coordinate representation of $f$, and $\hat{p} = (p^1, ..., p^n) = \varphi(p)$ is the coordinate representation of $p$. This can be summarized in the following lemma. 

\begin{lemma}
Let $M$ be a smooth manifold. For any $p \in M$, $T_p M$ is an $n$-dimensional vector space. If $\big( U, (x^i)\big)$ is any smooth chart containing $p$, the coordinate vectors 
\[\bigg\{ \frac{\partial}{\partial x^1} \bigg|_p, ..., \frac{\partial}{\partial x^n} \bigg|_p \bigg\}\]
form a basis for $T_p M$. Thus any tangent vector can be written uniquely as a linear combination. 
\[X = X^i \frac{\partial}{\partial x^i} \bigg|_p\]
using the summation convention. 
\end{lemma}

The numbers $X^i$ are the \textit{components} of $X$. If $X$ is known, its components can be computed easily from its action on the coordinate functions. That is, for each $j$, we can think of $x^j$ (which outputs the $j$th component of a vector) as a smooth real valued function on $U$, to get
\[X \big(x^j\big) = \bigg(X^i \frac{\partial}{\partial x^i} \bigg|_p \bigg) \big(x^j \big) = X^i \frac{\partial x^j}{\partial x^i} (p) = X^j\]
Abridged, the components of $X$ are given by $X^j = X(x^j)$. 

Now, we observe how pushforwards look in coordinates, starting off with maps between Euclidean spaces. Let $F: U \subset \mathbb{R}^n \longrightarrow V \subset \mathbb{R}^n$ be a smooth map ($U, V$ open sets in their respective spaces). For any $p \in U$, the pushforward is a linear map $F_* : T_p \mathbb{R}^n \longrightarrow T_{F(p)} \mathbb{R}^m$, which has a certain matrix representation under the standard basis coordinates. Taking a typical basis vector $\partial/\partial x^i \big|_p$ in $T_p \mathbb{R}^n$, we find its image in $T_p \mathbb{R}^m$ under $F_*$. Using the chain rule, 
\begin{align*}
    \bigg( F_* \frac{\partial}{\partial x^i} \bigg|_p \bigg) f & = \frac{\partial}{\partial x^i} \bigg|_p \big( f \circ F \big) = \frac{\partial f}{\partial y^j} \big( F(p)\big) \frac{\partial F^j}{\partial x^i} (p) \\
    & = \bigg( \frac{\partial F^j}{\partial x^i} (p) \frac{\partial}{\partial y^j} \bigg|_{F(p)} \bigg) f 
\end{align*}
Thus, 
\[F_* \frac{\partial}{\partial x^i} \bigg|_p = \frac{\partial F^j}{\partial x^i} (p) \frac{\partial}{\partial y^j} \bigg|_{F(p)}\]
This means that the matrix of the pushforward $F_*$ in terms of standard coordinate bases is precisely the Jacobian matrix, or total derivative, of $F$. 
\[\begin{pmatrix}
\frac{\partial F^1}{\partial x^1} (p) & ... & \frac{\partial F^1}{\partial x^n} (p) \\
... & ... & ... \\
\frac{\partial F^m}{\partial x^1} (p) & ... & \frac{\partial F^m}{\partial x^n} (p) 
\end{pmatrix}\]
Therefore, $F_*: T_p \mathbb{R}^n \longrightarrow T_p \mathbb{R}^m$ corresponds to the total derivative $D F (p): \mathbb{R}^n \longrightarrow \mathbb{R}^m$. Now considering the more general case of smooth maps between smooth manifolds: $F: M \longrightarrow N$, the derivation is not very different. Choosing smooth coordinate charts $(U, \varphi)$ for $M$ near $p$ and $(V, \psi)$ for $N$ near $F(p)$, we obtain the coordinate representation 
\[\hat{F} \equiv \psi \circ F \circ \varphi^{-1}: \varphi \big( U \cap F^{-1} (V) \big) \longrightarrow \psi (V)\]
Using the fact that $F \circ \varphi^{-1} = \psi^{-1} \circ \hat{F}$, we compute $F_*: T_p M \longrightarrow T_p N$
\begin{align*}
    F_* \frac{\partial}{\partial x^i} \bigg|_p & = F_* \bigg( ( \varphi^{-1} )_* \frac{\partial}{\partial x^i} \bigg|_{\varphi(p)} \bigg) \\
    & = (\psi^{-1})_* \bigg( \hat{F}_* \frac{\partial}{\partial x^i} \bigg|_{\varphi(p)}\bigg) \\ 
    & = (\psi^{-1})_* \bigg( \frac{\partial \hat{F}^j}{\partial x^i} (\hat{p}) \frac{\partial}{\partial y^j} \bigg|_{\hat{F}(\varphi(p))} \bigg) \\
    & = \frac{\partial \hat{F}^j}{\partial x^i} (\hat{p})\, \frac{\partial}{\partial y^j} \bigg|_{F(p)} 
\end{align*}
Thus, $F_*: T_p M \longrightarrow T_p N$ is represented in terms of the coordinate bases by the Jacobian matrix of the coordinate representation of $F$. One can see that the concept of the pushforward allows us to abstractify the Jacobian matrix into an abstract linear transformation from $T_p M$ to $T_p N$. Because of this, the pushforward of a smooth map $F: M \longrightarrow N$ is sometimes called its differential or its total derivative. We will denote $F_*$ for the pushforward of a smooth map between smooth manifolds and $DF(p)$ for the total derivative of a map between finite dimensional vector spaces. 

\subsubsection{Change of Coordinates}
Let $(U, \varphi)$ and $(V, \psi)$ be two smooth charts on $M$ with $p \in U \cap V$. Let us denote the coordinate function of $\varphi$ by $(x^i)$ and those of $\psi$ by $( \Tilde{x}^i)$. Then, any tangent vector at $p$ can be represented to either basis $ \big( \partial/\partial x^i \big|_p \big)$ or $\big( \partial/\partial \Tilde{x}^i \big|_p \big)$. 

It isn't too difficult to find out how these two representations are related. With the transition map 
\[\psi \circ \varphi^{-1} : \varphi(U \cap V) \longrightarrow \psi (U \cap V), \;\; \psi \circ \varphi^{-1} (x) = \big( \Tilde{x}^1 (x), ..., \Tilde{x}^n (x) \big)\]
the pushforward of $\psi \circ \varphi^{-1} \in$ End$(T_p \mathbb{R}^n)$ can be written
\[\big( \psi \circ \varphi^{-1}\big)_* \frac{\partial}{\partial x^i} \bigg|_{\varphi(p)} = \frac{\partial \Tilde{x}^j}{\partial x^i} \big( \varphi(p) \big) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_{\psi(p)}\]
Letting $\bar{p} = \varphi(p)$, we compute
\begin{align*}
    \frac{\partial}{\partial x^i} \bigg|_p & = \big( \varphi^{-1} \big)_* \frac{\partial}{\partial x_i} \bigg|_{\varphi(p)} = \big( \varphi^{-1} \big)_* \big( \psi \circ \varphi^{-1} \big)_* \frac{\partial}{\partial x_i} \bigg|_{\varphi(p)} \\ 
    & = \big( \psi^{-1}\big)_* \frac{\partial \Tilde{x}^j}{\partial x^i} \big( \varphi(p)\big) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_{\psi(p)} = \frac{\partial \Tilde{x}^j}{\partial x^i} \big( \varphi(p)\big) \big( \psi^{-1}\big)_* \frac{\partial}{\partial \Tilde{x}^j} \bigg|_{\psi (p)} \\
    & = \frac{\partial \Tilde{x}^j}{\partial x^i} (\hat{p}) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_p
\end{align*}
This formula conveniently, looks exactly like the multivariate chain rule of partial derivatives in $\mathbb{R}^n$. Applying this to the components of a vector, 
\begin{align*}
X = X^i \frac{\partial}{\partial x^i} \bigg|_p & = X^i \bigg( \frac{\partial \Tilde{x}^j}{\partial x^i} (\hat{p}) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_p \bigg) \\
& = \bigg(X^i \frac{\partial \Tilde{x}^j}{\partial x^i} (\hat{p}) \bigg) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_p =
\Tilde{X}^j \frac{\partial}{\partial \Tilde{x}^j} \bigg|_p
\end{align*}
We can find that the components transform by the rule 
\[\Tilde{X}^j = \frac{\partial \Tilde{x}^j}{\partial x^i} (\hat{p}) X^i\]

\subsection{Tangent Vectors to Curves}
\begin{definition}
We define a \textit{curve} in manifold $M$ to be a continuous map 
\[\gamma: J \longrightarrow M\]
where $J \in \mathbb{R}$ is an interval. 
\end{definition}

Our construction of tangent vectors and pushforwards leads to a very natural definition of tangent vectors of curves in manifolds. 

\begin{definition}
If $\gamma$ is a smooth curve in smooth manifold $M$, the \textit{tangent vector} to $\gamma$ at $t_0 \in J$ is the vector 
\[\gamma^\prime (t_0) \equiv \gamma_* \bigg( \frac{d}{dt} \bigg|_{t_0} \bigg) \in T_{\gamma(t_0)} M\]
where $d/dt \big|_{t_0}$ is the standard coordinate basis vector for the 1 dimensional $T_{t_0} \mathbb{R}$. 
\end{definition}

The tangent vector acts on $C^\infty(M)$ functions $f$ (that is, $f: M \longrightarrow \mathbb{R}$) by
\[\gamma^\prime (t_0) f = \bigg( \gamma_* \frac{d}{dt} \bigg|_{t_0} \bigg) f = \frac{d}{dt} \bigg|_{t_0} (f \circ \gamma) = \frac{d (f \circ \gamma)}{dt} (t_0)\]
where $f \circ \gamma: \mathbb{R} \longrightarrow \mathbb{R}$. In other words, $\gamma^\prime (t_0)$ is the derivation at $\gamma(t_0)$ obtained by taking the derivative of a function along $\gamma$. Note also that the path function $\gamma$ is also a smooth map between manifolds. 

Let $(U, \varphi)$ be a smooth chart with coordinate functions $(x^i)$. If $\gamma(t_0) \in U$, we can write the coordinate representation of $\gamma$ as $\gamma(t) = \big( \gamma^1 (t), ..., \gamma^n (t)\big)$ for $t$ near $t_0$. (Note that explicitly speaking, we are really writing the shorthand form of $(\varphi \circ \gamma) (t) = \big( (\varphi \circ \gamma)^1 (t), ..., (\varphi \circ \gamma)^n (t)\big)$). Then, the formula  for the pushforward in coordinates becomes 
\[\gamma^\prime (t_0) = (\gamma^i)^\prime (t_0) \frac{\partial}{\partial x^i} \bigg|_{\gamma(t_0)}\]
This means that $\gamma^\prime (t_0)$ is given by essentially the same formula sit would be in Euclidean space: It is the tangent vector whose components in a coordinate basis are the derivatives of the component functions of $\gamma$. 

\begin{lemma}
Let $M$ be a smooth manifold and $p \in M$. Then, every $X \in T_p M$ is the tangent vector to some smooth curve in $M$. 
\end{lemma}

This lemma tells us that we can think of the tangent space at $p$ as the set of tangent vectors to smooth curves in $M$ passing through $p$. Similar results hold under compositions of smooth maps. 

\begin{proposition}
Let $F: M \longrightarrow N$ be a smooth map, and let $\gamma: J \longrightarrow M$ be a smooth curve. For any $t_0 \in J$, the tangent vector at $t = t_0$ to the composite curve $F \circ \gamma: J \longrightarrow N$ is given by 
\[(F \circ \gamma)^\prime (t_0) = F_* \big( \gamma^\prime (t_0) \big)\]
We can think of this composition as the double pushforward of the basis vector $d/dt \big|_{t_0}$ to $T_{\gamma(t_0)} M$ first and $T_{(F \circ \gamma)(t_0)} N$ second). 
\end{proposition}

\section{Vector Fields}
\subsection{The Tangent Bundle}
\begin{definition}
For any smooth manifold $M$, we define the \textit{tangent bundle of $M$}, denoted $TM$ to be the disjoint union of the tangent spaces at all points of $M$. 
\[TM \equiv \bigsqcup_{p \in M} T_p M\]
Elements of $TM$ are written as an ordered pair 
\[\big(p, X \big) \text{ or } X_p, \;\; p \in M, X \in T_p M\]
The tangent bundle also comes with an natural \textit{projection map}
\[\pi: TM \longrightarrow M, \;\; \pi \big(p, X\big) = p\]
which sends each vector in $T_p M$ to the point $p$ at which it is tangent. 
\end{definition}

The following lemma reveals an important property of tangent bundles. 

\begin{lemma}
For any smooth $n$-manifold $M$, the tangent bundle $TM$ has a natural topology and smooth structure that make it into a $2n$-dimensional smooth manifold. With this structure, 
\[\pi: TM \longrightarrow M\]
is a smooth map. 
\end{lemma}

\subsection{Vector Fields on Manifolds}
\begin{definition}
Given a smooth manifold $M$, a \textit{vector field on $M$} is a continuous map 
\[Y: M \longrightarrow TM, \;\; p \mapsto Y_p\]
with the property that 
\[\pi \circ Y = \Id_M\]
or equivalently, $Y_p \in T_p M$ for each $p \in M$. We also say that the vector field is a \textit{section} (as in \textit{cross section}) of the map $\pi: TM \longrightarrow M$ (i.e. a continuous right inverse of $\pi$). 
\end{definition}

While each vector in the vector field $Y$ "lives" in distinct tangent spaces, we can visualize a vector field on manifold $M$ as an arrow attached to each point of $M$, chosen to be tangent to $M$ and to vary continuously from point to point. 

\begin{definition}
A \textit{smooth vector field} is a smooth map from $M$ to $TM$. A \textit{rough vector field} is a (not necessarily continuous) map $Y: M \longrightarrow TM$ satisfying the condition that $\pi\circ Y = \Id_M$. 
\end{definition}

If $Y: M \longrightarrow TM$ is a rough vector field and $\big( U, (x^i)\big)$ is any smooth coordinate chart for $M$, we can write the value of $Y$ at any point $p \in U$ in terms of the coordinate basis vectors. 
\[Y_p = Y^i (p) \frac{\partial}{\partial x^i} \bigg|_p\]
This defines $n$ functions $Y^i: U \longrightarrow \mathbb{R}$, called the \textit{component functions} of $Y$ in the given chart. 

\begin{lemma}[Smoothness Criterion for Vector Fields]
Let $M$ be a smooth manifold, and let $Y: M \longrightarrow TM$ be a rough vector field. If $\big( U, (x^i)\big)$ is any smooth coordinate chart on $M$, then $Y$ is smooth on $U$ if and only if its component functions with respect to this chart are smooth. 
\end{lemma}

With this lemma, it is now sufficient to check the smoothness of the component functions in order to check the smoothness of the entire vector field. The next lemma shows that every tangent vector at a point can be extended to a smooth global vector field. 

\begin{lemma}
Let $M$ be a smooth manifold. If $p \in M$ and $X \in T_p M$, then there exists a smooth vector field $\Tilde{X}$ on $M$ such that $\Tilde{X}_p = X$. 
\end{lemma}

\begin{definition}
Just as for functions, the \textit{support} of a vector field $Y$ is defined to be the closure of the set $\{ p \in M\;|\; Y_p \neq 0\}$. A vector field is said to be compactly supported if its support is a compact set. 
\end{definition}

Furthermore, if $U$ is any open set of $M$, the fact that $T_p U$ is naturally identified with $T_p M$ for each $p \in U$ allows us to identify the subset $\pi^{-1} (U) \subset TM$. Therefore, a vector field on $U$ can be thought of either as a map from $U$ to $TU$ or a map from $U$ to $TM$. If $Y$ is a vector field on $M$, its restriction $Y |_U$ is a vector field on $U$, which is smooth if $Y$ is. 

\begin{definition}
Let us denote the set of all smooth vector fields on $M$ as $\mathcal{T}(M)$. It is a vector space under pointwise addition and scalar multiplication. That is, given $Y, Z \in \mathcal{T}(M)$
\[(a Y + b Z)_p = a Y_p + b Z_p\]
The zero element of this vector space is also the zero vector field. In addition, smooth vector fields can be multiplied by smooth real-valued functions. That is, if $f \in C^\infty (M)$ and $Y \in \mathcal{T}(M)$, then we can define $f Y: M \longrightarrow TM$ as 
\[(fY)_p = f(p) Y_p\]
\end{definition}

The coordinate representation of a vector field $Y$ can also be written as an equation between vector fields rather than at a single point.
\[Y_p = Y^i (p) \frac{\partial}{\partial x^i} \bigg|_p \implies Y = Y^i \frac{\partial}{\partial x^i} \]
A property of vector fields is that they induce operators on the space of smooth real-valued functions $C^\infty (M)$. That is, if $Y \in \mathcal{T}(M)$ and $f \in C^\infty (U)$, where $U$ is an open set in $M$, then we obtain a new function $Y f: U \longrightarrow \mathbb{R}$, defined 
\[Y f \equiv Y^i \frac{\partial}{\partial x^i} (f) \implies Y f(p) \equiv Y_p f \equiv Y^i (p) \frac{\partial}{\partial x^i} f \bigg|_p \]
Note that there is a concrete difference between $Y f$ and $f Y$. $Y f$ is a real valued function shown above, while $f Y$ is a smooth vector field gotten by multiplying the vector produced by $Y$ at point $p$ ($Y_p$) with the value of $f$ at $p$ ($f(p)$). Because the action of a tangent vector on a function is determined by the values of the function in an arbitrarily small neighborhood, it follows that $Y f$ is locally determined. This leads to another sufficient condition for smoothness of vector fields. 

\begin{lemma}
Let $M$ be a smooth manifold, and let $Y: M \longrightarrow TM$ be a rough vector field. Then, $Y$ is smooth if and only if for every open set $U \subset M$ and every $f \in C^\infty (U)$, the function $Y f: U \longrightarrow \mathbb{R}$ is smooth. 
\end{lemma}

Notice that due to to this lemma, a smooth vector field $Y \in \mathcal{T}(M)$ defines a map from $C^\infty(M)$ to itself by the mapping $f \mapsto Y f$. This is clearly linear over $\mathbb{R}$ and satisfies the product rule 
\[Y(f g) = f Y g + g Y f\]
since it satisfies for arbitrary point $p \in M$. 

\begin{definition}
A linear endomorphism $Y$ of $C^\infty (M)$ satisfying 
\[Y(f g) = f Y g + g Y f, \; f, g \in C^\infty(M)\]
is called a \textit{derivation} of $C^\infty (M)$. 
\end{definition}

The next proposition shows that derivations of $C^\infty (M)$ can be identified with smooth vector fields. 

\begin{proposition}
Let $M$ be a smooth manifold. A map $\mathcal{Y}: C^\infty (M) \longrightarrow C^\infty (M)$ is a derivation if and only if it is of the form $\mathcal{Y} f = Y f$ for some smooth vector field $Y \in \mathcal{T}(M)$. 
\end{proposition}

\subsubsection{Pushforwards of Vector Fields}
If $F: M \longrightarrow N$ is a smooth map and $Y$ is a vector field on $M$, then for each point $p \in M$, we obtain a vector $F_* Y_p \in T_{F(p)} N$ by pushing forward $Y_p$. However, this does not in general define a vector field on $N$. For example, if $F$ is not surjective, we cannot assign a vector to point $q \in N \setminus F(M)$. If $F$ is not injective, then for some point of $N$ there may be several different vectors obtained as pushforwards of $Y$ from different points of $M$. Therefore, vector fields do not always push forward. 

\begin{definition}
If $F: M \longrightarrow N$ is smooth and $Y$ is a vector field on $M$, suppose there happens to be a vector $Z$ on $N$ with the property that for each $p \in M$, $F_* Y_p = Z_{F(p)}$. In this case, we say that the vector fields $Y$ and $Z$ are \textit{$F$-related}. 
\end{definition}

The vector field $Z$ in the definition above represents the "closest" vector field on $N$ that we can get that is a pushforward of $Y$. If $F$ is not surjective, the vector field $Z$ can take any value at points $p \in N \setminus F(M)$ (meaning that the $F$-related vector field to $Y$ is not unique). If $F$ is not injective, for all points $a_i$ that map onto $r \in N$, the pushforward of $F$ at each $a_i$ must agree on their output vector in $T_r N$. There is a useful criterion to see if two vector fields are $F$-related. 

\begin{proposition}
Suppose $F: M \longrightarrow N$ is a smooth map, $Y \in \mathcal{T}(M)$, and $Z \in \mathcal{T}(N)$. Then, $Y$ and $Z$ are $F$-related if and only if for every smooth real-valued function defined on an open subset of $N$, 
\[Y (f \circ F) = (Z f) \circ F\]
\end{proposition}

Note that for a given smooth map $F: M \longrightarrow N$ and vector field $Y \in \mathcal{T}(M)$, there may not be \textit{any} vector field on $N$ that is $F$-related to $Y$. However, there is one special case in which there always exists a unique vector field. 

\begin{proposition}
Suppose $F: M \longrightarrow N$ is a diffeomorphism. For every $Y \in \mathcal{T}(M)$, there is a unique smooth vector field on $N$ that is $F$-related to $Y$. 
\end{proposition}

It is quite easy to see why the proposition above is true. Since $F$ is a diffeomorphism (and thus a bijectiion), there will be no points on $N$ where the $F$-related vector field $Z$ is undefined (due to surjectivity) and there will be no contradictions in the values of $Z$ (due to injectivity). Finally, $F$ being a diffeomorphism will ensure smoothness of $Z$. . 

\begin{definition}
In the case where $F: M \longrightarrow N$ is a diffeomorphism, the unique vector field $F_* Y$ that is $F$-related to $Y$ is called the \textit{pushforward of $Y$ by $F$}. Note that $F_* Y$ is defined only if $F$ is a diffeomorphism.  
\end{definition}

\subsubsection{Vector Fields on Manifolds with Boundary}

\subsection{Lie Brackets}

We can fix this problem using the Lie bracket operator. 

\begin{definition}
The operator 
\[[\cdot, \cdot]: \mathcal{T}(M) \times \mathcal{T} (M) \longrightarrow \mathcal{T}(M)\]
is called the \textit{Lie bracket}. Given two vector fields $V, W$ on smooth manifold $M$, we define the $[V, W]$ as 
\[[V, W]: C^\infty(M) \longrightarrow C^\infty (M), \;\; [V, W] f \equiv V W f - W V f\]
\end{definition}

\begin{lemma}
The Lie bracket of any pair of smooth vector fields is a smooth vector field.
\end{lemma}

The value of the vector field $[V, W]$ at a point $p \in M$ is the derivation at $p$ given by the formula
\[[V, W]_p f \equiv V_p (W f) - W_p (V f)\]
but the formula is of limited usefulness for practical computations. The following lemma simpliies it greatly. 

\begin{lemma}
Let $V, W$ be smooth vector fields on a smooth manifold $M$, and let
\[V = V^i \frac{\partial}{\partial x^i} \text{ and } W = W^j \frac{\partial}{\partial x^j}\]
be the coordinate expressions for $V$ and $W$ in terms of some smooth local coordinates $(x^i)$ for $M$. Then, $[V, W]$ hsa the following coordinate expression: 
\[[V, W] = \bigg( V^i \frac{\partial W^j}{\partial x^i} - W^i \frac{\partial V^j}{\partial x^i}\bigg) \frac{\partial}{\partial x^j}\]
or more concisely, 
\[[V, W] = \big(V W^j - W V^j \big) \frac{\partial}{\partial x^j}\]
\end{lemma}
\begin{proof}
Since $[V, W]$ is a smooth vector field, its values are determined locally. Thus, it suffices to compute in a single smooth chart. 
\begin{align*}
    [V,W]_f & = V^i \frac{\partial}{\partial x^i} \bigg( W^j \frac{\partial f}{\partial x^j} \bigg) - W^j \frac{\partial}{\partial x^j} \bigg( V^i \frac{\partial f}{\partial x^i} \bigg) \\
    & = V^i \frac{\partial W^j}{\partial x^i} \frac{\partial f}{\partial x^j} + V^i W^j \frac{\partial^2 f}{\partial x^i \partial x^j} - W^j \frac{\partial V^i}{\partial x^j} \frac{\partial f}{\partial x^i} - W^j V^i \frac{\partial^2 f}{\partial x^j \partial x^i} \\
    & = V^i \frac{\partial W^j}{\partial x^i} \frac{\partial f}{\partial x^j} - W^j \frac{\partial V^i}{\partial x^j} \frac{\partial f}{\partial x^i}
\end{align*}
where we've used the product rule in the first to second step and the fact that mixed partial derivatives of a smooth function are equal in any order. 
\end{proof}

\begin{example}
Let us define smooth vector fields $V, W \in \mathcal{T}(\mathbb{R}^3)$ by 
\begin{align*}
    V & = x \frac{\partial}{\partial x} + \frac{\partial}{\partial y} + x (y+1) \frac{\partial}{\partial z} \\
    W & = \frac{\partial}{\partial x} + y \frac{\partial}{\partial z}
\end{align*}
After some tedious calculations, we compute a total of nine separate terms to get 
\begin{align*}
    [V, W] & = - \frac{\partial}{\partial x} - (y+1) \frac{\partial}{\partial z} + \frac{\partial}{\partial z} \\
    & = - \frac{\partial}{\partial x} - y \frac{\partial}{\partial z} 
\end{align*}
\end{example}

\begin{lemma}[Properties of the Lie Bracket]
The Lie bracket satisfies the following identities for all $V, W, X \in \mathcal{T}(M)$. 
\begin{enumerate}
    \item Bilinearity. For all $a, b \in \mathbb{R}$, 
    \begin{align*}
        [a V + b W, X] & = a [V, X] + b [W, X] \\
        [X, a V + b W] & = a [X, V] + b [X, W]
    \end{align*}
    \item Antisymmetry.
    \[[V, W] = - [W, V]\]
    \item Jacobi Identity. 
    \[[V,[W,X]] + [W,[X,V]] + [X,[V,W]] = 0\]
    \item For $f, g \in C^\infty (M)$, 
    \[[f V, g W] = f g [V, W] + ( fVg) W - (gWf) V\]
\end{enumerate}
\end{lemma}

The next proposition states the naturality of the Lie bracket. That is, $F$-relatedness is preserved with the Lie bracket. 
\begin{proposition}
Let $F: M \longrightarrow N$ be a smooth map, and let $V_1, V_2 \in \mathcal{T} (M)$ and $W_1, W_2 \in \mathcal{T}(N)$ be vector fields such that $V_i$ is $F$-related to $W_i$ for $i = 1, 2$. Then, $[V_1, V_2]$ is $F$-related to $[W_1, W_2]$. 
\end{proposition}

\begin{corollary}
Suppose $F: M \longrightarrow N$ is a diffeomorphism and $V_1, V_2 \in T(M)$. Then 
\[F_* [V_1, V_2] = [F_* V_1, F_* V_2]\]
\end{corollary}

\subsection{The Lie Algebra of a Lie Group}
\begin{definition}
Let $G$ be a Lie group. Any $g \in G$ defines maps $L_g, R_g : G \longrightarrow G$, called \textit{left translation} and \textit{right translation}, respectively, by 
\begin{align*}
    L_g (h) \equiv g h , & R_g (h) \equiv h g
\end{align*}
\end{definition}

Because $L_g$ can be written as the composition of smooth maps 
\[\begin{tikzcd}
G \arrow{r}{i_g} & G \times G \arrow{r}{m} & G
\end{tikzcd}
\]
where $i_g (h) \equiv (g, h)$ and $m$ is multiplication, it follows that $L_g$ is smooth. It is actually a diffeomorphism of $G$ since $L_{g^{-1}}$ is a smooth inverse for it. The same goes for $R_g$. Notice that given any two points $g_1, g_2 \in G$, there is a unique left translation of $G$ taking $g_1$ to $g_2$. This is the translation $g_2 g_1^{-1}$. Many important Lie groups follow from the fact that we can systematically map any point to any other by such a global diffeomorphism. 

\begin{definition}
A vector field $X$ on $G$ is said to be \textit{left-invariant} if it is invariant under all left translation, in the sense that it is $L_g$-related to itself for every $g \in G$. More explicitly, this means that
\begin{align*}
    (L_g)_* X_{g^\prime} = X_{g g^\prime} \text{ for all } g, g^\prime \in G
\end{align*}
\end{definition}

Furthermore, because
\[(L_g)_* \big( a X + b Y \big) = a (L_g)_* X + b (L_g)_* Y\]
the set of all smooth left-invariant vector fields on $G$ is a linear subspace of $\mathcal{T}(M)$. Even further, it is a \textit{Lie algebra}, which will be defined shortly.  

\begin{lemma}
Let $G$ be a Lie group, and suppose $X$ and $Y$ are smooth left-invariant vector fields on $G$. Then $[X, Y]$ is left-invariant. 
\end{lemma}
\begin{proof}
Since $(L_g)_* X = X$ and $(L_g)_* Y = Y$ by definition of left-invariance, it follows that
\[(L_g)_* [X,Y] = [(L_g)_* X, (L_g)_* Y] = [X,Y]\]
meaning that $[X, Y]$ is $L_g$-related to itself. 
\end{proof}

\begin{definition}
A \textit{Lie algebra} is a real vector space $\mathfrak{g}$ endowed with a map called the \textit{bracket} from $\mathfrak{g} \times \mathfrak{g} \longrightarrow \mathfrak{g}$, usually denoted by $(X, Y) \mapsto [X, Y]$, that satisfies the following properties for all $X, Y, Z \in \mathfrak{g}$. 
\begin{enumerate}
    \item Bilinearity. For all $a, b \in \mathbb{R}$, 
    \begin{align*}
        [a V + b W, X] & = a [V, X] + b [W, X] \\
        [X, a V + b W] & = a [X, V] + b [X, W]
    \end{align*}
    \item Antisymmetry.
    \[[V, W] = - [W, V]\]
    \item Jacobi Identity. 
    \[[V,[W,X]] + [W,[X,V]] + [X,[V,W]] = 0\]
\end{enumerate}
Notice that the Jacobi identity is a substitute for associativity, which does not hold in general for brackets in a Lie algebra. 
\end{definition}

\begin{definition}
If $\mathfrak{g}$ is a Lie algebra, a linear subspace $\mathfrak{h} \subset \mathfrak{g}$ is called a \textit{Lie subalgebra} of $\mathfrak{g}$ if it is closed under brackets. In other words, $\mathfrak{h}$ is itself a Lie algebra under the restriction of the bracket to $\mathfrak{h}$. 
\end{definition}

\begin{definition}
If $\mathfrak{g}$ and $\mathfrak{h}$ are Lie algebras, a linear map 
\[A: \mathfrak{g} \longrightarrow \mathfrak{h}\]
if if preserves brackets. That is, if 
\[A[X, Y] = [AX, AY]\]
An invertible Lie algebra homomorphism is called a \textit{Lie algebra isomorphism}. Two Lie algebra with an isomorphism between them are said to be \textit{isomorphic Lie algebras}. 
\end{definition}

\begin{example}
The space $\mathcal{T}(M)$ of all smooth vector fields on a smooth manifold $M$ is a Lie algebra under the Lie bracket. 
\end{example}

\begin{example}
Any vector space $V$ becomes a Lie algebra if we define all brackets to be $0$. Such a Lie algebra is said to be \textit{abelian}, because the underlying product $\cdot$ in the commutator $[A,B] = A \cdot B - B \cdot A$ is commutative. 
\end{example}

\begin{example}
If $V$ is a vector space, the linear space of endomorphisms of $V$, denoted $\mathfrak{gl}(V)$, becomes a Lie algebra with the commutator bracket
\[[A,B] x \equiv A (Bx) - B (Ax)\]
This can be represented using matrices, making the set of all $n \times n$ matrices with the commutator defined $[A,B] \equiv A B - B A$ also a Lie algebra. 
\end{example}

\begin{definition}
If $G$ is a Lie group, the set of all smooth left-invariant vector fields on $G$ is a Lie subalgebra of $\mathcal{T}(G)$ and it therefore a Lie algebra. This Lie algebra is denoted $\Lie(G)$.
\end{definition}

Note that we have already proved that the set of smooth left-invariant vector fields on $G$ is closed under the Lie bracket. 

\begin{theorem}
Let $G$ be a Lie group. The evaluation map 
\[\varepsilon: \Lie(G) \longrightarrow T_e G, \;\; \varepsilon(X) = X_e \]
where $e$ is the identity element of $G$, is a vector space isomorphism. Thus, $\Lie(G)$ is finite dimensional, with dimension equal to $\dim{G}$. 
\end{theorem}
\begin{proof}
Will be done. 
\end{proof}

Note also that the preceding proof shows that the assumption of smoothness in the definition of $\Lie(G)$ is unnecessary. 

\begin{corollary}
Every left-invariant rough vector field on a Lie group is smooth. 
\end{corollary}

\begin{proposition}[Lie algebra of the General Linear Group]
The composition of the natural maps
\[\Lie \big( \GL(n, \mathbb{R}) \big) \rightarrow T_{I_n} \GL(n, \mathbb{R}) \rightarrow \mathfrak{gl}(n, \mathbb{R})\]
gives a Lie algebra isomorphism between $\Lie\big(\GL(n, \mathbb{R})\big)$ and the matrix algebra $\mathfrak{gl}(n, \mathbb{R})$. 
\end{proposition}

\subsubsection{Induced Lie Algebra Homomorphisms}

It can be seen that each Lie group homomorphism induces a Lie algebra homomorphism. 

\begin{theorem}
Let $G$ and $H$ be Lie groups, and let $\mathfrak{g}$ and $\mathfrak{h}$ be their Lie algebras. Suppose $F: G \longrightarrow H$ is a Lie group homomorphism. For every $X \in \mathfrak{g}$, there is a unique vector field $\mathfrak{h}$ that is $F$-related to $X$. With this vector field, denoted $F_* X$, the map $F_*: \mathfrak{g} \longrightarrow \mathfrak{h}$ so defined is a Lie algebra homomorphism. 
\end{theorem}

\begin{lemma}[Properties of the Induced Homomorphism]
\begin{enumerate}
    \item The homomorphism $(\Id_G)_* : \Lie (G) \longrightarrow \Lie(G)$ induced by the identity map of $G$ is the identity of $\Lie(G)$. 
    \item If $F_1: G \longrightarrow H$ and $F_2: H \longrightarrow K$ are Lie group homomorphisms, then $(F_2 \circ F_1)_* = (F_2)_* \circ (F_1)_* : \Lie(G) \longrightarrow \Lie(G)$. 
    \item Isomorphic Lie groups have isomorphic Lie algebras. 
\end{enumerate}
\end{lemma}

\section{Vector (Fiber) Bundles}

We have already seen that the tangent bundle of a smooth manifold has a natural structure as a smooth manifold in its own right. The standard coordinates on $TM$ make it look, locally, like $M \times \mathbb{R}^n$. This kind of structure arises frequently. That is, a collection of vector spaces (one for each point in $M$) glued together so that it looks \textit{locally} liked the Cartesian product of $M$ with $\mathbb{R}^n$, but globally it may not be. This is called the vector bundle. Note that a tangent bundle is one type of vector bundle. 

\begin{definition}
Let $M$ be a topological space. A \textit{(real) vector bundle of rank $k$ over $M$} is a topological space $E$ together with a surjective continuous map $\pi: E \longrightarrow M$ satisfying: 
\begin{enumerate}
    \item For each $p \in M$, the set $E_p \equiv \pi^{-1} (p) \subset E$ (called the \textit{fiber of $E$ over $p$}) is endowed with the structure of a $k$-dimensional real vector space. 
    \item For each $p \in M$, there exists a neighborhood $U$ of $p$ in $M$ and a homeomorphism $\Phi: \pi^{-1}(U) \longrightarrow U \times \mathbb{R}^k$ (called a \textit{local trivilization of $E$ over $U$}), such that the following diagram commutes: 
    \[\begin{tikzcd}
    \pi^{-1}(U) \arrow{r}{\Phi} \arrow{d}{\pi}& U \times \mathbb{R}^k \arrow{ld}{\pi_1}\\
    U 
    \end{tikzcd}\]
    where $\pi_1$ is the projection onto the first factor. Furthermore, for each $q \in U$, the restriction of $\Phi$ to $E_q$ is a linear isomorphism from $E_q$ to $\{q\} \times \mathbb{R}^k \simeq \mathbb{R}^k$. 
\end{enumerate}
\end{definition}

Note that $E$ is \textit{not} the same space as $M \times \mathbb{R}^k$, but rather every two tuple in $M \times \mathbb{R}^k$ can be \textit{associated} with every element in $E$ through the surjective map $\pi$ (unless $E$ is a trivial bundle). 

\begin{definition}
If $M$ and $E$ are smooth manifolds, $\pi$ is a smooth projection map, and the local trivializations can be chosen to be diffeomorphisms, then $E$ is called a \textit{smooth vector bundle}. In this case, we will call any local trivialization that is a diffeomorphism onto its image a \textit{smooth local trivialization}. 

The space $E$ is called the \textit{total space} of the bundle, $M$ called its \textit{base}, and $\pi$ called its \textit{projection}. Also, if $U \subset M$ is any open set, it is easy to verify that the subset $E |_U = \pi^{-1} (U)$ is again a vector bundle with the restriction of $\pi$ as its projection map, called the \textit{restriction of $E$ to $U$}. 
\end{definition}

A rank-$1$ vector bundle is often called a \textit{line bundle}. Complex bundles are also defined with vector space over $\mathbb{C}$. 

\begin{definition}
If there exists a local trivialization over all of $M$ (called a \textit{global trivialization of $E$}), then $E$ is said to be a \textit{trivial bundle}. In this case, $E$ itself if homeomorphic to the product space $M \times \mathbb{R}^k$. If $E \longrightarrow M$ is a smooth bundle that admits a smooth global trivialization, then we say that $E$ is \textit{smoothly trivial} (in this case, $E$ is diffeomorphic to $M \times \mathbb{R}^k$, not just homeomorphic). 
\end{definition}

\begin{example}[Trivial Bundle]
Let $E = M \times \mathbb{R}^k$, and let $\pi = \pi_1: M \times \mathbb{R}^k \longrightarrow M$ be the projection onto the first factor. Then $E$ is a fiber bundle of $\mathbb{R}^k$ over $M$. Here $E$ is not just locally a product but \textit{globally} one. Every trivial bundle is of this form, with the identity map as a global trivialization. If $M$ is a smooth manifold, then $M \times \mathbb{R}^k$ is smoothly trivial. 
\end{example}

\begin{example}[The Cylinder as a Trivial Bundle]
Let $E$ be a cylinder, i.e. a cylindrical surface. We remind the reader that $E$ stretches infinitely long, and that it is "hollow." Then the 1-sphere, denoted $S^1$, is the base space, and $\mathbb{R}$ is the fiber. Geometrically, we can think of $S^1$ to be the base of the cylinder, while an infinite number of real lines orthogonally intersect $S^1$ at one point to cover $E$. We can then define a map $ S^1 \times \mathbb{R} \longrightarrow E$ to be 
\[ (\theta, z) \longrightarrow (\cos{\theta}, \sin{\theta}, z) \]
\end{example}

The standard fiber $F$ is $\mathbb{R}$, but we most note that there are an infinite number of copies of $\mathbb{R}$ passing through each point in $E$. So given points $p, q \in E$, the specific fibers associated with $p$ and $q$ are different $\mathbb{R}$s. We can think of this fiber $\mathbb{R}$ as the \textit{collection of all real lines that fill the surface of cylinder E}. 

Note that we could have very well just chosen $\mathbb{R}$ to be the base space and $S^1$ to be the fiber. The base space would then be unbounded, but this doesn't pose as a problem. 

Furthermore, in the example shown before, the map $B \times F \longrightarrow E$ doesn't have to be so simple as 
\[ (z, \theta) \longrightarrow (\cos{\theta}, \sin{\theta}, z) \]
In this mapping, all of the $\mathbb{R}$ passing through each point is paramaterized the same, since the same value of $z$ gives the same heights everywhere. However, for the more complex paramaterization
\[ (\theta, z) \longrightarrow (\cos{\theta}, \sin{\theta}, (2 + \sin{\theta}) z) \]
the paramaterizations in each $\mathbb{R}$ are different for every point $\theta \in S^1$. So, the same value of $z$ will not give you the same height everywhere. However, note that while all of these $\mathbb{R}$ are paramaterized differently, every single $\mathbb{R}$ are diffeomorphic since, once picking all of them to have the same paramaterization, we can identify the identity mapping as a diffeomorphism between all of them. 

Usually,we deal with nontrivial bundles that have a cover of open sets. Here is an example. 

\begin{example}[Mobius Bundle]
Let $I = [0,1] \subset \mathbb{R}$ be the unit interval, and let $p: I \longrightarrow S^1$ be the quotient map $p(x) \equiv e^{2 \pi i x}$, which identifies the two endpoints of $I$. Consider the "infinite strip" $I \times \mathbb{R}$, and let $\pi: I \times \mathbb{R} \longrightarrow I$ be the projection on the first factor. Let $\sim$ be the equivalence relation on $I \times \mathbb{R}$ that identifies each point $(0,y)$ in the fiber over $0$ with the point $(1, -y)$ in the fiber over $1$. Geometrically, we are half-twisting the right hand side of the strip and gluing it into the left-hand edge. The resulting quotient space is $E \equiv (I \times \mathbb{R})/ \sim$, with $q: I \times \mathbb{R} \longrightarrow E$ the quotient map. 

Because $p \circ \pi_1$ is constant on each equivalence class, it descends to a continuous map $p \circ \pi_1 = \pi: E \longrightarrow S^1$. THis makes $E$ into a smooth real line bundle over $S^1$. 
\end{example}

\begin{proposition}[The Tangent Bundle as a Vector Bundle]
Let $M$ be a smooth $n$-manifold and let $TM$ be its tangent bundle. With its standard projection map, its natural vector space structure on each fiber, and the smooth manifold structure, $TM$ is a smooth vector bundle of rank $n$ over $M$. 
\end{proposition}
\begin{proof}
Given any smooth chart $(U, \varphi)$ for $M$ with coordinate functions $(x^i)$, we define the map $\Phi: \pi^{-1} (U) \longrightarrow U \times \mathbb{R}^n$ by 
\[\Phi \bigg( v^i \frac{\partial}{\partial x^i} \bigg|_p \bigg) \equiv \big( p, (v^1, v^2, ..., v^n)\big)\]
This is obviously linear on fibers and satisfies $\pi \circ \Phi = \pi$. The composite map 
\[\pi^{-1} (U) \xrightarrow{\Phi} U \times \mathbb{R}^n \xrightarrow{\varphi \times \Id_{\mathbb{R}^n}} \varphi(U) \times \mathbb{R}^n\]
Since both $\Tilde{\varphi}$ and $\varphi \times \Id_{\mathbb{R}^n}$ are diffeomorphisms, $\Phi$ is also a diffeomorphism, satisfying all the conditions of a local trivialization. 
\end{proof}

We still have to deal with overlaps between trivializing neighborhoods. The next lemma introduces transition functions between different representations of a fiber. 

\begin{lemma}[Overlaps between Trivializing Neighborhoods]
Let $\pi: E \longrightarrow M$ be a smooth vector bundle, and suppose $\Phi: \pi^{-1} (U) \longrightarrow U \times \mathbb{R}^k$ and $\Psi: \pi^{-1} (V) \longrightarrow U \times \mathbb{R}^k$ be two smooth local trivializations of $E$ such that $U \cap V \neq \emptyset$. Then, there exists a smooth map $\tau: U \cap V \longrightarrow \GL(k, \mathbb{R})$ such that the composition $\Phi \circ \Psi^{-1} : (U \cap V) \times \mathbb{R}^k \longrightarrow (U \cap V) \times \mathbb{R}^k$ has the form
\[\Phi \circ \Psi^{-1} (p, v) \equiv \big(p, \tau(p) v \big)\]
where $\tau(p) v$ denotes the usual action of the $k \times k$ matrix $\tau(p)$ on the vector $v \in \mathbb{R}^k$. Furthermore, $\Phi \circ \Psi^{-1}$ is a diffeomorphism. We can represent this consistency by the following commutative diagram. 
\[\begin{tikzcd}
(U \cap V) \times \mathbb{R}^k \arrow{dr}{\pi_1}& \pi^{-1} (U \cap V) \arrow{l}{\Psi} \arrow{r}{\Phi} \arrow{d}{\pi} & (U \cap V) \times \mathbb{R}^k \arrow{dl}{\pi_1}\\
& U \cap V & 
\end{tikzcd}\]
\end{lemma}

\begin{definition}
The smooth map $\tau: U \cap V \longrightarrow \GL(k, \mathbb{R})$ is called the \textit{transition function} between the local trivializations $\Phi$ and $\Psi$. For example, if $M$ is a smooth manifold and $\Phi, \Psi$ are the local trivializations of $TM$ associated with two different smooth charts, then the transition functions between them is jsut the Jacobian matrix of the coordinate transition map. 
\end{definition}

In order to make a vector bundle into a smooth one, we would need to construct a manifold topology and a smooth structure on the disjoint union of all the vector spaces, and then construct the local trivializations and show that they have the requisite properties. The following lemma provides a shortcut by showing that it is sufficient to construct the local trivializations, as long as they overlap with smooth transition functions. 

\begin{lemma}[Vector Bundle Construction Lemma]
Let $M$ be a smooth manifold and suppose that we are given for each $p \in M$, a real vector space $E_p$ of some fixed dimension $k$. Furthermore, let 
\[E \equiv \bigsqcup_{p \in M} E_p\]
and let $\pi: E \longrightarrow M$ be the map that takes each element of $E_p$ to point $p$. Suppose furthermore that we are given
\begin{enumerate}
    \item an open cover $\{U_\alpha\}_{\alpha \in A}$ of $M$. 
    \item for each $\alpha \in A$, a bijective map $\Phi_\alpha : \pi^{-1} (U_\alpha) \longrightarrow U_\alpha \times \mathbb{R}^k$ whose restriction to each $E_p$ is a linear isomorphism from $E_p$ to $\{p\} \times \mathbb{R}^k \simeq \mathbb{R}^k$. 
    \item for each $\alpha, \beta \in A$ such that $U_\alpha \cap U_\beta \neq \emptyset$, a smooth map $\tau_{\alpha \beta}: U_\alpha \cap U_\beta \longrightarrow \GL(k, \mathbb{R})$ such that the composite map $\Phi_\alpha \circ \Phi_\beta^{-1}$ from $\big( (U_\alpha \cap U_\beta)\big) \times \mathbb{R}^k$ to itself has the form 
    \[\Phi_\alpha \circ \Phi_\beta^{-1} (p, v) \equiv \big( p, \tau_{\alpha \beta} (p) v \big)\]
\end{enumerate}
Then, $E$ has a unique smooth manifold structure making it into a smooth vector bundle of rank $k$ over $M$, with $\pi$ as projection and the maps $\Phi_\alpha$ as smooth local trivializations. 
\end{lemma}

\subsection{Categories and Functors}
We summarize the basic definitions of category theory, which provides a convenient and powerful language for talking about many mathematical structures. 

\begin{definition}
A \textit{category} $\mathbf{C}$ consists of three things: 
\begin{enumerate}
    \item a class of \textit{objects}
    \item for each pair $X, Y$ of objects a set $\Hom_\mathbf{C} (X, Y)$ whose elements are called \textit{morphisms}
    \item for each triple $X, Y, Z$ of objects a map called \textit{composition}
    \[\Hom_\mathbf{C} (X, Y) \times \Hom_\mathbf{C} (Y, Z) \longrightarrow \Hom_\mathbf{C} (X, Z)\]
    written $(f, g) \mapsto g \circ f$
\end{enumerate}
The morphisms are also required to satisfy the following properties: 
\begin{enumerate}
    \item Associativity: $(f \circ g) \circ h = f \circ (g \circ h)$
    \item Existence of Identities: For each object $X$ in $\mathbb{C}$, there exists an \textit{identity morphism} $\Id_X \in \Hom_{\mathbf{C}}(X, X)$ satisfying 
    \[Id_Y \circ f = f = f \circ \Id_X\]
    for all $f \in \Hom_\mathbb{C} (X, Y)$
\end{enumerate}
\end{definition}

\begin{definition}
A morphism $f \in \Hom_\mathbf{C}(X, Y)$ is called an \textit{isomorphism} in $\mathbf{C}$ if there exists a morphism $g \in \Hom_\mathbf{C} (Y, X)$ such that $f \circ g = \Id_Y$ and $g \circ f = \Id_X$. 
\end{definition}

\begin{example}[Categories]
When working with categories, the objects are sets with some extra structure, the morphisms are maps that preserve that structure, and the composition laws and identity morphisms are the obvious ones. Some common examples are: 
\begin{enumerate}
    \item SET: Sets and maps 
    \item TOP: Topological spaces and continuous maps. 
    \item TM: Topological manifolds and continuous maps. 
    \item SM: Smooth manifolds and smooth maps. 
    \item VB: Smooth vector bundles and smooth bundle maps. 
    \item VECT$_\mathbb{R}$: Real vector spaces and real-linear maps. 
    \item VECT$_\mathbb{C}$: Complex vector spaces and complex-linear maps. 
    \item GROUP: Groups and group homomorphisms. 
    \item AB: Abelian groups and group homomorphisms. \item LIE: Lie group and Lie group homomorphisms. 
    \item lie: Lie algebras and Lie algebra homomorphisms. 
\end{enumerate}
\end{example}

We use the word \textit{class} instead of set for the collection of objects in a category is that some categories are "too large" to be considered sets. For example, in the category SET, the class of objects is the class of all sets. Any attempt to treat this class as a set in its own right leads to the Russell paradox of set theory. 

Relations among morphisms are often depicted using commutative diagrams. 

\begin{definition}
Morphisms can have any of the following properties. A morphism $f: X \longrightarrow Y$ is a
\begin{enumerate}
    \item \textit{monomorphism} (or \textit{monic}) if $f \circ g_1 = f \circ g_2$ implies $g_1 = g_2$ for all morphisms $g_1, g_2: Z \longrightarrow X$. 
    \item \textit{epimorphism} (or \textit{epic}) if $g_1 \circ f = g_2 \circ f$ implies $g_1 = g_2$ for all morphisms $g_1, g_2: Y \longrightarrow Z$. 
    \item \textit{bimorphism} if $f$ is both monic and epic. 
    \item \textit{isomorphism} if (defined above). 
    \item \textit{endomorphism} if $X = Y$. End$(X)$ denotes the class of endomorphisms of $X$. 
    \item \textit{automorphism} if $f$ is both an endomorphism and an isomorphism. Aut$(X)$ denotes the class of automorphisms of $X$. 
    \item \textit{retraction} if a right inverse of $f$ exists, i.e. if there exists a morphism $g: Y \longrightarrow X$ such that $f \circ g = \Id_Y$. 
    \item \textit{section} if a left inverse of $f$ exists, i.e. if there exists a morphism $g: Y \longrightarrow X$ such that $g \circ f = \Id_X$. 
\end{enumerate}
\end{definition}

\begin{theorem}
Every retraction is an epimorphism. Every section is a monomorphism. Furthermore, the following three statements are equivalent
\begin{enumerate}
    \item $f$ is a monomorphism and a retraction. 
    \item $f$ is a epimorphism and a section. 
    \item $f$ is an isomorphism. 
\end{enumerate}
\end{theorem}

\begin{definition}
If $\mathbf{C}$ and $\mathbf{D}$ are categories, a \textit{covariant functor} from $\mathbf{C}$ to $\mathbf{D}$ is a rule $\mathcal{F}$ that assigns each object $X$ in $\mathbf{C}$ to an object $\mathcal{F}(X)$ in $\mathbf{D}$, and to each morphism $f \in \Hom_\mathbf{C} (X ,Y)$ to a morphism $\mathcal{F}(f) \in \Hom_\mathbf{D} (\mathcal{F}(X), \mathcal{F}(Y))$, so that identities and composition are preserved.
\begin{align*}
    \mathcal{F}(\Id_X) = \Id_{\mathcal{F}(X)}, & \mathcal{F}(g \circ h) = \mathcal{F}(g) \circ \mathcal{F} (h)
\end{align*}
\end{definition}

There are also functors that reverse morphisms. 

\begin{definition}
A \textit{contravariant functor} $\mathcal{F}$ from $\mathbf{C}$ to $\mathbf{D}$ assigns to each object $X$ in $\mathbf{C}$ an object $\mathcal{F}(X)$ in $\mathbf{D}$, and to each morphism $g \in \Hom_\mathbf{C} (X, Y)$ a morphism $\mathcal{F}(g) \in \Hom_\mathbf{D}(\mathcal{F}(Y), \mathcal{F}(X))$, such that
\begin{align*}
    \mathcal{F}(\Id_X) = \Id_{\mathcal{F}(X)}, & \mathcal{F}(g \circ h) = \mathcal{F}(g) \circ \mathcal{F}(h)
\end{align*}
\end{definition}

If the functor is understood, it is common for the morphism induced by a covariant functor to be denoted by $g_*$ (instead of $\mathcal{F} (g)$) and that induced by a contravariant functor by $g^*$. 

\begin{definition}
A covariant functor from any category to itself is the \textit{identity functor}, which takes each object and each morphism to itself. 
\end{definition}

\begin{definition}
If $\mathbf{C}$ is a category whose objects are sets with some additional structure and whose morphisms are maps preserving that structure (all categories listed in the example except for the first one), the \textit{forgetful functor} $\mathcal{F}: C \longrightarrow $ SET assisns to each object its underlying set and to each morphism the same map thought of as a map between sets. 
\end{definition}

Some more interesting functors arise in the following examples. 

\begin{example}
The assignment $G \mapsto \Lie(G), F \mapsto F_*$ is a covariant functor from LIE (category of Lie groups) to lie (category of Lie algebras). Note that every object $G$ in LIE gets mapped to object $\Lie(G)$ in lie, and every morphism $F$ gets mapped to morphism $F_*$. 
\end{example}

\begin{example}
If we define TOP$_*$ to be the category whose objects are \textit{pointed topological spaces} (topological spaces with a choice of base point in each), and whose morphisms are continuous maps taking base points to base points, then the fundamental group is a covariant functor from TOP$_*$ to GROUP. 
\end{example}

\begin{definition}
The \textit{tangent functor} is a covariant functor from the category SM of smooth manifolds to the category VB of smooth vector bundles. TO each smooth manifold $M$ is assigns the tangent bundle $TM \rightarrow M$, and to each smooth map $F: M \longrightarrow N$, it assigns the pushforward $F_* : TM \longrightarrow TN$.
\end{definition}

\begin{definition}
If $F$ and $G$ are covariant functors between the categories $\mathbf{C}$ and $\mathbf{D}$, then a \textit{natural transformation} $\eta$ from $F$ to $G$ associates to every object $X$ in $\mathbf{C}$ a morphism $\eta_X: F(X) \longrightarrow G(X)$ in $\mathbf{D}$ such that for every morphism $f: X \longrightarrow Y$ in $\mathbf{C}$, we have $\eta_Y \circ F(f) = G(f) \circ \eta_X$, meaning that the following diagram is commutative. 
\[\begin{tikzcd}
F(X) \arrow{r}{F(f)} \arrow{d}{\eta_X} & F(Y) \arrow{d}{\eta_Y} \\
G(X) \arrow{r}{G(f)} & G(Y)
\end{tikzcd}\]
The two functors $F$ and $G$ are called \textit{naturally isomorphic} if there exists a natural transformation from $F$ to $G$ such that $\eta_X$ is an isomorphism for every object $X$ in $\mathbf{C}$. 
\end{definition}

\section{The Cotangent Bundle}
Whereas tangent vectors give us a coordinate free interpretation of derivatives of curves, it turns out that derivatives of real-valued functions on a manifold are most naturally interpreted as tangent covectors. Thus, we will define the differential of a real-valued function as a covector field, similar to a coordinate-independent analogue of the classical gradient. 

We will assume that the reader is familiar with the concepts of the dual space and its respective dual basis. Recall the following. 

\begin{proposition}
The dual map satisfies the following properties 
\begin{enumerate}
    \item $(A \circ B)^* = B^* \circ A^*$
    \item $(\Id_V)^*: V^* \longrightarrow V^*$ is the identity map of $V^*$. 
\end{enumerate}
\end{proposition}

The dual map has a nice interpretation within the context of category theory.

\begin{corollary}
The assignment that sends a vector space to its dual space and a linear map to its dual map is a contravariant functor from the category of real vector spaces to itself. 
\end{corollary}

\subsection{Tangent Covectors on Manifolds}

\begin{definition}
Let $M$ be a smooth manifold. For $p \in M$, we define the \textit{cotangent space} at $p$, denoted by $T_p^* M$, to be the dual space to $T_p M$. 
\[T_p^* M \equiv (T_p M)^*\]
Elements of $T_p^* M$ are called \textit{tangent covectors at $p$}, or just \textit{covectors at $p$}. That is, if $\omega \in T_p^* M$, then 
\[\omega: T_p M \longrightarrow \mathbb{R}\]
\end{definition}

If $(x^i)$ are smooth local coordinate on an open subset $U \subset M$, then for each $p \in U$, the coordinate basis $(\partial/\partial x^i |_p )$ of $T_p M$ induces the dual basis of $T_p^* M$, denoted $(\lambda^i |_p)$. Therefore, any covector $\omega \in T_p^* M$ can be written uniquely as 
\[\omega = \omega_i \lambda^i \big|_p, \text{ where } \omega_i = \omega \bigg( \frac{\partial}{\partial x^i} \bigg|_p \bigg)\]

\subsubsection{Basis Transformations}
Suppose that $(\Tilde{x}^j)$ is another set of smooth coordinates whose domain contains $p$ and let $\big( \Tilde{\lambda}^j \big|_p\big)$ denote the basis for $T_p^* M$ dual to $\big(\partial /\partial \Tilde{x}^j \big|_p \big)$. We can compute the components of the same covector $\omega$ with respect to the new coordinate system as follows. First, note that coordinate vector fields transform as follows: 
\[\frac{\partial}{\partial x^i} \bigg|_p = \frac{\partial \Tilde{x}^j}{\partial x^i} (p) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_p\]
Writing $\omega$ with respect to both bases 
\[\omega = \omega_i \lambda^i \big|_p = \Tilde{\omega}_j \Tilde{\lambda}^j \big|_p\]
we can compute the components $\omega_i$ in terms of $\Tilde{\omega}_j$. 
\[\omega_i = \omega \bigg( \frac{\partial}{\partial x^i} \bigg|_p \bigg) = \omega \bigg( \frac{\partial \Tilde{x}^j}{\partial x^i} (p) \frac{\partial}{\partial \Tilde{x}^j} \bigg|_p \bigg) = \frac{\partial \Tilde{x}^j}{\partial x^i} (p) \Tilde{\omega}_j\]

\begin{definition}
\textit{Covariant vectors} transform in the same way as coordinate partial derivatives. Given a vector $V$ in coordinates with respect to basis vectors $(x^i)$ and $\Tilde{V}$ in coordinates with respect to basis vectors $(\Tilde{x}^i)$, we have
\[ x^i = \frac{\partial \Tilde{x}^j}{\partial x^i} \Tilde{x}^j\]
where the indices of $\Tilde{x}^j$ cancel out with the \textit{upper} term of the derivative meaning that if $\Tilde{x}^j$ is doubled, then the derivative is doubled and so $x^i$ is doubled.\textit{Contravariant vectors} transform in the opposite way. 
\[\Tilde{V}^j = \frac{\partial \Tilde{x}^j}{\partial x^i} (p) V^i\]
where the indices of $V^i$ cancel out with the \textit{lower} term of the derivative, meaning that if $V^i$ is doubled, then the derivative is halved and so $\Tilde{V}^j$ is halved. 
\end{definition}

\begin{proposition}
It is useful to note the following:
\begin{enumerate}
    \item Basis vectors of $V$, by definition, transform covariantly. 
    \item Coefficients of vectors in $V$ transform contravariantly. 
    \item Basis covectors of $V^*$ transform contravariantly. 
    \item Coefficients of covectors of $V^*$ transform covariantly. 
\end{enumerate}
\end{proposition}

Note that the use of the terms covariant and contravariant has nothing to do with the covariant and contravariant functors of category theory! 

\subsection{The Cotangent Bundle}
\begin{definition}
Given smooth manifold $M$, the disjoint union 
\[T^* M = \bigsqcup_{p \in M} T_p^* M\]
is called the \textit{cotangent bundle of $M$}. It has a natural projection map $\pi: T^* M \longrightarrow M$ sending $\omega \in T_p^* M$ to $p \in M$. In addition, given any smooth local coordinates $(x^i)$ on $U \subset M$, for each $p \in U$ we denote the basis for $T_p^* M$ dual to $(\partial / \partial x^i |_p )$ by $(\lambda^i |_p)$. This defines $n$ maps $\lambda^1, ..., \lambda^n: U \longrightarrow T^* M$, called \textit{coordinate covector fields}. 
\end{definition}

As expected, $T^* M$ can be naturally turned into a vector bundle over $M$. 

\begin{proposition}
Let $M$ be a smooth manifold and let $T^* M$ be its cotangent bundle. With its standard projectoin map and the natural vector space structure on each fiber, $T^*M$ has a unique smooth manifold structure making it into a rank-$n$ vector bundle over $M$ for which all coordinate covector fields are smooth local sections. 
\end{proposition}

Smooth local coordinates for $M$ induces smooth local coordinates for its cotangent space, which in turn induces local coordinates for its cotangent bundle. That is, if $(x^i)$ are smooth coordinates on an open set $U \subset M$, the map from $\pi^{-1} (U)$ to $\mathbb{R}^{2n}$ given by 
\[\zeta_i \lambda^i \big|_p \mapsto \big( x^1 (p), ..., x^n(p), \zeta_1, ..., \zeta_n \big) \]
is a smooth coordinate chart for $T^* M$, called the \textit{standard coordinates for $T^* M$ associated with $(x^i)$}. 

\begin{definition}
A section of $T^* M$ is called a \textit{covector field}, or a \textit{differential 1-form}. The value of a covector field $\omega$ at a point $p \in M$ is denoted $\omega_p$ (since writing $w(p)$ is used to denote the action of a covector on a vector). 
\end{definition}

\begin{definition}
In any smooth local coordinates on an open set $U \subset M$, a covector field $\omega$ can be written in terms of the coordinate covector fields $(\lambda^i)$ as $\omega = \omega_i \lambda_i$ for $n$ functions $\omega_i: U \longrightarrow \mathbb{R}$, called the \textit{component functions of $\omega$}. They are characterized by 
\[\omega_i (p) = \omega_p \bigg( \frac{\partial}{\partial x^i} \bigg|_p \bigg)\]
\end{definition}

Similarly for vector fields, there are several ways to check for smoothness of a covector field. 

\begin{lemma}[Smoothness Criteria for Covector Fields]
Let $M$ be a smooth manifold, and let $\omega: M \longrightarrow T^* M$ be a rough section. 
\begin{enumerate}
    \item If $\omega = \omega_i \lambda^i$ is the coordinate representation for $\omega$ in any smooth chart $\big(U, (x^i)\big)$ for $M$, then $\omega$ is smooth on $U$ if and only if its component functions $\omega_i$ are smooth. 
    \item $\omega$ is smooth if and only if for every smooth vector field $X$ on an open subset $U \subset M$, the function $\langle \omega, X \rangle: U \longrightarrow \mathbb{R}$ defined by 
    \[\langle \omega, X \rangle (p) \equiv \langle \omega_p, X_p \rangle \equiv \omega_p (X_p)\]
    is smooth. 
\end{enumerate}
\end{lemma}

\subsection{The Differential of a Function}
In elementary calculus, the gradient of a smooth real valued function $f$ on $\mathbb{R}^n$ is defined as the vector field whose components are the partial derivatives of $f$. In our notation, this would read
\[\text{grad} f = \sum_{i=1}^n \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^i}\]
However, the gradient does not make coordinate independent sense. In general, although the first partial derivatives of a smooth function cannot be interpreted in a coordinate independent way as the components of a vector field, it turns out that they can be interpreted as the components of a covector field. This is the most important application of covector fields. 

\begin{definition}
The covector field of $f$, or the \textit{differential of $f$}, denoted $df$ is defined
\[df_p (X_p) \equiv X_p f \text{ for } X_p \in T_p M\]
\end{definition}

In general, given a vector field existing on a manifold $M$, applying the covector field $df$ to it would give a scalar field on $M$. The definition above says that this application of the covector field $df$ to vector field $X$ is merely just applying the function $f$ itself to all points in $X$, outputting a scalar field. 

This intuition along with the following theorem leads to an alternate definition of the cotangent space. 

\begin{theorem}
$T_p^* M$ is isomorphic to $C^\infty(M) / \sim$, where $\sim$ is the equivalence relation between curves that pass through point $p \in M$ in the same direction with the same speed. The direction of the curves in an equivalence class determines the direction of the cotangent vector and the paramaterization of the curve determines its magnitude. 
\end{theorem}

\begin{definition}
The vector space 
\[ \{ (d f)_{p} \; | \; f \in C^{\infty} (M) \} \]
is called the \textit{cotangent space} at $p \in M$. 
\end{definition}

\begin{lemma}
The differential of a smooth function is a smooth covector field. 
\end{lemma}

To see what $df$ looks like more concretely, let us compute its coordinate representation. Let $(x^i)$ be smooth coordinates on an open subset $U \subset M$ and let $(\lambda^i)$ be the corresponding coordinates. Then, the coordinate representation of $df$ is
\[df_p = \frac{\partial f}{\partial x^i} (p) \lambda^i \big|_p\]
But by letting $f = x^j: U \longrightarrow \mathbb{R}$, we find that
\[d x^j \big|_p = \frac{\partial x^j}{\partial x^i} = \delta_i^j \lambda^i \big|_p = \lambda^j \big|_p\]
meaning that $\lambda^j$ is $dx^j$! Therefore, the formula for the coordinate representation of $df$ can be rewritten as
\[df_p = \frac{\partial f}{\partial x^i} (p) dx^i \big|_p \implies df = \frac{\partial f}{\partial x^i} dx^i\]
which is called the \textit{total differential of $f$}. 

\begin{example}
If $f(x, y) = x^2 y \cos{x}$ on $\mathbb{R}^2$, then 
\begin{align*}
df & = \frac{\partial( x^2 y \cos{x})}{\partial x} dx + \frac{\partial (x^2 y \cos{x})}{\partial y} dy \\
& = (2xy \cos{x} - x^2 y \sin{x}) dx + x^2 \cos{x} dy
\end{align*}
\end{example}

\begin{proposition}[Properties of the Differential]
let $M$ be a smooth manifold, and let $f, g \in C^\infty (M)$. 
\begin{enumerate}
    \item For any $a, b \in \mathbb{R}$, we have $d(a f + b g) = a\,df + b\,dg$. 
    \item $d(fg) = f\,dg + g\,df$
    \item $d(f/g) = (g\,df - f\,dg)/g^2$ on the set where $g \neq 0$. 
    \item If $J \subset \mathbb{R}$ is an interval containing the image of $f$, and $h: J \longrightarrow \mathbb{R}$ is a smooth function, then $d(h \circ f) = (h^\prime \circ f) df$. 
    \item $f$ is constant $\implies df = 0$
\end{enumerate}
\end{proposition}
Clearly, if $f$ is a smooth real-valued function on a smooth manifold $M$, then $df = 0$ if and only if $f$ is constant on each component of $M$. 

\begin{proposition}[Derivative of a Function along a Curve]
Suppose $M$ is a smooth manifold, $\gamma: J \longrightarrow M$ is a smooth curve, and $f: M \longrightarrow \mathbb{R}$ is a smooth function, then the derivative of real valued function $f \circ \gamma: \mathbb{R} \longrightarrow \mathbb{R}$ is 
\[(f \circ \gamma)^\prime (t) = df_{\gamma(t)} \big( \gamma^\prime(t) \big)\]
\end{proposition}
\begin{proof}
For any $t_0 \in J$,
\begin{align*}
    df_{\gamma(t_0)} \big( \gamma^\prime (t_0)\big) & = \gamma^\prime (t_0) f \\
    & = \bigg( \gamma_* \frac{d}{dt} \bigg|_{t_0} \bigg) f \\
    & = \frac{d}{dt} \bigg|_{t_0} (f \circ \gamma) \\
    & = (f \circ \gamma)^\prime (t_0) 
\end{align*}
\end{proof}

So far, we have defined two types of derivatives for a smooth real valued function $f: M \longrightarrow \mathbb{R}$ at a point $p \in M$. The first is the pushforward $f_*$ as a linear map from $T_p M$ to $T_{f(p)} \mathbb{R}$. Later, we have defined the differential $df_p$ a a covector at $p$, which is just a linear map from $T_p M$ to $\mathbb{R}$. But the canonical isomorphism between $\mathbb{R}$ and its tangent space at any point leads to these two interpretations of the derivative being exactly the same. 

Similarly, if $\gamma$ is a smooth curve in $M$, we have two different meanings for the expression $(f \circ \gamma)^\prime (t)$. 
\begin{enumerate}
    \item $f \circ \gamma$ can be interpreted as a smooth curve in $\mathbb{R}$, and thus $(f \circ \gamma)^\prime (t)$ is its tangent vector at the point $(f \circ \gamma) (t) \in \mathbb{R}$, i.e. an element of the tangent space $T_{(f \circ \gamma)^\prime (t)} \mathbb{R}$. 
    \item Or, $f \circ \gamma$ can be considered as an ordinary function from $\mathbb{R}$ to $\mathbb{R}$, with $(f \circ \gamma)^\prime$ being just its ordinary derivative. 
\end{enumerate}
Either one of these two interpretations are equally correct since the derivative shown in 2 is equal to the real number $df_{\gamma(t)} \big( \gamma^\prime (t)\big)$. 

\subsection{Pullbacks}
We know that a smooth map yields a linear map on the tangent vectors called the pushforward. Dualizing this leads to a linear map on covectors going in the opposite direction. 

\begin{definition}
Let $F: M \longrightarrow N$ be a smooth map, and let $p \in M$ be arbitrary. The pushforward map
\[F_* :T_p M \longrightarrow T_{F(p)} N\]
yields a dual linear map 
\[(F_*)^* : T_{F(p)}^* N \longrightarrow T_p^* M\]
called the \textit{pullback associated with $F$}. More simply, we rewrite the above as
\[F^*:T_{F(p)}^* N \longrightarrow T_p^* M\]
We can see that $F^*$ is defined by 
\[(F^* \omega)(X) = \omega (F_* X) \text{ for } \omega \in T^*_{F(p)} N, X \in T_p M\]
Note that $(F^* \omega)(X)$ is a scalar field on $M$ (since $F^* \omega$ is a covector field on $M$ and $X$ is a vector field on $M$). 
\end{definition}

We have noted that pushforwards do not always work on vector fields, but smooth covector fields always pull back to smooth covector fields. That is, given a smooth map $G: M \longrightarrow N$ and a smooth covector field $\omega$ on $N$, we can define a covector field $G^* \omega$ on $M$ by 
\[(G^* \omega) (p) = G^* (\omega_{G(p)})\]
Notice that there is no ambiguity about what point to pull back from. 

\begin{lemma}
Let $G: M \longrightarrow N$ be a smooth map, and let $f \in C^\infty(N)$ and $\omega \in \mathcal{T}^* (N)$. Then 
\begin{align*}
    G^* df & = d (f \circ G) \\
    G^* (f \omega) & = (f \circ G) G^* \omega 
\end{align*}
\end{lemma}

\begin{proposition}
Suppose $G: M \longrightarrow N$ is smooth, and let $\omega$ be a smooth covector field on $N$. Then $G^* \omega$ is a smooth covector field on $M$. 
\end{proposition}

The formula for the pullback of a covector field with respect to smooth coordinates $(x^i)$ on the domain and $(y^j)$ on the range is
\[G^* \omega = G^* (\omega_j dy^j) = (\omega_j \circ G) d(y^j \circ G) = (\omega_j \circ G) dG^j\]
where $G^j$ is the $j$th component function of $G$ in these coordinates. This makes the computation of pullbacks in coordinates very simple. 

\begin{example}
Let $G: \mathbb{R}^3 \longrightarrow \mathbb{R}^2$ be the map given by 
\[(u, v) = G(x, y, z) = (x^2 y, y \sin{z})\]
and let $\omega \in \mathcal{T}^*(\mathbb{R}^2)$ be the covector field 
\[\omega = u \,dv + v\,du\]
Then, the pullback $G^* \omega$ is given by 
\begin{align*}
    G^* \omega & = (u \circ G) d(v \circ G) + (v \circ G) d (u \circ G) \\
    & = (x^2 y) d(y \sin{z}) + (y \sin{z}) d (x^2 y) \\
    & = x^2 y (\sin{z} dy + y \cos{z} dz) + y \sin{z} (2xy dx + x^2 dy) \\
    & = 2xy^2 \sin{z} dx + 2x^2 y \sin{z} dy + x^2 y^2 \cos{z} dz
\end{align*}
\end{example}

\subsection{Line Integrals}
We would like to make a coordinate independent sense of the line integral. 

\begin{definition}
Let $[a, b] \subset \mathbb{R}$ be a compact interval, and let $\omega$ be a smooth covector field on $[a,b]$ (note that at the endpoints, smoothness of $\omega$ means that $\omega$ admits a smooth extension of to some neighborhood of $[a,b]$). Letting $t$ denote the one standard coordinate in $\mathbb{R}$, then we can write $\omega$ in terms of $t$ coordinates as 
\[\omega_t \equiv f(t)\,dt\]
for some smooth $f: [a,b] \longrightarrow \mathbb{R}$. Then, the \textit{integral of $\omega$ over $[a,b]$} is defined 
\[\int_{[a,b]} \omega \equiv \int_a^b f(t)\,dt\]
\end{definition}

This definition gives rise to the following property of the line integral. 

\begin{proposition}[Diffeomorphism Invariance of the Integral]
Let $\omega$ be a smooth covector field on the compact interval $[a,b] \subset \mathbb{R}$. If $\varphi: [c,d] \longrightarrow [a,b]$ is an increasing diffeomorphism (meaning that $t_1 < t_2 \implies \varphi(t_1) < \varphi(t_2)$), then
\[\int_{[c,d]} \varphi^* \omega = \int_{[a,b]} \omega\]
\end{proposition}
\begin{proof}
Let $t$ denote the standard coordinate on $[a,b]$ and $s$ denote that of $[c,d]$. Then the formula for the pullback of the covector field, in coordinate expression, is
\[(\varphi^*) \omega)_s = f\big(\varphi(s)\big) \varphi^\prime (s)\,ds\]
meaning that 
\[\int_{[c,d]} \varphi^* \omega = \int_c^d f\big( \varphi(s) \big) \varphi^\prime (s) \,ds = \int_a^b f(t)\,dt = \int_{[a,b]} \omega\]
by the change of variables formula for ordinary integrals. 
\end{proof}

\begin{definition}
Let $M$ be a smooth manifold. A \textit{curve segment in $M$} is a continuous curve $\gamma: [a,b] \longrightarrow M$ whose domain is a compact interval. It is a \textit{smooth curve segment} if it has a smooth extension to an open interval containing $[a,b]$. A \textit{piecewise smooth curve segment} is a curve segment $\gamma: [a,b] \longrightarrow M$ with the property that there exists a finite partition of $[a,b]$ such that the image of each partition is smooth. 
\end{definition}

Now we can define line integrals over smooth covector fields on an arbitrary manifold $M$. 

\begin{definition}
If $\gamma: [a,b] \longrightarrow M$ is a smooth curve segment and $\omega$ is a smooth covector field on $M$, the \textit{line integral of $\omega$ over $\gamma$} is defined to be the real number
\[\int_\gamma \omega \equiv \int_{[a,b]} \gamma^* \omega\]
More generally, if $\gamma$ is piecewise smooth (with partitions $[a_{i-1}, a_i]$ for $i = 1, ..., k$), then we define
\[\int_\gamma \omega \equiv \sum_{i=1}^k \int_{[a_{i-1}, a_i]} \gamma^* \omega\]
\end{definition}

Note that this definition now gives rigorous meaning to classical line integrals such as 
\[\int_\gamma P \,dx + Q\,dy\]
in $\mathbb{R}^2$ or 
\[\int_\gamma P\,dx + Q\,dy + R\,dz\]

\begin{proposition}[Properties of Line Integrals]
Let $M$ be a smooth manifold. Suppose $\gamma: [a,b] \longrightarrow M$ is a piecewise smooth curve segment and $\omega, \omega_1, \omega_2 \in \mathcal{T}^* (M)$. 
\begin{enumerate}
    \item For any $c_1, c_2 \in \mathbb{R}$, 
    \[\int_\gamma (c_1 \omega_1 + c_2 \omega_2) = c_1 \int_\gamma \omega_1 + c_2 \int_\gamma \omega_2\]
    \item If $\gamma$ is a constant map, then 
    \[\int_\gamma \omega = 0\]
    for all $\omega$. 
    \item If $a < c < b$, then 
    \[\int_\gamma \omega = \int_{\gamma_1} \omega + \int_{\gamma_2} \omega\]
    where $\gamma_1 = \gamma \big|_{[a,c]}$ and $\gamma_2 = \gamma \big|_{[a,c]}$. 
\end{enumerate}
\end{proposition}

The next lemma gives a useful alternative expression for the line integral of a covector field on a manifold. This is good for computations.

\begin{lemma}
If $\gamma: [a,b] \longrightarrow M$ is a piecewise smooth curve segment, the line integral of $\omega$ over $\gamma$ can also be expressed as the ordinary integral 
\[\int_\gamma \omega = \int_a^b \omega_{\gamma(t)} \big( \gamma^\prime (t) \big)\,dt\]
\end{lemma}

\begin{example}
Let $M = \mathbb{R}^2 \setminus \{0\}$, and let $\omega$ be the covector field on $M$ given by
\[\omega \equiv \frac{x \,dy - y\,dx}{x^2 + y^2}\]
and let $\gamma: [0, 2\pi] \longrightarrow M$ be the curve segment defined 
\[\gamma(t) \equiv \big( \cos{t}, \sin{t} \]
Since $\gamma^* \omega$ can be computed by substituting $x = \cos{t}$ and $y = \sin{t}$ everywhere in the formula for $\omega$, we get
\[\int_\gamma \omega = \int_{[0,2\pi]} \frac{\cos{t} (\cos{t}\,dt) - \sin{t} (-\sin{t}\,dt)}{\sin^2{t} + \cos^2{t}} = \int_0^{2\pi} \,dt = 2\pi\]
\end{example}

Another important property of line integrals is invariance under reparamaterizations.

\begin{definition}
Let $\gamma: [a,b] \longrightarrow M$ and $\Tilde{\gamma}: [c,d] \longrightarrow M$ be smooth curve segments. If $\Tilde{\gamma} = \gamma \circ \varphi$ for some diffeomorphism $\varphi: [c,d] \longrightarrow [a,b]$, then it is said that $\Tilde{\gamma}$ is a \textit{reparamaterization} of $\gamma$. 

If $\varphi$ is an increasing function, then $\Tilde{\gamma}$ is a \textit{forward paramaterization}, and if $\varphi$ is decreasing, then $\Tilde{\gamma}$ is a \textit{backward paramaterization}. 
\end{definition}

\begin{proposition}
Let $M$ be a smooth manifold, $\omega$ a smooth covector field on $M$, and $\gamma$ a piecewise smooth curve segment in $M$. For any reparamaterization $\Tilde{\gamma}$ of $\gamma$, we have
\[\int_{\Tilde{\gamma}} \omega = \begin{cases}
      \int_\gamma \omega, & \Tilde{\gamma} \text{ is a forward paramaterization} \\
      - \int_\gamma \omega, & \Tilde{\gamma} \text{ is a backward paramaterization}
\end{cases}\]
\end{proposition}
\begin{proof}
This is a direct result of the diffeomorphism invariance property of the integral. 
\end{proof}

There is one special case in which a line integral is trivial to compute: the line integral of a differential. 

\begin{theorem}[Fundamental Theorem of Line Integrals]
Let $M$ be a smooth manifold. Let $f$ is a smooth real-valued function on $M$ and let $\gamma: [a,b] \longrightarrow M$ be a piecewise smooth curve segment in $M$. Then 
\[\int_\gamma \,df = \int_\gamma \, \frac{\partial f}{\partial x^i} dx^i = f\big(\gamma(b)\big) - f\big(\gamma(a)\big)\]
\end{theorem}
\begin{proof}
Suppose that $\gamma$ is smooth. Then, 
\[\int_\gamma\,df = \int_a^b df_{\gamma(t)} \big( \gamma^\prime (t) \big) \,dt = \int_a^b (f \circ \gamma)^\prime (t) \,dt = f \circ \gamma (b) - f \circ \gamma (a)\]
This naturally extends to piecewise smooth functions, since then the right hand side will be a telescoping sum in which the middle terms cancel out. 
\end{proof}

\subsection{Conservative Covector Fields}
The fundamental theorem of line integrals shows that if a covector field $\omega$ can be written as the differential of a smooth function, then the line integral can be computed extremely easily once the smooth function is known. We formally define this kind of vector field. 

\begin{definition}
A smooth covector field $\omega$ on manifold $M$ is \textit{exact} (or an \textit{exact differential}) on $M$ if there exists a function $f \in C^\infty (M)$ such that $\omega = df$. The function $f$ is called the \textit{potential for $\omega$}. 
\end{definition}

Note that the potential of an exact smooth covector field is not uniquely determined, but the difference between any two potentials must be constant. We now define a similar construction called the conservative covector field. 

\begin{definition}
A smooth covector field $\omega$ is \textit{conservative} if the line integral of $\omega$ over any closed piecewise smooth curve segment is $0$. 
\end{definition}

It is easy to understand the following lemma given the definition of conservative covector fields. 

\begin{lemma}
A smooth covector field $\omega$ is conservative if and only if the line integral of $\omega$ depends on the endpoints of the curve. That is, 
\[\int_\gamma \omega = \int_{\Tilde{\gamma}} \omega\]
if $\gamma$ and $\Tilde{\gamma}$ are piecewise smooth curve segment swith the same starting and ending points. 
\end{lemma}

This leads to the equivalence of exact and conservative vector fields. 

\begin{theorem}
A smooth covector field is conservative if and only if it is exact. 
\end{theorem}

\section{Submersions, Immersions, and Embeddings}
Because the pushforward represents the "best linear approximation" to the map near a given point, we can learn a great deal about the map itself by studying linear-algebraic properties of its pushforward at each point. The most important property is the rank of the pushforward. 

\subsection{Maps of Constant Rank}
\begin{definition}
If $F: M \longrightarrow N$ is a smooth map, the \textit{rank of $F$ at $p \in M$} is the rank of the linear map 
\[F_*: T_p M \longrightarrow T_{F(p)}M\]
In an abstract sense, it is the dimension of the image of $F_*$ in $T_{F(p)} M$. Given any charts in the neighborhoods of $p$ and $F(p)$, the rank of $F$ at $p$ is the rank of the matrix of partial derivatives of $F$. 
\end{definition}

Note that the rank does not depend on the choice of basis for our chart mappings. 

\begin{definition}
If $F: M \longrightarrow N$ has the same rank $k$ at every point, then we can say that $F$ has \textit{constant rank}. That is, 
\[\rank{F} = k\]
\end{definition}

\begin{definition}
A smooth map $F: M \longrightarrow N$ is called a \textit{submersion} if $F_*$ is surjective at each point, or equivalently, $\rank{F} = \dim{N}$. 
\end{definition}

\begin{definition}
A smooth map $F: M \longrightarrow N$ is called an \textit{immersion} if $F_*$ is injective at each point, or equivalently, $\rank{F} = \dim{M}$. 
\end{definition}

We can imagine submersions and immersions behaving locally like surjective and injective linear maps, respectively. 

\begin{definition}
A \textit{smooth embedding} is an immersion $F: M \longrightarrow N$ that is also a topological embedding (i.e. a homeomorphism onto its image $F(M) \subset N$ in the subspace topology). 
\end{definition}

\subsection{The Inverse Function Theorem}

\begin{definition}
Let $X$ be a metric space. A map $G: X \longrightarrow X$ is said to be a \textit{contraction} if there is a constant $\lambda < 1$ such that $d\big( G(x), G(y) \big) \leq \lambda d(x, y)$ for all $x, y \in X$. Clearly, any contraction is continuous. 
\end{definition}

\begin{theorem}[Inverse Function Theorem on Euclidean Space]
Suppose $U$ and $V$ are open subsets in $\mathbb{R}^n$, and $F: U \longrightarrow V$ is a smooth map. If $DF(p)$ is nonsingular at some point $p \in U$, then there exists connected neighborhoods $U_0 \subset U$ of $p$ and $V_0 \subset V$ of $F(p)$ such that 
\[F \big|_{U_0} : U_0 \longrightarrow V_0\]
is a diffeomorphism. 
\end{theorem}

\section{Tensors}
We will always assume that the base field of every vector space mentioned is $\mathbb{R}$. 

\subsection{The Algebra of Tensors}
We will assume that the reader is already familiar with the notion of tensors both as multilinear maps and as the abstract tensor product of vector spaces. There will be slight changes in notation compared to the descriptions of tensors in previous chapters. 

\begin{definition}
A \textit{covariant $k$-tensor} is an element of 
\[T^k (V) = \bigotimes_k V^*\]
which is just a multilinear map from the Cartesian product of $V$'s to $\mathbb{R}$. A \textit{contravariant $l$-tensor} is an element of 
\[T_l (V) = \bigotimes_l V\]
Generally, for any nonnegative integers $k, l$, the space of \textit{mixed tensors} of type $(k, l)$ is defined as 
\[T^k_l (V) \equiv \bigotimes_k V^* \otimes \bigotimes_l V\]
which is really the space of real-valued multilinear functions of $k$ vectors and $l$ covectors. 
\end{definition}

Strictly speaking, the $T^k (V)$ and the space of all covariant tensors are not the same, but rather naturally isomorphic to each other. However, we will treat them as the same thing. 

\begin{example}[Covariant Tensors]
\begin{enumerate}
    \item Every linear map $\omega: V \longrightarrow \mathbb{R}$ is multilinear. It is a covariant $1$-tensor. 
    \item An inner product on $V$ is a covariant $2$-tensor, since by definition an inner product is bilinear.  
    \item The determinant, thought of as a function of $n$ vectors (columns of a matrix) is a covariant $n$-tensor of $\mathbb{R}^n$. 
    \item Suppose $\omega, \eta \in V^*$. We define a map $\omega \otimes \eta: V \times V \longrightarrow \mathbb{R}$ as
    \[\omega \otimes \eta (X, Y) \equiv \omega (X) \, \eta(Y)\]
    where the product on the right is ordinary multiplication of real numbers. The linearity of $\omega$ and $\eta$ guarantees that $\omega \otimes \eta$ is a bilinear function of $X$ and $Y$. 
\end{enumerate}
\end{example}

We will now provide another abstract construction of a tensor product space. 

\begin{definition}
Let $S$ be a set. A \textit{finite formal linear combination} is a function $\mathcal{F}: S\longrightarrow \mathbb{R}$ such that $\mathcal{F}(s) = 0$ for all but finitely many $s \in S$. 
\end{definition}

\begin{definition}
Let $S$ be a set. The \textit{free vector space on $S$}, denoted $\mathbb{R} \langle S \rangle$, is the set of all finite formal linear combination of elements of $S$ with real coefficients. Under pointwise addition and scalar multiplication, $\mathbb{R} \langle S \rangle$ becomes a real vector space. 
\end{definition}

Identifying each element $x \in S$ with the function that takes the value $1$ on $x$ and $0$ on all other elements of $S$, any element $\mathcal{F} \in \mathbb{R} \langle R \rangle$ can be written uniquely as a linear combination of these functions as the basis. This means that $\mathbb{R} \langle S \rangle$ is finite dimensional if and only if $S$ is a finite set. 

Now, we construct the tensor product space in a more abstract way. 
\begin{definition}
Let $V, W$ be finite-dimensional real vector spaces, and let $\mathcal{R}$ be the subspace of the free vector space $\mathbb{R} \langle V \times W \rangle$ spanned by all elements of the form 
\begin{align*}
    &a (v, w) - (a v, w), \\
    &a (v, w) - (v, a w), \\
    &(v, w) + (v^\prime, w) - (v + v^\prime, w) \\
    &(v, w) + (v, w^\prime) - (v, w + w^\prime) 
\end{align*}
for $a \in \mathbb{R}, v, v^\prime \in V$, and $w, w^\prime \in W$. The \textit{tensor product} of $V$ and $W$, denoted by $V \otimes W$, is the quotient space 
\[V \otimes W \equiv \frac{\mathbb{R} \langle V \times W \rangle}{\mathcal{R}}\]
The equivalence class of an element $(v, w)$ in $V \otimes W$ is denoted by $v \otimes w$. 
\end{definition}

\begin{proposition}[Bilinearity of the Tensor Product]
The construction of the tensor product implies 
\begin{align*}
    a (v \otimes w) & = av \otimes w = v \otimes a w \\
    v \otimes w + v^\prime \otimes w & = (v + v^\prime) \otimes w \\
    v \otimes w + v \otimes w^\prime & = v \otimes (w + w^\prime) 
\end{align*}
\end{proposition}

\begin{proposition}[Characteristic Property of Tensor Products]
Let $V$ and $W$ be finite-dimensional real vector spaces. If $A: V \times W \longrightarrow X$ is a bilinear map into any vector space $X$, there is a unique linear map $\Tilde{A}: V \otimes W \longrightarrow X$ such that the following diagram commutes. 
\[\begin{tikzcd}
V \times W \arrow{r}{A} \arrow{d}{\pi} & X \\
V \otimes W \arrow{ru}{\Tilde{A}}
\end{tikzcd}\]
where $\pi(v, w) = v \otimes w$. 
\end{proposition}

This is called the characteristic property because it uniquely characterizes the tensor product up to isomorphism. 

\begin{proposition}[Properties of Tensor Products]
Let $V, W$, and $X$ be finite-dimensional real vector spaces. 
\begin{enumerate}
    \item The tensor product $V^* \otimes W^*$ is canonically isomorphic to the space $B(V, W)$ of bilinear maps from $V \otimes W$ to $\mathbb{R}$. 
    \item If $(E_i)$ is a basis for $V$ and $(F_j)$ is a basis for $W$, then the set of all elements of the form $E_i \otimes F_j$ is a basis for $V \otimes W$, with $\dim{V\otimes W} = (\dim{V}) (\dim{W})$. 
    \item There is a unique isomorphism $V \otimes (W \otimes X) \longrightarrow (V \otimes W) \otimes X$ sending $v \otimes (w \otimes x) \mapsto (v \otimes w) \otimes x$. 
\end{enumerate}
\end{proposition}

In most cases, we will concern ourselves with covariant tensors. 

\subsection{Tensors and Tensor Fields on Manifolds}

\begin{definition}
Let $M$ be a smooth manifold. The \textit{bundle of covariant $k$-tensors on $M$} is defined to be 
\[T^k M \equiv \bigsqcup_{p \in M} T^k (T_p M)\]
The \textit{bundle of contravariant $l$-tensors} is defined
\[T_l M \equiv \bigsqcup_{p \in M} T_l (T_p M)\]
and the \textit{bundle of mixed tensors of type $(k, l)$} is defined
\[T^k_l M \equiv \bigsqcup_{p \in M} T_l^k (T_p M)\]
These are all called \textit{tensor bundles over $M$}. 
\end{definition}

This allows us to generalize previously defined bundles, leading to the identifications: 
\begin{enumerate}
    \item $T^0 M = T_0 M = M \times \mathbb{R}$
    \item $T^1 M = T^* M$
    \item $T_1 M = T M$
    \item $T^k_0 M = T^k M$
    \item $T^0_l M = T_l M$
\end{enumerate}

\begin{definition}
A \textit{section} of a tangent bundle is called a \textit{(covariant, contravariant, or mixed) tensor field on $M$}. A \textit{smooth tensor field} is a section that is smooth in the usual sense of smooth sections of vector bundles. The vector spaces of smooth sections of these bundles is denoted
\begin{align*}
    \mathcal{T}^k (M) \equiv \{\text{smooth sections of } T^k M \} \\
    \mathcal{T}_l (M) \equiv \{\text{smooth sections of } T^l M \} \\
    \mathcal{T}^k_l (M) \equiv \{\text{smooth sections of } T^k_l M \}
\end{align*}
\end{definition}

In any smooth local coordinates $(x^i)$, sections of these bundles can be written (using the summation convention) as
\[\sigma = \begin{cases}
      \sigma_{i_1 ... i_k} \, dx^{i_1} \otimes ... \otimes dx^{i_k}, & \sigma \in \mathcal{T}^k (M) \\
      \sigma^{j_1 ... j_l} \, \frac{\partial}{\partial x^{j_1}} \otimes ... \otimes \frac{\partial}{\partial x^{j_l}}, & \sigma \in \mathcal{T}_l (M) \\
      \sigma_{i_1 ... i_k}^{j_1 ... j_l} \, dx^{i_1} \otimes ... \otimes dx^{i_k} \otimes \frac{\partial}{\partial x^{j_1}} \otimes ... \otimes \frac{\partial}{\partial x^{j_l}}, & \sigma \in \mathcal{T}^k_l (M)
\end{cases}\]
The functions $\sigma_{i_1 ... i_k}^{j_1 ... j_l} : M \longrightarrow \mathbb{R}$ are called the \textit{component functions} of $\sigma$. 

\begin{lemma}
Let $M$ be a smooth vector field. The following are equivalent.
\begin{enumerate}
    \item $\sigma$ is smooth. 
    \item In any smooth coordinate chart, the component functions of $\sigma$ are smooth. 
    \item If $X_1, ..., X_k$ are smooth vector fields defined on any open subset $U \in M$, then the function $\sigma(X_1, ..., X_k): U \longrightarrow \mathbb{R}$ defined by 
    \[\sigma(X_1, ..., X_k) (p) \equiv \sigma_p (X_1 \big|_p, ..., X_k \big|_p)\]
    is smooth. 
\end{enumerate}
\end{lemma}

\subsubsection{Pullbacks}

\subsection{Symmetric Tensors}
\begin{definition}
Let $V$ be a finite-dimensional vector space. A covariant $k$-tensor $T$ on $V$ is said to be \textit{symmetric} if its value is unchanged by interchanging any pair of arguments. 
\[T(X_1,..., X_i, ..., X_j, ..., X_k) = T(X_1,..., X_j, ..., X_i, ..., X_k)\]
Since the set of transpositions form the generating set of the set of all permutations of $n$ elements, a symmetric tensor is invariant under any permutation of its arguments. 
\end{definition}

\begin{definition}
The set of symmetric covariant $k$-tensors on $V$ is denoted $\Sigma^k (V)$, which is a vector subspace of $T^k (V)$. There is a natural surjective projection 
\[\Sym: T^k (V) \longrightarrow \Sigma^k (V)\]
called \textit{symmetrization}. Given a $k$-tensor $T$ and a permutation $\sigma \in S_k$ ($S_k$ is the symmetric group of $k$ elements), we define the symmetrization of tensor $T$ by
\[\Sym(T) \equiv \frac{1}{k!} \sum_{\sigma \in S_k} T (X_{\sigma(1)}, ... X_{\sigma(k)})\]
\end{definition}

Note that if $S$ and $T$ are symmetric tensors on $V$, then $S \otimes T$ is not symmetric in general. But we can simply define a new product that does produce a symmetric product. 

\begin{definition}
Given $S \in \Sigma^k (V)$ and $T \in \Sigma^l (V)$, their \textit{symmetric product} is the $(k+l)$-tensor $ST$ defined
\[S T \equiv \Sym(S \otimes T)\]
We can explicitly define this as 
\[ST(X_1, ..., X_{k+l}) \equiv \frac{1}{(k+l)!} \sum_{\sigma \in S_{k+l}} S\big(X_{\sigma(1)}, ..., X_{\sigma(k)} \big)\, T\big( X_{\sigma(k+1)}, ..., X_{\sigma(k+l)} \big)\]
\end{definition}

Note that the symmetric product (written using juxtaposition of tensors above) is the same product as the product "$\odot$" mentioned in the linear algebra chapter.  

\begin{proposition}[Properties of the Symmetric Product]
We list two additional important properties. 
\begin{enumerate}
    \item The symmetric product is symmetric and bilinear. For all symmetric tensors $R, S, T$ and all $a, b \in \mathbb{R}$, 
    \begin{align*}
        ST & = TS \\
        (a R + b S) T & = a RT + b ST= T (a R + bS) 
    \end{align*}
    \item If $\omega$ and $\eta$ are covectors, then 
    \[\omega \eta = \frac{1}{2} (\omega \otimes \eta + \eta \otimes \omega)\]
\end{enumerate}
\end{proposition}

\begin{definition}
A \textit{symmetric tensor field} on a manifold is a covariant tensor field whose value at any point is a symmetric tensor. 
\end{definition}

\subsection{Riemannian Metrics}
\begin{definition}
A \textit{Riemannian metric} on manifold $M$ is a smooth symmetric 2-tensor field that is positive definite at each point. A \textit{Riemannian manifold} is a pair $(M, g)$ where $M$ is a smooth manifold and $g$ is a Riemannian metric on $M$. 
\end{definition}

Note that a Riemannian metric is not the same as a metric on a vector space. 

\begin{proposition}[Existence of Riemannian Metrics]
Every smooth manifold admits a Riemannian metric. 
\end{proposition}

If $g$ is a Riemannian metric on $M$, then for each $p \in M$, $g_p$ is an inner product on $T_p M$. For $X, Y \in T_p M$, the expression $\langle X, Y \rangle_g$ is used to denote the real number $g_p (X, Y)$. Furthermore, in any smooth local coordinates $(x^i)$, a Riemannian metric can be written 
\[g = g_{i g} dx^i \otimes dx^j\]
where $g_{ij}$ is a symmetric positive definite matrix of smooth functions. The symmetry of $g$ also allows us to write $g$ as 
\begin{align*}
    g & = g_{ij} dx^i \otimes dx^j \\
    & = \frac{1}{2} (g_{ij} dx^i \otimes dx^j + g_{ji} dx^i \otimes dx^j) \\
    & = \frac{1}{2} (g_{ij} dx^i \otimes dx^j + g_{ij} dx^i \otimes dx^j) \\
    & = g_{ij} dx^i dx^j 
\end{align*}

\begin{example}
The simplest example of a Riemannian metric is the \textit{Euclidean metric} $\bar{g}$ on $\mathbb{R}^n$, defined in standard coordinates as 
\[\bar{g}(x, y) \equiv \delta_{ij} dx^i dx^j\]
where $\delta_{ij}$ is the Kronecker delta. It is common to use the notation $\omega^2$ for the symmetric product of tensor $\omega$ with itself, so the Euclidean metric can also be written 
\[\bar{g} = (dx^1)^2 + ... + (dx^n)^2\]
\end{example}

\subsubsection{Pseudo-Riemannian Metrics}
Relaxing the requirement that the metric be positive definite results in a generalization of the Riemannian  metric. 

\begin{definition}
A $2$-tensor $g$ on a vector space $V$ is said to be nondegenerate if $g(X, Y) = 0$ for all $Y \in V$ if and only if $X = 0$. 
\end{definition}

Just as any inner product can be transformed to the Euclidean one by switching to an orthonormal basis, every nondegenerate  symmetric $2$-tensor can be transformed by a change of basis to one with a diagonal matrix of diagonal entire $\pm 1$. However, the number of $-1$'s and $+1$'s are invariant under a choice of basis. That is, the \textit{signature} of $g$ is an invariant of $g$. 

\section{Differential Forms}

We have introduced line integrals of covector fields, which generalized ordinary integrals to curves in manifolds. Now, we will generalize the theory of multiple integrals over manifolds. 

\subsection{The Algebra of Alternating Tensors}
\begin{definition}
A covariant $k$-tensor $T$ on a finite-dimensional vector space $V$ is said to be \textit{alternating} if its has the property
\[T(X_1, ..., X_i, ..., X_j, ..., X_k) = - T(X_1, ..., X_j, ..., X_i, ..., X_k)\]
An alternating $k$-tensor is also called a \textit{$k$-covector}. Note that this 
\end{definition}

Bilinearity and the alternating properties of the alternating $k$-tensor indicates that it is a good measure of the \textit{signed volume} of a parallelopiped. The following lemma also supports this notion, since a $m$-dimensional parallelopiped in an $n$-dimensional space has volume $0$ when $m < n$. 

\begin{lemma}
Suppose $\Omega$ is a $k$-tensor on a vector space $V$ with the property that $\Omega(X_1, ..., X_k) = 0$ whenever $X_1, ..., X_k$ is linearly dependent. Then $\Omega$ is alternating.
\end{lemma}
\begin{proof}
By bilinearity, the hypothesis says that $\Omega$ gives the value $0$ whenever two arguments are the same. So, 
\begin{align*}
    0 & = \Omega(X_1, ..., X_{i+j}, ... X_{i+j}, ..., X_n)  \\
    & = \Omega(X_1, ..., X_{i}, ... X_{i}, ..., X_n) + \Omega(X_1, ..., X_{i}, ... X_{j}, ..., X_n) \\
    & + \Omega(X_1, ..., X_{j}, ... X_{i}, ..., X_n) + \Omega(X_1, ..., X_{j}, ... X_{j}, ..., X_n) \\
    & = \Omega(X_1, ..., X_{i}, ... X_{i+j}, ..., X_n) + \Omega(X_1, ..., X_{j}, ... X_{i+j}, ..., X_n)
\end{align*}
which means that 
\[\Omega(X_1, ..., X_{i}, ... X_{i+j}, ..., X_n) = - \Omega(X_1, ..., X_{j}, ... X_{i+j}, ..., X_n)\]
\end{proof}

Because of these properties, alternating tensor fields are good candidates for objects that can be integrated in a coordinate-independent way. 

\begin{proposition}
The following are equivalent for a covariant $k$-tensor $T$. 
\begin{enumerate}
    \item $T$ is alternating. 
    \item For any vectors $X_1, ..., X_n$, 
    \[T(X_{\sigma(1)}, ..., T(X_{\sigma(n)}) = (\text{sgn}(\sigma) T(X_1, ..., X_n)\]
    \item $T$ gives zero whenever two of its arguments are equal. 
    \item $T = 0$ whenever its arguments are linearly dependent.
\end{enumerate}
\end{proposition}

Note that any $2$-tensor can be expressed as a sum of its symmetric components and alternating components, since
\begin{align*}
    T(X, Y) & = \frac{1}{2} \big( T(X, Y) - T(X, Y)\big) + \frac{1}{2} \big( T(X, Y) + T(Y, X) \big) \\
    & = A(X, Y) + S(X, Y)
\end{align*}
where $A(X, Y) = \frac{1}{2} \big( T(X, Y) - T(X, Y) \big)$ is alternating and $S (X, Y) = \frac{1}{2} \big( T(X, Y) + T(X, Y) \big)$ is symmetric. However, this is not true for tensors of higher rank. 

Note that $S$ is just defined as $\Sym{T}$, the symmetric projection of $T$. We can define a similar projection 
\[\Alt: T^k (V) \longrightarrow \Lambda^k (V)\]
called the \textit{alternating projection}, defined
\[\Alt{T} \equiv \frac{1}{k!} \sum_{\sigma \in S_k} (\text{sgn}\,\sigma) (X_{\sigma(1)}, ..., X_{\sigma(k)})\]

\begin{example}
Let $T$ be a $1$-tensor. Then $\Alt{T} = T$. It $T$ is a $2$-tensor, then
\[\Alt{T(X, Y)} = \frac{1}{2} \big(T(X, Y) - T(Y, X) \big)\]
If $T$ is a $3$-tensor, 
\begin{align*}
    \Alt{T(X, Y, Z)} & = \frac{1}{6} \big( T(X, Y, Z) + T(Y, Z, X) + T(Z, X, Y) \\ & - T(Y, X, Z) - T(X, Z, Y) - T(Z, Y, X) \big)  
\end{align*}
\end{example}

\begin{lemma}[Properties of the Alternating Projection]
For any tensor $T$, $\Alt{T}$ is alternating. $T$ is alternating if and only if $\Alt{T} = T$. 
\end{lemma}

\begin{proposition}
Let $V$ be an $n$-dimensional vector space. If $(\varepsilon^i)$ is any basis for $V^*$, then for each positive integer $k \leq n$, the collection of $k$-covectors 
\[\mathcal{E} = \{\varepsilon^I \;|\; I \text{ is an increasing multi-index of length } k\}\]
is a basis for $\Lambda^k (V)$. Therefore, 
\[\dim \Lambda^k (V) = {{n}\choose{k}}\]
and if $k > n$, then $\dim{\Lambda^k (V)} = 0$. 
\end{proposition}

\subsection{The Wedge Product}

\begin{definition}
If $\omega \in \Lambda^k (V)$ and $\eta \in \Lambda^l (V)$, the \textit{wedge product}, or \textit{exterior product} of $\omega$ and $\eta$ is the alternating $(k+l)$-tensor 
\[\omega \wedge \eta \equiv \frac{(k+l)!}{k! l!} \Alt(\omega \otimes \eta)\]
\end{definition}

\begin{lemma}
Let $(\varepsilon^1, ..., \varepsilon^n)$ be a basis for $V^*$. For any multi-indices $I = (i_1, ..., i_k)$ and $J = (j_1, ..., j_l)$, 
\[\varepsilon^I \wedge \varepsilon^J = \varepsilon^{IJ}\]
where $IJ$ is the multi-index $(i_1, ..., i_k, j_1, ..., j_l)$ obtained by concatenating $I$ and $J$. 
\end{lemma}

\begin{proposition}[Properties of the Wedge Product]
We list properties of the wedge product. 
\begin{enumerate}
    \item Bilinearity. 
    \begin{align*}
        & (a \omega + a^\prime \omega^\prime) \wedge \eta = a (\omega \wedge \eta) + a^\prime (\omega^\prime \wedge \eta) \\
        & \eta \wedge (a \omega + a^\prime \omega^\prime) = a (\eta \wedge \omega) + a^\prime (\eta \wedge \omega^\prime) 
    \end{align*}
    \item Associativity. 
    \[\omega \wedge (\eta \wedge \zeta) = (\omega \wedge \eta) \wedge \zeta\]
    \item Anticommutativity. 
    \[\omega \wedge \eta = (-1)^{kl} \eta \wedge \omega\]
    \item If $(\varepsilon^1, ..., \varepsilon^n)$ is any basis for $V^*$ and $I = (i_1,..., i_k)$ is any multi-index, then 
    \[\varepsilon^{i+1} \wedge ... \wedge \varepsilon^{i_k} = \varepsilon^I\]
    \item For any covectors $\omega^1, ..., \omega^k$ and vectors $X_1, ..., X_k$, 
    \[\omega^1 \wedge ... \wedge \omega^k (X_1, ..., X_k) = \det \big( \omega^j (X_i)\big) \]
\end{enumerate}
\end{proposition}

\begin{definition}
For any $n$-dimensional vector space $V$, the vector space $\Lambda^* (V)$ is defined
\[\Lambda^* (V) = \bigoplus_{k=0}^n \Lambda^k (V)\]
called the \textit{exterior algebra of $V$}. 
\end{definition}

\begin{definition}
An algebra $A$ is said to be \textit{graded} if it has a direct sum decomposition $A = \bigoplus_k A^k$ such that the product satisfies $(A^k) (A^l) \subset A^{k+l}$. 

A graded algebra is \textit{anticommutative} if the product satisfies $ab = (-1)^{kl} ba$ for $a \in A^k, b \in A^l$. 
\end{definition}

Clearly, $\Lambda^* (V)$ is an anticommutative graded algebra. 

\subsection{Differential Forms on Manifolds}
\begin{definition}
Given an $n$-dimensional smooth manifold $M$, the subset of $T^k M$ consisting of alternating tensors is defined
\[\Lambda^k M = \bigsqcup_{p \in M} \Lambda^k (T_p M)\]
It is a smooth subbundle of $T^k M$. 
\end{definition}

\begin{definition}
A section of $\Lambda^k M$ is called a \textit{differential $k$-form}, or just a \textit{$k$-form}. In other words, it is a continuous tensor field whose value at each point is an alternating tensor. The integer $k$ is called the \textit{degree} of the form. 
\end{definition}

\begin{definition}
The vector space of smooth sections of $\Lambda^k M$ is denoted $\mathcal{A}^k M$. 
\end{definition}

In any smooth chart, a $k$-form $\omega$ can be written locally as 
\[\omega = \sum_I \omega_I \, dx^{i_1} \wedge ... \wedge dx^{i_k} = \sum_I \omega_I \, dx^I\]
where the coefficients $\omega_I$ are continuous functions defined on the coordinate domain. We use $dx^I$ as an abbreviation for $dx^{i_1} \wedge ... \wedge dx^{i_k}$. Interpreting the basis forms as forms themselves, 
\[dx^{i_1} \wedge ... \wedge dx^{i_k} \bigg( \frac{\partial}{\partial x^{j_1}}, ..., \frac{\partial}{\partial x^{j_k}} \bigg) = \delta^I_J\]
Thus, the component functions are determined by
\[\omega^I = \omega \bigg( \frac{\partial}{\partial x^{i_1}}, ... ,\frac{\partial}{\partial x^{i_k}} \bigg)\]

\begin{example}
On $\mathbb{R}^3$, some examples of smooth $2$-forms are given by 
\begin{align*}
    & \omega = (\sin{xy}) \,dy \wedge dz \\
    & \eta = dx \wedge dy + dx \wedge dz + dy \wedge dz 
\end{align*}
A $0$-form is just a continuous real-valued function, and a $1$-form is a covector field. Every $n$-form $\mathbb{R}^n$ is a continuous real-valued function times $dx^1 \wedge ... \wedge dx^n$. 
\end{example}

We can take the vector spaces of smooth sections of $\Lambda^k (M)$ of all the degrees $k$ and direct sum them to create an algebra. 

\begin{definition}
Defining the wedge product of two differential forms pointwise
\[(\omega \wedge \eta)_p \equiv \omega_p \wedge \eta_p\]
we can see that the wedge product of a $k$-form with an $l$-form is a $(k+l)$-form. Defining 
\[\mathcal{A}^* (M) \equiv \bigoplus_{k=0}^n \mathcal{A}^k (M)\]
equipped with the wedge product turns this set into a associative, anticommutative graded algebra. 
\end{definition}

If $F: M \longrightarrow N$ is a smooth map and $\omega$ is a smooth differential form on $N$, the pullback $F^* \omega$ is a smooth differential form on $M$, defined as for any smooth tensor field 
\[(F^* \omega)_p (X_1, ..., X_k) \equiv \omega_{F(p)} (F_* X_1, ..., F_* X_k)\]
If $i: N \longrightarrow M$ is the inclusion map of an immersed submanifold, then we denote it as $\omega \big|_N$ for $i^* \omega$. 

The following lemma gives a computational rule for pullbacks of differential forms. It can also be used to compute the expression for a differential form in another smooth chart. 
\begin{lemma}
Suppose $F: M \longrightarrow N$ is smooth. 
\begin{enumerate}
    \item $F^*: \mathcal{A}^k (N) \longrightarrow \mathcal{A}^k (M)$ is linear. 
    \item $F^* (\omega \wedge \eta) = (F^* \omega) \wedge (F^* \eta)$
    \item In any smooth chart 
    \[F^* \Big( \sum_I \omega_I \, dy^{i_1} \wedge ... \wedge dy^{i_k} \Big) = \sum_I (\omega_I \circ F) \, d(y^{i_1} \circ F) \wedge ... \wedge d(y^{i_k} \circ F)\]
\end{enumerate}
\end{lemma}

\begin{proposition}
Let $F: M \longrightarrow N$ be a smooth map between $n$-manifolds. If $(x^i)$ and $(y^j)$ are smooth coordinates on open sets $U \subset M$ and $V \subset N$, respectively, and $u$ is a smooth real-valued function on $V$, then the following holds on $U \cap F^{-1} (V)$. 
\[F^* (u dy^1 \wedge ... \wedge dy^n) = (u \circ F) (\det{DF})\, dx^1 \wedge ... \wedge dx^n\]
where $DF$ represents the matrix of partial derivatives of $F$ in coordinates. 
\end{proposition}

\begin{corollary}
If $\big(U, (x^i)\big)$ and $\big(\Tilde{U}, (\Tilde{x}^j)\big)$ are overlapping smooth coordinate charts on $M$, then the following identity holds on $U \cap \Tilde{U}$:
\[d\Tilde{x}^1 \wedge ... \wedge d\Tilde{x}^n = \det \Big( \frac{\partial \Tilde{x}^j}{\partial x^i}\Big)\, dx^1 \wedge ... \wedge dx^n\]
\end{corollary}

\subsection{Exterior Derivatives}

\begin{theorem}[The Exterior Derivative]
For every smooth manifold $M$, there are unique linear maps
\[d: \mathcal{A}^k (M) \longrightarrow \mathcal{A}^{k+1} (M)\]
defined for each integer $k \geq 0$ and satisfying the following conditions: 
\begin{enumerate}
    \item If $f$ is a smooth real-valued function (i.e. a $0$-form), then $df$ is the differential of $f$, defined as 
    \[df(X) \equiv X f\]
    \item If $\omega \in \mathcal{A}^k (M)$ and $\eta \in \mathcal{A}^l (M)$, then 
    \[d (\omega \wedge \eta) = d \omega \wedge \eta + (-1)^k \omega \wedge d\eta\]
    \item $d \circ d = 0$
\end{enumerate}
The operator $d$ also satisfies the following properties: 
\begin{enumerate}
    \item In every smooth coordinate chart, $d$ is given by 
    \[d \bigg( \sum_J \omega_J dx^J \bigg) = \sum_J d\omega_J \wedge d x^J\]
    \item $d$ is local. That is, if $\omega = \omega^\prime$ on an open set $U \subset M$, then $d\omega = d\omega^\prime$ on $U$. 
    \item $d$ commutes with restriction. That is, if $U \subset M$ is any open set, then 
    \[d (\omega|_U) = (d \omega) \big|_U\]
\end{enumerate}
\end{theorem}

\begin{lemma}[Naturality of the Exterior Derivative]
If $G: M \longrightarrow N$ is a smooth map, then the pullback map
\[G^* : \mathcal{A}^k (N) \longrightarrow \mathcal{A}^k (M)\]
commutes with $d$. That is, for all $\omega \in \mathcal{A}^k (N)$, 
\[G^*(d \omega) = d (G^* \omega) \]
\end{lemma}

\section{Orientations}
\subsection{Orientations on Vector Spaces}
In order to properly define the integration of $k$-forms in a way that is consistent with signed volume of a parallelopiped, we must properly define the orientation of certain vector spaces. 

We could try this using a certain choice of basis. For example, given a choice of \textit{ordered} basis vectors $\{f_1, ..., f_n\}$, we can define the orientation of the vector space spanned by these vectors by computing the sign of the determinant of the matrix with column vectors $f_i$. However, since abstract vector spaces have no canonical vector spaces, we cannot say which vector spaces have the "positive orientation" or is "right-handed." However, we can \textit{compare} whether two bases have a consistent orientation. Thus, we are led to the following definition. 

\begin{definition}
Let $V$ be a vector space of dimension $n \geq 1$. We say that two ordered bases 
\begin{align*}
    & (E_1, ..., E_n) \\
    & (\Tilde{E}_1, ..., \Tilde{E}_n)
\end{align*}
are \textit{consistently oriented} if the transition matrix $(B^j_i)$, defined by the equation
\[E_i = B^j_i \Tilde{E}_j\]
has positive determinant. 
\end{definition}

\begin{definition}
Given vector space $V$ with $\dim{V} \geq 1$, the \textit{orientation of $V$} is an equivalence class of ordered bases. If $(E_1, ..., E_n)$ is any ordered basis for $V$, we denote that orientation that it determines by (the equivalence class)
\[[E_1, ..., E_n]\]
A vector space together with a choice is called an \textit{oriented vector space}. If $V$ is oriented, then any ordered basis $(E_1, ..., E_n)$ that is in the given orientation is said to be \textit{oriented} or \textit{positively oriented}. Any basis that is not in the given orientation is said to be \textit{negatively oriented}. 

For the special case of a $0$-dimensional vector space $V$, we define an orientation of $V$ to be simply a choice of one of the number $\pm 1$. 
\end{definition}

\begin{example}
The orientation $[e_1, ..., e_n]$ of $\mathbb{R}^n$ determined by the standard basis is called the \textit{standard orientation}. The standard orientation for
\begin{enumerate}
    \item $\mathbb{R}$ is the unit vector pointing to the right. 
    \item $\mathbb{R}^2$ is one which the rotation from the first vector to the second is counterclockwise. 
    \item $\mathbb{R}^3$ is one that has a right-handed orientation. 
\end{enumerate}
\end{example}

There is an important connection between orientation and alternating tensors, expressed in the following lemma. 

\begin{lemma}
Let $V$ be a vector space of dimension $\geq 1$, and let $\Omega$ is a nonzero element of $\Lambda^n (V)$. The set of ordered bases $(E_1, ..., E_n)$ such that $\Omega (E_1, ..., E_n) > 0$ is an orientation of $V$. 
\end{lemma}

\begin{definition}
if $v$ is an oriented vector space and $\Omega$ is an $n$-covector that determines the orientation of $V$ as described in the previous lemma, it is said that $\Omega$ is an \textit{oriented} (or \textit{positively oriented}) $n$-covector. 
\end{definition}

\begin{example}
The $n$-covector $e^1 \wedge ... \wedge e^n$ is positively oriented for the standard orientation on $\mathbb{R}^n$. 
\end{example}

\subsection{Orientations on Manifolds}

\begin{definition}
Let $M$ be a smooth manifold with a given pointwise orientation. It is said that a local frame $(E_i)$ for $M$ is \textit{(positively) oriented} if $(E_1 \big|_p, ..., E_n \big|_p)$ is a positively oriented basis for $T_p M$ at each point $p \in M$. A \textit{negatively oriented manifold} is defined analogously. 
\end{definition}

\begin{definition}
A pointwise orientation is said to be \textit{continuous} if every point of $M$ is in the domain of an oriented local frame. An \textit{orientation} of $M$ is a continuous pointwise orientation. An \textit{oriented manifold} is a smooth manifold together with a choice of orientation. It is said that $M$ is \textit{orientable} if there exists an orientation for it, and \textit{nonorientable} if there isn't. 
\end{definition}

\chapter{Classical Mechanics}
\section{Elementary Principles}

\begin{definition}
Let $r$ be the radius/displacement vector of a particle from some given origin and $v$ its velocity vector. Then, 
\[v = \frac{dr}{dt}\]
\end{definition}

In the context of physics, it is conventional to use Newton's notation for the derivative, denoted by a dot. That is, we can rewrite the above equation as
\[v = \dot{r}\]

\begin{definition}
The \textit{linear momentum} $p$ of the particle is defined as the product of its mass and velocity. 
\[p = m v\]
\end{definition}

Let $F$ be the total force (that is, the net sum of all forces) exerted on a particle. Then, $F$ satisfies the differential equation 
\[F = \frac{dp}{dt} \equiv \dot{p} \iff F = \frac{d}{dt} (m v) = m \frac{d}{dt} v = m a\]
where $a$ is the acceleration vector defined as 
\[a = \frac{d^2 r}{d t^2}\]
Therefore, the equation of motion of a particle induced by a force is a linear differential equation of second order, assuming that the force $F$ is constant (i.e. does not depend on higher derivatives). 

\begin{theorem}[Conservation Theorem for Linear Momentum of a Particle]
If the total force $F = 0$, then $\dot{p} = 0$ and the linear momentum $p$ is conserved. This is also known as \textit{Newton's First Law of Motion}. 
\end{theorem}

\begin{definition}
In $\mathbb{R}^3$, the \textit{angular momentum} of a particle around point $0$ is defined as 
\[L = r \times p\]
where $\times$ is the cross product, $r$ is the radius vector from $0$, and $p$ is the linear momentum of the particle. 
\end{definition}

\begin{definition}
The \textit{torque}, or \textit{moment of force}, of a particle around point $0$ is defined 
\[N = r \times F = r \times \frac{d}{dt} (mv)\]
Using the vector identity 
\[\frac{d}{dt} (r \times m v) = v \times mv + r \times \frac{d}{dt} (mv) = r \times \frac{d}{dt} (mv)\]
we can establish its relation to the angular momentum as such. 
\[N = r \times \frac{d}{dt} (mv) = \frac{d}{dt} (r \times mv) = \frac{d}{dt} L = \dot{L} \implies N = \frac{d}{dt} L\]
Note that both $N$ and $L$ depend on the origin $0$, that is, some point of reference. 
\end{definition}

\begin{theorem}
If the total torque (sum of individual torques, all with respect to the same origin $0$) $N = 0$, then $\dot{L} = 0$ and the angular momentum $L$ is conserved. 
\end{theorem}

\begin{definition}
The \textit{work} done by an external force $F$ upon a particle in going from point $1$ to point $2$ is defined as 
\[W_{12} = \int_1^2 F \cdot ds\]
Note that $F$ is a vector field. Assuming that the particle has constant mass, we use the fact that $\frac{d}{dt} v^2 = 2 v \dot{v}$ to get 
\begin{align*}
    W_{12} = \int_1^2 F \cdot ds & = m \int_1^2 \frac{dv}{dt} \cdot v\,dt \\
    & = \frac{m}{2} \int_1^2 \frac{d}{dt} v^2 \,dt = \frac{m}{2} \big( v_2^2 - v_1^2 \big)
\end{align*}
\end{definition}

\begin{definition}
The scalar quantity $m v^2 / 2$ is called the \textit{kinetic energy} of the particle and is denoted by $T$. Note that the kinetic energy is defined pointwise. 
\end{definition}

\begin{lemma}
Work is equal to the change in kinetic energy. That is, 
\[W_{12} = T_2 - T_1\]
\end{lemma}

\begin{definition}
If a force field $F$ is such that the work $W_{12}$ is the same for any physically possible paths between points $1$ and $2$, then the force (and the system) is said to be \textit{conservative}. Mathematically, this means that given two paths $p, q$ from point $1$ to $2$,
\[\int_p F \cdot ds = \int_q F \cdot ds\]
With the equation above, it is easy to see that $F$ is conservative if and only if the work done around any closed circuit is $0$. That is, 
\[\oint F \cdot ds = 0\]
\end{definition}

In a non-conservative force field, the above is not necessarily true. That is, given points $1$ and $2$, with two different paramaterizations of paths $p$ and $q$ going from $1$ to $2$, the equality does not necessarily hold. 
\[W_p \neq W_q \iff \int_p F \cdot ds \neq \int_q F \cdot ds\]
The physical interpretation of a nonconservative force field is that the work done by it adds or removes mechanical energy from the system. For example, friction creates thermal energy that dissipates, removing energy from this system. Mathematically, since the friction force $F$ always works \textit{against} the direction of the particle's velocity vector, $F \cdot ds < 0$, meaning that the integral 
\[\int_p F \cdot ds\]
over any nontrivial path $p$ can never vanish. 

Note that due to the invariance of work over paths in a conservative force field, we can simplify the formula for work as 
\[W_p \equiv \int_p F \cdot ds = F \cdot d\]
where $d$ represents the \textit{displacement} of the particle from point $1$ to $2$ (note that we can also use distance). However, if $F$ is nonconservative, the paramaterization of the path $p$ does indeed affect the work done on the particle, and so we must account for the \textit{distance} taken by path $p$. In the actual integral 
\[\int_p F \cdot ds\]
$ds$ can be interpreted both as a infinitesimal distance or displacement. 

Using the theorems of vector calculus, it is an equivalent condition that if $W_{12}$ is independent of the path taken, then $F$ is the gradient of some scalar function of position. 
\[F = - \triangledown V\]
That is, if a force field is conservative, then it is the gradient of some function $V$, meaning that $W_{12}$ is really just dependeont on the endpoints. 

\begin{definition}
The scalar function $V: \mathbb{R}^n \longrightarrow \mathbb{R}$ is called the \textit{potential}, or \textit{potential energy}, of the particle. 
\end{definition}

Note that we have only proved the existence of such a function $V$ but have not specified a method to compute it. Furthermore, we can see that by definition
\[F \cdot ds = - dV \iff F_s = -\frac{\partial V}{\partial s}\]
where $F_s$ represents the $s$th component of $F$. Also, 
\[F \cdot ds = - \frac{\partial V}{\partial s} ds\]
We can therefore represent work as
\[W_{12} = V_1 - V_2\]
This leads to the following theorem. 

\begin{theorem}[Conservation of Energy of a Particle]
If the force $F$ acting on a particle is conservative, then the total energy of the particle, $T+V$, is conserved. That is,
\[T_1 + V_1 = T_2 + V_2\]
\end{theorem}

\subsubsection{Motion of a Particle in a Nonconstant Force Field}
In certain cases, a force field $F$ may change with respect to time, meaning that we must interpret as a function
\[F: \mathbb{R}^n \times T \longrightarrow \mathbb{R}^n\]
This also induces the modification of $V$ as
\[V: \mathbb{R}^n \times T \longrightarrow \mathbb{R}\]
which now has another parameter $t$. If $F$ is conservative (that is, it stays conservative as $t$ varies), it follows that
\[V_1 (t) - V_2 (t)\]
stays constant. However, since every path function is paramaterized over a time period of positive length, the work done by the particle as it moves from point $1$ to point $2$ is no longer simply the difference in the function $V$ between the two points. Therefore, even though the total energy $T + V$ may still be defined, it is not conserved.  

\subsection{Mechanics of a System of Particles}
We first distinguish\textit{external forces} acting on particles, which originate from outside sources, from \textit{internal forces} on some particle $i$ to all other particles in the system. The equation of motion for the $i$th particle is written as 
\[\sum_j F_{ji} + F_i^{(e)} = \dot{p}_i\]
where $F_i^{(e)}$ is the external force exerted on the $i$th particle and $F_{ji}$ is the internal force exerted by the $j$th particle on the $i$th particle. Naturally, $F_{ii} = 0$. We will assume that the $F_{ij}$ obeys the \textit{weak law of action and reaction} that the forces the two particles exert on each other are equal and opposite (also called Newton's third law of motion). Note that the weak law does not hold for all types of forces. 

Summed over all particles, we get
\[\frac{d^2}{d t^2} \sum_{i} m_i r_i = \sum_i F_i^{(e)} + \sum_{i \neq j} F_{ji} = \sum_i F_i^{(e)}\]
since the second term on the right hand side vanishes due to $F_{ij} = - F_{ji}$. 

\begin{definition}
Given $n$ particles with radii vectors $r_i (i = 1, 2, ..., n)$ with respect to some origin and respective masses $m_i$, their \textit{center of mass} is defined.
\[R = \frac{1}{\sum m_i} \sum_i m_i r_i = \frac{1}{M} \sum_i m_i r_i\]
\end{definition}

\begin{definition}
The \textit{total external force} is the sum of the individual external forces on each particle. 
\[F^{(e)} \equiv \sum_i F_i^{(e)}\]
\end{definition}

This reduces the above equation to
\[M \frac{d^2 R}{dt^2} = F^{(e)}\]
This equation states that the center of mass moves as if the total external force were acting on the entire mass of the system concentrated at the center of mass. This tells us an important fact. Purely internal forces, if they obey Newton's third law, therefore have no effect on the motion of the center of mass. 

\begin{definition}
The \textit{total linear momentum} of the system with center of mass $R$ is defined
\[P = \sum_i m_i \frac{d r_i}{dt} = M \frac{d R}{dt}\]
\end{definition}

This allows us to generalize the conservation theorem to the following. 

\begin{theorem}
If the total external force on a system of particles is $0$, then the total linear momentum is conserved. 
\end{theorem}

\begin{definition}
To calculate the total angular momentum, we sum over the individual ones. 
\begin{align*}
    \dot{L} = \sum_i \big( r_i \times \dot{p}_i \big) & = \sum_i \frac{d}{dt} \big( r_i \times p_i\big) \\
    & = \sum_i r_i \times F_i^{(e)} + \sum_{i \neq j} r_i \times F_{ji}
\end{align*}
But since 
\begin{align*}
    r_i \times F_{ji} + r_j \times F_{ij} & = (r_i - r_j) \times F_{ji} \\
    & = r_{ij} \times F_{ji}
\end{align*}

Assuming that the internal forces between 2 particles are equal and opposite, \textit{and lie along the line joining the pair} (the law with this additional condition is known as the \textit{strong law of action and reaction}), then the sum 
\[\sum_{i \neq j} r_i \times F_{ji}\]
vanishes. Letting $N^{(e)} = \sum_i r_i \times F_i^{(e)}$, we get
\[\frac{d L}{d t} = N^{(e)}\]
\end{definition}

\begin{definition}
The \textit{total angular momentum} of the system is analogously defined
\[L = \sum_i r_i \times p_i\]
given that all the $r_i$'s are defined with respect to an origin. 
\end{definition}

\begin{theorem}[Conservation theorem for angular momentum of a system]
$L$ is constant in time if the external torque of the system is $0$. 
\end{theorem}

The intuition for this theorem is a bit more complicated. That is, for each particle's radius vector $r_i$, we can represent it as 
\[r_i = r_i^\prime + R\]
where $R$ is the center of mass of the system. Taking the derivative with respect to time gives 
\[v_i = v_i^\prime + v, \;\; v = \frac{dR}{dt}, v_i^\prime = \frac{d r_i^\prime}{dt}\]
Then, 
\begin{align*}
    L & = \sum_i r_i \times p_i = \sum_i \big(r_i^\prime + R\big) \times m_i \big( v_i^\prime + v) \\
    & = \sum_i R \times m_i v + \sum_i r_i^\prime \times m_i v_i^\prime + \bigg( \sum_i m_i r_i^\prime \bigg) \times v + R \times \frac{d}{dt} \sum_i m_i v_i^\prime 
\end{align*}

But
\[\sum_i m_i r_i^\prime = 0\]
since the law of conservation of total linear momentum of a system of particles does not change (where we are assuming that $R$ is the origin). This reduces the expression to
\[L = \sum_i R \times m_i v + \sum_i r_i^\prime \times m_i v_i^\prime = R \times M v + \sum_i r_i^\prime \times p_i^\prime\]
This equation therefore mathematically defines the conservation theorem for the angular momentum of a system. That is, the total angular momentum around origin $0$ is the angular momentum of motion concentrated at the center of mass \textit{plus} the angular momentum of motion of each particle about the center of mass. 

In general, $L$ depends on the origin $0$ through vector $R$. Only if the center of mass is at rest with respect to $0$ will the angular momentum be independent of the point of reference, since this will mean that $v = 0$. 

The work of a system is calculated by summing the work of the individual particles. 
\[W_{12} = \sum_i \int_1^2 F_i \cdot d s_i = \sum_i \int_1^2 F_i^{(e)} \cdot ds_i + \sum_i \int_1^2 F_{ji} \cdot ds_i\]
where $1$ and $2$ are not points, but rather \textit{configurations} of the particles of the entire system. Then, 
\begin{align*}
    W_{12} & = \sum_i \int_1^2 F_i \cdot ds_i \\
    & = \sum_i \int_1^2 m_i \dot{v}_i \cdot v_i \,dt = \sum_i \int_1^2 d \Big( \frac{1}{2} m_i v_i^2\Big)
\end{align*}
$\implies W_{12} = T_2 - T_1$, where $T$ represents the \textit{total kinetic energy of the system}. 
\[T = \frac{1}{2} \sum_i m_i v_i^2\]
With the coordinates around the center of mass $R$, we can calculate
\begin{align*}
    T & = \frac{1}{2} \sum_i m_i \big( v + v_i^\prime \big) \cdot \big( v + v_i^\prime \big) \\
    & = \frac{1}{2} M v^2 + \frac{1}{2} \sum_i m_i v_i^2 
\end{align*}
This tells us that the kinetic energy, like the angular momentum, also consists of two parts: the kinetic energy of the mass concentrated around the center of mass plus the kinetic energy of motion about the center of mass. 

\subsection{Constraints}
We may infer that all problems in classial mechanics have been reduced to solving the system of differential equations
\[m_i \ddot{r}_i = F_i^{(e)} - \sum_{j} F_{ji}\]
by substituting the known forces acting on the particle. However, we must take a look at the \textit{constraints} that limit the motion of the system. Some examples of constraints are:
\begin{enumerate}
    \item Dealing with rigid bodies, which is a system of particles that can only be moved through isometries. 
    \item Gas molecules constrained within a container are constrained by the walls of the container. 
    \item A particle allowed to move only within a certain surface or manifold. 
\end{enumerate}

\begin{definition}
If the constraints can be expressed as equations connecting the coordinates of the particles (and possibly the time) having the form 
\begin{equation}
    f\big(r_1, r_2, ..., t\big) = 0
\end{equation}
then the constraints are said to be \textit{holonomic}. 
\end{definition}

\begin{example}
The constraints of rigid bodies are holonomic since it can be expressed with the equations 
\[ \big(r_i - r_j \big)^2 - c_{ij}^2 = 0\]
\end{example}

\begin{example}
A particle constrained to move along a surface is a holonomic constraint, defined by the equation of the surface.
\end{example}

\begin{example}
The walls of a gas container is a nonholonomic constraint. 
\end{example}

\begin{example}
The constraint describing the motion of a particle placed on a sphere is nonholonomic, since it can be described with the inequality
\[r^2 - a^2 \geq 0\]
\end{example}

\begin{definition}
Constraint equations that contain time as an explicit variable (meaning that the physical constraints are changing) are called \textit{rheonomous}. Ones that are not explicitly dependent on time are called \textit{scleronomous}. 

Note that if the constraint moes as a reaction to the particle's motion, then the time paramater is really dependent on the components of the particle's radius vector. This means that the system is \textit{scleronomous}. 
\[f\big( r_1, r_2, ..., t \big) = f\big( r_1, r_2, ..., t(r_1, r_2, ...)\big)\]
\end{definition}

For more complicated systems, it is necessary to step away from Cartesian coordinates and use a basis transformation to convert them to \textit{generalized coordinates} with a certain degree of freedom. 

A system of $N$ particles in three dimensional space has $3N$ independent coordinates, which translates to $3N$ degrees of freedom. Given $k$ holonomic constraints given in the form (1), the system has $3N-k$ degrees of freedom. A convenient way to integrate these constraint equations is with transformation equations. With $3N-k$ degrees of freedom, we define the new set of independent variables $q_1, q_2, ..., q_{3N-k}$. This induces a transformation $T$ from the $q$-variables to the $r$-variables. 
\[T: \big( q_1, q_2, ..., q_{3N-k}\big) \mapsto \big( r_1 (q), r_2 (q) , ..., r_{3N} (q)\big)\]
where $q = (q_1, q_2, ..., q_{3N-k})$. Equivalently, we write the radius vectors of each particle in terms of the new coordinates, with possibly a time variable $t$. This gives the set of $N$ \textit{transformation equations} 
\begin{align*}
    r_1 & = r_1 \big( q_1, q_2, ..., q_{3N-k}, t\big) \\
    r_2 & = r_2 \big( q_1, q_2, ..., q_{3N-k}, t\big) \\
    ... & = ... \\
    r_N & = r_N \big( q_1, q_2, ..., q_{3N-k}, t\big) 
\end{align*}
which constraints the motion of the particles implicitly. It is assumed that we can always invert the transformation. That is, let $Q \subset \mathbb{R}^3$ be the constrained space. Given $T: Q \longrightarrow \mathbb{R}^3$, the restriction of $T^{-1}$ onto the image of $T$is well-defined and surjective
\[T^{-1}: \im(T) \subset \mathbb{R}^3 \longrightarrow Q\]
Furthermore, note that $T$ is a homeomorphism. This leads to a very important realization that $Q$ is $(3N-k)$-manifold embedded in the $3N$-manifold $\mathbb{R}$. This set $Q$ consisting of points that represent viable configurations of the system is called the \textit{configuration manifold} of the system. The existence of the chart mappings guarantees that every point is locally paramaterizable with new coordinates (which, in this case, is the $q$-variables). 

\begin{example}
In the case that a particle is constrained to move on the surface of a sphere, two angles $\theta, \phi$ representing latitude and longitude are obvious possible generalized coordinates. 
\end{example}

\begin{example}
A double pendulum moving in a plane can be represented by two angles. 
\end{example}

\begin{example}
A disk rolling vertically on the horizontal $xy$-plane. 
\end{example}

Holonomic constraints therefore allow us to use the tools in manifold theory to model systems of equations. However, there is no standardized method of tackling systems with nonholonomic constraints. Therefore, it is almost always assumed that constraints are holonomic, and this doesn't greatly limit the applicability of the theory. 

\subsection{D'Alembert's Principle and Lagrange's Equations}
\begin{definition}
A system is in \textit{equilibrium} if the total force on each particle vanishes. That is, if $F_i = 0$ for all $i$. 
\end{definition}

\begin{definition}
A \textit{virtual (infinitesmial) displacement} of a system refers to a change in the configuration of a system as the result of any infinitesmal change of the coordinates $\delta r_i$, consistent with the forces and constraints imposed on the system at given instance $t$. 
\end{definition}

Note that this displacement is called virtual to distinguish it from an actual displacement of a system occurring in the time interval $dt$, during which the forces and constraints may be changing. To solidify this concept of a virtual displacement and its difference from the actual displacement, consider the configuration manifold $Q$. The time evolution of the system can be modeled with a path function $q(t)$ on $Q$ with paramater time. The actual displacement of the system is modeled by an infinitesimal displacement on the curve. 

However, we can define another path $\gamma$ (a "virtual curve" as opposed to the real curve) along which the system evolves. Again, this must be consistent with the actual constraints, or equivalently, $\gamma$ cannot "leave" the configuration manifold. 

Now, suppose that that we are working with a system that is in equilibrium. Since the total force on each particle vanishes, then clearly the dot product of the force in direction $\delta r_i$, which is the virtual work of the particle over displacement $\delta r_i$, vanishes, too. Summing over all particles, 
\[\sum_i F_i \cdot \delta r_i = 0\]
We decompose $F_i$ into the applied force $F_i^{(a)}$ and the force of constraint $f_i$. Then, 
\[\sum_i F_i \cdot \delta r_i = 0 \implies \sum_i F_i^{(a)} \cdot \delta r_i + \sum_i f_i \cdot \delta r_i = 0\]
Let us now restrict the system such that the net virtual work of the forces of constraint is $0$. 

It is preferred to simplify the mechanics of a system (e.g. paramaterizing it) in such a way that the forces of constraint disappear. It is a common problem that the forces of constraint are unknown a priori, so we try to have them vanish. Looking at the time-evolution path through the configuration manifold, we can interpret the assumption above as saying that the vectors of the forces of constraint are perpendicular to the surface of the manifold.

\begin{example}
A particle constrained to move on a surface has a form of constraint perpendicular to the particle's displacement (e.g. a normal force) $\implies f_i \cdot \delta r_i = 0$, where $\delta r_i$ is an infinitesimal virtual displacement on the surface. 
\end{example}

\begin{theorem}[Principle of Virtual Work]
This reduces the above equation to
\[\sum_i F_i^{(a)} \cdot \delta r_i = 0\]
which states that a condition for equilibrium of a system is that the virtual work of the applied forces vanishes. 
\end{theorem}

We can write this in a different way. The equation of motion can be rewritten as 
\[F_i = \dot{p}_i \implies F_i - \dot{p}_i = 0 \]
which states that particles in the system will be in equilibrium under a force equal to the actual force plus a "reversed effective force" $- \dot{p}_i$. This leads to 
\begin{align*}
    & \sum_i \big( F_i - \dot{p}_i \big) \cdot \delta r_i = 0 \\
    \implies & \sum_{i} \big( F_i^{(a)} - \dot{p}_i \cdot \delta r_i + \sum_i f_i \cdot \delta r_i = 0 
\end{align*}
where $F_i^{(a)}$ represents the applied forces and $f_i$ represents the constraint forces. We again restrict our work to systems where the virtual work of the forces of constraints vanishes, to get 
\[ \sum_i \big( F_i^{(a)} - \dot{p}_i \big) \cdot \delta r_i = 0\]

\begin{example}
In the diagram, we can see that the normal force $F_N$ is the constraint force, while friction $F_f$ and gravity $F_g$ are applied forces. 
\begin{center}
\begin{tikzpicture}[scale=0.7]
    \draw (0,0)--(6,0)--(0,3)--(0,0);
    \draw (3, 1.5)--(2,2)--(2.5,3)--(3.5,2.5)--(3, 1.5);
    \draw[fill] (2.75,2.25) circle (0.1);
    \draw[->] (2.75, 2.25)--(1.75,2.75);
    \draw[->] (2.75,2.25)--(2.75,0.5);
    \draw[->] (2.75,2.25)--(3.45,3.65);
    \node[right] at (3.45,3.5) {$F_N$};
    \node[left] at (1.75, 2.7) {$F_f$};
    \node[left] at (2.75, 0.6) {$F_g$};
\end{tikzpicture}
\end{center}
Furthermore, this system has the property that $f_i \cdot \delta r_i = 0$, since the normal force is always perpendicular to the back-and-forth movement of the block. Note that if the box leaves the surface and into the air (which is viable, since the system isn't constrained by the ramp and ground), the normal force then vanishes and is still consistent with the system. 

If the system is in equilibrium, then 
\[F = F_f + F_N + F_g = 0\]
and the virtual displacement from, say point $A$ to point $B$, denoted $\delta r$, cancels out with the total force $F$ (since $F=0$). That is, 
\[F \cdot \delta r = 0 \cdot \delta r = 0\]
Therefore, the virtual displacement of a system in equilibrium is $\delta r$ with component displacement $\delta r_i$ and the virtual work always $0$. 
\end{example}

\begin{definition}
Let $\mathcal{M}$ be the configuration manifold of a mechanical system, with $t_0, t_1 \in \mathbb{R}$ time constants, $q_0, q_1 \in \mathcal{M}$, and 
\[P(\mathcal{M}) \equiv \big\{\gamma \in C^\infty([t_0, t_1], \mathcal{M}) \;|\; \gamma(t_0) = q_0, \gamma(t_1) = q_1\big\}\]
For each path $\gamma \in P(\mathcal{M})$ and $\varepsilon_0 > 0$, a \textit{variation} of $\gamma$ is a function 
\[\Gamma: [t_0, t_1] \times [-\varepsilon_0, \varepsilon] \longrightarrow \mathcal{M}\]
such that for every $\varepsilon \in [-\varepsilon_0, \varepsilon_0]$, 
\[\Gamma(\cdot, \epsilon) \in P(\mathcal{M}) \text{ and } \Gamma(t, 0) = \gamma(t)\]
Alternatively, we can imagine the variation $\Gamma$ as an infinitesimal homotopy of $\gamma$ in $\mathcal{M}$. 
\end{definition}

Going back to D'Alembert's principle, we let $F_i = F_i^{(a)}$ and have 
\[\sum_i \big(F_i - \dot{p}_i \big) \cdot \delta r_i = 0 \]
Since 
\[r_i = r_i (q_1, q_2, ..., q_n, t)\]
with generalized coordinates $q_i$ (assuming independent coordinates), we use the multivariate chain rule to get
\[V_i \equiv \frac{d r_i}{d t} = \bigg( \sum_k \frac{\partial r_i}{\partial q_k} \dot{q}_k \bigg) + \frac{\partial r_i}{\partial t}\]
Analogously, we find the displacement
\[\delta r_i = \sum_j \frac{\partial r_i}{\partial q_j} \delta q_j\]
Note that no variation of time, $\delta t$, is involved here since virtual displacement by definition considers displacements of the coordinates. Therefore, in generalized coordinates, the virtual work of $F_i$ is 
\begin{align*}
    \sum_i F_i \cdot \delta r_i & = \sum_{i, j} F_i \cdot \frac{\partial f_i}{\partial q_j} \delta q_j \\
    & = \sum_j Q_j \delta q_j, \text{ where } Q_j = \sum_i F_i \frac{\partial r_i}{\partial q_j}
\end{align*}
Note that even though $Q_j \delta q_j$ must always have the dimensions of work, the $Q$'s do not necessarily need to have the dimensions of force since the $q$'s need not have dimensions of length. 

\begin{example}
$Q_j$ may be a value of torque $N_j$ and $d q_j$ a differential angle $d \theta_j$, which makes $N_j d\theta_j$ a differential of work. 
\end{example}

We now evaluate
\[\sum_i \dot{p}_i \delta r_i = \sum_i m_i \ddot{r}_i \delta r_i = \sum_{i, j} m_i \ddot{r}_i \frac{\partial r_i}{\partial q_j} \delta q_j\]
Using the product rule for derivatives, we get
\[\sum_i m_i \ddot{r}_i \frac{\partial r_i}{\partial q_j} = \sum_i \bigg( \frac{d}{dt} \Big( m_i \dot{r}_i \frac{\partial r_i}{\partial q_j} \Big) - m_i \dot{r}_i \frac{d}{dt} \Big( \frac{\partial r_i}{\partial q_j}\Big)\bigg)\]
By equality of partial derivatives, 
\[\frac{d}{dt} \bigg(\frac{\partial r_i}{\partial q_j} \bigg) = \frac{\partial \dot{r}_i}{\partial q_j} = \bigg( \sum_k \frac{\partial^2 r_i}{\partial q_j \partial q_k} \dot{q}_k \bigg) + \frac{\partial^2 r_i}{\partial q_j \partial t} = \frac{\partial v_i}{\partial q_j}\]
Remember that we are deriving with respect to generalized $q$-coordinates. 

\begin{lemma}
In this type of system, 
\[\frac{\partial v_i}{\partial \dot{q}_j} = \frac{\partial r_i}{\partial q_j}\]
\end{lemma}
\begin{proof}
To be done. 
\end{proof}

Using the previous lemma, we get 
\begin{align*}
    \sum_i m_i \ddot{r}_i & = \sum_i \bigg( \frac{d}{dt} \Big( m_i v_i \frac{\partial v_i}{\partial \dot{q}_j} \Big) - m_i v_i \frac{\partial v_i}{\partial q_j} \bigg) \\
    & = \sum_i \Bigg( \frac{d}{dt} \bigg( \frac{\partial}{\partial \dot{q}_j} \Big( \frac{1}{2} m_i v_i^2 \Big) \bigg) - \frac{\partial}{\partial q_j} \bigg(\frac{1}{2} m_i v_i^2 \bigg) \Bigg) 
\end{align*}
So rewriting D'Alembert's principle, we have 
\[\sum_j \Bigg( \frac{d}{dt} \bigg( \frac{\partial}{\partial \dot{q}_j} \Big( \sum_i \frac{1}{2} m_i v_i^2 \Big) \bigg) - \frac{\partial}{\partial q_j} \bigg( \sum_i \frac{1}{2} m_i v_i^2 \bigg) - Q_j \Bigg) \delta q_j\]
Letting $T = \sum_i \frac{1}{2} m_i v_i^2$, we get
\begin{equation}
    \sum_j \Bigg[ \bigg( \frac{d}{dt} \Big(\frac{\partial T}{\partial q_j} \Big) - \frac{\partial T}{\partial q_j} \bigg) - Q_j \Bigg] \delta q_j = 0
\end{equation}
So far, no restriction has been made in the system constraints other than they be workless in a virtual displacement. In the case that the constraint is holonomic, the generalized variables $q_j$ will be completely independent of each other (with the constraints implicitly contained within the transformation of coordinates). This means that any virtual displacement $\delta q_j$ is independent of $\delta q_k$ ($j \neq k$)., so the only way that (2) can be $0$ is if all the individual elements are $0$ for every $j = 1, 2, ..., n$. That is, 
\[\forall j = 1, 2, ..., n, \;\; \frac{d}{dt} \bigg(\frac{\partial T}{\partial \dot{q}_j} \bigg) - \frac{\partial T}{\partial q_j} - Q_j = 0\]
If the forces can be derived from a certain scalar potential function $V$ (i.e. $F$ is a conservative vector field), then 
\[F = -\nabla_i V \implies Q_j = \sum_i F_i \frac{\partial r_i}{\partial q_j} = - \sum_i \nabla_i V \frac{\partial r_i}{\partial q_j}\]
But this last expression is just the partial derivative of the function $-V (r_1, r_2, ..., r_n, t)$ with respect to $q_j$. So, 
\[Q_j = - \frac{\partial V}{\partial q_j}\]
However, note that the field cannot be conservative if $V$ is a function of time. So, $V$ must be invariant under time for the above equations to hold. 

As defined, the potential $V$ does not depend on the generalized velocities. Hence, we can include a term $V$ in the partial derivative with respect to $\dot{q}_j$ without changing the outcome. This leads to 
\[\frac{d}{dt} \bigg( \frac{\partial (T-V)}{\partial \dot{q}_j} \bigg) - \frac{\partial (T-V)}{\partial q_j} = 0\]

\begin{definition}
The \textit{Lagrangian}, denoted $L$, is defined
\[L = T - V\]
where $T$ is the kinetic energy and $V$ is the potential energy of the system. 
\end{definition}

\begin{theorem}[Lagrange's Equations]
\[\frac{d}{dt} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) - \frac{\partial L}{\partial q_j} = 0\]
\end{theorem}
Note that for a particular set of equations of motion there is no unique choice of Lagrangian such that Lagrange's equations lead to the equations of motions in the given generalized coordinates. In fact, if $L(q, \dot{q}, t)$ is an appropriate Lagrangian, and $F(q, t)$ is any differentiable function of the generalized coordinates and time, then 
\[L^\prime (q, \dot{q}, t) = L(q, \dot{q}, t) + \frac{\partial F}{\partial t}\]
is a Lagrangian also resulting in the same equations of motion. There are other methods to find other Lagrangians, too. 

\appendix
\chapter{Further Readings}
\begin{enumerate}
    \item Ted Shifrin. \textit{Linear Algebra, A Geometric Approach}
    \item Peter D. Lax. \textit{Linear Algebra and Its Applications, 2nd Edition}
    \item Jerrold E. Marsden. \textit{Vector Calculus, 6th Edition}
    \item Fred Brauer. \textit{Ordinary Differential Equations, A First Course}
    \item Vladimir I. Arnold. \textit{Ordinary Differential Equations}
    \item Paul Dawkins. \textit{Differential Equations}
    \item Ernest B. Vinberg. \textit{A Course in Algebra}
    \item Vladimir A. Zorich. \textit{Mathematical Analysis 1}
    \item Rick Durrett. \textit{Elementary Probability for Applications, 2nd Edition}
    \item James R. Munkres. \textit{Topology, A First Course}
    \item John M. Lee. \textit{An Introduction to Smooth Manifolds}
    \item David M. Burton. \textit{Elementary Number Theory, Sixth Edition}
\end{enumerate}
\end{document}

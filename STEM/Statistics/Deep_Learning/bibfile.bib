@misc{he2015deep,
  title={Deep Residual Learning for Image Recognition}, 
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year={2015},
  eprint={1512.03385},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@article{Lecun1998ConvNets,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@misc{tam2020fiedler,
  title={Fiedler Regularization: Learning Neural Networks with Graph Sparsity}, 
  author={Edric Tam and David Dunson},
  year={2020},
  eprint={2003.00992},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}

@misc{frankle2019lottery,
  title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks}, 
  author={Jonathan Frankle and Michael Carbin},
  year={2019},
  eprint={1803.03635},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@misc{misra2020mish,
  title={Mish: A Self Regularized Non-Monotonic Activation Function}, 
  author={Diganta Misra},
  year={2020},
  eprint={1908.08681},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@INPROCEEDINGS{ImageNet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}
}

@misc{berthelot2019mixmatch,
  title={MixMatch: A Holistic Approach to Semi-Supervised Learning}, 
  author={David Berthelot and Nicholas Carlini and Ian Goodfellow and Nicolas Papernot and Avital Oliver and Colin Raffel},
  year={2019},
  eprint={1905.02249},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@misc{berthelot2020remixmatch,
  title={ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring}, 
  author={David Berthelot and Nicholas Carlini and Ekin D. Cubuk and Alex Kurakin and Kihyuk Sohn and Han Zhang and Colin Raffel},
  year={2020},
  eprint={1911.09785},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@misc{sohn2020fixmatch,
      title={FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence}, 
      author={Kihyuk Sohn and David Berthelot and Chun-Liang Li and Zizhao Zhang and Nicholas Carlini and Ekin D. Cubuk and Alex Kurakin and Han Zhang and Colin Raffel},
      year={2020},
      eprint={2001.07685},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{symmetry,
    author = {Chen, An Mei and Lu, Haw-minn and Hecht-Nielsen, Robert},
    title = {On the Geometry of Feedforward Neural Network Error Surfaces},
    journal = {Neural Computation},
    volume = {5},
    number = {6},
    pages = {910-927},
    year = {1993},
    month = {11},
    abstract = {Many feedforward neural network architectures have the property that their overall input-output function is unchanged by certain weight permutations and sign flips. In this paper, the geometric structure of these equioutput weight space transformations is explored for the case of multilayer perceptron networks with tanh activation functions (similar results hold for many other types of neural networks). It is shown that these transformations form an algebraic group isomorphic to a direct product of Weyl groups. Results concerning the root spaces of the Lie algebras associated with these Weyl groups are then used to derive sets of simple equations for minimal sufficient search sets in weight space. These sets, which take the geometric forms of a wedge and a cone, occupy only a minute fraction of the volume of weight space. A separate analysis shows that large numbers of copies of a network performance function optimum weight vector are created by the action of the equioutput transformation group and that these copies all lie on the same sphere. Some implications of these results for learning are discussed.},
    issn = {0899-7667},
    doi = {10.1162/neco.1993.5.6.910},
    url = {https://doi.org/10.1162/neco.1993.5.6.910},
    eprint = {https://direct.mit.edu/neco/article-pdf/5/6/910/812656/neco.1993.5.6.910.pdf},
}

@article{score,
  author       = {Yang Song and
                  Jascha Sohl{-}Dickstein and
                  Diederik P. Kingma and
                  Abhishek Kumar and
                  Stefano Ermon and
                  Ben Poole},
  title        = {Score-Based Generative Modeling through Stochastic Differential Equations},
  journal      = {CoRR},
  volume       = {abs/2011.13456},
  year         = {2020},
  url          = {https://arxiv.org/abs/2011.13456},
  eprinttype    = {arXiv},
  eprint       = {2011.13456},
  timestamp    = {Wed, 02 Dec 2020 10:10:16 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2011-13456.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{orig_score, 
  author  = {Aapo Hyv{{\"a}}rinen},
  title   = {Estimation of Non-Normalized Statistical Models by Score Matching},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {24},
  pages   = {695--709},
  url     = {http://jmlr.org/papers/v6/hyvarinen05a.html}
}

@misc{vae,
  title={Auto-Encoding Variational Bayes}, 
  author={Diederik P Kingma and Max Welling},
  year={2022},
  eprint={1312.6114},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1312.6114}, 
}

@misc{gans,
  title={Generative Adversarial Networks}, 
  author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year={2014},
  eprint={1406.2661},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1406.2661}, 
}

@misc{gsns,
  title={GSNs : Generative Stochastic Networks}, 
  author={Guillaume Alain and Yoshua Bengio and Li Yao and Jason Yosinski and Eric Thibodeau-Laufer and Saizheng Zhang and Pascal Vincent},
  year={2015},
  eprint={1503.05571},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1503.05571}, 
}

@misc{flow,
  title={Variational Inference with Normalizing Flows}, 
  author={Danilo Jimenez Rezende and Shakir Mohamed},
  year={2016},
  eprint={1505.05770},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1505.05770}, 
}

@misc{nice,
  title={NICE: Non-linear Independent Components Estimation}, 
  author={Laurent Dinh and David Krueger and Yoshua Bengio},
  year={2015},
  eprint={1410.8516},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1410.8516}, 
}

@misc{glow,
  title={Glow: Generative Flow with Invertible 1x1 Convolutions}, 
  author={Diederik P. Kingma and Prafulla Dhariwal},
  year={2018},
  eprint={1807.03039},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1807.03039}, 
}

@misc{realnvp,
  title={Density estimation using Real NVP}, 
  author={Laurent Dinh and Jascha Sohl-Dickstein and Samy Bengio},
  year={2017},
  eprint={1605.08803},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1605.08803}, 
}

@misc{cglow,
  title={Structured Output Learning with Conditional Generative Flows}, 
  author={You Lu and Bert Huang},
  year={2020},
  eprint={1905.13288},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1905.13288}, 
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we even make a CNN, we should explore the full functionalities of convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image is shape torch.Size([3, 28, 28]), with 3 input channels\n",
      "Convolved image is shape torch.Size([5, 26, 26]), with 5 output channels\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(\n",
    "    in_channels = 3, \n",
    "    out_channels = 5, \n",
    "    kernel_size = 3, \n",
    "    stride = 1, \n",
    "    padding = 0\n",
    ")\n",
    "\n",
    "img = torch.randn(3, 28, 28) \n",
    "print(f\"Original Image is shape {img.shape}, with {img.size()[0]} input channels\") \n",
    "conved = conv(img) \n",
    "print(f\"Convolved image is shape {conved.shape}, with {conved.size()[0]} output channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing pooling layers is simple. The kernel size determines how big the kernels are that we will pool over. The stride at least in most introductory deep learning courses is automatically set to the kernel size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image is of size torch.Size([3, 10, 10])\n",
      "After max pooling, image is of size torch.Size([3, 5, 5])\n",
      "After average pooling, image is of size torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "max_pool = nn.MaxPool2d(\n",
    "    kernel_size= 2, \n",
    "    stride= 2, \n",
    "    padding = 0\n",
    ")\n",
    "\n",
    "average_pool = nn.AvgPool2d(\n",
    "    kernel_size= 5, \n",
    "    stride= 5, \n",
    "    padding = 0\n",
    ")\n",
    "\n",
    "x1 = torch.randn(3, 10, 10) \n",
    "x2 = x1.clone()\n",
    "print(f\"Input image is of size {x1.size()}\") \n",
    "\n",
    "y1 = max_pool(x1) \n",
    "y2 = average_pool(x2) \n",
    "\n",
    "print(f\"After max pooling, image is of size {y1.size()}\") \n",
    "print(f\"After average pooling, image is of size {y2.size()}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it may be tedious to set all the parameters to get some desired max pool output, especially if the width and height are not the same. In this case, we can do an adaptive pooling mechanism to get the desired output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size : torch.Size([3, 45, 67])\n",
      "Adaptive Pooled Size : torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "adaptive_pool = nn.AdaptiveAvgPool2d(\n",
    "    output_size= (4, 5)         # we can predetermine what the output size will be  \n",
    ")\n",
    "\n",
    "x = torch.randn(3, 45, 67)\n",
    "y = adaptive_pool(x) \n",
    "\n",
    "print(f\"Original Size : {x.size()}\")\n",
    "print(f\"Adaptive Pooled Size : {y.size()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

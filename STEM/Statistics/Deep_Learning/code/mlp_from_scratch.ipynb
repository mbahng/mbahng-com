{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Make sure to update where the MNIST dataset is being downloaded to\n",
    "DATA_PATH = \"~/Research/data\" \n",
    "\n",
    "train_set = datasets.MNIST(DATA_PATH, train=True, download=True)\n",
    "test_set = datasets.MNIST(DATA_PATH, train=False, download=True)\n",
    "\n",
    "# Check the lengths of train sets and test sets\n",
    "assert len(train_set) == 60000 and len(test_set) == 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([picture.numpy().reshape(-1) for picture in train_set.data]).T / 255.\n",
    "Y_train = train_set.targets.numpy() \n",
    "X_test = np.array([picture.numpy().reshape(-1) for picture in test_set.data]).T / 255.\n",
    "Y_test = test_set.targets.numpy()\n",
    "\n",
    "# Check shapes \n",
    "assert X_train.shape == (784, 60000) and Y_train.shape == (60000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(): \n",
    "    W1 = np.random.uniform(-1, 1, size=(10, 784)) \n",
    "    b1 = np.random.uniform(-1, 1, size=(10, 1)) \n",
    "    W2 = np.random.uniform(-1, 1, size=(10, 10)) \n",
    "    b2 = np.random.uniform(-1, 1, size=(10, 1)) \n",
    "    return W1, b1, W2, b2 \n",
    "\n",
    "def oneHot(Y): \n",
    "    # Y is 60000 \n",
    "    oneHotY = np.zeros((10, Y.size))\n",
    "    oneHotY[Y, np.arange(Y.size)] = 1 \n",
    "    return oneHotY # 10x60000\n",
    "\n",
    "def ReLU(Z): \n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def ReLU_d(Z): \n",
    "    return Z > 0\n",
    "\n",
    "def softMax(X:np.array): \n",
    "    x_max = np.max(X, axis=0)\n",
    "    X = X - x_max\n",
    "    return np.exp(X) / np.sum(np.exp(X), axis=0) \n",
    "\n",
    "def softMax_d(X:np.array): \n",
    "    sm = softMax(X)\n",
    "    return - (np.diag(sm.sum(axis=1)) - np.matmul(sm, np.transpose(sm))) / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProp(W1, b1, W2, b2, X): \n",
    "    # Z1 12x1, W1 12x784 , X 784x1, b1 12x1\n",
    "    Z1 = np.matmul(W1, X) + b1\n",
    "    # A1 12x60000\n",
    "    A1 = ReLU(Z1) \n",
    "    \n",
    "    # Z2 10x1, W2 10x12, A1 12x60000, b2 10x60000\n",
    "    Z2 = np.matmul(W2, A1) + b2 \n",
    "    # A2 10x60000\n",
    "    A2 = softMax(Z2) \n",
    "    return Z1, A1, Z2, A2 \n",
    "\n",
    "def backProp(Z1, A1, Z2, A2, W1, W2, X, Y): \n",
    "    N = Y.size\n",
    "    oneHotY = oneHot(Y)\n",
    "    \n",
    "    # 10x1 = 10x10 10x1\n",
    "    error2 = A2 - oneHotY\n",
    "    # error2 = np.matmul(np.transpose(softMax_d(Z2)), A2 - oneHotY) \n",
    "    # 10x12 = 10x1 1x12\n",
    "    dW2 = 1/N * np.matmul(error2, A1.T)\n",
    "    # 10x1\n",
    "    dB2 = 1/N * error2.sum(axis=1)\n",
    "    \n",
    "    # 12x1 = 12x1 .* 12x10 10x1\n",
    "    error1 = np.vectorize(ReLU_d)(Z1) * np.matmul(W2.T, error2) \n",
    "    # 12x784 = 12x1 1x784\n",
    "    dW1 = 1/N * np.matmul(error1, X.T)\n",
    "    # 12x1 \n",
    "    dB1 = 1/N * error1.sum(axis=1)\n",
    "\n",
    "    return dW1, dB1, dW2, dB2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[2 2 2 ... 2 2 2] [5 0 4 ... 5 6 8]\n",
      "0.10655\n",
      "Iteration:  10\n",
      "[2 0 2 ... 6 1 6] [5 0 4 ... 5 6 8]\n",
      "0.19211666666666666\n",
      "Iteration:  20\n",
      "[2 0 2 ... 6 1 6] [5 0 4 ... 5 6 8]\n",
      "0.23388333333333333\n",
      "Iteration:  30\n",
      "[2 0 2 ... 6 1 6] [5 0 4 ... 5 6 8]\n",
      "0.29236666666666666\n",
      "Iteration:  40\n",
      "[2 0 2 ... 9 1 6] [5 0 4 ... 5 6 8]\n",
      "0.3263666666666667\n",
      "Iteration:  50\n",
      "[2 0 2 ... 9 1 3] [5 0 4 ... 5 6 8]\n",
      "0.3559833333333333\n",
      "Iteration:  60\n",
      "[2 0 2 ... 9 1 3] [5 0 4 ... 5 6 8]\n",
      "0.3825\n",
      "Iteration:  70\n",
      "[2 0 2 ... 9 1 3] [5 0 4 ... 5 6 8]\n",
      "0.40676666666666667\n",
      "Iteration:  80\n",
      "[2 0 2 ... 9 1 3] [5 0 4 ... 5 6 8]\n",
      "0.42583333333333334\n",
      "Iteration:  90\n",
      "[2 0 2 ... 9 1 3] [5 0 4 ... 5 6 8]\n",
      "0.44276666666666664\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, b1, W2, b2\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(X, Y, alpha, iterations)\u001b[0m\n\u001b[1;32m     16\u001b[0m W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m initialize_params()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m---> 18\u001b[0m     Z1, A1, Z2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mforwardProp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     dW1, db1, dW2, db2 \u001b[38;5;241m=\u001b[39m backProp(Z1, A1, Z2, A2, W1, W2, X, Y)\n\u001b[1;32m     20\u001b[0m     W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mforwardProp\u001b[0;34m(W1, b1, W2, b2, X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforwardProp\u001b[39m(W1, b1, W2, b2, X): \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Z1 12x1, W1 12x784 , X 784x1, b1 12x1\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     Z1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b1\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# A1 12x60000\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     A1 \u001b[38;5;241m=\u001b[39m ReLU(Z1) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1.reshape(-1, 1)    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2.reshape(-1, 1)       \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations): \n",
    "    W1, b1, W2, b2 = initialize_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forwardProp(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backProp(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Run it\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.1, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

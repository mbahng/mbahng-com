{
  "snapshot_time": "2026-02-09T15:25:58.631987+00:00",
  "objects": {
    "paper:arxiv.2511.09744": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.09744",
        "url": "https://arxiv.org/pdf/2511.09744",
        "title": "Computing parametric weighted Ehrhart polynomials of smooth polytopes",
        "authors": [
          "Daniel Hwang",
          "Juliet Whidden",
          "Josephine Yu"
        ],
        "abstract": "We show that when integral polytopes are deformed while keeping the same facet normal vectors, the coefficients of weighted Ehrhart and $h^*$-polynomials are piecewise polynomial functions in the ``right hand sides'' of the linear inequalities defining the polytopes. We give an algorithm and an implementation in SageMath for computing these polynomials for smooth polytopes, such as type $A$ alcoved polytopes, using a weighted Euler-Maclaurin type formula by Khovanski\u01d0 and Pukhlikov. We discuss some natural questions concerning signs of the coefficients of the weighted $h^*$-polynomials.",
        "timestamp": "2025-12-21T06:10:03.453Z",
        "rating": "novote",
        "publishedDate": "2025-11-12",
        "tags": [
          "math.CO"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.CO"
        ]
      },
      "meta": {
        "issue_number": 7,
        "object_id": "paper:arxiv.2511.09744",
        "created_at": "2025-12-21T06:10:03+00:00",
        "updated_at": "2025-12-21T19:49:06+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2210.05846": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2210.05846",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T07:37:55.265Z",
            "data": {
              "session_id": "session_1766302675253_l788cpw",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T07:37:40.215Z",
              "end_time": "2025-12-21T07:37:55.253Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 0,
              "total_elapsed_seconds": 15
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T07:46:28.708Z",
            "data": {
              "session_id": "session_1766303188695_2r0em9o",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T07:46:11.238Z",
              "end_time": "2025-12-21T07:46:28.695Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 2,
              "total_elapsed_seconds": 17
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T08:11:01.730Z",
            "data": {
              "session_id": "session_1766304661522_yuwoaey",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T08:10:43.211Z",
              "end_time": "2025-12-21T08:11:01.522Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 3,
              "total_elapsed_seconds": 18
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T08:55:48.943Z",
            "data": {
              "session_id": "session_1766307348939_asapyqf",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T08:55:43.720Z",
              "end_time": "2025-12-21T08:55:48.939Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          }
        ],
        "title": "FasterRisk: Fast and Accurate Interpretable Risk Scores",
        "authors": [
          "Jiachang Liu",
          "Chudi Zhong",
          "Boxuan Li",
          "Margo Seltzer",
          "Cynthia Rudin"
        ],
        "abstract": "Over the last century, risk scores have been the most popular form of predictive model used in healthcare and criminal justice. Risk scores are sparse linear models with integer coefficients; often these models can be memorized or placed on an index card. Typically, risk scores have been created either without data or by rounding logistic regression coefficients, but these methods do not reliably produce high-quality risk scores. Recent work used mathematical programming, which is computationally slow. We introduce an approach for efficiently producing a collection of high-quality risk scores learned from data. Specifically, our approach produces a pool of almost-optimal sparse continuous solutions, each with a different support set, using a beam-search algorithm. Each of these continuous solutions is transformed into a separate risk score through a \"star ray\" search, where a range of multipliers are considered before rounding the coefficients sequentially to maintain low logistic loss. Our algorithm returns all of these high-quality risk scores for the user to consider. This method completes within minutes and can be valuable in a broad variety of applications.",
        "publishedDate": "2022-10-12"
      },
      "meta": {
        "issue_number": 9,
        "object_id": "interactions:arxiv.2210.05846",
        "created_at": "2025-12-21T06:42:27+00:00",
        "updated_at": "2025-12-21T08:56:37+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1706.03762": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1706.03762",
        "url": "https://arxiv.org/abs/1706.03762",
        "title": "Attention Is All You Need",
        "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
        "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
        "timestamp": "2025-12-21T07:46:33.198Z",
        "rating": "novote",
        "publishedDate": "2017/06/12",
        "tags": [
          "Computation and Language (cs.CL)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 18,
        "object_id": "paper:arxiv.1706.03762",
        "created_at": "2025-12-21T07:46:33+00:00",
        "updated_at": "2025-12-21T07:47:33+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.06709": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.06709",
        "url": "https://arxiv.org/pdf/2502.06709",
        "title": "Talagrand Meets Talagrand: Upper and Lower Bounds on Expected Soft Maxima of Gaussian Processes with Finite Index Sets",
        "authors": [
          "Yifeng Chu",
          "Maxim Raginsky"
        ],
        "abstract": "Analysis of extremal behavior of stochastic processes is a key ingredient in a wide variety of applications, including probability, statistical physics, theoretical computer science, and learning theory. In this paper, we consider centered Gaussian processes on finite index sets and investigate expected values of their smoothed, or ``soft,'' maxima. We obtain upper and lower bounds for these expected values using a combination of ideas from statistical physics (the Gibbs variational principle for the equilibrium free energy and replica-symmetric representations of Gibbs averages) and from probability theory (Sudakov minoration). These bounds are parametrized by an inverse temperature $\u03b2> 0$ and reduce to the usual Gaussian maximal inequalities in the zero-temperature limit $\u03b2\\to \\infty$. We provide an illustration of our methods in the context of the Random Energy Model, one of the simplest models of physical systems with random disorder.",
        "timestamp": "2025-12-21T07:00:23.584Z",
        "rating": "novote",
        "publishedDate": "2025-02-10",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 10,
        "object_id": "paper:arxiv.2502.06709",
        "created_at": "2025-12-21T07:00:23+00:00",
        "updated_at": "2025-12-21T07:35:40+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2502.06709": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.06709",
        "interactions": [],
        "title": "Talagrand Meets Talagrand: Upper and Lower Bounds on Expected Soft Maxima of Gaussian Processes with Finite Index Sets",
        "authors": [
          "Yifeng Chu",
          "Maxim Raginsky"
        ],
        "abstract": "Analysis of extremal behavior of stochastic processes is a key ingredient in a wide variety of applications, including probability, statistical physics, theoretical computer science, and learning theory. In this paper, we consider centered Gaussian processes on finite index sets and investigate expected values of their smoothed, or ``soft,'' maxima. We obtain upper and lower bounds for these expected values using a combination of ideas from statistical physics (the Gibbs variational principle for the equilibrium free energy and replica-symmetric representations of Gibbs averages) and from probability theory (Sudakov minoration). These bounds are parametrized by an inverse temperature $\u03b2> 0$ and reduce to the usual Gaussian maximal inequalities in the zero-temperature limit $\u03b2\\to \\infty$. We provide an illustration of our methods in the context of the Random Energy Model, one of the simplest models of physical systems with random disorder.",
        "publishedDate": "2025-02-10"
      },
      "meta": {
        "issue_number": 11,
        "object_id": "interactions:arxiv.2502.06709",
        "created_at": "2025-12-21T07:00:39+00:00",
        "updated_at": "2025-12-21T07:35:40+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2210.05846": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2210.05846",
        "url": "https://arxiv.org/pdf/2210.05846",
        "title": "FasterRisk: Fast and Accurate Interpretable Risk Scores",
        "authors": [
          "Jiachang Liu",
          "Chudi Zhong",
          "Boxuan Li",
          "Margo Seltzer",
          "Cynthia Rudin"
        ],
        "abstract": "Over the last century, risk scores have been the most popular form of predictive model used in healthcare and criminal justice. Risk scores are sparse linear models with integer coefficients; often these models can be memorized or placed on an index card. Typically, risk scores have been created either without data or by rounding logistic regression coefficients, but these methods do not reliably produce high-quality risk scores. Recent work used mathematical programming, which is computationally slow. We introduce an approach for efficiently producing a collection of high-quality risk scores learned from data. Specifically, our approach produces a pool of almost-optimal sparse continuous solutions, each with a different support set, using a beam-search algorithm. Each of these continuous solutions is transformed into a separate risk score through a \"star ray\" search, where a range of multipliers are considered before rounding the coefficients sequentially to maintain low logistic loss. Our algorithm returns all of these high-quality risk scores for the user to consider. This method completes within minutes and can be valuable in a broad variety of applications.",
        "timestamp": "2025-12-21T07:08:01.847Z",
        "rating": "novote",
        "publishedDate": "2022-10-12",
        "tags": [
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 13,
        "object_id": "paper:arxiv.2210.05846",
        "created_at": "2025-12-21T07:08:02+00:00",
        "updated_at": "2025-12-21T19:49:04+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2511.09744": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.09744",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T08:10:43.405Z",
            "data": {
              "session_id": "session_1766304643180_o3cxxk6",
              "source_id": "arxiv",
              "paper_id": "2511.09744",
              "start_time": "2025-12-21T08:10:23.410Z",
              "end_time": "2025-12-21T08:10:43.180Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 5,
              "total_elapsed_seconds": 20
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:46:09.482Z",
            "data": {
              "session_id": "session_1766346369023_c8x2yrm",
              "source_id": "arxiv",
              "paper_id": "2511.09744",
              "start_time": "2025-12-21T19:45:01.685Z",
              "end_time": "2025-12-21T19:46:09.023Z",
              "heartbeat_count": 13,
              "duration_seconds": 65,
              "idle_seconds": 2,
              "total_elapsed_seconds": 67
            }
          }
        ],
        "title": "Computing parametric weighted Ehrhart polynomials of smooth polytopes",
        "authors": [
          "Daniel Hwang",
          "Juliet Whidden",
          "Josephine Yu"
        ],
        "abstract": "We show that when integral polytopes are deformed while keeping the same facet normal vectors, the coefficients of weighted Ehrhart and $h^*$-polynomials are piecewise polynomial functions in the ``right hand sides'' of the linear inequalities defining the polytopes. We give an algorithm and an implementation in SageMath for computing these polynomials for smooth polytopes, such as type $A$ alcoved polytopes, using a weighted Euler-Maclaurin type formula by Khovanski\u01d0 and Pukhlikov. We discuss some natural questions concerning signs of the coefficients of the weighted $h^*$-polynomials.",
        "publishedDate": "2025-11-12"
      },
      "meta": {
        "issue_number": 12,
        "object_id": "interactions:arxiv.2511.09744",
        "created_at": "2025-12-21T07:04:09+00:00",
        "updated_at": "2025-12-21T19:47:16+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2510.23866": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.23866",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:57:33.275Z",
            "data": {
              "session_id": "session_1766339852711_1xcok4t",
              "source_id": "arxiv",
              "paper_id": "2510.23866",
              "start_time": "2025-12-21T17:55:29.315Z",
              "end_time": "2025-12-21T17:57:32.711Z",
              "heartbeat_count": 24,
              "duration_seconds": 120,
              "idle_seconds": 3,
              "total_elapsed_seconds": 123
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:59:33.801Z",
            "data": {
              "session_id": "session_1766339973316_ln3tnxq",
              "source_id": "arxiv",
              "paper_id": "2510.23866",
              "start_time": "2025-12-21T17:57:54.949Z",
              "end_time": "2025-12-21T17:59:33.316Z",
              "heartbeat_count": 19,
              "duration_seconds": 95,
              "idle_seconds": 3,
              "total_elapsed_seconds": 98
            }
          }
        ]
      },
      "meta": {
        "issue_number": 25,
        "object_id": "interactions:arxiv.2510.23866",
        "created_at": "2025-12-21T09:40:23+00:00",
        "updated_at": "2025-12-21T18:00:33+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.23866": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.23866",
        "url": "https://arxiv.org/abs/2510.23866",
        "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling",
        "authors": "Paul Rosu, Muchang Bahng, Erick Jiang, Rico Zhu, Vahid Tarokh",
        "abstract": "This work presents a physics-conditioned latent diffusion model tailored for dynamical downscaling of atmospheric data, with a focus on reconstructing high-resolution 2-m temperature fields. Building upon a pre-existing diffusion architecture and employing a residual formulation against a reference UNet, we integrate a partial differential equation (PDE) loss term into the model's training objective. The PDE loss is computed in the full resolution (pixel) space by decoding the latent representation and is designed to enforce physical consistency through a finite-difference approximation of an effective advection-diffusion balance. Empirical observations indicate that conventional diffusion training already yields low PDE residuals, and we investigate how fine-tuning with this additional loss further regularizes the model and enhances the physical plausibility of the generated fields. The entirety of our codebase is available on Github, for future reference and development.",
        "timestamp": "2025-12-21T09:40:14.789Z",
        "rating": "novote",
        "publishedDate": "2025/10/27",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 24,
        "object_id": "paper:arxiv.2510.23866",
        "created_at": "2025-12-21T09:40:15+00:00",
        "updated_at": "2025-12-21T09:41:16+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2506.22947": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.22947",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T09:46:44.916Z",
            "data": {
              "session_id": "session_1766310404731_nc534t6",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T09:46:34.608Z",
              "end_time": "2025-12-21T09:46:44.731Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 10
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T09:51:33.939Z",
            "data": {
              "session_id": "session_1766310693460_w7tj227",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T09:48:11.956Z",
              "end_time": "2025-12-21T09:51:33.460Z",
              "heartbeat_count": 40,
              "duration_seconds": 200,
              "idle_seconds": 2,
              "total_elapsed_seconds": 202
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:14:33.462Z",
            "data": {
              "session_id": "session_1766337273153_3nta5vf",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:14:25.187Z",
              "end_time": "2025-12-21T17:14:33.153Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 3,
              "total_elapsed_seconds": 8
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:15:36.538Z",
            "data": {
              "session_id": "session_1766337335942_7af9cqr",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:15:04.790Z",
              "end_time": "2025-12-21T17:15:35.942Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 1,
              "total_elapsed_seconds": 31
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:17:48.894Z",
            "data": {
              "session_id": "session_1766337468591_74jfp3f",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:17:04.158Z",
              "end_time": "2025-12-21T17:17:48.591Z",
              "heartbeat_count": 8,
              "duration_seconds": 40,
              "idle_seconds": 4,
              "total_elapsed_seconds": 44
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:49:05.721Z",
            "data": {
              "session_id": "session_1766339345230_x4dvdys",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:47:33.543Z",
              "end_time": "2025-12-21T17:49:05.230Z",
              "heartbeat_count": 18,
              "duration_seconds": 90,
              "idle_seconds": 2,
              "total_elapsed_seconds": 92
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:10:19.144Z",
            "data": {
              "session_id": "session_1766340618633_3nj9dk4",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:08:05.905Z",
              "end_time": "2025-12-21T18:10:18.633Z",
              "heartbeat_count": 26,
              "duration_seconds": 130,
              "idle_seconds": 3,
              "total_elapsed_seconds": 133
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:24:35.107Z",
            "data": {
              "session_id": "session_1766341475100_46yx4s0",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:24:25.015Z",
              "end_time": "2025-12-21T18:24:35.100Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 10
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:25:41.930Z",
            "data": {
              "session_id": "session_1766341541497_x9mr9ra",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:24:35.194Z",
              "end_time": "2025-12-21T18:25:41.497Z",
              "heartbeat_count": 13,
              "duration_seconds": 65,
              "idle_seconds": 1,
              "total_elapsed_seconds": 66
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:27:22.128Z",
            "data": {
              "session_id": "session_1766341641662_9t8tw11",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:25:43.458Z",
              "end_time": "2025-12-21T18:27:21.662Z",
              "heartbeat_count": 19,
              "duration_seconds": 95,
              "idle_seconds": 3,
              "total_elapsed_seconds": 98
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:44:22.155Z",
            "data": {
              "session_id": "session_1766342661879_37pigqp",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:43:29.937Z",
              "end_time": "2025-12-21T18:44:21.879Z",
              "heartbeat_count": 10,
              "duration_seconds": 50,
              "idle_seconds": 2,
              "total_elapsed_seconds": 52
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:45:31.838Z",
            "data": {
              "session_id": "session_1766342731358_zgwk4k1",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:44:30.425Z",
              "end_time": "2025-12-21T18:45:31.358Z",
              "heartbeat_count": 12,
              "duration_seconds": 60,
              "idle_seconds": 1,
              "total_elapsed_seconds": 61
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:06:56.274Z",
            "data": {
              "session_id": "session_1766344016271_kjudoau",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:06:41.518Z",
              "end_time": "2025-12-21T19:06:56.271Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 5,
              "total_elapsed_seconds": 15
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:22:31.303Z",
            "data": {
              "session_id": "session_1766344950779_oyy06g1",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:19:45.908Z",
              "end_time": "2025-12-21T19:22:30.779Z",
              "heartbeat_count": 32,
              "duration_seconds": 160,
              "idle_seconds": 5,
              "total_elapsed_seconds": 165
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:31:29.797Z",
            "data": {
              "session_id": "session_1766345489299_rxkmnev",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:29:49.195Z",
              "end_time": "2025-12-21T19:31:29.299Z",
              "heartbeat_count": 20,
              "duration_seconds": 100,
              "idle_seconds": 0,
              "total_elapsed_seconds": 100
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:33:08.782Z",
            "data": {
              "session_id": "session_1766345588239_orl4m82",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:31:34.417Z",
              "end_time": "2025-12-21T19:33:08.239Z",
              "heartbeat_count": 18,
              "duration_seconds": 90,
              "idle_seconds": 4,
              "total_elapsed_seconds": 94
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:39:56.852Z",
            "data": {
              "session_id": "session_1766345996674_ujk4228",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:39:44.959Z",
              "end_time": "2025-12-21T19:39:56.674Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 2,
              "total_elapsed_seconds": 12
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T20:29:27.190Z",
            "data": {
              "session_id": "session_1766348967007_f1itd4w",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T20:29:11.146Z",
              "end_time": "2025-12-21T20:29:27.007Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 1,
              "total_elapsed_seconds": 16
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-22T04:16:18.291Z",
            "data": {
              "session_id": "session_1766376978083_q6q09h0",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-22T04:16:05.597Z",
              "end_time": "2025-12-22T04:16:18.083Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 2,
              "total_elapsed_seconds": 12
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-22T06:46:50.384Z",
            "data": {
              "session_id": "session_1766386009847_vxqtp1k",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-22T06:45:34.532Z",
              "end_time": "2025-12-22T06:46:49.847Z",
              "heartbeat_count": 15,
              "duration_seconds": 75,
              "idle_seconds": 0,
              "total_elapsed_seconds": 75
            }
          }
        ]
      },
      "meta": {
        "issue_number": 23,
        "object_id": "interactions:arxiv.2506.22947",
        "created_at": "2025-12-21T09:37:38+00:00",
        "updated_at": "2025-12-22T06:47:57+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2506.22947": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.22947",
        "url": "https://arxiv.org/pdf/2506.22947",
        "title": "Monotone Multispecies Flows",
        "authors": [
          "Lauren Conger",
          "Franca Hoffmann",
          "Eric Mazumdar",
          "Lillian J. Ratliff"
        ],
        "abstract": "We present a novel notion of $\u03bb$-monotonicity for an $n$-species system of partial differential equations governed by mass-preserving flow dynamics, extending monotonicity in Banach spaces to the Wasserstein-2 metric space. We show that monotonicity implies the existence of and convergence to a unique steady state, convergence of the velocity fields and second moments, and contraction in the Wasserstein-2 metric, at rates dependent on $\u03bb$. In the special setting of Wasserstein-2 gradient descent of different energies for each species, we prove convergence to the unique Nash equilibrium of the associated energies and delineate the relationship between monotonicity and displacement convexity. This extends known zero-sum results in infinite-dimensional game theory to the general-sum setting. We provide a number of examples of monotone coupled gradient flow systems, including cross-diffusion, gradient flows with potentials, nonlocal interaction, linear and nonlinear diffusion, and min-max systems, and draw connections to a class of mean-field games. Numerically, we demonstrate convergence of a four-player economic model for service providers and strategic users competing in a market, and a degenerately monotone game.",
        "timestamp": "2025-12-21T09:37:17.804Z",
        "rating": "novote",
        "publishedDate": "2025-06-28",
        "tags": [
          "math.AP"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.AP"
        ]
      },
      "meta": {
        "issue_number": 22,
        "object_id": "paper:arxiv.2506.22947",
        "created_at": "2025-12-21T09:37:18+00:00",
        "updated_at": "2025-12-21T19:49:02+00:00",
        "version": 1
      }
    },
    "interactions:url.2A46BCB2": {
      "data": {
        "sourceId": "url",
        "paperId": "2A46BCB2",
        "interactions": []
      },
      "meta": {
        "issue_number": 21,
        "object_id": "interactions:url.2A46BCB2",
        "created_at": "2025-12-21T09:27:04+00:00",
        "updated_at": "2025-12-21T09:27:05+00:00",
        "version": 1
      }
    },
    "paper:url.2A46BCB2": {
      "data": {
        "sourceId": "url",
        "paperId": "2A46BCB2",
        "url": "https://arxiv.org/pdf/physics/0605057",
        "title": "2A46BCB2",
        "authors": "",
        "abstract": "",
        "timestamp": "2025-12-21T09:26:45.932Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 20,
        "object_id": "paper:url.2A46BCB2",
        "created_at": "2025-12-21T09:26:46+00:00",
        "updated_at": "2025-12-21T09:27:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2112.10752": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2112.10752",
        "url": "https://arxiv.org/abs/2112.10752",
        "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
        "authors": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer",
        "abstract": "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at this https URL .",
        "timestamp": "2025-12-21T20:19:28.145Z",
        "rating": "novote",
        "publishedDate": "2021/12/20",
        "tags": [
          "Computer Vision and Pattern Recognition (cs.CV)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 26,
        "object_id": "paper:arxiv.2112.10752",
        "created_at": "2025-12-21T20:19:28+00:00",
        "updated_at": "2025-12-21T20:20:27+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2112.10752": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2112.10752",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T20:28:22.502Z",
            "data": {
              "session_id": "session_1766348901785_ma830kq",
              "source_id": "arxiv",
              "paper_id": "2112.10752",
              "start_time": "2025-12-21T20:19:29.958Z",
              "end_time": "2025-12-21T20:28:21.785Z",
              "heartbeat_count": 106,
              "duration_seconds": 530,
              "idle_seconds": 2,
              "total_elapsed_seconds": 532
            }
          }
        ]
      },
      "meta": {
        "issue_number": 27,
        "object_id": "interactions:arxiv.2112.10752",
        "created_at": "2025-12-21T20:28:23+00:00",
        "updated_at": "2025-12-21T20:29:21+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2512.10047": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2512.10047",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-22T05:32:59.159Z",
            "data": {
              "session_id": "session_1766381578580_mvbsh7c",
              "source_id": "arxiv",
              "paper_id": "2512.10047",
              "start_time": "2025-12-22T05:27:56.093Z",
              "end_time": "2025-12-22T05:32:58.580Z",
              "heartbeat_count": 60,
              "duration_seconds": 300,
              "idle_seconds": 2,
              "total_elapsed_seconds": 302
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-22T05:46:46.627Z",
            "data": {
              "session_id": "session_1766382406060_eiy3auh",
              "source_id": "arxiv",
              "paper_id": "2512.10047",
              "start_time": "2025-12-22T05:39:29.308Z",
              "end_time": "2025-12-22T05:46:46.060Z",
              "heartbeat_count": 87,
              "duration_seconds": 435,
              "idle_seconds": 2,
              "total_elapsed_seconds": 437
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-22T06:50:45.123Z",
            "data": {
              "session_id": "session_1766386244900_xm8c359",
              "source_id": "arxiv",
              "paper_id": "2512.10047",
              "start_time": "2025-12-22T06:50:37.390Z",
              "end_time": "2025-12-22T06:50:44.900Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 3,
              "total_elapsed_seconds": 8
            }
          }
        ]
      },
      "meta": {
        "issue_number": 29,
        "object_id": "interactions:arxiv.2512.10047",
        "created_at": "2025-12-21T20:35:39+00:00",
        "updated_at": "2025-12-22T06:51:56+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2512.10047": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2512.10047",
        "url": "https://arxiv.org/pdf/2512.10047",
        "title": "Detailed balance in large language model-driven agents",
        "authors": [
          "Zhuo-Yang Song",
          "Qing-Hong Cao",
          "Ming-xing Luo",
          "Hua Xing Zhu"
        ],
        "abstract": "Large language model (LLM)-driven agents are emerging as a powerful new paradigm for solving complex problems. Despite the empirical success of these practices, a theoretical framework to understand and unify their macroscopic dynamics remains lacking. This Letter proposes a method based on the least action principle to estimate the underlying generative directionality of LLMs embedded within agents. By experimentally measuring the transition probabilities between LLM-generated states, we statistically discover a detailed balance in LLM-generated transitions, indicating that LLM generation may not be achieved by generally learning rule sets and strategies, but rather by implicitly learning a class of underlying potential functions that may transcend different LLM architectures and prompt templates. To our knowledge, this is the first discovery of a macroscopic physical law in LLM generative dynamics that does not depend on specific model details. This work is an attempt to establish a macroscopic dynamics theory of complex AI systems, aiming to elevate the study of AI agents from a collection of engineering practices to a science built on effective measurements that are predictable and quantifiable.",
        "timestamp": "2025-12-21T20:34:11.989Z",
        "rating": "novote",
        "publishedDate": "2025-12-10",
        "tags": [
          "cs.LG",
          "cond-mat.stat-mech",
          "cs.AI",
          "nlin.AO",
          "physics.data-an"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.LG",
          "cond-mat.stat-mech",
          "cs.AI",
          "nlin.AO",
          "physics.data-an"
        ]
      },
      "meta": {
        "issue_number": 28,
        "object_id": "paper:arxiv.2512.10047",
        "created_at": "2025-12-21T20:34:12+00:00",
        "updated_at": "2025-12-21T20:38:18+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2506.16668": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.16668",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T22:20:04.284Z",
            "data": {
              "session_id": "session_1766355604018_dzox8wa",
              "source_id": "arxiv",
              "paper_id": "2506.16668",
              "start_time": "2025-12-21T22:19:48.272Z",
              "end_time": "2025-12-21T22:20:04.018Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 1,
              "total_elapsed_seconds": 16
            }
          }
        ]
      },
      "meta": {
        "issue_number": 31,
        "object_id": "interactions:arxiv.2506.16668",
        "created_at": "2025-12-21T22:05:32+00:00",
        "updated_at": "2025-12-21T22:21:06+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2506.16668": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.16668",
        "url": "https://arxiv.org/pdf/2506.16668",
        "title": "Bayesian Semiparametric Orthogonal Tucker Factorized Mixed Models for Multi-dimensional Longitudinal Functional Data",
        "authors": [
          "Arkaprava Roy",
          "Abhra Sarkar"
        ],
        "abstract": "We introduce a novel longitudinal mixed model for analyzing complex multidimensional functional data, addressing challenges such as high-resolution, structural complexities, and computational demands. Our approach integrates dimension reduction techniques, including basis function representation and Tucker tensor decomposition, to model complex functional (e.g., spatial and temporal) variations, group differences, and individual heterogeneity while drastically reducing model dimensions. The model accommodates multiplicative random effects whose marginalization yields a novel Tucker-decomposed covariance-tensor framework. To ensure scalability, we employ semi-orthogonal mode matrices implemented via a novel graph-Laplacian-based smoothness prior with low-rank approximation, leading to an efficient posterior sampling method. A cumulative shrinkage strategy promotes sparsity and enables semiautomated rank selection. We establish theoretical guarantees for posterior convergence and demonstrate the method's effectiveness through simulations, showing significant improvements over existing techniques. Applying the method to Alzheimer's Disease Neuroimaging Initiative (ADNI) neuroimaging data reveals novel insights into local brain changes associated with disease progression, highlighting the method's practical utility for studying cognitive decline and neurodegenerative conditions.",
        "timestamp": "2025-12-21T22:05:11.204Z",
        "rating": "novote",
        "publishedDate": "2025-06-20",
        "tags": [
          "stat.ME"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "stat.ME"
        ]
      },
      "meta": {
        "issue_number": 30,
        "object_id": "paper:arxiv.2506.16668",
        "created_at": "2025-12-21T22:05:11+00:00",
        "updated_at": "2025-12-21T22:08:13+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2508.12551": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2508.12551",
        "url": "https://arxiv.org/abs/2508.12551",
        "title": "OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning",
        "authors": "Hongyu Lin, Yuchen Li, Haoran Luo, Kaichun Yao, Libo Zhang, Mingjie Xing, Yanjun Wu",
        "abstract": "Linux kernel tuning is essential for optimizing operating system (OS) performance. However, existing methods often face challenges in terms of efficiency, scalability, and generalization. This paper introduces OS-R1, an agentic Linux kernel tuning framework powered by rule-based reinforcement learning (RL). By abstracting the kernel configuration space as an RL environment, OS-R1 facilitates efficient exploration by large language models (LLMs) and ensures accurate configuration modifications. Additionally, custom reward functions are designed to enhance reasoning standardization, configuration modification accuracy, and system performance awareness of the LLMs. Furthermore, we propose a two-phase training process that accelerates convergence and minimizes retraining across diverse tuning scenarios. Experimental results show that OS-R1 significantly outperforms existing baseline methods, achieving up to 5.6% performance improvement over heuristic tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across various real-world applications, demonstrating its potential for practical deployment in diverse environments. Our dataset and code are publicly available at this https URL.",
        "timestamp": "2025-12-21T23:02:28.928Z",
        "rating": "novote",
        "publishedDate": "2025/08/18",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)",
          "Operating Systems (cs.OS)",
          "Software Engineering (cs.SE)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 32,
        "object_id": "paper:arxiv.2508.12551",
        "created_at": "2025-12-21T23:02:29+00:00",
        "updated_at": "2025-12-21T23:03:29+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1905.02199": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1905.02199",
        "url": "https://arxiv.org/abs/1905.02199",
        "title": "Nonlinear Approximation and (Deep) ReLU Networks",
        "authors": "I. Daubechies, R. DeVore, S. Foucart, B. Hanin, G. Petrova",
        "abstract": "This article is concerned with the approximation and expressive powers of deep neural networks. This is an active research area currently producing many interesting papers. The results most commonly found in the literature prove that neural networks approximate functions with classical smoothness to the same accuracy as classical linear methods of approximation, e.g. approximation by polynomials or by piecewise polynomials on prescribed partitions. However, approximation by neural networks depending on n parameters is a form of nonlinear approximation and as such should be compared with other nonlinear methods such as variable knot splines or n-term approximation from dictionaries. The performance of neural networks in targeted applications such as machine learning indicate that they actually possess even greater approximation power than these traditional methods of nonlinear approximation. The main results of this article prove that this is indeed the case. This is done by exhibiting large classes of functions which can be efficiently captured by neural networks where classical nonlinear methods fall short of the task. The present article purposefully limits itself to studying the approximation of univariate functions by ReLU networks. Many generalizations to functions of several variables and other activation functions can be envisioned. However, even in this simplest of settings considered here, a theory that completely quantifies the approximation power of neural networks is still lacking.",
        "timestamp": "2025-12-21T23:20:55.922Z",
        "rating": "novote",
        "publishedDate": "2019/05/05",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 33,
        "object_id": "paper:arxiv.1905.02199",
        "created_at": "2025-12-21T23:20:56+00:00",
        "updated_at": "2025-12-21T23:21:53+00:00",
        "version": 1
      }
    },
    "interactions:url.27C1C870": {
      "data": {
        "sourceId": "url",
        "paperId": "27C1C870",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T03:36:14.296Z",
            "data": {
              "session_id": "session_1766460973785_ly32h6z",
              "source_id": "url",
              "paper_id": "27C1C870",
              "start_time": "2025-12-23T03:35:34.479Z",
              "end_time": "2025-12-23T03:36:13.784Z",
              "heartbeat_count": 7,
              "duration_seconds": 35,
              "idle_seconds": 4,
              "total_elapsed_seconds": 39
            }
          }
        ]
      },
      "meta": {
        "issue_number": 35,
        "object_id": "interactions:url.27C1C870",
        "created_at": "2025-12-23T03:36:14+00:00",
        "updated_at": "2025-12-23T03:37:18+00:00",
        "version": 1
      }
    },
    "paper:url.27C1C870": {
      "data": {
        "sourceId": "url",
        "paperId": "27C1C870",
        "url": "https://jack-clark.net/about/",
        "title": "About",
        "authors": "",
        "abstract": "The greatest challenge of the 21st century is to make an increasingly fast-moving technical world \u2018legible\u2019 to a large number of people. My belief is that by solving these information a\u2026",
        "timestamp": "2025-12-23T03:35:33.754Z",
        "rating": "novote",
        "publishedDate": "2009-11-30T12:12:55+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 34,
        "object_id": "paper:url.27C1C870",
        "created_at": "2025-12-23T03:35:33+00:00",
        "updated_at": "2025-12-23T03:36:31+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1406.2661": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1406.2661",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T18:45:27.418Z",
            "data": {
              "session_id": "session_1766515527054_3h2t1mt",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-23T18:36:24.607Z",
              "end_time": "2025-12-23T18:45:27.054Z",
              "heartbeat_count": 108,
              "duration_seconds": 540,
              "idle_seconds": 2,
              "total_elapsed_seconds": 542
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T20:53:11.456Z",
            "data": {
              "session_id": "session_1766523191255_p7q4h0v",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-23T20:53:00.003Z",
              "end_time": "2025-12-23T20:53:11.255Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 1,
              "total_elapsed_seconds": 11
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T20:58:59.409Z",
            "data": {
              "session_id": "session_1766523539167_dbs4l4i",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-23T20:58:28.399Z",
              "end_time": "2025-12-23T20:58:59.167Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 1,
              "total_elapsed_seconds": 31
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T21:01:28.472Z",
            "data": {
              "session_id": "session_1766523688466_3dknjyu",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-23T21:01:12.228Z",
              "end_time": "2025-12-23T21:01:28.466Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 1,
              "total_elapsed_seconds": 16
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T21:16:10.723Z",
            "data": {
              "session_id": "session_1766524570553_sv4t9xo",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-23T21:15:14.823Z",
              "end_time": "2025-12-23T21:16:10.553Z",
              "heartbeat_count": 11,
              "duration_seconds": 55,
              "idle_seconds": 1,
              "total_elapsed_seconds": 56
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T21:27:52.809Z",
            "data": {
              "session_id": "session_1766525272804_5r9i2tq",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-23T21:27:34.101Z",
              "end_time": "2025-12-23T21:27:52.804Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 4,
              "total_elapsed_seconds": 19
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T02:27:12.745Z",
            "data": {
              "session_id": "session_1766543232246_z7ysp19",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-24T02:25:28.068Z",
              "end_time": "2025-12-24T02:27:12.246Z",
              "heartbeat_count": 20,
              "duration_seconds": 100,
              "idle_seconds": 4,
              "total_elapsed_seconds": 104
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T03:40:55.465Z",
            "data": {
              "session_id": "session_1766547654987_c9ea9vj",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-24T03:39:29.351Z",
              "end_time": "2025-12-24T03:40:54.987Z",
              "heartbeat_count": 17,
              "duration_seconds": 85,
              "idle_seconds": 1,
              "total_elapsed_seconds": 86
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T05:21:39.821Z",
            "data": {
              "session_id": "session_1766553699607_9lj19t3",
              "source_id": "arxiv",
              "paper_id": "1406.2661",
              "start_time": "2025-12-24T05:21:18.162Z",
              "end_time": "2025-12-24T05:21:39.607Z",
              "heartbeat_count": 4,
              "duration_seconds": 20,
              "idle_seconds": 1,
              "total_elapsed_seconds": 21
            }
          }
        ]
      },
      "meta": {
        "issue_number": 37,
        "object_id": "interactions:arxiv.1406.2661",
        "created_at": "2025-12-23T18:36:23+00:00",
        "updated_at": "2025-12-24T05:22:47+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1406.2661": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1406.2661",
        "url": "https://arxiv.org/abs/1406.2661",
        "title": "Generative Adversarial Networks",
        "authors": "Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio",
        "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
        "timestamp": "2025-12-23T18:35:56.249Z",
        "rating": "novote",
        "publishedDate": "2014/06/10",
        "tags": [
          "Machine Learning (stat.ML)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 36,
        "object_id": "paper:arxiv.1406.2661",
        "created_at": "2025-12-23T18:35:56+00:00",
        "updated_at": "2025-12-23T18:36:55+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1503.03585": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1503.03585",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-23T23:04:04.018Z",
            "data": {
              "session_id": "session_1766531043763_y70ft1t",
              "source_id": "arxiv",
              "paper_id": "1503.03585",
              "start_time": "2025-12-23T23:03:48.654Z",
              "end_time": "2025-12-23T23:04:03.763Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 0,
              "total_elapsed_seconds": 15
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T06:00:45.566Z",
            "data": {
              "session_id": "session_1766556045022_xuiypcn",
              "source_id": "arxiv",
              "paper_id": "1503.03585",
              "start_time": "2025-12-24T05:57:10.252Z",
              "end_time": "2025-12-24T06:00:45.022Z",
              "heartbeat_count": 42,
              "duration_seconds": 210,
              "idle_seconds": 5,
              "total_elapsed_seconds": 215
            }
          }
        ]
      },
      "meta": {
        "issue_number": 39,
        "object_id": "interactions:arxiv.1503.03585",
        "created_at": "2025-12-23T21:43:44+00:00",
        "updated_at": "2025-12-24T06:01:50+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1503.03585": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1503.03585",
        "url": "https://arxiv.org/abs/1503.03585",
        "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
        "authors": "Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli",
        "abstract": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.",
        "timestamp": "2025-12-23T21:41:50.039Z",
        "rating": "novote",
        "publishedDate": "2015/03/12",
        "tags": [
          "Machine Learning (cs.LG)",
          "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
          "Neurons and Cognition (q-bio.NC)",
          "Machine Learning (stat.ML)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 38,
        "object_id": "paper:arxiv.1503.03585",
        "created_at": "2025-12-23T21:41:50+00:00",
        "updated_at": "2025-12-23T21:42:48+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1701.07875": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1701.07875",
        "interactions": []
      },
      "meta": {
        "issue_number": 41,
        "object_id": "interactions:arxiv.1701.07875",
        "created_at": "2025-12-23T23:09:09+00:00",
        "updated_at": "2025-12-23T23:09:10+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1701.07875": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1701.07875",
        "url": "https://arxiv.org/abs/1701.07875",
        "title": "Wasserstein GAN",
        "authors": "Martin Arjovsky, Soumith Chintala, L\u00e9on Bottou",
        "abstract": "We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.",
        "timestamp": "2025-12-23T23:08:59.657Z",
        "rating": "novote",
        "publishedDate": "2017/01/26",
        "tags": [
          "Machine Learning (stat.ML)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 40,
        "object_id": "paper:arxiv.1701.07875",
        "created_at": "2025-12-23T23:08:59+00:00",
        "updated_at": "2025-12-23T23:09:53+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2510.21890": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.21890",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T18:57:58.518Z",
            "data": {
              "session_id": "session_1766602678095_eaxc6wm",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T18:57:20.735Z",
              "end_time": "2025-12-24T18:57:58.095Z",
              "heartbeat_count": 7,
              "duration_seconds": 35,
              "idle_seconds": 2,
              "total_elapsed_seconds": 37
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T20:08:22.499Z",
            "data": {
              "session_id": "session_1766606902493_shp6byl",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T20:08:04.869Z",
              "end_time": "2025-12-24T20:08:22.493Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 3,
              "total_elapsed_seconds": 18
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T20:10:45.144Z",
            "data": {
              "session_id": "session_1766607044557_ca75jde",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T20:08:29.534Z",
              "end_time": "2025-12-24T20:10:44.557Z",
              "heartbeat_count": 27,
              "duration_seconds": 135,
              "idle_seconds": 0,
              "total_elapsed_seconds": 135
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T22:15:29.382Z",
            "data": {
              "session_id": "session_1766614529370_brwnusw",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T22:15:07.126Z",
              "end_time": "2025-12-24T22:15:29.370Z",
              "heartbeat_count": 4,
              "duration_seconds": 20,
              "idle_seconds": 2,
              "total_elapsed_seconds": 22
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T22:19:01.165Z",
            "data": {
              "session_id": "session_1766614740754_acwi8fo",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T22:17:39.438Z",
              "end_time": "2025-12-24T22:19:00.754Z",
              "heartbeat_count": 16,
              "duration_seconds": 80,
              "idle_seconds": 1,
              "total_elapsed_seconds": 81
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T22:22:13.119Z",
            "data": {
              "session_id": "session_1766614932662_8h460er",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T22:19:08.775Z",
              "end_time": "2025-12-24T22:22:12.662Z",
              "heartbeat_count": 36,
              "duration_seconds": 180,
              "idle_seconds": 4,
              "total_elapsed_seconds": 184
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T22:24:48.741Z",
            "data": {
              "session_id": "session_1766615088199_sftzrir",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T22:22:21.656Z",
              "end_time": "2025-12-24T22:24:48.199Z",
              "heartbeat_count": 29,
              "duration_seconds": 145,
              "idle_seconds": 2,
              "total_elapsed_seconds": 147
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-24T22:31:43.377Z",
            "data": {
              "session_id": "session_1766615503349_kj8ka5t",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-24T22:31:10.166Z",
              "end_time": "2025-12-24T22:31:43.349Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 3,
              "total_elapsed_seconds": 33
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-27T03:18:59.386Z",
            "data": {
              "session_id": "session_1766805538853_fnttr7z",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-27T03:16:13.819Z",
              "end_time": "2025-12-27T03:18:58.853Z",
              "heartbeat_count": 33,
              "duration_seconds": 165,
              "idle_seconds": 0,
              "total_elapsed_seconds": 165
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-27T03:55:45.948Z",
            "data": {
              "session_id": "session_1766807745764_zty2nbg",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-27T03:55:38.814Z",
              "end_time": "2025-12-27T03:55:45.764Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 2,
              "total_elapsed_seconds": 7
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-27T03:58:45.699Z",
            "data": {
              "session_id": "session_1766807925136_wpqg2mf",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-27T03:55:55.678Z",
              "end_time": "2025-12-27T03:58:45.136Z",
              "heartbeat_count": 33,
              "duration_seconds": 165,
              "idle_seconds": 4,
              "total_elapsed_seconds": 169
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-27T04:01:00.844Z",
            "data": {
              "session_id": "session_1766808060552_s5nogau",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-27T04:00:47.853Z",
              "end_time": "2025-12-27T04:01:00.552Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 3,
              "total_elapsed_seconds": 13
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-29T22:31:43.388Z",
            "data": {
              "session_id": "session_1767047503381_tx3etzn",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-29T22:31:31.260Z",
              "end_time": "2025-12-29T22:31:43.381Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 2,
              "total_elapsed_seconds": 12
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-29T22:33:04.526Z",
            "data": {
              "session_id": "session_1767047584328_h410cen",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2025-12-29T22:32:57.889Z",
              "end_time": "2025-12-29T22:33:04.328Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 1,
              "total_elapsed_seconds": 6
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-01T22:05:50.314Z",
            "data": {
              "session_id": "session_1767305150301_5nuhwlo",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-01T22:05:14.952Z",
              "end_time": "2026-01-01T22:05:50.301Z",
              "heartbeat_count": 7,
              "duration_seconds": 35,
              "idle_seconds": 0,
              "total_elapsed_seconds": 35
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-01T22:19:19.105Z",
            "data": {
              "session_id": "session_1767305958645_aw7xvq9",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-01T22:15:38.431Z",
              "end_time": "2026-01-01T22:19:18.645Z",
              "heartbeat_count": 44,
              "duration_seconds": 220,
              "idle_seconds": 0,
              "total_elapsed_seconds": 220
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-02T00:25:57.052Z",
            "data": {
              "session_id": "session_1767313556834_kb1qe9l",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-02T00:25:45.651Z",
              "end_time": "2026-01-02T00:25:56.834Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 1,
              "total_elapsed_seconds": 11
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-10T20:58:29.246Z",
            "data": {
              "session_id": "session_1768078708860_ijz74fb",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-10T20:56:06.837Z",
              "end_time": "2026-01-10T20:58:28.860Z",
              "heartbeat_count": 28,
              "duration_seconds": 140,
              "idle_seconds": 2,
              "total_elapsed_seconds": 142
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-12T00:18:26.279Z",
            "data": {
              "session_id": "session_1768177106064_h2jomz0",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-12T00:18:10.037Z",
              "end_time": "2026-01-12T00:18:26.064Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 1,
              "total_elapsed_seconds": 16
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-12T00:21:19.790Z",
            "data": {
              "session_id": "session_1768177279369_zld79go",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-12T00:18:44.162Z",
              "end_time": "2026-01-12T00:21:19.369Z",
              "heartbeat_count": 31,
              "duration_seconds": 155,
              "idle_seconds": 0,
              "total_elapsed_seconds": 155
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-12T02:57:31.354Z",
            "data": {
              "session_id": "session_1768186650759_96g092v",
              "source_id": "arxiv",
              "paper_id": "2510.21890",
              "start_time": "2026-01-12T02:57:24.151Z",
              "end_time": "2026-01-12T02:57:30.759Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 2,
              "total_elapsed_seconds": 7
            }
          }
        ]
      },
      "meta": {
        "issue_number": 43,
        "object_id": "interactions:arxiv.2510.21890",
        "created_at": "2025-12-24T18:57:58+00:00",
        "updated_at": "2026-01-12T02:58:42+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.21890": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.21890",
        "url": "https://arxiv.org/pdf/2510.21890",
        "title": "The Principles of Diffusion Models",
        "authors": [
          "Chieh-Hsin Lai",
          "Yang Song",
          "Dongjun Kim",
          "Yuki Mitsufuji",
          "Stefano Ermon"
        ],
        "abstract": "This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions. The goal is to learn a reverse process that transforms noise back into data while recovering the same intermediates. We describe three complementary views. The variational view, inspired by variational autoencoders, sees diffusion as learning to remove noise step by step. The score-based view, rooted in energy-based modeling, learns the gradient of the evolving data distribution, indicating how to nudge samples toward more likely regions. The flow-based view, related to normalizing flows, treats generation as following a smooth path that moves samples from noise to data under a learned velocity field. These perspectives share a common backbone: a time-dependent velocity field whose flow transports a simple prior to the data. Sampling then amounts to solving a differential equation that evolves noise into data along a continuous trajectory. On this foundation, the monograph discusses guidance for controllable generation, efficient numerical solvers, and diffusion-motivated flow-map models that learn direct mappings between arbitrary times. It provides a conceptual and mathematically grounded understanding of diffusion models for readers with basic deep-learning knowledge.",
        "timestamp": "2025-12-24T18:57:20.995Z",
        "rating": "novote",
        "publishedDate": "2025-10-24",
        "tags": [
          "cs.LG",
          "cs.AI",
          "cs.GR"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI",
          "cs.GR"
        ]
      },
      "meta": {
        "issue_number": 42,
        "object_id": "paper:arxiv.2510.21890",
        "created_at": "2025-12-24T18:57:21+00:00",
        "updated_at": "2025-12-24T19:01:11+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2110.11235": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2110.11235",
        "interactions": []
      },
      "meta": {
        "issue_number": 45,
        "object_id": "interactions:arxiv.2110.11235",
        "created_at": "2025-12-24T22:14:10+00:00",
        "updated_at": "2025-12-24T22:14:11+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2110.11235": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2110.11235",
        "url": "https://arxiv.org/pdf/2110.11235",
        "title": "When is the composition of functions measurable?",
        "authors": [
          "F. Javier Fern\u00e1ndez",
          "F. Adri\u00e1n F. Tojo"
        ],
        "abstract": "In this article we explore under which conditions on the interior function the composition of functions is measurable. We also study the sharpness of the result by providing a counterexample for weaker hypotheses.",
        "timestamp": "2025-12-24T22:14:01.688Z",
        "rating": "novote",
        "publishedDate": "2021-10-05",
        "tags": [
          "math.FA"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.FA"
        ]
      },
      "meta": {
        "issue_number": 44,
        "object_id": "paper:arxiv.2110.11235",
        "created_at": "2025-12-24T22:14:01+00:00",
        "updated_at": "2025-12-24T22:18:22+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2511.19752": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.19752",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-27T01:32:41.996Z",
            "data": {
              "session_id": "session_1769477561484_ydpoo0e",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-27T01:31:18.754Z",
              "end_time": "2026-01-27T01:32:41.484Z",
              "heartbeat_count": 16,
              "duration_seconds": 80,
              "idle_seconds": 3,
              "total_elapsed_seconds": 83
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T01:05:07.589Z",
            "data": {
              "session_id": "session_1769562307250_fxbqcrm",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T01:04:36.015Z",
              "end_time": "2026-01-28T01:05:07.250Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 1,
              "total_elapsed_seconds": 31
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T01:08:16.600Z",
            "data": {
              "session_id": "session_1769562496594_bemes4v",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T01:07:58.883Z",
              "end_time": "2026-01-28T01:08:16.594Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 3,
              "total_elapsed_seconds": 18
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T01:18:31.887Z",
            "data": {
              "session_id": "session_1769563111388_p76vtox",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T01:09:09.777Z",
              "end_time": "2026-01-28T01:18:31.388Z",
              "heartbeat_count": 112,
              "duration_seconds": 560,
              "idle_seconds": 2,
              "total_elapsed_seconds": 562
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T02:50:57.111Z",
            "data": {
              "session_id": "session_1769568656308_upsion6",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T01:29:18.048Z",
              "end_time": "2026-01-28T02:50:56.308Z",
              "heartbeat_count": 979,
              "duration_seconds": 4895,
              "idle_seconds": 3,
              "total_elapsed_seconds": 4898
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T23:16:54.074Z",
            "data": {
              "session_id": "session_1769642213829_1rjtg8x",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T23:16:44.732Z",
              "end_time": "2026-01-28T23:16:53.829Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 4,
              "total_elapsed_seconds": 9
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T23:18:02.593Z",
            "data": {
              "session_id": "session_1769642282053_8vw1rj5",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T23:17:14.357Z",
              "end_time": "2026-01-28T23:18:02.053Z",
              "heartbeat_count": 9,
              "duration_seconds": 45,
              "idle_seconds": 3,
              "total_elapsed_seconds": 48
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T23:21:18.583Z",
            "data": {
              "session_id": "session_1769642477979_o2ygd2t",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T23:18:06.133Z",
              "end_time": "2026-01-28T23:21:17.979Z",
              "heartbeat_count": 38,
              "duration_seconds": 190,
              "idle_seconds": 2,
              "total_elapsed_seconds": 192
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T23:22:44.550Z",
            "data": {
              "session_id": "session_1769642563906_cuiqgs2",
              "source_id": "arxiv",
              "paper_id": "2511.19752",
              "start_time": "2026-01-28T23:21:23.628Z",
              "end_time": "2026-01-28T23:22:43.906Z",
              "heartbeat_count": 16,
              "duration_seconds": 80,
              "idle_seconds": 0,
              "total_elapsed_seconds": 80
            }
          }
        ]
      },
      "meta": {
        "issue_number": 109,
        "object_id": "interactions:arxiv.2511.19752",
        "created_at": "2026-01-27T01:31:16+00:00",
        "updated_at": "2026-01-28T23:23:49+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1806.10574": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1806.10574",
        "url": "https://arxiv.org/abs/1806.10574",
        "title": "This Looks Like That: Deep Learning for Interpretable Image Recognition",
        "authors": "Chaofan Chen, Oscar Li, Chaofan Tao, Alina Jade Barnett, Jonathan Su, Cynthia Rudin",
        "abstract": "When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.",
        "timestamp": "2025-12-30T02:20:48.656Z",
        "rating": "novote",
        "publishedDate": "2018/06/27",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)",
          "Computer Vision and Pattern Recognition (cs.CV)",
          "Machine Learning (stat.ML)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 47,
        "object_id": "paper:arxiv.1806.10574",
        "created_at": "2025-12-30T02:20:48+00:00",
        "updated_at": "2025-12-30T02:21:48+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2511.19752": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.19752",
        "url": "https://arxiv.org/abs/2511.19752",
        "title": "What You See is (Usually) What You Get: Multimodal Prototype Networks that Abstain from Expensive Modalities",
        "authors": "Muchang Bahng, Charlie Berens, Jon Donnelly, Eric Chen, Chaofan Chen, Cynthia Rudin",
        "abstract": "Species detection is important for monitoring the health of ecosystems and identifying invasive species, serving a crucial role in guiding conservation efforts. Multimodal neural networks have seen increasing use for identifying species to help automate this task, but they have two major drawbacks. First, their black-box nature prevents the interpretability of their decision making process. Second, collecting genetic data is often expensive and requires invasive procedures, often necessitating researchers to capture or kill the target specimen. We address both of these problems by extending prototype networks (ProtoPNets), which are a popular and interpretable alternative to traditional neural networks, to the multimodal, cost-aware setting. We ensemble prototypes from each modality, using an associated weight to determine how much a given prediction relies on each modality. We further introduce methods to identify cases for which we do not need the expensive genetic information to make confident predictions. We demonstrate that our approach can intelligently allocate expensive genetic data for fine-grained distinctions while using abundant image data for clearer visual classifications and achieving comparable accuracy to models that consistently use both modalities.",
        "timestamp": "2025-12-30T02:20:48.631Z",
        "rating": "novote",
        "publishedDate": "2025/11/24",
        "tags": [
          "Computer Vision and Pattern Recognition (cs.CV)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 46,
        "object_id": "paper:arxiv.2511.19752",
        "created_at": "2025-12-30T02:20:48+00:00",
        "updated_at": "2025-12-30T02:21:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.17100": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.17100",
        "url": "https://arxiv.org/abs/2502.17100",
        "title": "Generative Models in Decision Making: A Survey",
        "authors": "Yinchuan Li, Xinyu Shao, Jianping Zhang, Haozhi Wang, Leo Maxime Brunswic, Kaiwen Zhou, Jiqian Dong, Kaiyang Guo, Xiu Li, Zhitang Chen, Jun Wang, Jianye Hao",
        "abstract": "In recent years, the exceptional performance of generative models in generative tasks has sparked significant interest in their integration into decision-making processes. Due to their ability to handle complex data distributions and their strong model capacity, generative models can be effectively incorporated into decision-making systems by generating trajectories that guide agents toward high-reward state-action regions or intermediate sub-goals. This paper presents a comprehensive review of the application of generative models in decision-making tasks. We classify seven fundamental types of generative models: energy-based models, generative adversarial networks, variational autoencoders, normalizing flows, diffusion models, generative flow networks, and autoregressive models. Regarding their applications, we categorize their functions into three main roles: controllers, modelers and optimizers, and discuss how each role contributes to decision-making. Furthermore, we examine the deployment of these models across five critical real-world decision-making scenarios. Finally, we summarize the strengths and limitations of current approaches and propose three key directions for advancing next-generation generative directive models: high-performance algorithms, large-scale generalized decision-making models, and self-evolving and adaptive models.",
        "timestamp": "2026-01-01T21:48:05.517Z",
        "rating": "novote",
        "publishedDate": "2025/02/24",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 49,
        "object_id": "paper:arxiv.2502.17100",
        "created_at": "2026-01-01T21:48:05+00:00",
        "updated_at": "2026-01-01T21:49:06+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2502.17100": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.17100",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-01T21:50:58.501Z",
            "data": {
              "session_id": "session_1767304257930_g648u58",
              "source_id": "arxiv",
              "paper_id": "2502.17100",
              "start_time": "2026-01-01T21:48:08.896Z",
              "end_time": "2026-01-01T21:50:57.930Z",
              "heartbeat_count": 33,
              "duration_seconds": 165,
              "idle_seconds": 4,
              "total_elapsed_seconds": 169
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-01T21:58:48.910Z",
            "data": {
              "session_id": "session_1767304728425_9mc6vzf",
              "source_id": "arxiv",
              "paper_id": "2502.17100",
              "start_time": "2026-01-01T21:51:19.270Z",
              "end_time": "2026-01-01T21:58:48.425Z",
              "heartbeat_count": 89,
              "duration_seconds": 445,
              "idle_seconds": 4,
              "total_elapsed_seconds": 449
            }
          }
        ]
      },
      "meta": {
        "issue_number": 50,
        "object_id": "interactions:arxiv.2502.17100",
        "created_at": "2026-01-01T21:50:58+00:00",
        "updated_at": "2026-01-01T21:59:52+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2006.11239": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2006.11239",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T02:09:26.247Z",
            "data": {
              "session_id": "session_1768097366239_fzqgi46",
              "source_id": "arxiv",
              "paper_id": "2006.11239",
              "start_time": "2026-01-11T02:08:46.434Z",
              "end_time": "2026-01-11T02:09:26.239Z",
              "heartbeat_count": 7,
              "duration_seconds": 35,
              "idle_seconds": 5,
              "total_elapsed_seconds": 40
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T03:00:53.458Z",
            "data": {
              "session_id": "session_1768100453445_i76qvkh",
              "source_id": "arxiv",
              "paper_id": "2006.11239",
              "start_time": "2026-01-11T03:00:11.335Z",
              "end_time": "2026-01-11T03:00:53.445Z",
              "heartbeat_count": 8,
              "duration_seconds": 40,
              "idle_seconds": 2,
              "total_elapsed_seconds": 42
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T03:04:03.906Z",
            "data": {
              "session_id": "session_1768100643572_q6gsgp4",
              "source_id": "arxiv",
              "paper_id": "2006.11239",
              "start_time": "2026-01-11T03:00:54.177Z",
              "end_time": "2026-01-11T03:04:03.572Z",
              "heartbeat_count": 37,
              "duration_seconds": 185,
              "idle_seconds": 4,
              "total_elapsed_seconds": 189
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T07:50:03.891Z",
            "data": {
              "session_id": "session_1768117803466_cwviagb",
              "source_id": "arxiv",
              "paper_id": "2006.11239",
              "start_time": "2026-01-11T07:47:58.433Z",
              "end_time": "2026-01-11T07:50:03.466Z",
              "heartbeat_count": 25,
              "duration_seconds": 125,
              "idle_seconds": 0,
              "total_elapsed_seconds": 125
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T07:51:43.544Z",
            "data": {
              "session_id": "session_1768117903348_77hgug5",
              "source_id": "arxiv",
              "paper_id": "2006.11239",
              "start_time": "2026-01-11T07:51:31.518Z",
              "end_time": "2026-01-11T07:51:43.348Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 2,
              "total_elapsed_seconds": 12
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T08:24:02.485Z",
            "data": {
              "session_id": "session_1768119842478_dqmfh0z",
              "source_id": "arxiv",
              "paper_id": "2006.11239",
              "start_time": "2026-01-11T08:23:47.370Z",
              "end_time": "2026-01-11T08:24:02.478Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 0,
              "total_elapsed_seconds": 15
            }
          }
        ]
      },
      "meta": {
        "issue_number": 52,
        "object_id": "interactions:arxiv.2006.11239",
        "created_at": "2026-01-01T22:03:36+00:00",
        "updated_at": "2026-01-11T08:24:57+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2006.11239": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2006.11239",
        "url": "https://arxiv.org/abs/2006.11239",
        "title": "Denoising Diffusion Probabilistic Models",
        "authors": "Jonathan Ho, Ajay Jain, Pieter Abbeel",
        "abstract": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at this https URL",
        "timestamp": "2026-01-01T22:03:24.954Z",
        "rating": "novote",
        "publishedDate": "2020/06/19",
        "tags": [
          "Machine Learning (cs.LG)",
          "Machine Learning (stat.ML)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 51,
        "object_id": "paper:arxiv.2006.11239",
        "created_at": "2026-01-01T22:03:25+00:00",
        "updated_at": "2026-01-01T22:04:33+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2511.03032": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.03032",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-05T20:30:44.477Z",
            "data": {
              "session_id": "session_1767645044051_gtquuvh",
              "source_id": "arxiv",
              "paper_id": "2511.03032",
              "start_time": "2026-01-05T20:30:33.941Z",
              "end_time": "2026-01-05T20:30:44.051Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 10
            }
          }
        ]
      },
      "meta": {
        "issue_number": 54,
        "object_id": "interactions:arxiv.2511.03032",
        "created_at": "2026-01-05T20:30:44+00:00",
        "updated_at": "2026-01-05T20:31:48+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2511.03032": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.03032",
        "url": "https://arxiv.org/pdf/2511.03032",
        "title": "Leveraging Discrete Function Decomposability for Scientific Design",
        "authors": [
          "James C. Bowden",
          "Sergey Levine",
          "Jennifer Listgarten"
        ],
        "abstract": "In the era of AI-driven science and engineering, we often want to design discrete objects in silico according to user-specified properties. For example, we may wish to design a protein to bind its target, arrange components within a circuit to minimize latency, or find materials with certain properties. Given a property predictive model, in silico design typically involves training a generative model over the design space (e.g., protein sequence space) to concentrate on designs with the desired properties. Distributional optimization -- which can be formalized as an estimation of distribution algorithm or as reinforcement learning policy optimization -- finds the generative model that maximizes an objective function in expectation. Optimizing a distribution over discrete-valued designs is in general challenging because of the combinatorial nature of the design space. However, many property predictors in scientific applications are decomposable in the sense that they can be factorized over design variables in a way that could in principle enable more effective optimization. For example, amino acids at a catalytic site of a protein may only loosely interact with amino acids of the rest of the protein to achieve maximal catalytic activity. Current distributional optimization algorithms are unable to make use of such decomposability structure. Herein, we propose and demonstrate use of a new distributional optimization algorithm, Decomposition-Aware Distributional Optimization (DADO), that can leverage any decomposability defined by a junction tree on the design variables, to make optimization more efficient. At its core, DADO employs a soft-factorized \"search distribution\" -- a learned generative model -- for efficient navigation of the search space, invoking graph message-passing to coordinate optimization across linked factors.",
        "timestamp": "2026-01-05T20:30:34.207Z",
        "rating": "novote",
        "publishedDate": "2025-11-04",
        "tags": [
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 53,
        "object_id": "paper:arxiv.2511.03032",
        "created_at": "2026-01-05T20:30:34+00:00",
        "updated_at": "2026-01-05T20:33:27+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2510.22835": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.22835",
        "interactions": []
      },
      "meta": {
        "issue_number": 56,
        "object_id": "interactions:arxiv.2510.22835",
        "created_at": "2026-01-05T22:31:31+00:00",
        "updated_at": "2026-01-05T22:31:33+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.22835": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.22835",
        "url": "https://arxiv.org/abs/2510.22835",
        "title": "Clustering by Denoising: Latent plug-and-play diffusion for single-cell data",
        "authors": "Dominik Meier, Shixing Yu, Sagnik Nandy, Promit Ghosal, Kyra Gan",
        "abstract": "Single-cell RNA sequencing (scRNA-seq) enables the study of cellular heterogeneity. Yet, clustering accuracy, and with it downstream analyses based on cell labels, remain challenging due to measurement noise and biological variability. In standard latent spaces (e.g., obtained through PCA), data from different cell types can be projected close together, making accurate clustering difficult. We introduce a latent plug-and-play diffusion framework that separates the observation and denoising space. This separation is operationalized through a novel Gibbs sampling procedure: the learned diffusion prior is applied in a low-dimensional latent space to perform denoising, while to steer this process, noise is reintroduced into the original high-dimensional observation space. This unique \"input-space steering\" ensures the denoising trajectory remains faithful to the original data structure. Our approach offers three key advantages: (1) adaptive noise handling via a tunable balance between prior and observed data; (2) uncertainty quantification through principled uncertainty estimates for downstream analysis; and (3) generalizable denoising by leveraging clean reference data to denoise noisier datasets, and via averaging, improve quality beyond the training set. We evaluate robustness on both synthetic and real single-cell genomics data. Our method improves clustering accuracy on synthetic data across varied noise levels and dataset shifts. On real-world single-cell data, our method demonstrates improved biological coherence in the resulting cell clusters, with cluster boundaries that better align with known cell type markers and developmental trajectories.",
        "timestamp": "2026-01-05T22:31:20.535Z",
        "rating": "novote",
        "publishedDate": "2025/10/26",
        "tags": [
          "Machine Learning (cs.LG)",
          "Computation (stat.CO)",
          "Machine Learning (stat.ML)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 55,
        "object_id": "paper:arxiv.2510.22835",
        "created_at": "2026-01-05T22:31:20+00:00",
        "updated_at": "2026-01-05T22:32:21+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2507.09808": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2507.09808",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-05T23:26:09.798Z",
            "data": {
              "session_id": "session_1767655569300_9tse9xs",
              "source_id": "arxiv",
              "paper_id": "2507.09808",
              "start_time": "2026-01-05T23:26:04.071Z",
              "end_time": "2026-01-05T23:26:09.300Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          }
        ]
      },
      "meta": {
        "issue_number": 58,
        "object_id": "interactions:arxiv.2507.09808",
        "created_at": "2026-01-05T23:26:10+00:00",
        "updated_at": "2026-01-05T23:27:17+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2507.09808": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2507.09808",
        "url": "https://arxiv.org/abs/2507.09808",
        "title": "Frank-Wolfe Recursions for the Emergency Response Problem on Measure Spaces",
        "authors": "Di Yu, Shane G. Henderson, Raghu Pasupathy",
        "abstract": "We consider an optimization problem over measures for emergency response to out-of-hospital cardiac arrest (OHCA), where the goal is to allocate volunteer resources across a spatial region to minimize the probability of death. The problem is infinite-dimensional and poses challenges for analysis and computation. We first establish structural properties, including convexity of the objective functional, compactness of the feasible set, and existence of optimal solutions. We also derive the influence function, which serves as the first-order variational object in our optimization framework. We then adapt and analyze a fully-corrective Frank-Wolfe (fc-FW) algorithm that operates directly on the infinite-dimensional problem without discretization or parametric approximation. We show a form of convergence even when subproblems are not solved to global optimality. Our full implementation of fc-FW demonstrates complex solution structure even in simple discrete cases, reveals nontrivial volunteer allocations in continuous cases, and scales to realistic urban scenarios using OHCA data from the city of Auckland, New Zealand. Finally, we show that when volunteer travel is modeled through the $L_1$ norm, the influence function is piecewise strictly concave, enabling fast computation via support reduction. The proposed framework and analysis extend naturally to a broad class of $P$-means problems.",
        "timestamp": "2026-01-05T23:26:04.367Z",
        "rating": "novote",
        "publishedDate": "2025/07/13",
        "tags": [
          "Optimization and Control (math.OC)",
          "Computation (stat.CO)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 57,
        "object_id": "paper:arxiv.2507.09808",
        "created_at": "2026-01-05T23:26:04+00:00",
        "updated_at": "2026-01-05T23:27:12+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1806.10574": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1806.10574",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-06T17:40:40.797Z",
            "data": {
              "session_id": "session_1767721240299_0lfza5l",
              "source_id": "arxiv",
              "paper_id": "1806.10574",
              "start_time": "2026-01-06T17:36:40.836Z",
              "end_time": "2026-01-06T17:40:40.299Z",
              "heartbeat_count": 47,
              "duration_seconds": 235,
              "idle_seconds": 4,
              "total_elapsed_seconds": 239
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T21:55:06.194Z",
            "data": {
              "session_id": "session_1769464506150_5xrsut6",
              "source_id": "arxiv",
              "paper_id": "1806.10574",
              "start_time": "2026-01-26T21:55:00.517Z",
              "end_time": "2026-01-26T21:55:06.150Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 6
            }
          }
        ]
      },
      "meta": {
        "issue_number": 59,
        "object_id": "interactions:arxiv.1806.10574",
        "created_at": "2026-01-06T17:40:41+00:00",
        "updated_at": "2026-01-26T22:06:22+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2506.18283": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.18283",
        "url": "https://arxiv.org/pdf/2506.18283",
        "title": "Quantifying Uncertainty in the Presence of Distribution Shifts",
        "authors": [
          "Yuli Slavutsky",
          "David M. Blei"
        ],
        "abstract": "Neural networks make accurate predictions but often fail to provide reliable uncertainty estimates, especially under covariate distribution shifts between training and testing. To address this problem, we propose a Bayesian framework for uncertainty estimation that explicitly accounts for covariate shifts. While conventional approaches rely on fixed priors, the key idea of our method is an adaptive prior, conditioned on both training and new covariates. This prior naturally increases uncertainty for inputs that lie far from the training distribution in regions where predictive performance is likely to degrade. To efficiently approximate the resulting posterior predictive distribution, we employ amortized variational inference. Finally, we construct synthetic environments by drawing small bootstrap samples from the training data, simulating a range of plausible covariate shift using only the original dataset. We evaluate our method on both synthetic and real-world data. It yields substantially improved uncertainty estimates under distribution shifts.",
        "timestamp": "2026-01-06T18:58:52.806Z",
        "rating": "novote",
        "publishedDate": "2025-06-23",
        "tags": [
          "stat.ML",
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "stat.ML",
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 60,
        "object_id": "paper:arxiv.2506.18283",
        "created_at": "2026-01-06T18:58:53+00:00",
        "updated_at": "2026-01-06T19:01:46+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2506.18283": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.18283",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-06T19:04:14.351Z",
            "data": {
              "session_id": "session_1767726253906_o13sl0p",
              "source_id": "arxiv",
              "paper_id": "2506.18283",
              "start_time": "2026-01-06T18:58:52.503Z",
              "end_time": "2026-01-06T19:04:13.906Z",
              "heartbeat_count": 64,
              "duration_seconds": 320,
              "idle_seconds": 1,
              "total_elapsed_seconds": 321
            }
          }
        ]
      },
      "meta": {
        "issue_number": 61,
        "object_id": "interactions:arxiv.2506.18283",
        "created_at": "2026-01-06T19:04:14+00:00",
        "updated_at": "2026-01-06T19:05:19+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2212.09561": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2212.09561",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-06T21:00:27.102Z",
            "data": {
              "session_id": "session_1767733225533_4afov27",
              "source_id": "arxiv",
              "paper_id": "2212.09561",
              "start_time": "2026-01-06T21:00:16.947Z",
              "end_time": "2026-01-06T21:00:25.533Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 4,
              "total_elapsed_seconds": 9
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-06T21:06:28.346Z",
            "data": {
              "session_id": "session_1767733587859_50byxg4",
              "source_id": "arxiv",
              "paper_id": "2212.09561",
              "start_time": "2026-01-06T21:00:25.608Z",
              "end_time": "2026-01-06T21:06:27.859Z",
              "heartbeat_count": 72,
              "duration_seconds": 360,
              "idle_seconds": 2,
              "total_elapsed_seconds": 362
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-06T21:15:33.837Z",
            "data": {
              "session_id": "session_1767734133360_h22upqm",
              "source_id": "arxiv",
              "paper_id": "2212.09561",
              "start_time": "2026-01-06T21:14:30.971Z",
              "end_time": "2026-01-06T21:15:33.360Z",
              "heartbeat_count": 12,
              "duration_seconds": 60,
              "idle_seconds": 2,
              "total_elapsed_seconds": 62
            }
          }
        ]
      },
      "meta": {
        "issue_number": 63,
        "object_id": "interactions:arxiv.2212.09561",
        "created_at": "2026-01-06T21:00:27+00:00",
        "updated_at": "2026-01-06T21:23:19+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2212.09561": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2212.09561",
        "url": "https://arxiv.org/abs/2212.09561",
        "title": "Large Language Models are Better Reasoners with Self-Verification",
        "authors": "Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, Jun Zhao",
        "abstract": "Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: this https URL.",
        "timestamp": "2026-01-06T21:00:12.861Z",
        "rating": "novote",
        "publishedDate": "2022/12/19",
        "tags": [
          "Artificial Intelligence (cs.AI)",
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 62,
        "object_id": "paper:arxiv.2212.09561",
        "created_at": "2026-01-06T21:00:13+00:00",
        "updated_at": "2026-01-06T21:01:18+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2012.02046": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2012.02046",
        "url": "https://arxiv.org/abs/2012.02046",
        "title": "Neural Prototype Trees for Interpretable Fine-grained Image Recognition",
        "authors": "Meike Nauta, Ron van Bree, Christin Seifert",
        "abstract": "Prototype-based methods use interpretable representations to address the black-box nature of deep learning models, in contrast to post-hoc explanation methods that only approximate such models. We propose the Neural Prototype Tree (ProtoTree), an intrinsically interpretable deep learning method for fine-grained image recognition. ProtoTree combines prototype learning with decision trees, and thus results in a globally interpretable model by design. Additionally, ProtoTree can locally explain a single prediction by outlining a decision path through the tree. Each node in our binary tree contains a trainable prototypical part. The presence or absence of this learned prototype in an image determines the routing through a node. Decision making is therefore similar to human reasoning: Does the bird have a red throat? And an elongated beak? Then it's a hummingbird! We tune the accuracy-interpretability trade-off using ensemble methods, pruning and binarizing. We apply pruning without sacrificing accuracy, resulting in a small tree with only 8 learned prototypes along a path to classify a bird from 200 species. An ensemble of 5 ProtoTrees achieves competitive accuracy on the CUB-200- 2011 and Stanford Cars data sets. Code is available at this https URL",
        "timestamp": "2026-01-07T17:24:48.984Z",
        "rating": "novote",
        "publishedDate": "2020/12/03",
        "tags": [
          "Computer Vision and Pattern Recognition (cs.CV)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 64,
        "object_id": "paper:arxiv.2012.02046",
        "created_at": "2026-01-07T17:24:49+00:00",
        "updated_at": "2026-01-07T17:25:54+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2012.02046": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2012.02046",
        "interactions": []
      },
      "meta": {
        "issue_number": 65,
        "object_id": "interactions:arxiv.2012.02046",
        "created_at": "2026-01-07T21:04:01+00:00",
        "updated_at": "2026-01-07T21:04:02+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2005.08513": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2005.08513",
        "url": "https://arxiv.org/pdf/2005.08513",
        "title": "Convergence of constant step stochastic gradient descent for non-smooth non-convex functions",
        "authors": [
          "Pascal Bianchi",
          "Walid Hachem",
          "Sholom Schechtman"
        ],
        "abstract": "This paper studies the asymptotic behavior of the constant step Stochastic Gradient Descent for the minimization of an unknown function F , defined as the expectation of a non convex, non smooth, locally Lipschitz random function. As the gradient may not exist, it is replaced by a certain operator: a reasonable choice is to use an element of the Clarke subdifferential of the random function; an other choice is the output of the celebrated backpropagation algorithm, which is popular amongst practionners, and whose properties have recently been studied by Bolte and Pauwels [7]. Since the expectation of the chosen operator is not in general an element of the Clarke subdifferential BF of the mean function, it has been assumed in the literature that an oracle of BF is available. As a first result, it is shown in this paper that such an oracle is not needed for almost all initialization points of the algorithm. Next, in the small step size regime, it is shown that the interpolated trajectory of the algorithm converges in probability (in the compact convergence sense) towards the set of solutions of the differential inclusion. Finally, viewing the iterates as a Markov chain whose transition kernel is indexed by the step size, it is shown that the invariant distribution of the kernel converge weakly to the set of invariant distribution of this differential inclusion as the step size tends to zero. These results show that when the step size is small, with large probability, the iterates eventually lie in a neighborhood of the critical points of the mean function F .",
        "timestamp": "2026-01-08T22:06:41.544Z",
        "rating": "novote",
        "publishedDate": "2020-05-18",
        "tags": [
          "math.NA",
          "math.OC"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.NA",
          "math.OC"
        ]
      },
      "meta": {
        "issue_number": 66,
        "object_id": "paper:arxiv.2005.08513",
        "created_at": "2026-01-08T22:06:41+00:00",
        "updated_at": "2026-01-08T22:10:30+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2103.16662": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2103.16662",
        "url": "https://arxiv.org/abs/2103.16662",
        "title": "A genuinely natural information measure",
        "authors": "Andreas Winter",
        "abstract": "The theoretical measuring of information was famously initiated by Shannon in his mathematical theory of communication, in which he proposed a now widely used quantity, the entropy, measured in bits. Yet, in the same paper, Shannon also chose to measure the information in continuous systems in nats, which differ from bits by the use of the natural rather than the binary logarithm.\nWe point out that there is nothing natural about the choice of logarithm basis, rather it is arbitrary. We remedy this problematic state of affairs by proposing a genuinely natural measure of information, which we dub gnats. We show that gnats have many advantages in information theory, and propose to adopt the underlying methodology throughout science, arts and everyday life.",
        "timestamp": "2026-01-09T15:42:31.566Z",
        "rating": "novote",
        "publishedDate": "2021/03/30",
        "tags": [
          "Information Theory (cs.IT)",
          "Quantum Physics (quant-ph)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 67,
        "object_id": "paper:arxiv.2103.16662",
        "created_at": "2026-01-09T15:42:31+00:00",
        "updated_at": "2026-01-09T15:43:38+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1805.11965": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1805.11965",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-09T19:24:10.284Z",
            "data": {
              "session_id": "session_1767986649809_v01kqgr",
              "source_id": "arxiv",
              "paper_id": "1805.11965",
              "start_time": "2026-01-09T19:23:00.019Z",
              "end_time": "2026-01-09T19:24:09.809Z",
              "heartbeat_count": 13,
              "duration_seconds": 65,
              "idle_seconds": 5,
              "total_elapsed_seconds": 70
            }
          }
        ]
      },
      "meta": {
        "issue_number": 69,
        "object_id": "interactions:arxiv.1805.11965",
        "created_at": "2026-01-09T19:24:10+00:00",
        "updated_at": "2026-01-09T19:25:13+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1805.11965": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1805.11965",
        "url": "https://arxiv.org/abs/1805.11965",
        "title": "A Mini-Introduction To Information Theory",
        "authors": "Edward Witten",
        "abstract": "This article consists of a very short introduction to classical and quantum information theory. Basic properties of the classical Shannon entropy and the quantum von Neumann entropy are described, along with related concepts such as classical and quantum relative entropy, conditional entropy, and mutual information. A few more detailed topics are considered in the quantum case.",
        "timestamp": "2026-01-09T19:22:58.820Z",
        "rating": "novote",
        "publishedDate": "2018/05/30",
        "tags": [
          "High Energy Physics - Theory (hep-th)",
          "Quantum Physics (quant-ph)"
        ],
        "doi": "10.1007/s40766-020-00004-5",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 68,
        "object_id": "paper:arxiv.1805.11965",
        "created_at": "2026-01-09T19:22:59+00:00",
        "updated_at": "2026-01-09T19:24:00+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2302.04842": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2302.04842",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-11T04:03:16.821Z",
            "data": {
              "session_id": "session_1768104196465_berixra",
              "source_id": "arxiv",
              "paper_id": "2302.04842",
              "start_time": "2026-01-11T04:03:07.521Z",
              "end_time": "2026-01-11T04:03:16.465Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 4,
              "total_elapsed_seconds": 9
            }
          }
        ]
      },
      "meta": {
        "issue_number": 71,
        "object_id": "interactions:arxiv.2302.04842",
        "created_at": "2026-01-11T04:03:17+00:00",
        "updated_at": "2026-01-11T04:04:16+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2302.04842": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2302.04842",
        "url": "https://arxiv.org/pdf/2302.04842",
        "title": "An Introduction to the Theory of Spin Glasses",
        "authors": [
          "Ada Altieri",
          "Marco Baity-Jesi"
        ],
        "abstract": "We review the main methods used to study spin glasses. In the first part, we focus on methods for fully connected models and systems defined on a tree, such as the replica method, the Thouless-Anderson-Palmer formalism, the cavity method, and the dynamical mean-field theory. In the second part, we deal with the description of low-dimensional systems, mostly in three spatial dimensions, which are mostly studied through numerical simulations. We conclude by mentioning some of the main open problems in the field.",
        "timestamp": "2026-01-11T04:03:07.717Z",
        "rating": "novote",
        "publishedDate": "2023-02-09",
        "tags": [
          "cond-mat.dis-nn",
          "cond-mat.stat-mech"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cond-mat.dis-nn",
          "cond-mat.stat-mech"
        ]
      },
      "meta": {
        "issue_number": 70,
        "object_id": "paper:arxiv.2302.04842",
        "created_at": "2026-01-11T04:03:08+00:00",
        "updated_at": "2026-01-11T04:06:05+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2401.02414": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2401.02414",
        "interactions": []
      },
      "meta": {
        "issue_number": 73,
        "object_id": "interactions:arxiv.2401.02414",
        "created_at": "2026-01-11T22:55:12+00:00",
        "updated_at": "2026-01-11T22:55:14+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2401.02414": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2401.02414",
        "url": "https://arxiv.org/html/2401.02414v1",
        "title": "Bring Metric Functions into Diffusion Models",
        "authors": [
          "Jie An",
          "Zhengyuan Yang",
          "Jianfeng Wang",
          "Linjie Li",
          "Zicheng Liu",
          "Lijuan Wang",
          "Jiebo Luo"
        ],
        "abstract": "We introduce a Cascaded Diffusion Model (Cas-DM) that improves a Denoising Diffusion Probabilistic Model (DDPM) by effectively incorporating additional metric functions in training. Metric functions such as the LPIPS loss have been proven highly effective in consistency models derived from the score matching. However, for the diffusion counterparts, the methodology and efficacy of adding extra metric functions remain unclear. One major challenge is the mismatch between the noise predicted by a DDPM at each step and the desired clean image that the metric function works well on. To address this problem, we propose Cas-DM, a network architecture that cascades two network modules to effectively apply metric functions to the diffusion model training. The first module, similar to a standard DDPM, learns to predict the added noise and is unaffected by the metric function. The second cascaded module learns to predict the clean image, thereby facilitating the metric function computation. Experiment results show that the proposed diffusion model backbone enables the effective use of the LPIPS loss, leading to state-of-the-art image quality (FID, sFID, IS) on various established benchmarks.",
        "timestamp": "2026-01-11T22:54:58.777Z",
        "rating": "novote",
        "publishedDate": "2024-01-04",
        "tags": [
          "cs.CV"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.CV"
        ]
      },
      "meta": {
        "issue_number": 72,
        "object_id": "paper:arxiv.2401.02414",
        "created_at": "2026-01-11T22:54:59+00:00",
        "updated_at": "2026-01-11T22:58:07+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1901.06032": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1901.06032",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-12T00:31:04.495Z",
            "data": {
              "session_id": "session_1768177864312_g3nkg3k",
              "source_id": "arxiv",
              "paper_id": "1901.06032",
              "start_time": "2026-01-12T00:30:49.158Z",
              "end_time": "2026-01-12T00:31:04.312Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 0,
              "total_elapsed_seconds": 15
            }
          }
        ]
      },
      "meta": {
        "issue_number": 75,
        "object_id": "interactions:arxiv.1901.06032",
        "created_at": "2026-01-12T00:29:31+00:00",
        "updated_at": "2026-01-12T00:32:14+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1901.06032": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1901.06032",
        "url": "https://arxiv.org/pdf/1901.06032",
        "title": "A Survey of the Recent Architectures of Deep Convolutional Neural Networks",
        "authors": [
          "Asifullah Khan",
          "Anabia Sohail",
          "Umme Zahoora",
          "Aqsa Saeed Qureshi"
        ],
        "abstract": "Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.",
        "timestamp": "2026-01-12T00:28:50.577Z",
        "rating": "novote",
        "publishedDate": "2019-01-17",
        "tags": [
          "cs.CV"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.CV"
        ]
      },
      "meta": {
        "issue_number": 74,
        "object_id": "paper:arxiv.1901.06032",
        "created_at": "2026-01-12T00:28:50+00:00",
        "updated_at": "2026-01-12T00:34:07+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1707.06642": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1707.06642",
        "url": "https://arxiv.org/abs/1707.06642",
        "title": "The iNaturalist Species Classification and Detection Dataset",
        "authors": "Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard, Hartwig Adam, Pietro Perona, Serge Belongie",
        "abstract": "Existing image classification datasets used in computer vision tend to have a uniform distribution of images across object categories. In contrast, the natural world is heavily imbalanced, as some species are more abundant and easier to photograph than others. To encourage further progress in challenging real world conditions we present the iNaturalist species classification and detection dataset, consisting of 859,000 images from over 5,000 different species of plants and animals. It features visually similar species, captured in a wide variety of situations, from all over the world. Images were collected with different camera types, have varying image quality, feature a large class imbalance, and have been verified by multiple citizen scientists. We discuss the collection of the dataset and present extensive baseline experiments using state-of-the-art computer vision classification and detection models. Results show that current non-ensemble based methods achieve only 67% top one classification accuracy, illustrating the difficulty of the dataset. Specifically, we observe poor results for classes with small numbers of training examples suggesting more attention is needed in low-shot learning.",
        "timestamp": "2026-01-12T06:43:52.819Z",
        "rating": "novote",
        "publishedDate": "2017/07/20",
        "tags": [
          "Computer Vision and Pattern Recognition (cs.CV)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 76,
        "object_id": "paper:arxiv.1707.06642",
        "created_at": "2026-01-12T06:43:53+00:00",
        "updated_at": "2026-01-12T06:44:54+00:00",
        "version": 1
      }
    },
    "interactions:url.386EC529": {
      "data": {
        "sourceId": "url",
        "paperId": "386EC529",
        "interactions": []
      },
      "meta": {
        "issue_number": 78,
        "object_id": "interactions:url.386EC529",
        "created_at": "2026-01-12T19:13:57+00:00",
        "updated_at": "2026-01-12T19:13:59+00:00",
        "version": 1
      }
    },
    "paper:url.386EC529": {
      "data": {
        "sourceId": "url",
        "paperId": "386EC529",
        "url": "https://download.ssrn.com/2026/1/6/5877662.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjECsaCXVzLWVhc3QtMSJHMEUCIQDE0vj6OwRc74i9wax37IbGc9QksgnOp96%2BtQ%2BjsW6EfAIgI%2B8Nc1KJmNajBSHKm%2BNjlf7UUe6HBn%2B6FQd5yz5I0kwqxwUI9P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAEGgwzMDg0NzUzMDEyNTciDE0%2FYhMrbLo3Yl922SqbBTid6dCz%2FM8Ja8%2FSMY5JGUfz%2BBFQ%2B9mbS3nzXWEmQDe0GMivnc0kTdOLROZEw4lPaOLdMTx9a6kQPds99fSDdRxFfhRZhCD7mU5jgdVwjeDAuoCokVWYtROys8qzPnmxLDQ1SymSD1ruxM4Gro7pVTteMaGKT02P9LogAAvRI3WrpFUisSjL%2FK7FrVIOx8csh9Jfwz1AagBK7fJDf1Hs8KGuVTtUGIQQUMy9ZHLK%2FIup9EpejMOPfJ1fIwWrxUpiuPVIZgzlQqMaewnq6KvOW3mJyFP13v2GNeykuGX0i1s%2FVkgF8hkCAdHHFGIsk7R%2BNd8Jhs6OsvGTpoKZnDMaM4W4TC3S4uSt%2BQ62uhgpPqaUATZqozAafoqL8LmtKQaXvFqv9vYy6PF7UL41Rsk8JrPplm%2B5MqutOuMYMORXj7FBhoLVl54y31CvMve6gBsFc8LvmKORp86rG2Pvy5G3x23%2Bv8NRv8pEPONLZnVJ1Y5ufppI63R5c9lIH3C9LGkYka7jYMwmIjqioqu4YFCBfytkRtLIj%2BTRaTgHxnrsOtnRHsuuskfj%2FExtyhtlte5FRxLv7wE3%2F1jfz5RAOzT7YRGXfVByUkosmZ2Fs1rbvEgpUt%2BbQ6AEoj5MRfFZnag%2FW5G6Kek7SP4zNhtASj0rwrzYKB8eg4q8IEkGFbCU1IT%2F0Kbf2QzhZVxYcQ4%2FEB0%2FdEDfXU%2BZBNdZncUBoLg2s1VWi%2BF5hFPl78Gf0kloCC%2BE7drmU6hIuBzOOJ4mdVaAoGUky5DT1ooMQYQr%2Ft6y9WU2OXkkRugYnP6Dgei3vUzZzTbcfJTedrQnGEuGo5QH%2BSWoMaKMysTuzGqlM2I5%2BLazQoCvyYp1xOjRojVyWO9%2Fq5Y%2BYMBX%2FIbe%2FbIw6ICVywY6sQEHFg9Fq4%2B63qMwVpZVUxTIfVG3PynW0b92IZpxxcSojUyXFNQ938jgLfBoJiYB9uqivSWFu7sD2iHH5nnf3CamifEbvz4dmLdJvpFoHk8kJjYvcFW6%2FtTzKT8zhnB9JyQduV3TDfcgpqlsUWBiOq8Ws4xt1DjvCPYfZCdlEibWY7%2F7OSPqFLbVshcNtMjfUKHjzWE%2BHxYmWHPF%2Bshu2ytcqn5WrxenyJ%2F0%2BVqMAJ1LhUs%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20260112T191343Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWE7U5CLPTR%2F20260112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=2a05418d3e86b625231df48f51309d7dd4b318a19446d377b77f0e4f35f34d01&abstractId=5877662",
        "title": "386EC529",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-01-12T19:13:49.107Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 77,
        "object_id": "paper:url.386EC529",
        "created_at": "2026-01-12T19:13:49+00:00",
        "updated_at": "2026-01-12T19:14:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2401.06284": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2401.06284",
        "url": "https://arxiv.org/abs/2401.06284",
        "title": "Extremal random matrices with independent entries and matrix superconcentration inequalities",
        "authors": "Tatiana Brailovskaya, Ramon van Handel",
        "abstract": "We prove nonasymptotic matrix concentration inequalities for the spectral norm of (sub)gaussian random matrices with centered independent entries that capture fluctuations at the Tracy-Widom scale. This considerably improves previous bounds in this setting due to Bandeira and Van Handel, and establishes the best possible tail behavior for random matrices with an arbitrary variance pattern. These bounds arise from an extremum problem for nonhomogeneous random matrices: among all variance patterns with a given sparsity parameter, the moments of the random matrix are maximized by block-diagonal matrices with i.i.d. entries in each block. As part of the proof, we obtain sharp bounds on large moments of Gaussian Wishart matrices.",
        "timestamp": "2026-01-12T20:06:15.227Z",
        "rating": "novote",
        "publishedDate": "2024/01/11",
        "tags": [
          "Probability (math.PR)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 79,
        "object_id": "paper:arxiv.2401.06284",
        "created_at": "2026-01-12T20:06:15+00:00",
        "updated_at": "2026-01-12T20:07:17+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2502.11362": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.11362",
        "interactions": []
      },
      "meta": {
        "issue_number": 81,
        "object_id": "interactions:arxiv.2502.11362",
        "created_at": "2026-01-13T01:26:29+00:00",
        "updated_at": "2026-01-13T01:26:31+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.11362": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.11362",
        "url": "https://arxiv.org/abs/2502.11362v1",
        "title": "Teleportation With Null Space Gradient Projection for Optimization Acceleration",
        "authors": "Zihao Wu, Juncheng Dong, Ahmed Aloui, Vahid Tarokh",
        "abstract": "Optimization techniques have become increasingly critical due to the ever-growing model complexity and data scale. In particular, teleportation has emerged as a promising approach, which accelerates convergence of gradient descent-based methods by navigating within the loss invariant level set to identify parameters with advantageous geometric properties. Existing teleportation algorithms have primarily demonstrated their effectiveness in optimizing Multi-Layer Perceptrons (MLPs), but their extension to more advanced architectures, such as Convolutional Neural Networks (CNNs) and Transformers, remains challenging. Moreover, they often impose significant computational demands, limiting their applicability to complex architectures. To this end, we introduce an algorithm that projects the gradient of the teleportation objective function onto the input null space, effectively preserving the teleportation within the loss invariant level set and reducing computational cost. Our approach is readily generalizable from MLPs to CNNs, transformers, and potentially other advanced architectures. We validate the effectiveness of our algorithm across various benchmark datasets and optimizers, demonstrating its broad applicability.",
        "timestamp": "2026-01-13T01:26:23.767Z",
        "rating": "novote",
        "publishedDate": "2025/02/17",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 80,
        "object_id": "paper:arxiv.2502.11362",
        "created_at": "2026-01-13T01:26:24+00:00",
        "updated_at": "2026-01-13T01:27:29+00:00",
        "version": 1
      }
    },
    "interactions:url.52BCADA2": {
      "data": {
        "sourceId": "url",
        "paperId": "52BCADA2",
        "interactions": []
      },
      "meta": {
        "issue_number": 83,
        "object_id": "interactions:url.52BCADA2",
        "created_at": "2026-01-13T07:45:12+00:00",
        "updated_at": "2026-01-13T07:45:13+00:00",
        "version": 1
      }
    },
    "paper:url.52BCADA2": {
      "data": {
        "sourceId": "url",
        "paperId": "52BCADA2",
        "url": "https://pdf.sciencedirectassets.com/271668/1-s2.0-S0148619500X00288/1-s2.0-S0148619599000211/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDgaCXVzLWVhc3QtMSJHMEUCIE5QpollGrJ196g7s9aJmkF7uj6UXi%2BEsWISKhlTpi2JAiEA7I8%2FZeRdsASEdhth2pDZxaQ5Ec0pAeN3DQkanORNZp0qswUIABAFGgwwNTkwMDM1NDY4NjUiDP%2BiNYRkMFKDR2x%2FYSqQBRSHOkdpf1tYlD8oWBWTXLIX9p9%2Fr4hm6tn%2B9cEpe7V%2Bjd9Repez2dKuDyQqfIYnyE1On0NXl4SL8DbshOhj6Qx2FKaPYwUFKFe5006bRa33wCIsk8HICXEGqk%2F%2FVFrB0e%2BXL3UAbKxIiLITAqut3RpPkwPpI3klQVFI4YO8zoI8RDm1wDvotW6R7tmM7ekw7SQnZK3KAA6KoZ1SWIXGL%2FgdvIwfIV3YnKSrd7R3kxyb5DOvGJw1ZaH8KhkOyrxtc26ZXWLc0aHel9nzjFBmERBDC%2FjOuERo316dU9N0rQCp5Mvw9U7g5o7LWUzPu3HDIC9%2B3Rcy%2Fcpc6koEbRhZHBylW%2BSsa5A1gBZ3OqYMSu4EO2wx4v%2F4Vx0wRiSovyhxoiwCnFmeht5wZHEM8jShLdarYtOu%2B5hNE7Yr%2Bc%2FGUys8oM73pxlY5G%2BXmUCyl75IZqy92Ph9oN8kC68HD3V%2B4OYge1QCufefaR40R5%2F4HmuZZzmHj%2BtlD%2BE%2FqbXy1XYUwKN9916UG%2FzB7n8dNKUsFq4wfTaJyGf%2B3pqYwcD24s%2F2dBMtcypFCH%2F3RPvm48mXTfFVydlKKpDfedDIn%2Bp6HNEa6vA8bcVIROLijC8eZywSZ1YvbktM0u34Gt6qZxueM7hZBubAyzjBpzvjkP8PjhVwKX6LXhyjZ2Q4brB%2BWob6icgm9HrHAPCUukzIRXCPPaBo55Qq8txeVrWwU73%2FYhK505Muvem%2FBbD00m%2FJd6CCqSR%2FWHmLV0Ym2JTWt4OETN1jzApkneDNJzz0rRNe4SwIs40O2LRkHcX9cj8ojVwoxmEHxVpC9kpdWO1Ls0re4PXbUinN9XN8%2F3PsE3JvbHuKw80POQgo5XKkJSAIE877MP%2Ffl8sGOrEBZoRu2Fxq945Zdq2NCBMIl0OpI%2BFLMvzqxpmTAm3ILkfjoF2Bt9utCBb8JnRr9DhXaaddeWAFZimu%2BpAQVg1m468xXc83CAToLYeOpf1CY6clwaNxymEMUzdBSVLNeM7eSwJH%2BeVugwzWXEqMbEQFt1PP2%2FPEsT2ua%2FRB5leLD5voUXzGO8%2FzjTQxvus7yc45i%2FpRQsqz9yAMrpAqhs4t12vRzYLAt5bM2PW8JoK%2FOKDd&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20260113T074456Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY636OCYZI%2F20260113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=228f8a805a0788575e74e5f679dbf1b9ea7b874463869f7f7c69d8d71505430b&hash=ba11c244191c84afaf2f368c00ba3db807e882ad3480f41e40df5c8834fbc83a&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0148619599000211&tid=spdf-adca77fd-0c80-4a17-bea6-584f13c66eff&sid=c2be3a8a8460d7445c3bdc264151ad3c8eccgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=13175700065650545400&rr=9bd3456f7b883b2c&cc=us",
        "title": "52BCADA2",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-01-13T07:45:02.094Z",
        "rating": "thumbsup",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 82,
        "object_id": "paper:url.52BCADA2",
        "created_at": "2026-01-13T07:45:02+00:00",
        "updated_at": "2026-01-13T07:46:35+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2412.18992": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2412.18992",
        "url": "https://arxiv.org/pdf/2412.18992?",
        "title": "Optimal Federated Learning for Functional Mean Estimation under Heterogeneous Privacy Constraints",
        "authors": [
          "Tony Cai",
          "Abhinav Chakraborty",
          "Lasse Vuursteen"
        ],
        "abstract": "Federated learning (FL) is a distributed machine learning technique designed to preserve data privacy and security, and it has gained significant importance due to its broad range of applications. This paper addresses the problem of optimal functional mean estimation from discretely sampled data in a federated setting.   We consider a heterogeneous framework where the number of individuals, measurements per individual, and privacy parameters vary across one or more servers, under both common and independent design settings. In the common design setting, the same design points are measured for each individual, whereas in the independent design, each individual has their own random collection of design points. Within this framework, we establish minimax upper and lower bounds for the estimation error of the underlying mean function, highlighting the nuanced differences between common and independent designs under distributed privacy constraints.   We propose algorithms that achieve the optimal trade-off between privacy and accuracy and provide optimality results that quantify the fundamental limits of private functional mean estimation across diverse distributed settings. These results characterize the cost of privacy and offer practical insights into the potential for privacy-preserving statistical analysis in federated environments.",
        "timestamp": "2026-01-13T16:03:18.491Z",
        "rating": "novote",
        "publishedDate": "2024-12-25",
        "tags": [
          "math.ST",
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.ST",
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 84,
        "object_id": "paper:arxiv.2412.18992",
        "created_at": "2026-01-13T16:03:18+00:00",
        "updated_at": "2026-01-13T16:06:43+00:00",
        "version": 1
      }
    },
    "paper:url.71F9552A": {
      "data": {
        "sourceId": "url",
        "paperId": "71F9552A",
        "url": "https://lassev.github.io/assets/pdf/sta732/ln/ch1.pdf",
        "title": "71F9552A",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-01-13T17:32:48.789Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "pdf"
      },
      "meta": {
        "issue_number": 85,
        "object_id": "paper:url.71F9552A",
        "created_at": "2026-01-13T17:32:49+00:00",
        "updated_at": "2026-01-13T17:33:46+00:00",
        "version": 1
      }
    },
    "interactions:url.71F9552A": {
      "data": {
        "sourceId": "url",
        "paperId": "71F9552A",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-13T17:42:15.187Z",
            "data": {
              "session_id": "session_1768326134723_fyhxk95",
              "source_id": "url",
              "paper_id": "71F9552A",
              "start_time": "2026-01-13T17:32:48.488Z",
              "end_time": "2026-01-13T17:42:14.723Z",
              "heartbeat_count": 113,
              "duration_seconds": 565,
              "idle_seconds": 1,
              "total_elapsed_seconds": 566
            }
          }
        ]
      },
      "meta": {
        "issue_number": 86,
        "object_id": "interactions:url.71F9552A",
        "created_at": "2026-01-13T17:42:15+00:00",
        "updated_at": "2026-01-13T17:43:18+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2509.25260": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.25260",
        "url": "https://arxiv.org/pdf/2509.25260",
        "title": "Language Model Planning from an Information Theoretic Perspective",
        "authors": [
          "Muhammed Ustaomeroglu",
          "Baris Askin",
          "Gauri Joshi",
          "Carlee Joe-Wong",
          "Guannan Qu"
        ],
        "abstract": "The extent to which decoder-only language models (LMs) engage in planning, that is, organizing intermediate computations to support coherent long-range generation, remains an open and important question, with implications for interpretability, reliability, and principled model design. Planning involves structuring computations over long horizons, considering multiple possible continuations, and selectively reusing past information, but how effectively transformer-based LMs realize these capabilities is still unclear. We address these questions by analyzing the hidden states at the core of transformer computations, which capture intermediate results and act as carriers of information. Since these hidden representations are often redundant and encumbered with fine-grained details, we develop a pipeline based on vector-quantized variational autoencoders that compresses them into compact summary codes. These codes enable measuring mutual information, allowing systematic analysis of the computational structure underlying model behavior. Using this framework, we study planning in LMs across synthetic grammar, path-finding tasks, and natural language datasets, focusing on three key aspects: (i) the planning horizon of pre-output computations, (ii) the extent to which the model considers alternative valid continuations, and (iii) the reliance of new predictions on earlier computations. By answering these questions, we advance the understanding of how planning is realized in LMs and contribute a general-purpose pipeline for probing the internal dynamics of LMs and deep learning systems. Our results reveal that the effective planning horizon is task-dependent, that models implicitly preserve information about unused correct continuations, and that predictions draw most on recent computations, though earlier blocks remain informative.",
        "timestamp": "2026-01-14T18:24:40.396Z",
        "rating": "novote",
        "publishedDate": "2025-09-28",
        "tags": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 87,
        "object_id": "paper:arxiv.2509.25260",
        "created_at": "2026-01-14T18:24:40+00:00",
        "updated_at": "2026-01-14T18:28:37+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.15988": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.15988",
        "url": "https://arxiv.org/abs/2502.15988",
        "title": "Near Optimal Decision Trees in a SPLIT Second",
        "authors": "Varun Babbar, Hayden McTavish, Cynthia Rudin, Margo Seltzer",
        "abstract": "Decision tree optimization is fundamental to interpretable machine learning. The most popular approach is to greedily search for the best feature at every decision point, which is fast but provably suboptimal. Recent approaches find the global optimum using branch and bound with dynamic programming, showing substantial improvements in accuracy and sparsity at great cost to scalability. An ideal solution would have the accuracy of an optimal method and the scalability of a greedy method. We introduce a family of algorithms called SPLIT (SParse Lookahead for Interpretable Trees) that moves us significantly forward in achieving this ideal balance. We demonstrate that not all sub-problems need to be solved to optimality to find high quality trees; greediness suffices near the leaves. Since each depth adds an exponential number of possible trees, this change makes our algorithms orders of magnitude faster than existing optimal methods, with negligible loss in performance. We extend this algorithm to allow scalable computation of sets of near-optimal trees (i.e., the Rashomon set).",
        "timestamp": "2026-01-14T18:41:58.056Z",
        "rating": "novote",
        "publishedDate": "2025/02/21",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 91,
        "object_id": "paper:arxiv.2502.15988",
        "created_at": "2026-01-14T18:41:58+00:00",
        "updated_at": "2026-01-14T18:42:45+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2508.18098": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2508.18098",
        "interactions": []
      },
      "meta": {
        "issue_number": 90,
        "object_id": "interactions:arxiv.2508.18098",
        "created_at": "2026-01-14T18:41:26+00:00",
        "updated_at": "2026-01-14T18:41:28+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2508.18098": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2508.18098",
        "url": "https://arxiv.org/pdf/2508.18098",
        "title": "Detecting and Characterizing Planning in Language Models",
        "authors": [
          "Jatin Nainani",
          "Sankaran Vaidyanathan",
          "Connor Watts",
          "Andre N. Assis",
          "Alice Rigg"
        ],
        "abstract": "Modern large language models (LLMs) have demonstrated impressive performance across a wide range of multi-step reasoning tasks. Recent work suggests that LLMs may perform planning - selecting a future target token in advance and generating intermediate tokens that lead towards it - rather than merely improvising one token at a time. However, existing studies assume fixed planning horizons and often focus on single prompts or narrow domains. To distinguish planning from improvisation across models and tasks, we present formal and causally grounded criteria for detecting planning and operationalize them as a semi-automated annotation pipeline. We apply this pipeline to both base and instruction-tuned Gemma-2-2B models on the MBPP code generation benchmark and a poem generation task where Claude 3.5 Haiku was previously shown to plan. Our findings show that planning is not universal: unlike Haiku, Gemma-2-2B solves the same poem generation task through improvisation, and on MBPP it switches between planning and improvisation across similar tasks and even successive token predictions. We further show that instruction tuning refines existing planning behaviors in the base model rather than creating them from scratch. Together, these studies provide a reproducible and scalable foundation for mechanistic studies of planning in LLMs.",
        "timestamp": "2026-01-14T18:41:07.797Z",
        "rating": "novote",
        "publishedDate": "2025-08-25",
        "tags": [
          "cs.CL",
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.CL",
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 89,
        "object_id": "paper:arxiv.2508.18098",
        "created_at": "2026-01-14T18:41:08+00:00",
        "updated_at": "2026-01-14T18:45:37+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2509.25260": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.25260",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-14T18:33:28.882Z",
            "data": {
              "session_id": "session_1768415608478_l7fy5sk",
              "source_id": "arxiv",
              "paper_id": "2509.25260",
              "start_time": "2026-01-14T18:24:40.178Z",
              "end_time": "2026-01-14T18:33:28.478Z",
              "heartbeat_count": 105,
              "duration_seconds": 525,
              "idle_seconds": 3,
              "total_elapsed_seconds": 528
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-14T18:35:33.989Z",
            "data": {
              "session_id": "session_1768415733978_syk5i2q",
              "source_id": "arxiv",
              "paper_id": "2509.25260",
              "start_time": "2026-01-14T18:35:26.159Z",
              "end_time": "2026-01-14T18:35:33.978Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 3,
              "total_elapsed_seconds": 8
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-14T18:41:57.938Z",
            "data": {
              "session_id": "session_1768416117714_ccxzhor",
              "source_id": "arxiv",
              "paper_id": "2509.25260",
              "start_time": "2026-01-14T18:41:25.622Z",
              "end_time": "2026-01-14T18:41:57.714Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 2,
              "total_elapsed_seconds": 32
            }
          }
        ]
      },
      "meta": {
        "issue_number": 88,
        "object_id": "interactions:arxiv.2509.25260",
        "created_at": "2026-01-14T18:33:29+00:00",
        "updated_at": "2026-01-14T18:42:24+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2507.03884": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2507.03884",
        "url": "https://arxiv.org/abs/2507.03884",
        "title": "Leo Breiman, the Rashomon Effect, and the Occam Dilemma",
        "authors": "Cynthia Rudin",
        "abstract": "In the famous Two Cultures paper, Leo Breiman provided a visionary perspective on the cultures of ''data models'' (modeling with consideration of data generation) versus ''algorithmic models'' (vanilla machine learning models). I provide a modern perspective on these approaches. One of Breiman's key arguments against data models is the ''Rashomon Effect,'' which is the existence of many different-but-equally-good models. The Rashomon Effect implies that data modelers would not be able to determine which model generated the data. Conversely, one of his core advantages in favor of data models is simplicity, as he claimed there exists an ''Occam Dilemma,'' i.e., an accuracy-simplicity tradeoff. After 25 years of powerful computers, it has become clear that this claim is not generally true, in that algorithmic models do not need to be complex to be accurate; however, there are nuances that help explain Breiman's logic, specifically, that by ''simple,'' he appears to consider only linear models or unoptimized decision trees. Interestingly, the Rashomon Effect is a key tool in proving the nullification of the Occam Dilemma. To his credit though, Breiman did not have the benefit of modern computers, with which my observations are much easier to make.\nBreiman's goal for interpretability was somewhat intertwined with causality: simpler models can help reveal which variables have a causal relationship with the outcome. However, I argue that causality can be investigated without the use of single models, whether or not they are simple. Interpretability is useful in its own right, and I think Breiman knew that too.\nTechnically, my modern perspective does not belong to either of Breiman's Two Cultures, but shares the goals of both of them - causality, simplicity, accuracy - and shows that these goals can be accomplished in other ways, without the limitations Breiman was concerned about.",
        "timestamp": "2026-01-14T18:49:47.460Z",
        "rating": "novote",
        "publishedDate": "2025/07/05",
        "tags": [
          "Machine Learning (stat.ML)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 93,
        "object_id": "paper:arxiv.2507.03884",
        "created_at": "2026-01-14T18:49:47+00:00",
        "updated_at": "2026-01-14T18:50:47+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2502.15988": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.15988",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-14T18:46:43.713Z",
            "data": {
              "session_id": "session_1768416403274_rolab69",
              "source_id": "arxiv",
              "paper_id": "2502.15988",
              "start_time": "2026-01-14T18:42:02.441Z",
              "end_time": "2026-01-14T18:46:43.274Z",
              "heartbeat_count": 56,
              "duration_seconds": 280,
              "idle_seconds": 1,
              "total_elapsed_seconds": 281
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-14T18:50:40.662Z",
            "data": {
              "session_id": "session_1768416640403_rungso2",
              "source_id": "arxiv",
              "paper_id": "2502.15988",
              "start_time": "2026-01-14T18:50:29.012Z",
              "end_time": "2026-01-14T18:50:40.403Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 1,
              "total_elapsed_seconds": 11
            }
          }
        ]
      },
      "meta": {
        "issue_number": 92,
        "object_id": "interactions:arxiv.2502.15988",
        "created_at": "2026-01-14T18:46:44+00:00",
        "updated_at": "2026-01-14T18:51:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2509.08629": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.08629",
        "url": "https://arxiv.org/pdf/2509.08629",
        "title": "A Cycle Walk for Sampling Measures on Spanning Forests for Redistricting",
        "authors": [
          "Daryl R. DeFord",
          "Gregory Herschlag",
          "Jonathan C. Mattingly"
        ],
        "abstract": "We introduce a new Markov Chain called the Cycle Walk for sampling measures of graph partitions where the partition elements have roughly equal size. Such Markov Chains are of current interest in the generation and evaluation of political districts. We present numerical evidence that this chain can efficiently sample target distributions that have been difficult for existing sampling Markov chains.",
        "timestamp": "2026-01-16T16:34:18.953Z",
        "rating": "novote",
        "publishedDate": "2025-09-10",
        "tags": [
          "cs.SI",
          "math.PR"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.SI",
          "math.PR"
        ]
      },
      "meta": {
        "issue_number": 94,
        "object_id": "paper:arxiv.2509.08629",
        "created_at": "2026-01-16T16:34:19+00:00",
        "updated_at": "2026-01-16T16:37:38+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2509.08629": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.08629",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-16T16:56:37.919Z",
            "data": {
              "session_id": "session_1768582597406_ptb7hlw",
              "source_id": "arxiv",
              "paper_id": "2509.08629",
              "start_time": "2026-01-16T16:52:14.009Z",
              "end_time": "2026-01-16T16:56:37.406Z",
              "heartbeat_count": 52,
              "duration_seconds": 260,
              "idle_seconds": 3,
              "total_elapsed_seconds": 263
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-16T17:05:11.015Z",
            "data": {
              "session_id": "session_1768583110491_o2480or",
              "source_id": "arxiv",
              "paper_id": "2509.08629",
              "start_time": "2026-01-16T16:56:39.115Z",
              "end_time": "2026-01-16T17:05:10.491Z",
              "heartbeat_count": 102,
              "duration_seconds": 510,
              "idle_seconds": 1,
              "total_elapsed_seconds": 511
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-16T17:41:17.189Z",
            "data": {
              "session_id": "session_1768585276791_pgu4msu",
              "source_id": "arxiv",
              "paper_id": "2509.08629",
              "start_time": "2026-01-16T17:35:31.884Z",
              "end_time": "2026-01-16T17:41:16.791Z",
              "heartbeat_count": 68,
              "duration_seconds": 340,
              "idle_seconds": 5,
              "total_elapsed_seconds": 345
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-16T17:53:29.962Z",
            "data": {
              "session_id": "session_1768586009704_16stjvp",
              "source_id": "arxiv",
              "paper_id": "2509.08629",
              "start_time": "2026-01-16T17:53:22.361Z",
              "end_time": "2026-01-16T17:53:29.704Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 2,
              "total_elapsed_seconds": 7
            }
          }
        ]
      },
      "meta": {
        "issue_number": 95,
        "object_id": "interactions:arxiv.2509.08629",
        "created_at": "2026-01-16T16:51:50+00:00",
        "updated_at": "2026-01-16T17:56:07+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2206.13512": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2206.13512",
        "url": "https://arxiv.org/abs/2206.13512",
        "title": "The Banach-Tarski Paradox",
        "authors": "Mats Wahlberg",
        "abstract": "This thesis presents the strong and weak forms of the Banach-Tarski paradox based on the Hausdorff paradox. It provides modernized proofs of the paradoxes and necessary properties of equidecomposable and paradoxical sets. The historical significance of the paradox for measure theory is covered, along with its incorrect attribution to Banach and Tarski. Finally, the necessity of the axiom of choice is discussed and contrasted with other axiomatic and topological assumptions that enable the paradoxes.",
        "timestamp": "2026-01-21T18:09:21.184Z",
        "rating": "novote",
        "publishedDate": "2022/06/26",
        "tags": [
          "History and Overview (math.HO)",
          "Combinatorics (math.CO)",
          "Functional Analysis (math.FA)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 98,
        "object_id": "paper:arxiv.2206.13512",
        "created_at": "2026-01-21T18:09:21+00:00",
        "updated_at": "2026-01-21T18:10:23+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2108.05714": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2108.05714",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-22T00:03:27.960Z",
            "data": {
              "session_id": "session_1769040207712_s03vdqk",
              "source_id": "arxiv",
              "paper_id": "2108.05714",
              "start_time": "2026-01-22T00:03:12.136Z",
              "end_time": "2026-01-22T00:03:27.712Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 1,
              "total_elapsed_seconds": 16
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-22T00:16:20.525Z",
            "data": {
              "session_id": "session_1769040979906_a788zw8",
              "source_id": "arxiv",
              "paper_id": "2108.05714",
              "start_time": "2026-01-22T00:03:28.042Z",
              "end_time": "2026-01-22T00:16:19.906Z",
              "heartbeat_count": 154,
              "duration_seconds": 770,
              "idle_seconds": 2,
              "total_elapsed_seconds": 772
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-22T02:16:45.752Z",
            "data": {
              "session_id": "session_1769048205095_5udowec",
              "source_id": "arxiv",
              "paper_id": "2108.05714",
              "start_time": "2026-01-22T00:16:46.767Z",
              "end_time": "2026-01-22T02:16:45.095Z",
              "heartbeat_count": 253,
              "duration_seconds": 1265,
              "idle_seconds": 5933,
              "total_elapsed_seconds": 7198
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-22T02:57:55.231Z",
            "data": {
              "session_id": "session_1769050674958_8wj94qh",
              "source_id": "arxiv",
              "paper_id": "2108.05714",
              "start_time": "2026-01-22T02:57:46.094Z",
              "end_time": "2026-01-22T02:57:54.958Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 4,
              "total_elapsed_seconds": 9
            }
          }
        ]
      },
      "meta": {
        "issue_number": 97,
        "object_id": "interactions:arxiv.2108.05714",
        "created_at": "2026-01-21T18:05:02+00:00",
        "updated_at": "2026-01-22T02:59:29+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2108.05714": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2108.05714",
        "url": "https://arxiv.org/pdf/2108.05714",
        "title": "The Banach-Tarski Paradox",
        "authors": [
          "Katie Buchhorn"
        ],
        "abstract": "In 1924, S. Banach and A. Tarski proved an astonishing, yet rather counterintuitive paradox: given a solid ball in $\\mathbb{R}^3$, it is possible to partition it into finitely many pieces and reassemble them to form two solid balls, each identical in size to the first. When this paradox is applied to 3-dimensional space it does go against our intuition, but very often our intuition is flawed.   The aim of the paper is to provide a comprehensive proof of the Banach-Tarski paradox, expanding in between the lines of the original volume. We explore the notions of paradoxical and equidecomposable sets which are phrased in terms of group actions. Finally, provided we have the Axiom of Choice at our disposal, we can construct sets that are nonmeasurable (not Lebesgue measurable) and the proof of the Banach-Tarski Paradox follows naturally.",
        "timestamp": "2026-01-21T18:04:52.121Z",
        "rating": "novote",
        "publishedDate": "2021-08-08",
        "tags": [
          "math.HO",
          "math.FA",
          "math.LO"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.HO",
          "math.FA",
          "math.LO"
        ]
      },
      "meta": {
        "issue_number": 96,
        "object_id": "paper:arxiv.2108.05714",
        "created_at": "2026-01-21T18:04:52+00:00",
        "updated_at": "2026-01-21T18:12:18+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2206.13512": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2206.13512",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-21T18:29:45.454Z",
            "data": {
              "session_id": "session_1769020185220_zkl4bs1",
              "source_id": "arxiv",
              "paper_id": "2206.13512",
              "start_time": "2026-01-21T18:29:40.100Z",
              "end_time": "2026-01-21T18:29:45.220Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-21T18:55:02.316Z",
            "data": {
              "session_id": "session_1769021702008_ul5y49a",
              "source_id": "arxiv",
              "paper_id": "2206.13512",
              "start_time": "2026-01-21T18:54:44.384Z",
              "end_time": "2026-01-21T18:55:02.008Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 3,
              "total_elapsed_seconds": 18
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-02-04T11:10:26.965Z",
            "data": {
              "session_id": "session_1770203426953_0ye2dg2",
              "source_id": "arxiv",
              "paper_id": "2206.13512",
              "start_time": "2026-02-04T11:10:02.289Z",
              "end_time": "2026-02-04T11:10:26.953Z",
              "heartbeat_count": 4,
              "duration_seconds": 20,
              "idle_seconds": 5,
              "total_elapsed_seconds": 25
            }
          }
        ]
      },
      "meta": {
        "issue_number": 99,
        "object_id": "interactions:arxiv.2206.13512",
        "created_at": "2026-01-21T18:13:55+00:00",
        "updated_at": "2026-02-04T11:11:14+00:00",
        "version": 1
      }
    },
    "interactions:openreview.ldbChKj0HP": {
      "data": {
        "sourceId": "openreview",
        "paperId": "ldbChKj0HP",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T20:40:44.972Z",
            "data": {
              "session_id": "session_1769460044968_cp1xr7v",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-26T20:40:39.653Z",
              "end_time": "2026-01-26T20:40:44.968Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T20:41:58.849Z",
            "data": {
              "session_id": "session_1769460118508_5c1w9xn",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-26T20:41:00.709Z",
              "end_time": "2026-01-26T20:41:58.508Z",
              "heartbeat_count": 11,
              "duration_seconds": 55,
              "idle_seconds": 3,
              "total_elapsed_seconds": 58
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T20:51:46.130Z",
            "data": {
              "session_id": "session_1769460706124_6j6r96i",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-26T20:51:40.131Z",
              "end_time": "2026-01-26T20:51:46.124Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 1,
              "total_elapsed_seconds": 6
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T21:25:40.587Z",
            "data": {
              "session_id": "session_1769462740312_gi64vsc",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-26T21:25:30.909Z",
              "end_time": "2026-01-26T21:25:40.312Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 4,
              "total_elapsed_seconds": 9
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T22:14:30.717Z",
            "data": {
              "session_id": "session_1769465670708_4uecmyd",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-26T22:14:23.307Z",
              "end_time": "2026-01-26T22:14:30.708Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 7
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T01:08:40.345Z",
            "data": {
              "session_id": "session_1769562520334_8deyfhw",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T01:08:24.332Z",
              "end_time": "2026-01-28T01:08:40.334Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 1,
              "total_elapsed_seconds": 16
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T01:19:34.347Z",
            "data": {
              "session_id": "session_1769563173782_eeb2naj",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T01:19:02.232Z",
              "end_time": "2026-01-28T01:19:33.782Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 2,
              "total_elapsed_seconds": 32
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T08:07:53.157Z",
            "data": {
              "session_id": "session_1769587673153_8paq8rc",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T08:07:37.807Z",
              "end_time": "2026-01-28T08:07:53.153Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 0,
              "total_elapsed_seconds": 15
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T08:11:32.023Z",
            "data": {
              "session_id": "session_1769587891456_aqu6ulc",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T08:08:13.661Z",
              "end_time": "2026-01-28T08:11:31.456Z",
              "heartbeat_count": 39,
              "duration_seconds": 195,
              "idle_seconds": 3,
              "total_elapsed_seconds": 198
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T08:14:04.812Z",
            "data": {
              "session_id": "session_1769588044568_1yju7ap",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T08:13:59.473Z",
              "end_time": "2026-01-28T08:14:04.568Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T08:17:05.325Z",
            "data": {
              "session_id": "session_1769588224762_79od5wd",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T08:14:54.417Z",
              "end_time": "2026-01-28T08:17:04.762Z",
              "heartbeat_count": 26,
              "duration_seconds": 130,
              "idle_seconds": 0,
              "total_elapsed_seconds": 130
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T23:53:31.492Z",
            "data": {
              "session_id": "session_1769644411224_trwbg7f",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-28T23:53:25.749Z",
              "end_time": "2026-01-28T23:53:31.224Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-29T20:23:33.657Z",
            "data": {
              "session_id": "session_1769718213319_jwpvz63",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-29T20:22:50.125Z",
              "end_time": "2026-01-29T20:23:33.319Z",
              "heartbeat_count": 8,
              "duration_seconds": 40,
              "idle_seconds": 3,
              "total_elapsed_seconds": 43
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-29T20:26:08.576Z",
            "data": {
              "session_id": "session_1769718367876_xhn8l7o",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-29T20:23:36.660Z",
              "end_time": "2026-01-29T20:26:07.876Z",
              "heartbeat_count": 30,
              "duration_seconds": 150,
              "idle_seconds": 1,
              "total_elapsed_seconds": 151
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-01-29T20:30:07.411Z",
            "data": {
              "session_id": "session_1769718606822_apxfnwj",
              "source_id": "openreview",
              "paper_id": "ldbChKj0HP",
              "start_time": "2026-01-29T20:26:15.025Z",
              "end_time": "2026-01-29T20:30:06.822Z",
              "heartbeat_count": 46,
              "duration_seconds": 230,
              "idle_seconds": 2,
              "total_elapsed_seconds": 232
            }
          }
        ]
      },
      "meta": {
        "issue_number": 108,
        "object_id": "interactions:openreview.ldbChKj0HP",
        "created_at": "2026-01-26T20:38:00+00:00",
        "updated_at": "2026-01-29T20:31:11+00:00",
        "version": 1
      }
    },
    "paper:openreview.ldbChKj0HP": {
      "data": {
        "sourceId": "openreview",
        "paperId": "ldbChKj0HP",
        "url": "https://openreview.net/forum?id=ldbChKj0HP&noteId=VBdUax4YjW&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Dthecvf.com%2FCVPR%2F2026%2FConference%2FAuthors%23your-submissions)",
        "title": "What You See is (Usually) What You Get: Multimodal Prototype Networks that Abstain from Expensive Modalities",
        "authors": "Muchang Bahng, Charles Berens, Jon Donnelly, Eric Chen, Chaofan Chen, Cynthia Rudin",
        "abstract": "Species detection is important for monitoring the health of ecosystems and identifying invasive species, serving a crucial role in guiding conservation efforts. Multimodal neural networks have seen increasing use for identifying species to help automate this task, but they have two major drawbacks. First, their black-box nature prevents the interpretability of their decision making process. Second, collecting genetic data is often expensive and requires invasive procedures, often necessitating researchers to capture or kill the target specimen. We address both of these problems by extending prototype networks (ProtoPNets), which are a popular and interpretable alternative to traditional neural networks, to the multimodal, cost-aware setting. We ensemble prototypes from each modality, using an associated weight to determine how much a given prediction relies on each modality. We further introduce methods to identify cases for which we do not need the expensive genetic information to make confident predictions. We demonstrate that our approach can intelligently allocate expensive genetic data for fine-grained distinctions while using abundant image data for clearer visual classifications and achieving comparable accuracy to models that consistently use both modalities.",
        "timestamp": "2026-01-22T18:42:48.240Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "Interpretable",
          "ProtoPNet",
          "Multimodal",
          "Genetics"
        ],
        "doi": "",
        "journalName": "CVPR 2026 Conference Submission",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 100,
        "object_id": "paper:openreview.ldbChKj0HP",
        "created_at": "2026-01-22T18:42:48+00:00",
        "updated_at": "2026-01-22T18:43:50+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2510.09534": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.09534",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-26T16:58:51.261Z",
            "data": {
              "session_id": "session_1769446731021_etalpkm",
              "source_id": "arxiv",
              "paper_id": "2510.09534",
              "start_time": "2026-01-26T16:58:43.917Z",
              "end_time": "2026-01-26T16:58:51.021Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 2,
              "total_elapsed_seconds": 7
            }
          }
        ]
      },
      "meta": {
        "issue_number": 105,
        "object_id": "interactions:arxiv.2510.09534",
        "created_at": "2026-01-26T16:52:00+00:00",
        "updated_at": "2026-01-26T16:59:57+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.09534": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.09534",
        "url": "https://arxiv.org/pdf/2510.09534",
        "title": "",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-01-26T16:50:32.791Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 104,
        "object_id": "paper:arxiv.2510.09534",
        "created_at": "2026-01-26T16:50:33+00:00",
        "updated_at": "2026-01-26T16:51:57+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2507.04168": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2507.04168",
        "interactions": []
      },
      "meta": {
        "issue_number": 103,
        "object_id": "interactions:arxiv.2507.04168",
        "created_at": "2026-01-26T16:47:37+00:00",
        "updated_at": "2026-01-26T16:47:38+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2507.04168": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2507.04168",
        "url": "https://arxiv.org/abs/2507.04168",
        "title": "Generative Regression with IQ-BART",
        "authors": "Sean O'Hagan, Veronika Ro\u010dkov\u00e1",
        "abstract": "Implicit Quantile BART (IQ-BART) posits a non-parametric Bayesian model on the conditional quantile function, acting as a model over a conditional model for $Y$ given $X$. One of the key ingredients is augmenting the observed data $\\{(Y_i,X_i)\\}_{i=1}^n$ with uniformly sampled values $\\tau_i$ for $1\\leq i\\leq n$ which serve as training data for quantile function estimation. Using the fact that the location parameter $\\mu$ in a $\\tau$-tilted asymmetric Laplace distribution corresponds to the $\\tau^{th}$ quantile, we build a check-loss likelihood targeting $\\mu$ as the parameter of interest. We equip the check-loss likelihood parametrized by $\\mu=f(X,\\tau)$ with a BART prior on $f(\\cdot)$, allowing the conditional quantile function to vary both in $X$ and $\\tau$. The posterior distribution over $\\mu(\\tau,X)$ can be then distilled for estimation of the {\\em entire quantile function} as well as for assessing uncertainty through the variation of posterior draws. Simulation-based predictive inference is immediately available through inverse transform sampling using the learned quantile function. The sum-of-trees structure over the conditional quantile function enables flexible distribution-free regression with theoretical guarantees. As a byproduct, we investigate posterior mean quantile estimator as an alternative to the routine sample (posterior mode) quantile estimator. We demonstrate the power of IQ-BART on time series forecasting datasets where IQ-BART can capture multimodality in predictive distributions that might be otherwise missed using traditional parametric approaches.",
        "timestamp": "2026-01-26T16:47:16.204Z",
        "rating": "novote",
        "publishedDate": "2025/07/05",
        "tags": [
          "Methodology (stat.ME)",
          "Machine Learning (stat.ML)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 102,
        "object_id": "paper:arxiv.2507.04168",
        "created_at": "2026-01-26T16:47:16+00:00",
        "updated_at": "2026-01-26T16:48:16+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2504.11609": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2504.11609",
        "interactions": []
      },
      "meta": {
        "issue_number": 107,
        "object_id": "interactions:arxiv.2504.11609",
        "created_at": "2026-01-26T17:05:17+00:00",
        "updated_at": "2026-01-26T17:05:19+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.11609": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2504.11609",
        "url": "https://arxiv.org/abs/2504.11609",
        "title": "Towards Interpretable Deep Generative Models via Causal Representation Learning",
        "authors": "Gemma E. Moran, Bryon Aragam",
        "abstract": "Recent developments in generative artificial intelligence (AI) rely on machine learning techniques such as deep learning and generative modeling to achieve state-of-the-art performance across wide-ranging domains. These methods' surprising performance is due in part to their ability to learn implicit \"representations'' of complex, multi-modal data. Unfortunately, deep neural networks are notoriously black boxes that obscure these representations, making them difficult to interpret or analyze. To resolve these difficulties, one approach is to build new interpretable neural network models from the ground up. This is the goal of the emerging field of causal representation learning (CRL) that uses causality as a vector for building flexible, interpretable, and transferable generative AI. CRL can be seen as a culmination of three intrinsically statistical problems: (i) latent variable models such as factor analysis; (ii) causal graphical models with latent variables; and (iii) nonparametric statistics and deep learning. This paper reviews recent progress in CRL from a statistical perspective, focusing on connections to classical models and statistical and causal identifiablity results. This review also highlights key application areas, implementation strategies, and open statistical questions in CRL.",
        "timestamp": "2026-01-26T17:04:20.160Z",
        "rating": "novote",
        "publishedDate": "2025/04/15",
        "tags": [
          "Machine Learning (stat.ML)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)",
          "Methodology (stat.ME)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 106,
        "object_id": "paper:arxiv.2504.11609",
        "created_at": "2026-01-26T17:04:20+00:00",
        "updated_at": "2026-01-26T17:05:18+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2307.10455": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2307.10455",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-28T23:27:03.110Z",
            "data": {
              "session_id": "session_1769642822658_z8e3ht0",
              "source_id": "arxiv",
              "paper_id": "2307.10455",
              "start_time": "2026-01-28T23:22:55.722Z",
              "end_time": "2026-01-28T23:27:02.658Z",
              "heartbeat_count": 49,
              "duration_seconds": 245,
              "idle_seconds": 2,
              "total_elapsed_seconds": 247
            }
          }
        ]
      },
      "meta": {
        "issue_number": 111,
        "object_id": "interactions:arxiv.2307.10455",
        "created_at": "2026-01-28T23:27:03+00:00",
        "updated_at": "2026-01-28T23:28:05+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2307.10455": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2307.10455",
        "url": "https://arxiv.org/abs/2307.10455",
        "title": "A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset",
        "authors": "Zahra Gharaee, ZeMing Gong, Nicholas Pellegrino, Iuliia Zarubiieva, Joakim Bruslund Haurum, Scott C. Lowe, Jaclyn T.A. McKeown, Chris C.Y. Ho, Joschka McLeod, Yi-Yun C Wei, Jireh Agda, Sujeevan Ratnasingham, Dirk Steinke, Angel X. Chang, Graham W. Taylor, Paul Fieguth",
        "abstract": "In an effort to catalog insect biodiversity, we propose a new large dataset of hand-labelled insect images, the BIOSCAN-Insect Dataset. Each record is taxonomically classified by an expert, and also has associated genetic information including raw nucleotide barcode sequences and assigned barcode index numbers, which are genetically-based proxies for species classification. This paper presents a curated million-image dataset, primarily to train computer-vision models capable of providing image-based taxonomic assessment, however, the dataset also presents compelling characteristics, the study of which would be of interest to the broader machine learning community. Driven by the biological nature inherent to the dataset, a characteristic long-tailed class-imbalance distribution is exhibited. Furthermore, taxonomic labelling is a hierarchical classification scheme, presenting a highly fine-grained classification problem at lower levels. Beyond spurring interest in biodiversity research within the machine learning community, progress on creating an image-based taxonomic classifier will also further the ultimate goal of all BIOSCAN research: to lay the foundation for a comprehensive survey of global biodiversity. This paper introduces the dataset and explores the classification task through the implementation and analysis of a baseline classifier.",
        "timestamp": "2026-01-28T23:22:52.933Z",
        "rating": "novote",
        "publishedDate": "2023/07/19",
        "tags": [
          "Computer Vision and Pattern Recognition (cs.CV)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 110,
        "object_id": "paper:arxiv.2307.10455",
        "created_at": "2026-01-28T23:22:53+00:00",
        "updated_at": "2026-01-28T23:23:52+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1511.04561": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1511.04561",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-31T18:20:36.946Z",
            "data": {
              "session_id": "session_1769883636910_1dsadl2",
              "source_id": "arxiv",
              "paper_id": "1511.04561",
              "start_time": "2026-01-31T18:20:27.677Z",
              "end_time": "2026-01-31T18:20:36.910Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 4,
              "total_elapsed_seconds": 9
            }
          }
        ]
      },
      "meta": {
        "issue_number": 113,
        "object_id": "interactions:arxiv.1511.04561",
        "created_at": "2026-01-31T18:20:37+00:00",
        "updated_at": "2026-01-31T18:21:24+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1511.04561": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1511.04561",
        "url": "https://arxiv.org/abs/1511.04561",
        "title": "8-Bit Approximations for Parallelism in Deep Learning",
        "authors": "Tim Dettmers",
        "abstract": "The creation of practical deep learning data-products often requires parallelization across processors and computers to make deep learning feasible on large data sets, but bottlenecks in communication bandwidth make it difficult to attain good speedups through parallelism. Here we develop and test 8-bit approximation algorithms which make better use of the available bandwidth by compressing 32-bit gradients and nonlinear activations to 8-bit approximations. We show that these approximations do not decrease predictive performance on MNIST, CIFAR10, and ImageNet for both model and data parallelism and provide a data transfer speedup of 2x relative to 32-bit parallelism. We build a predictive model for speedups based on our experimental data, verify its validity on known speedup data, and show that we can obtain a speedup of 50x and more on a system of 96 GPUs compared to a speedup of 23x for 32-bit. We compare our data types with other methods and show that 8-bit approximations achieve state-of-the-art speedups for model parallelism. Thus 8-bit approximation is an efficient method to parallelize convolutional networks on very large systems of GPUs.",
        "timestamp": "2026-01-31T18:20:24.539Z",
        "rating": "novote",
        "publishedDate": "2015/11/14",
        "tags": [
          "Neural and Evolutionary Computing (cs.NE)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 112,
        "object_id": "paper:arxiv.1511.04561",
        "created_at": "2026-01-31T18:20:24+00:00",
        "updated_at": "2026-01-31T18:21:23+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1907.04840": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1907.04840",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-01-31T18:28:55.921Z",
            "data": {
              "session_id": "session_1769884135884_zvx4yi0",
              "source_id": "arxiv",
              "paper_id": "1907.04840",
              "start_time": "2026-01-31T18:28:27.228Z",
              "end_time": "2026-01-31T18:28:55.884Z",
              "heartbeat_count": 5,
              "duration_seconds": 25,
              "idle_seconds": 4,
              "total_elapsed_seconds": 29
            }
          }
        ]
      },
      "meta": {
        "issue_number": 115,
        "object_id": "interactions:arxiv.1907.04840",
        "created_at": "2026-01-31T18:28:56+00:00",
        "updated_at": "2026-01-31T18:29:57+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1907.04840": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1907.04840",
        "url": "https://arxiv.org/abs/1907.04840",
        "title": "Sparse Networks from Scratch: Faster Training without Losing Performance",
        "authors": "Tim Dettmers, Luke Zettlemoyer",
        "abstract": "We demonstrate the possibility of what we call sparse learning: accelerated training of deep neural networks that maintain sparse weights throughout training while achieving dense performance levels. We accomplish this by developing sparse momentum, an algorithm which uses exponentially smoothed gradients (momentum) to identify layers and weights which reduce the error efficiently. Sparse momentum redistributes pruned weights across layers according to the mean momentum magnitude of each layer. Within a layer, sparse momentum grows weights according to the momentum magnitude of zero-valued weights. We demonstrate state-of-the-art sparse performance on MNIST, CIFAR-10, and ImageNet, decreasing the mean error by a relative 8%, 15%, and 6% compared to other sparse algorithms. Furthermore, we show that sparse momentum reliably reproduces dense performance levels while providing up to 5.61x faster training. In our analysis, ablations show that the benefits of momentum redistribution and growth increase with the depth and size of the network. Additionally, we find that sparse momentum is insensitive to the choice of its hyperparameters suggesting that sparse momentum is robust and easy to use.",
        "timestamp": "2026-01-31T18:28:17.515Z",
        "rating": "novote",
        "publishedDate": "2019/07/10",
        "tags": [
          "Machine Learning (cs.LG)",
          "Neural and Evolutionary Computing (cs.NE)",
          "Machine Learning (stat.ML)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 114,
        "object_id": "paper:arxiv.1907.04840",
        "created_at": "2026-01-31T18:28:17+00:00",
        "updated_at": "2026-01-31T18:29:12+00:00",
        "version": 1
      }
    },
    "interactions:openreview.qR59RrG7Om": {
      "data": {
        "sourceId": "openreview",
        "paperId": "qR59RrG7Om",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T23:05:46.557Z",
            "data": {
              "session_id": "session_1770073545714_ygmkevf",
              "source_id": "openreview",
              "paper_id": "qR59RrG7Om",
              "start_time": "2026-02-02T23:02:48.369Z",
              "end_time": "2026-02-02T23:05:45.713Z",
              "heartbeat_count": 35,
              "duration_seconds": 175,
              "idle_seconds": 2,
              "total_elapsed_seconds": 177
            }
          }
        ]
      },
      "meta": {
        "issue_number": 144,
        "object_id": "interactions:openreview.qR59RrG7Om",
        "created_at": "2026-02-02T23:05:47+00:00",
        "updated_at": "2026-02-02T23:07:02+00:00",
        "version": 1
      }
    },
    "paper:openreview.qR59RrG7Om": {
      "data": {
        "sourceId": "openreview",
        "paperId": "qR59RrG7Om",
        "url": "https://openreview.net/pdf?id=qR59RrG7Om",
        "title": "qR59RrG7Om",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-02T23:02:44.126Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "pdf"
      },
      "meta": {
        "issue_number": 143,
        "object_id": "paper:openreview.qR59RrG7Om",
        "created_at": "2026-02-02T23:02:44+00:00",
        "updated_at": "2026-02-02T23:03:44+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2509.21906": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.21906",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T23:02:28.409Z",
            "data": {
              "session_id": "session_1770073347629_0wjrvy8",
              "source_id": "arxiv",
              "paper_id": "2509.21906",
              "start_time": "2026-02-02T23:00:49.147Z",
              "end_time": "2026-02-02T23:02:27.629Z",
              "heartbeat_count": 19,
              "duration_seconds": 95,
              "idle_seconds": 3,
              "total_elapsed_seconds": 98
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T23:13:18.935Z",
            "data": {
              "session_id": "session_1770073998053_097f4ua",
              "source_id": "arxiv",
              "paper_id": "2509.21906",
              "start_time": "2026-02-02T23:07:23.635Z",
              "end_time": "2026-02-02T23:13:18.053Z",
              "heartbeat_count": 70,
              "duration_seconds": 350,
              "idle_seconds": 4,
              "total_elapsed_seconds": 354
            }
          }
        ]
      },
      "meta": {
        "issue_number": 142,
        "object_id": "interactions:arxiv.2509.21906",
        "created_at": "2026-02-02T23:02:29+00:00",
        "updated_at": "2026-02-02T23:14:27+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2509.21906": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.21906",
        "url": "https://arxiv.org/pdf/2509.21906",
        "title": "",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-02T23:00:49.471Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 141,
        "object_id": "paper:arxiv.2509.21906",
        "created_at": "2026-02-02T23:00:49+00:00",
        "updated_at": "2026-02-02T23:01:42+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2403.12187": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2403.12187",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T23:00:29.406Z",
            "data": {
              "session_id": "session_1770073229393_b9jtd7y",
              "source_id": "arxiv",
              "paper_id": "2403.12187",
              "start_time": "2026-02-02T23:00:16.127Z",
              "end_time": "2026-02-02T23:00:29.393Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 3,
              "total_elapsed_seconds": 13
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T23:06:59.726Z",
            "data": {
              "session_id": "session_1770073618888_9e118vr",
              "source_id": "arxiv",
              "paper_id": "2403.12187",
              "start_time": "2026-02-02T23:05:46.403Z",
              "end_time": "2026-02-02T23:06:58.888Z",
              "heartbeat_count": 14,
              "duration_seconds": 70,
              "idle_seconds": 2,
              "total_elapsed_seconds": 72
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T23:14:02.719Z",
            "data": {
              "session_id": "session_1770074042713_5zf4hbj",
              "source_id": "arxiv",
              "paper_id": "2403.12187",
              "start_time": "2026-02-02T23:13:18.072Z",
              "end_time": "2026-02-02T23:14:02.713Z",
              "heartbeat_count": 8,
              "duration_seconds": 40,
              "idle_seconds": 5,
              "total_elapsed_seconds": 45
            }
          }
        ]
      },
      "meta": {
        "issue_number": 140,
        "object_id": "interactions:arxiv.2403.12187",
        "created_at": "2026-02-02T23:00:14+00:00",
        "updated_at": "2026-02-02T23:15:10+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2402.04997": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2402.04997",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T22:57:29.373Z",
            "data": {
              "session_id": "session_1770073049367_xy93pfd",
              "source_id": "arxiv",
              "paper_id": "2402.04997",
              "start_time": "2026-02-02T22:57:19.785Z",
              "end_time": "2026-02-02T22:57:29.367Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 5,
              "total_elapsed_seconds": 10
            }
          }
        ]
      },
      "meta": {
        "issue_number": 139,
        "object_id": "interactions:arxiv.2402.04997",
        "created_at": "2026-02-02T22:55:13+00:00",
        "updated_at": "2026-02-02T22:59:39+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2402.04997": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2402.04997",
        "url": "https://arxiv.org/abs/2402.04997",
        "title": "Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design",
        "authors": "Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, Tommi Jaakkola",
        "abstract": "Combining discrete and continuous data is an important capability for generative models. We present Discrete Flow Models (DFMs), a new flow-based model of discrete data that provides the missing link in enabling flow-based generative models to be applied to multimodal continuous and discrete data problems. Our key insight is that the discrete equivalent of continuous space flow matching can be realized using Continuous Time Markov Chains. DFMs benefit from a simple derivation that includes discrete diffusion models as a specific instance while allowing improved performance over existing diffusion-based approaches. We utilize our DFMs method to build a multimodal flow-based modeling framework. We apply this capability to the task of protein co-design, wherein we learn a model for jointly generating protein structure and sequence. Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or structure.",
        "timestamp": "2026-02-02T22:55:01.323Z",
        "rating": "novote",
        "publishedDate": "2024/02/07",
        "tags": [
          "Machine Learning (stat.ML)",
          "Machine Learning (cs.LG)",
          "Quantitative Methods (q-bio.QM)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 138,
        "object_id": "paper:arxiv.2402.04997",
        "created_at": "2026-02-02T22:55:01+00:00",
        "updated_at": "2026-02-02T22:59:21+00:00",
        "version": 1
      }
    },
    "interactions:openreview.EFYb8SsRi7": {
      "data": {
        "sourceId": "openreview",
        "paperId": "EFYb8SsRi7",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-02T22:50:36.305Z",
            "data": {
              "session_id": "session_1770072635578_qixvjni",
              "source_id": "openreview",
              "paper_id": "EFYb8SsRi7",
              "start_time": "2026-02-02T22:48:49.425Z",
              "end_time": "2026-02-02T22:50:35.578Z",
              "heartbeat_count": 21,
              "duration_seconds": 105,
              "idle_seconds": 1,
              "total_elapsed_seconds": 106
            }
          }
        ]
      },
      "meta": {
        "issue_number": 137,
        "object_id": "interactions:openreview.EFYb8SsRi7",
        "created_at": "2026-02-02T22:50:36+00:00",
        "updated_at": "2026-02-02T22:55:58+00:00",
        "version": 1
      }
    },
    "paper:openreview.EFYb8SsRi7": {
      "data": {
        "sourceId": "openreview",
        "paperId": "EFYb8SsRi7",
        "url": "https://openreview.net/forum?id=EFYb8SsRi7",
        "title": "Error Analysis of Discrete Flow with Generator Matching",
        "authors": "",
        "abstract": "Discrete flow models offer a powerful framework for learning distributions over discrete state spaces and have demonstrated superior performance compared to the discrete diffusion model. However, their convergence properties and error analysis remain largely unexplored. In this work, we develop a unified framework grounded in stochastic calculus theory to systematically investigate the theoretical properties of discrete flow. Specifically, we derive the KL divergence of two path measures regarding two continuous-time Markov chains (CTMCs) with different transition rates by deriving a Girsanov-type theorem, and provide a comprehensive analysis that encompasses the error arising from transition rate estimation and early stopping, where the first type of error has rarely been analyzed by existing works. Unlike discrete diffusion models, discrete flow incurs no truncation error caused by truncating the time horizon in the noising process. Building on generator matching and uniformization, we establish non-asymptotic error bounds for distribution estimation. Our results provide the first error analysis for discrete flow models.",
        "timestamp": "2026-02-02T22:48:49.730Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "Discrete Flow",
          "Error Analysis",
          "Distribution Estimation",
          "Error Bound"
        ],
        "doi": "",
        "journalName": "Submitted to ICLR 2026",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 136,
        "object_id": "paper:openreview.EFYb8SsRi7",
        "created_at": "2026-02-02T22:48:50+00:00",
        "updated_at": "2026-02-02T23:09:20+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2403.12187": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2403.12187",
        "url": "https://arxiv.org/pdf/2403.12187",
        "title": "",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-02T22:48:02.935Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 134,
        "object_id": "paper:arxiv.2403.12187",
        "created_at": "2026-02-02T22:48:03+00:00",
        "updated_at": "2026-02-02T22:50:58+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2212.01473": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2212.01473",
        "url": "https://arxiv.org/pdf/2212.01473",
        "title": "",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-04T02:44:33.977Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 145,
        "object_id": "paper:arxiv.2212.01473",
        "created_at": "2026-02-04T02:44:34+00:00",
        "updated_at": "2026-02-04T02:45:40+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2210.12497": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2210.12497",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-06T11:31:24.926Z",
            "data": {
              "session_id": "session_1770377484372_oc1v47q",
              "source_id": "arxiv",
              "paper_id": "2210.12497",
              "start_time": "2026-02-06T11:31:16.182Z",
              "end_time": "2026-02-06T11:31:24.372Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 3,
              "total_elapsed_seconds": 8
            }
          }
        ]
      },
      "meta": {
        "issue_number": 147,
        "object_id": "interactions:arxiv.2210.12497",
        "created_at": "2026-02-06T11:31:25+00:00",
        "updated_at": "2026-02-06T11:32:28+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2210.12497": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2210.12497",
        "url": "https://arxiv.org/abs/2210.12497",
        "title": "Deep Linear Networks for Matrix Completion -- An Infinite Depth Limit",
        "authors": "Nadav Cohen, Govind Menon, Zsolt Veraszto",
        "abstract": "The deep linear network (DLN) is a model for implicit regularization in gradient based optimization of overparametrized learning architectures. Training the DLN corresponds to a Riemannian gradient flow, where the Riemannian metric is defined by the architecture of the network and the loss function is defined by the learning task. We extend this geometric framework, obtaining explicit expressions for the volume form, including the case when the network has infinite depth. We investigate the link between the Riemannian geometry and the training asymptotics for matrix completion with rigorous analysis and numerics. We propose that implicit regularization is a result of bias towards high state space volume.",
        "timestamp": "2026-02-06T11:31:12.645Z",
        "rating": "novote",
        "publishedDate": "2022/10/22",
        "tags": [
          "Dynamical Systems (math.DS)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 146,
        "object_id": "paper:arxiv.2210.12497",
        "created_at": "2026-02-06T11:31:13+00:00",
        "updated_at": "2026-02-06T11:32:21+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.1506.03493": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1506.03493",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2026-02-09T15:20:39.061Z",
            "data": {
              "session_id": "session_1770650439053_xhzy1cj",
              "source_id": "arxiv",
              "paper_id": "1506.03493",
              "start_time": "2026-02-09T15:20:31.305Z",
              "end_time": "2026-02-09T15:20:39.053Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 3,
              "total_elapsed_seconds": 8
            }
          }
        ]
      },
      "meta": {
        "issue_number": 149,
        "object_id": "interactions:arxiv.1506.03493",
        "created_at": "2026-02-09T15:20:30+00:00",
        "updated_at": "2026-02-09T15:21:27+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1506.03493": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1506.03493",
        "url": "https://arxiv.org/abs/1506.03493",
        "title": "Bayesian Poisson Tensor Factorization for Inferring Multilateral Relations from Sparse Dyadic Event Counts",
        "authors": "Aaron Schein, John Paisley, David M. Blei, Hanna Wallach",
        "abstract": "We present a Bayesian tensor factorization model for inferring latent group structures from dynamic pairwise interaction patterns. For decades, political scientists have collected and analyzed records of the form \"country $i$ took action $a$ toward country $j$ at time $t$\"---known as dyadic events---in order to form and test theories of international relations. We represent these event data as a tensor of counts and develop Bayesian Poisson tensor factorization to infer a low-dimensional, interpretable representation of their salient patterns. We demonstrate that our model's predictive performance is better than that of standard non-negative tensor factorization methods. We also provide a comparison of our variational updates to their maximum likelihood counterparts. In doing so, we identify a better way to form point estimates of the latent factors than that typically used in Bayesian Poisson matrix factorization. Finally, we showcase our model as an exploratory analysis tool for political scientists. We show that the inferred latent factor matrices capture interpretable multilateral relations that both conform to and inform our knowledge of international affairs.",
        "timestamp": "2026-02-09T15:19:40.531Z",
        "rating": "novote",
        "publishedDate": "2015/06/10",
        "tags": [
          "Machine Learning (stat.ML)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)",
          "Social and Information Networks (cs.SI)",
          "Applications (stat.AP)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 148,
        "object_id": "paper:arxiv.1506.03493",
        "created_at": "2026-02-09T15:19:41+00:00",
        "updated_at": "2026-02-09T15:20:44+00:00",
        "version": 1
      }
    }
  }
}
{
  "snapshot_time": "2025-12-21T20:22:25.471025+00:00",
  "objects": {
    "paper:arxiv.2511.09744": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.09744",
        "url": "https://arxiv.org/pdf/2511.09744",
        "title": "Computing parametric weighted Ehrhart polynomials of smooth polytopes",
        "authors": [
          "Daniel Hwang",
          "Juliet Whidden",
          "Josephine Yu"
        ],
        "abstract": "We show that when integral polytopes are deformed while keeping the same facet normal vectors, the coefficients of weighted Ehrhart and $h^*$-polynomials are piecewise polynomial functions in the ``right hand sides'' of the linear inequalities defining the polytopes. We give an algorithm and an implementation in SageMath for computing these polynomials for smooth polytopes, such as type $A$ alcoved polytopes, using a weighted Euler-Maclaurin type formula by Khovanski\u01d0 and Pukhlikov. We discuss some natural questions concerning signs of the coefficients of the weighted $h^*$-polynomials.",
        "timestamp": "2025-12-21T06:10:03.453Z",
        "rating": "novote",
        "publishedDate": "2025-11-12",
        "tags": [
          "math.CO"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.CO"
        ]
      },
      "meta": {
        "issue_number": 7,
        "object_id": "paper:arxiv.2511.09744",
        "created_at": "2025-12-21T06:10:03+00:00",
        "updated_at": "2025-12-21T19:49:06+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2210.05846": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2210.05846",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T07:37:55.265Z",
            "data": {
              "session_id": "session_1766302675253_l788cpw",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T07:37:40.215Z",
              "end_time": "2025-12-21T07:37:55.253Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 0,
              "total_elapsed_seconds": 15
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T07:46:28.708Z",
            "data": {
              "session_id": "session_1766303188695_2r0em9o",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T07:46:11.238Z",
              "end_time": "2025-12-21T07:46:28.695Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 2,
              "total_elapsed_seconds": 17
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T08:11:01.730Z",
            "data": {
              "session_id": "session_1766304661522_yuwoaey",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T08:10:43.211Z",
              "end_time": "2025-12-21T08:11:01.522Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 3,
              "total_elapsed_seconds": 18
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T08:55:48.943Z",
            "data": {
              "session_id": "session_1766307348939_asapyqf",
              "source_id": "arxiv",
              "paper_id": "2210.05846",
              "start_time": "2025-12-21T08:55:43.720Z",
              "end_time": "2025-12-21T08:55:48.939Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 0,
              "total_elapsed_seconds": 5
            }
          }
        ],
        "title": "FasterRisk: Fast and Accurate Interpretable Risk Scores",
        "authors": [
          "Jiachang Liu",
          "Chudi Zhong",
          "Boxuan Li",
          "Margo Seltzer",
          "Cynthia Rudin"
        ],
        "abstract": "Over the last century, risk scores have been the most popular form of predictive model used in healthcare and criminal justice. Risk scores are sparse linear models with integer coefficients; often these models can be memorized or placed on an index card. Typically, risk scores have been created either without data or by rounding logistic regression coefficients, but these methods do not reliably produce high-quality risk scores. Recent work used mathematical programming, which is computationally slow. We introduce an approach for efficiently producing a collection of high-quality risk scores learned from data. Specifically, our approach produces a pool of almost-optimal sparse continuous solutions, each with a different support set, using a beam-search algorithm. Each of these continuous solutions is transformed into a separate risk score through a \"star ray\" search, where a range of multipliers are considered before rounding the coefficients sequentially to maintain low logistic loss. Our algorithm returns all of these high-quality risk scores for the user to consider. This method completes within minutes and can be valuable in a broad variety of applications.",
        "publishedDate": "2022-10-12"
      },
      "meta": {
        "issue_number": 9,
        "object_id": "interactions:arxiv.2210.05846",
        "created_at": "2025-12-21T06:42:27+00:00",
        "updated_at": "2025-12-21T08:56:37+00:00",
        "version": 1
      }
    },
    "paper:arxiv.1706.03762": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "1706.03762",
        "url": "https://arxiv.org/abs/1706.03762",
        "title": "Attention Is All You Need",
        "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
        "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
        "timestamp": "2025-12-21T07:46:33.198Z",
        "rating": "novote",
        "publishedDate": "2017/06/12",
        "tags": [
          "Computation and Language (cs.CL)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 18,
        "object_id": "paper:arxiv.1706.03762",
        "created_at": "2025-12-21T07:46:33+00:00",
        "updated_at": "2025-12-21T07:47:33+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.06709": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.06709",
        "url": "https://arxiv.org/pdf/2502.06709",
        "title": "Talagrand Meets Talagrand: Upper and Lower Bounds on Expected Soft Maxima of Gaussian Processes with Finite Index Sets",
        "authors": [
          "Yifeng Chu",
          "Maxim Raginsky"
        ],
        "abstract": "Analysis of extremal behavior of stochastic processes is a key ingredient in a wide variety of applications, including probability, statistical physics, theoretical computer science, and learning theory. In this paper, we consider centered Gaussian processes on finite index sets and investigate expected values of their smoothed, or ``soft,'' maxima. We obtain upper and lower bounds for these expected values using a combination of ideas from statistical physics (the Gibbs variational principle for the equilibrium free energy and replica-symmetric representations of Gibbs averages) and from probability theory (Sudakov minoration). These bounds are parametrized by an inverse temperature $\u03b2> 0$ and reduce to the usual Gaussian maximal inequalities in the zero-temperature limit $\u03b2\\to \\infty$. We provide an illustration of our methods in the context of the Random Energy Model, one of the simplest models of physical systems with random disorder.",
        "timestamp": "2025-12-21T07:00:23.584Z",
        "rating": "novote",
        "publishedDate": "2025-02-10",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 10,
        "object_id": "paper:arxiv.2502.06709",
        "created_at": "2025-12-21T07:00:23+00:00",
        "updated_at": "2025-12-21T07:35:40+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2502.06709": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.06709",
        "interactions": [],
        "title": "Talagrand Meets Talagrand: Upper and Lower Bounds on Expected Soft Maxima of Gaussian Processes with Finite Index Sets",
        "authors": [
          "Yifeng Chu",
          "Maxim Raginsky"
        ],
        "abstract": "Analysis of extremal behavior of stochastic processes is a key ingredient in a wide variety of applications, including probability, statistical physics, theoretical computer science, and learning theory. In this paper, we consider centered Gaussian processes on finite index sets and investigate expected values of their smoothed, or ``soft,'' maxima. We obtain upper and lower bounds for these expected values using a combination of ideas from statistical physics (the Gibbs variational principle for the equilibrium free energy and replica-symmetric representations of Gibbs averages) and from probability theory (Sudakov minoration). These bounds are parametrized by an inverse temperature $\u03b2> 0$ and reduce to the usual Gaussian maximal inequalities in the zero-temperature limit $\u03b2\\to \\infty$. We provide an illustration of our methods in the context of the Random Energy Model, one of the simplest models of physical systems with random disorder.",
        "publishedDate": "2025-02-10"
      },
      "meta": {
        "issue_number": 11,
        "object_id": "interactions:arxiv.2502.06709",
        "created_at": "2025-12-21T07:00:39+00:00",
        "updated_at": "2025-12-21T07:35:40+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2210.05846": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2210.05846",
        "url": "https://arxiv.org/pdf/2210.05846",
        "title": "FasterRisk: Fast and Accurate Interpretable Risk Scores",
        "authors": [
          "Jiachang Liu",
          "Chudi Zhong",
          "Boxuan Li",
          "Margo Seltzer",
          "Cynthia Rudin"
        ],
        "abstract": "Over the last century, risk scores have been the most popular form of predictive model used in healthcare and criminal justice. Risk scores are sparse linear models with integer coefficients; often these models can be memorized or placed on an index card. Typically, risk scores have been created either without data or by rounding logistic regression coefficients, but these methods do not reliably produce high-quality risk scores. Recent work used mathematical programming, which is computationally slow. We introduce an approach for efficiently producing a collection of high-quality risk scores learned from data. Specifically, our approach produces a pool of almost-optimal sparse continuous solutions, each with a different support set, using a beam-search algorithm. Each of these continuous solutions is transformed into a separate risk score through a \"star ray\" search, where a range of multipliers are considered before rounding the coefficients sequentially to maintain low logistic loss. Our algorithm returns all of these high-quality risk scores for the user to consider. This method completes within minutes and can be valuable in a broad variety of applications.",
        "timestamp": "2025-12-21T07:08:01.847Z",
        "rating": "novote",
        "publishedDate": "2022-10-12",
        "tags": [
          "cs.LG"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "cs.LG"
        ]
      },
      "meta": {
        "issue_number": 13,
        "object_id": "paper:arxiv.2210.05846",
        "created_at": "2025-12-21T07:08:02+00:00",
        "updated_at": "2025-12-21T19:49:04+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2511.09744": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.09744",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T08:10:43.405Z",
            "data": {
              "session_id": "session_1766304643180_o3cxxk6",
              "source_id": "arxiv",
              "paper_id": "2511.09744",
              "start_time": "2025-12-21T08:10:23.410Z",
              "end_time": "2025-12-21T08:10:43.180Z",
              "heartbeat_count": 3,
              "duration_seconds": 15,
              "idle_seconds": 5,
              "total_elapsed_seconds": 20
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:46:09.482Z",
            "data": {
              "session_id": "session_1766346369023_c8x2yrm",
              "source_id": "arxiv",
              "paper_id": "2511.09744",
              "start_time": "2025-12-21T19:45:01.685Z",
              "end_time": "2025-12-21T19:46:09.023Z",
              "heartbeat_count": 13,
              "duration_seconds": 65,
              "idle_seconds": 2,
              "total_elapsed_seconds": 67
            }
          }
        ],
        "title": "Computing parametric weighted Ehrhart polynomials of smooth polytopes",
        "authors": [
          "Daniel Hwang",
          "Juliet Whidden",
          "Josephine Yu"
        ],
        "abstract": "We show that when integral polytopes are deformed while keeping the same facet normal vectors, the coefficients of weighted Ehrhart and $h^*$-polynomials are piecewise polynomial functions in the ``right hand sides'' of the linear inequalities defining the polytopes. We give an algorithm and an implementation in SageMath for computing these polynomials for smooth polytopes, such as type $A$ alcoved polytopes, using a weighted Euler-Maclaurin type formula by Khovanski\u01d0 and Pukhlikov. We discuss some natural questions concerning signs of the coefficients of the weighted $h^*$-polynomials.",
        "publishedDate": "2025-11-12"
      },
      "meta": {
        "issue_number": 12,
        "object_id": "interactions:arxiv.2511.09744",
        "created_at": "2025-12-21T07:04:09+00:00",
        "updated_at": "2025-12-21T19:47:16+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2510.23866": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.23866",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:57:33.275Z",
            "data": {
              "session_id": "session_1766339852711_1xcok4t",
              "source_id": "arxiv",
              "paper_id": "2510.23866",
              "start_time": "2025-12-21T17:55:29.315Z",
              "end_time": "2025-12-21T17:57:32.711Z",
              "heartbeat_count": 24,
              "duration_seconds": 120,
              "idle_seconds": 3,
              "total_elapsed_seconds": 123
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:59:33.801Z",
            "data": {
              "session_id": "session_1766339973316_ln3tnxq",
              "source_id": "arxiv",
              "paper_id": "2510.23866",
              "start_time": "2025-12-21T17:57:54.949Z",
              "end_time": "2025-12-21T17:59:33.316Z",
              "heartbeat_count": 19,
              "duration_seconds": 95,
              "idle_seconds": 3,
              "total_elapsed_seconds": 98
            }
          }
        ]
      },
      "meta": {
        "issue_number": 25,
        "object_id": "interactions:arxiv.2510.23866",
        "created_at": "2025-12-21T09:40:23+00:00",
        "updated_at": "2025-12-21T18:00:33+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.23866": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.23866",
        "url": "https://arxiv.org/abs/2510.23866",
        "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling",
        "authors": "Paul Rosu, Muchang Bahng, Erick Jiang, Rico Zhu, Vahid Tarokh",
        "abstract": "This work presents a physics-conditioned latent diffusion model tailored for dynamical downscaling of atmospheric data, with a focus on reconstructing high-resolution 2-m temperature fields. Building upon a pre-existing diffusion architecture and employing a residual formulation against a reference UNet, we integrate a partial differential equation (PDE) loss term into the model's training objective. The PDE loss is computed in the full resolution (pixel) space by decoding the latent representation and is designed to enforce physical consistency through a finite-difference approximation of an effective advection-diffusion balance. Empirical observations indicate that conventional diffusion training already yields low PDE residuals, and we investigate how fine-tuning with this additional loss further regularizes the model and enhances the physical plausibility of the generated fields. The entirety of our codebase is available on Github, for future reference and development.",
        "timestamp": "2025-12-21T09:40:14.789Z",
        "rating": "novote",
        "publishedDate": "2025/10/27",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 24,
        "object_id": "paper:arxiv.2510.23866",
        "created_at": "2025-12-21T09:40:15+00:00",
        "updated_at": "2025-12-21T09:41:16+00:00",
        "version": 1
      }
    },
    "interactions:arxiv.2506.22947": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.22947",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T09:46:44.916Z",
            "data": {
              "session_id": "session_1766310404731_nc534t6",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T09:46:34.608Z",
              "end_time": "2025-12-21T09:46:44.731Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 10
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T09:51:33.939Z",
            "data": {
              "session_id": "session_1766310693460_w7tj227",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T09:48:11.956Z",
              "end_time": "2025-12-21T09:51:33.460Z",
              "heartbeat_count": 40,
              "duration_seconds": 200,
              "idle_seconds": 2,
              "total_elapsed_seconds": 202
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:14:33.462Z",
            "data": {
              "session_id": "session_1766337273153_3nta5vf",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:14:25.187Z",
              "end_time": "2025-12-21T17:14:33.153Z",
              "heartbeat_count": 1,
              "duration_seconds": 5,
              "idle_seconds": 3,
              "total_elapsed_seconds": 8
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:15:36.538Z",
            "data": {
              "session_id": "session_1766337335942_7af9cqr",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:15:04.790Z",
              "end_time": "2025-12-21T17:15:35.942Z",
              "heartbeat_count": 6,
              "duration_seconds": 30,
              "idle_seconds": 1,
              "total_elapsed_seconds": 31
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:17:48.894Z",
            "data": {
              "session_id": "session_1766337468591_74jfp3f",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:17:04.158Z",
              "end_time": "2025-12-21T17:17:48.591Z",
              "heartbeat_count": 8,
              "duration_seconds": 40,
              "idle_seconds": 4,
              "total_elapsed_seconds": 44
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T17:49:05.721Z",
            "data": {
              "session_id": "session_1766339345230_x4dvdys",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T17:47:33.543Z",
              "end_time": "2025-12-21T17:49:05.230Z",
              "heartbeat_count": 18,
              "duration_seconds": 90,
              "idle_seconds": 2,
              "total_elapsed_seconds": 92
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:10:19.144Z",
            "data": {
              "session_id": "session_1766340618633_3nj9dk4",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:08:05.905Z",
              "end_time": "2025-12-21T18:10:18.633Z",
              "heartbeat_count": 26,
              "duration_seconds": 130,
              "idle_seconds": 3,
              "total_elapsed_seconds": 133
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:24:35.107Z",
            "data": {
              "session_id": "session_1766341475100_46yx4s0",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:24:25.015Z",
              "end_time": "2025-12-21T18:24:35.100Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 0,
              "total_elapsed_seconds": 10
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:25:41.930Z",
            "data": {
              "session_id": "session_1766341541497_x9mr9ra",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:24:35.194Z",
              "end_time": "2025-12-21T18:25:41.497Z",
              "heartbeat_count": 13,
              "duration_seconds": 65,
              "idle_seconds": 1,
              "total_elapsed_seconds": 66
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:27:22.128Z",
            "data": {
              "session_id": "session_1766341641662_9t8tw11",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:25:43.458Z",
              "end_time": "2025-12-21T18:27:21.662Z",
              "heartbeat_count": 19,
              "duration_seconds": 95,
              "idle_seconds": 3,
              "total_elapsed_seconds": 98
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:44:22.155Z",
            "data": {
              "session_id": "session_1766342661879_37pigqp",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:43:29.937Z",
              "end_time": "2025-12-21T18:44:21.879Z",
              "heartbeat_count": 10,
              "duration_seconds": 50,
              "idle_seconds": 2,
              "total_elapsed_seconds": 52
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T18:45:31.838Z",
            "data": {
              "session_id": "session_1766342731358_zgwk4k1",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T18:44:30.425Z",
              "end_time": "2025-12-21T18:45:31.358Z",
              "heartbeat_count": 12,
              "duration_seconds": 60,
              "idle_seconds": 1,
              "total_elapsed_seconds": 61
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:06:56.274Z",
            "data": {
              "session_id": "session_1766344016271_kjudoau",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:06:41.518Z",
              "end_time": "2025-12-21T19:06:56.271Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 5,
              "total_elapsed_seconds": 15
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:22:31.303Z",
            "data": {
              "session_id": "session_1766344950779_oyy06g1",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:19:45.908Z",
              "end_time": "2025-12-21T19:22:30.779Z",
              "heartbeat_count": 32,
              "duration_seconds": 160,
              "idle_seconds": 5,
              "total_elapsed_seconds": 165
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:31:29.797Z",
            "data": {
              "session_id": "session_1766345489299_rxkmnev",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:29:49.195Z",
              "end_time": "2025-12-21T19:31:29.299Z",
              "heartbeat_count": 20,
              "duration_seconds": 100,
              "idle_seconds": 0,
              "total_elapsed_seconds": 100
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:33:08.782Z",
            "data": {
              "session_id": "session_1766345588239_orl4m82",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:31:34.417Z",
              "end_time": "2025-12-21T19:33:08.239Z",
              "heartbeat_count": 18,
              "duration_seconds": 90,
              "idle_seconds": 4,
              "total_elapsed_seconds": 94
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-12-21T19:39:56.852Z",
            "data": {
              "session_id": "session_1766345996674_ujk4228",
              "source_id": "arxiv",
              "paper_id": "2506.22947",
              "start_time": "2025-12-21T19:39:44.959Z",
              "end_time": "2025-12-21T19:39:56.674Z",
              "heartbeat_count": 2,
              "duration_seconds": 10,
              "idle_seconds": 2,
              "total_elapsed_seconds": 12
            }
          }
        ]
      },
      "meta": {
        "issue_number": 23,
        "object_id": "interactions:arxiv.2506.22947",
        "created_at": "2025-12-21T09:37:38+00:00",
        "updated_at": "2025-12-21T19:41:09+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2506.22947": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.22947",
        "url": "https://arxiv.org/pdf/2506.22947",
        "title": "Monotone Multispecies Flows",
        "authors": [
          "Lauren Conger",
          "Franca Hoffmann",
          "Eric Mazumdar",
          "Lillian J. Ratliff"
        ],
        "abstract": "We present a novel notion of $\u03bb$-monotonicity for an $n$-species system of partial differential equations governed by mass-preserving flow dynamics, extending monotonicity in Banach spaces to the Wasserstein-2 metric space. We show that monotonicity implies the existence of and convergence to a unique steady state, convergence of the velocity fields and second moments, and contraction in the Wasserstein-2 metric, at rates dependent on $\u03bb$. In the special setting of Wasserstein-2 gradient descent of different energies for each species, we prove convergence to the unique Nash equilibrium of the associated energies and delineate the relationship between monotonicity and displacement convexity. This extends known zero-sum results in infinite-dimensional game theory to the general-sum setting. We provide a number of examples of monotone coupled gradient flow systems, including cross-diffusion, gradient flows with potentials, nonlocal interaction, linear and nonlinear diffusion, and min-max systems, and draw connections to a class of mean-field games. Numerically, we demonstrate convergence of a four-player economic model for service providers and strategic users competing in a market, and a degenerately monotone game.",
        "timestamp": "2025-12-21T09:37:17.804Z",
        "rating": "novote",
        "publishedDate": "2025-06-28",
        "tags": [
          "math.AP"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url",
        "arxiv_tags": [
          "math.AP"
        ]
      },
      "meta": {
        "issue_number": 22,
        "object_id": "paper:arxiv.2506.22947",
        "created_at": "2025-12-21T09:37:18+00:00",
        "updated_at": "2025-12-21T19:49:02+00:00",
        "version": 1
      }
    },
    "interactions:url.2A46BCB2": {
      "data": {
        "sourceId": "url",
        "paperId": "2A46BCB2",
        "interactions": []
      },
      "meta": {
        "issue_number": 21,
        "object_id": "interactions:url.2A46BCB2",
        "created_at": "2025-12-21T09:27:04+00:00",
        "updated_at": "2025-12-21T09:27:05+00:00",
        "version": 1
      }
    },
    "paper:url.2A46BCB2": {
      "data": {
        "sourceId": "url",
        "paperId": "2A46BCB2",
        "url": "https://arxiv.org/pdf/physics/0605057",
        "title": "2A46BCB2",
        "authors": "",
        "abstract": "",
        "timestamp": "2025-12-21T09:26:45.932Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 20,
        "object_id": "paper:url.2A46BCB2",
        "created_at": "2025-12-21T09:26:46+00:00",
        "updated_at": "2025-12-21T09:27:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2112.10752": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2112.10752",
        "url": "https://arxiv.org/abs/2112.10752",
        "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
        "authors": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer",
        "abstract": "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at this https URL .",
        "timestamp": "2025-12-21T20:19:28.145Z",
        "rating": "novote",
        "publishedDate": "2021/12/20",
        "tags": [
          "Computer Vision and Pattern Recognition (cs.CV)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 26,
        "object_id": "paper:arxiv.2112.10752",
        "created_at": "2025-12-21T20:19:28+00:00",
        "updated_at": "2025-12-21T20:20:27+00:00",
        "version": 1
      }
    }
  }
}